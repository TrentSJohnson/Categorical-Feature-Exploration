{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "#Load the data and make new df\n",
    "target = pd.read_csv(\"input/train.csv\").target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_emb50.npy',\n",
       " 'train_emb100.npy',\n",
       " 'tanh_train_emb50.npy',\n",
       " 'train_emb50.npy',\n",
       " 'train_emb10.npy',\n",
       " 'tanh_test_emb10.npy',\n",
       " 'sig_train_emb5.npy',\n",
       " 'tanh_train_emb20.npy',\n",
       " 'test_emb10.npy',\n",
       " 'test_emb100.npy',\n",
       " 'test_emb20.npy',\n",
       " 'tanh_test_emb20.npy',\n",
       " 'sig_train_emb10.npy',\n",
       " 'train_emb5.npy',\n",
       " 'sig_test_emb20.npy',\n",
       " 'tanh_test_emb100.npy',\n",
       " 'tanh_test_emb50.npy',\n",
       " 'sig_test_emb10.npy',\n",
       " 'tanh_train_emb10.npy',\n",
       " 'sig_train_emb20.npy',\n",
       " 'tanh_train_emb5.npy',\n",
       " 'tanh_test_emb5.npy',\n",
       " 'sig_test_emb5.npy',\n",
       " 'test_emb5.npy',\n",
       " 'train_emb20.npy',\n",
       " 'tanh_train_emb100.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('embs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuned_xgb(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'n_estimators' : [50, 100, 200, 300, 500, 800, 1000]\n",
    "        }\n",
    "    \n",
    "    xgb = XGBClassifier(objective='binary:logistic', n_jobs=10)\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1003)\n",
    "    random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', cv=skf.split(x,y), verbose=2, random_state=1003 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return XGBClassifier(**random_search.best_params_), random_search.best_score_\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "def get_tuned_lgbm(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "    \n",
    "    lg = LGBMClassifier(objective='binary')\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1002)\n",
    "    random_search = RandomizedSearchCV(lg, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=10, cv=skf.split(x,y), verbose=0, random_state=1002 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return LGBMClassifier(**random_search.best_params_), random_search.best_score_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_tuned_cat(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "          'iterations':[2,50,100,500,1000],\n",
    "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "          'l2_leaf_reg':[3,1,5,10,100],\n",
    "          'border_count':[32,5,10,20,50,100,200],\n",
    "          'thread_count':[4],\n",
    "              'loss_function': ['Logloss', 'CrossEntropy']}\n",
    "    \n",
    "    cat = CatBoostClassifier(eval_metric = 'AUC')\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "    random_search = RandomizedSearchCV(cat, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=10, cv=skf.split(x,y), verbose=0, random_state=1001 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return CatBoostClassifier(**random_search.best_params_), random_search.best_score_\n",
    "\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n",
    "\n",
    "\n",
    "def get_nn(n_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape= (n_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_tuned_lr(x,y): \n",
    "    penalty = ['l1', 'l2']\n",
    "    C = np.logspace(0, 4, 10)\n",
    "    solver=['liblinear']\n",
    "    params = dict(C=C, penalty=penalty, solver=solver)\n",
    "    \n",
    "    lr = LogisticRegression( )\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "    random_search = RandomizedSearchCV(lr, param_distributions=params, n_jobs=10, n_iter=param_comb, scoring='roc_auc', cv=skf.split(x,y), verbose=0, random_state=1001 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return LogisticRegression(**random_search.best_params_), random_search.best_score_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.840738721623152\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 2.2min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 2.4min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 2.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 2.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 2.3min\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   9.0s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   9.0s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   9.3s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   9.2s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   9.3s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 2.3min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 2.3min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 2.2min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 2.3min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 2.2min\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  21.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  21.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  22.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  21.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  21.9s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  56.0s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  56.6s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  56.8s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  57.3s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  56.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 3.1min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 3.1min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 3.1min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 3.1min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 3.1min\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  55.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  54.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  53.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  54.1s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  53.3s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  22.2s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  22.2s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  22.1s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  22.0s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  22.0s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  46.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  45.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  44.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  45.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  45.2s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 2.0min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 2.1min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 2.1min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 2.0min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 2.0min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total= 1.1min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total= 1.5min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total= 1.6min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total= 1.5min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total= 1.5min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total= 1.5min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=  11.9s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=  11.5s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=  11.5s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=  11.6s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=  11.6s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  43.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  43.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  43.3s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  43.0s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  43.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 90.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465255523325426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 167ms\tremaining: 1m 23s\n",
      "1:\ttotal: 279ms\tremaining: 1m 9s\n",
      "2:\ttotal: 405ms\tremaining: 1m 7s\n",
      "3:\ttotal: 537ms\tremaining: 1m 6s\n",
      "4:\ttotal: 671ms\tremaining: 1m 6s\n",
      "5:\ttotal: 803ms\tremaining: 1m 6s\n",
      "6:\ttotal: 927ms\tremaining: 1m 5s\n",
      "7:\ttotal: 1.04s\tremaining: 1m 3s\n",
      "8:\ttotal: 1.15s\tremaining: 1m 2s\n",
      "9:\ttotal: 1.27s\tremaining: 1m 2s\n",
      "10:\ttotal: 1.39s\tremaining: 1m 1s\n",
      "11:\ttotal: 1.52s\tremaining: 1m 1s\n",
      "12:\ttotal: 1.64s\tremaining: 1m 1s\n",
      "13:\ttotal: 1.76s\tremaining: 1m 1s\n",
      "14:\ttotal: 1.9s\tremaining: 1m 1s\n",
      "15:\ttotal: 2.02s\tremaining: 1m 1s\n",
      "16:\ttotal: 2.14s\tremaining: 1m\n",
      "17:\ttotal: 2.25s\tremaining: 1m\n",
      "18:\ttotal: 2.38s\tremaining: 1m\n",
      "19:\ttotal: 2.49s\tremaining: 59.8s\n",
      "20:\ttotal: 2.62s\tremaining: 59.8s\n",
      "21:\ttotal: 2.74s\tremaining: 59.6s\n",
      "22:\ttotal: 2.87s\tremaining: 59.6s\n",
      "23:\ttotal: 3s\tremaining: 59.5s\n",
      "24:\ttotal: 3.13s\tremaining: 59.5s\n",
      "25:\ttotal: 3.23s\tremaining: 59s\n",
      "26:\ttotal: 3.36s\tremaining: 58.8s\n",
      "27:\ttotal: 3.48s\tremaining: 58.8s\n",
      "28:\ttotal: 3.62s\tremaining: 58.7s\n",
      "29:\ttotal: 3.72s\tremaining: 58.4s\n",
      "30:\ttotal: 3.85s\tremaining: 58.2s\n",
      "31:\ttotal: 3.96s\tremaining: 58s\n",
      "32:\ttotal: 4.09s\tremaining: 57.9s\n",
      "33:\ttotal: 4.21s\tremaining: 57.7s\n",
      "34:\ttotal: 4.32s\tremaining: 57.4s\n",
      "35:\ttotal: 4.44s\tremaining: 57.2s\n",
      "36:\ttotal: 4.56s\tremaining: 57.1s\n",
      "37:\ttotal: 4.67s\tremaining: 56.7s\n",
      "38:\ttotal: 4.78s\tremaining: 56.5s\n",
      "39:\ttotal: 4.9s\tremaining: 56.4s\n",
      "40:\ttotal: 5.02s\tremaining: 56.2s\n",
      "41:\ttotal: 5.13s\tremaining: 55.9s\n",
      "42:\ttotal: 5.24s\tremaining: 55.7s\n",
      "43:\ttotal: 5.35s\tremaining: 55.4s\n",
      "44:\ttotal: 5.46s\tremaining: 55.3s\n",
      "45:\ttotal: 5.56s\tremaining: 54.9s\n",
      "46:\ttotal: 5.66s\tremaining: 54.5s\n",
      "47:\ttotal: 5.76s\tremaining: 54.2s\n",
      "48:\ttotal: 5.87s\tremaining: 54s\n",
      "49:\ttotal: 5.97s\tremaining: 53.8s\n",
      "50:\ttotal: 6.08s\tremaining: 53.5s\n",
      "51:\ttotal: 6.18s\tremaining: 53.3s\n",
      "52:\ttotal: 6.29s\tremaining: 53s\n",
      "53:\ttotal: 6.41s\tremaining: 52.9s\n",
      "54:\ttotal: 6.51s\tremaining: 52.7s\n",
      "55:\ttotal: 6.62s\tremaining: 52.5s\n",
      "56:\ttotal: 6.73s\tremaining: 52.3s\n",
      "57:\ttotal: 6.83s\tremaining: 52.1s\n",
      "58:\ttotal: 6.93s\tremaining: 51.8s\n",
      "59:\ttotal: 7.03s\tremaining: 51.6s\n",
      "60:\ttotal: 7.14s\tremaining: 51.4s\n",
      "61:\ttotal: 7.24s\tremaining: 51.1s\n",
      "62:\ttotal: 7.35s\tremaining: 51s\n",
      "63:\ttotal: 7.45s\tremaining: 50.8s\n",
      "64:\ttotal: 7.56s\tremaining: 50.6s\n",
      "65:\ttotal: 7.66s\tremaining: 50.4s\n",
      "66:\ttotal: 7.76s\tremaining: 50.1s\n",
      "67:\ttotal: 7.86s\tremaining: 49.9s\n",
      "68:\ttotal: 7.98s\tremaining: 49.9s\n",
      "69:\ttotal: 8.09s\tremaining: 49.7s\n",
      "70:\ttotal: 8.19s\tremaining: 49.5s\n",
      "71:\ttotal: 8.3s\tremaining: 49.3s\n",
      "72:\ttotal: 8.4s\tremaining: 49.1s\n",
      "73:\ttotal: 8.51s\tremaining: 49s\n",
      "74:\ttotal: 8.62s\tremaining: 48.8s\n",
      "75:\ttotal: 8.72s\tremaining: 48.7s\n",
      "76:\ttotal: 8.83s\tremaining: 48.5s\n",
      "77:\ttotal: 8.94s\tremaining: 48.3s\n",
      "78:\ttotal: 9.05s\tremaining: 48.2s\n",
      "79:\ttotal: 9.16s\tremaining: 48.1s\n",
      "80:\ttotal: 9.26s\tremaining: 47.9s\n",
      "81:\ttotal: 9.36s\tremaining: 47.7s\n",
      "82:\ttotal: 9.46s\tremaining: 47.5s\n",
      "83:\ttotal: 9.56s\tremaining: 47.3s\n",
      "84:\ttotal: 9.67s\tremaining: 47.2s\n",
      "85:\ttotal: 9.78s\tremaining: 47.1s\n",
      "86:\ttotal: 9.87s\tremaining: 46.9s\n",
      "87:\ttotal: 9.97s\tremaining: 46.7s\n",
      "88:\ttotal: 10.1s\tremaining: 46.5s\n",
      "89:\ttotal: 10.2s\tremaining: 46.4s\n",
      "90:\ttotal: 10.3s\tremaining: 46.3s\n",
      "91:\ttotal: 10.4s\tremaining: 46.1s\n",
      "92:\ttotal: 10.5s\tremaining: 46s\n",
      "93:\ttotal: 10.6s\tremaining: 45.9s\n",
      "94:\ttotal: 10.7s\tremaining: 45.7s\n",
      "95:\ttotal: 10.8s\tremaining: 45.6s\n",
      "96:\ttotal: 10.9s\tremaining: 45.4s\n",
      "97:\ttotal: 11s\tremaining: 45.2s\n",
      "98:\ttotal: 11.1s\tremaining: 45.1s\n",
      "99:\ttotal: 11.2s\tremaining: 45s\n",
      "100:\ttotal: 11.3s\tremaining: 44.8s\n",
      "101:\ttotal: 11.4s\tremaining: 44.7s\n",
      "102:\ttotal: 11.5s\tremaining: 44.5s\n",
      "103:\ttotal: 11.6s\tremaining: 44.3s\n",
      "104:\ttotal: 11.7s\tremaining: 44.2s\n",
      "105:\ttotal: 11.8s\tremaining: 44s\n",
      "106:\ttotal: 11.9s\tremaining: 43.9s\n",
      "107:\ttotal: 12s\tremaining: 43.7s\n",
      "108:\ttotal: 12.1s\tremaining: 43.6s\n",
      "109:\ttotal: 12.3s\tremaining: 43.4s\n",
      "110:\ttotal: 12.4s\tremaining: 43.3s\n",
      "111:\ttotal: 12.5s\tremaining: 43.2s\n",
      "112:\ttotal: 12.6s\tremaining: 43s\n",
      "113:\ttotal: 12.7s\tremaining: 42.9s\n",
      "114:\ttotal: 12.8s\tremaining: 42.7s\n",
      "115:\ttotal: 12.9s\tremaining: 42.6s\n",
      "116:\ttotal: 13s\tremaining: 42.5s\n",
      "117:\ttotal: 13.1s\tremaining: 42.4s\n",
      "118:\ttotal: 13.2s\tremaining: 42.3s\n",
      "119:\ttotal: 13.3s\tremaining: 42.2s\n",
      "120:\ttotal: 13.4s\tremaining: 42s\n",
      "121:\ttotal: 13.5s\tremaining: 41.9s\n",
      "122:\ttotal: 13.6s\tremaining: 41.8s\n",
      "123:\ttotal: 13.7s\tremaining: 41.6s\n",
      "124:\ttotal: 13.8s\tremaining: 41.4s\n",
      "125:\ttotal: 13.9s\tremaining: 41.3s\n",
      "126:\ttotal: 14s\tremaining: 41.2s\n",
      "127:\ttotal: 14.1s\tremaining: 41s\n",
      "128:\ttotal: 14.2s\tremaining: 40.9s\n",
      "129:\ttotal: 14.3s\tremaining: 40.7s\n",
      "130:\ttotal: 14.4s\tremaining: 40.6s\n",
      "131:\ttotal: 14.5s\tremaining: 40.4s\n",
      "132:\ttotal: 14.6s\tremaining: 40.4s\n",
      "133:\ttotal: 14.7s\tremaining: 40.2s\n",
      "134:\ttotal: 14.8s\tremaining: 40.1s\n",
      "135:\ttotal: 14.9s\tremaining: 39.9s\n",
      "136:\ttotal: 15s\tremaining: 39.8s\n",
      "137:\ttotal: 15.1s\tremaining: 39.7s\n",
      "138:\ttotal: 15.2s\tremaining: 39.5s\n",
      "139:\ttotal: 15.3s\tremaining: 39.4s\n",
      "140:\ttotal: 15.4s\tremaining: 39.3s\n",
      "141:\ttotal: 15.5s\tremaining: 39.2s\n",
      "142:\ttotal: 15.6s\tremaining: 39s\n",
      "143:\ttotal: 15.7s\tremaining: 38.9s\n",
      "144:\ttotal: 15.8s\tremaining: 38.8s\n",
      "145:\ttotal: 15.9s\tremaining: 38.7s\n",
      "146:\ttotal: 16s\tremaining: 38.5s\n",
      "147:\ttotal: 16.1s\tremaining: 38.4s\n",
      "148:\ttotal: 16.3s\tremaining: 38.3s\n",
      "149:\ttotal: 16.4s\tremaining: 38.2s\n",
      "150:\ttotal: 16.5s\tremaining: 38.1s\n",
      "151:\ttotal: 16.6s\tremaining: 37.9s\n",
      "152:\ttotal: 16.7s\tremaining: 37.8s\n",
      "153:\ttotal: 16.8s\tremaining: 37.7s\n",
      "154:\ttotal: 16.9s\tremaining: 37.5s\n",
      "155:\ttotal: 17s\tremaining: 37.4s\n",
      "156:\ttotal: 17.1s\tremaining: 37.3s\n",
      "157:\ttotal: 17.2s\tremaining: 37.1s\n",
      "158:\ttotal: 17.2s\tremaining: 37s\n",
      "159:\ttotal: 17.3s\tremaining: 36.8s\n",
      "160:\ttotal: 17.5s\tremaining: 36.7s\n",
      "161:\ttotal: 17.6s\tremaining: 36.6s\n",
      "162:\ttotal: 17.7s\tremaining: 36.5s\n",
      "163:\ttotal: 17.8s\tremaining: 36.4s\n",
      "164:\ttotal: 17.9s\tremaining: 36.3s\n",
      "165:\ttotal: 18s\tremaining: 36.1s\n",
      "166:\ttotal: 18.1s\tremaining: 36s\n",
      "167:\ttotal: 18.2s\tremaining: 35.9s\n",
      "168:\ttotal: 18.3s\tremaining: 35.8s\n",
      "169:\ttotal: 18.4s\tremaining: 35.7s\n",
      "170:\ttotal: 18.5s\tremaining: 35.6s\n",
      "171:\ttotal: 18.6s\tremaining: 35.5s\n",
      "172:\ttotal: 18.7s\tremaining: 35.3s\n",
      "173:\ttotal: 18.8s\tremaining: 35.3s\n",
      "174:\ttotal: 18.9s\tremaining: 35.1s\n",
      "175:\ttotal: 19s\tremaining: 35s\n",
      "176:\ttotal: 19.1s\tremaining: 34.9s\n",
      "177:\ttotal: 19.2s\tremaining: 34.8s\n",
      "178:\ttotal: 19.3s\tremaining: 34.7s\n",
      "179:\ttotal: 19.4s\tremaining: 34.5s\n",
      "180:\ttotal: 19.5s\tremaining: 34.4s\n",
      "181:\ttotal: 19.6s\tremaining: 34.3s\n",
      "182:\ttotal: 19.7s\tremaining: 34.2s\n",
      "183:\ttotal: 19.8s\tremaining: 34.1s\n",
      "184:\ttotal: 19.9s\tremaining: 34s\n",
      "185:\ttotal: 20.1s\tremaining: 33.9s\n",
      "186:\ttotal: 20.2s\tremaining: 33.7s\n",
      "187:\ttotal: 20.3s\tremaining: 33.7s\n",
      "188:\ttotal: 20.4s\tremaining: 33.5s\n",
      "189:\ttotal: 20.5s\tremaining: 33.4s\n",
      "190:\ttotal: 20.6s\tremaining: 33.3s\n",
      "191:\ttotal: 20.7s\tremaining: 33.2s\n",
      "192:\ttotal: 20.8s\tremaining: 33.1s\n",
      "193:\ttotal: 20.9s\tremaining: 33s\n",
      "194:\ttotal: 21s\tremaining: 32.8s\n",
      "195:\ttotal: 21.1s\tremaining: 32.7s\n",
      "196:\ttotal: 21.2s\tremaining: 32.6s\n",
      "197:\ttotal: 21.3s\tremaining: 32.5s\n",
      "198:\ttotal: 21.4s\tremaining: 32.4s\n",
      "199:\ttotal: 21.5s\tremaining: 32.3s\n",
      "200:\ttotal: 21.6s\tremaining: 32.2s\n",
      "201:\ttotal: 21.7s\tremaining: 32s\n",
      "202:\ttotal: 21.8s\tremaining: 31.9s\n",
      "203:\ttotal: 21.9s\tremaining: 31.8s\n",
      "204:\ttotal: 22s\tremaining: 31.7s\n",
      "205:\ttotal: 22.1s\tremaining: 31.6s\n",
      "206:\ttotal: 22.2s\tremaining: 31.4s\n",
      "207:\ttotal: 22.3s\tremaining: 31.3s\n",
      "208:\ttotal: 22.4s\tremaining: 31.2s\n",
      "209:\ttotal: 22.5s\tremaining: 31.1s\n",
      "210:\ttotal: 22.6s\tremaining: 31s\n",
      "211:\ttotal: 22.7s\tremaining: 30.8s\n",
      "212:\ttotal: 22.8s\tremaining: 30.7s\n",
      "213:\ttotal: 22.9s\tremaining: 30.6s\n",
      "214:\ttotal: 23s\tremaining: 30.5s\n",
      "215:\ttotal: 23.1s\tremaining: 30.4s\n",
      "216:\ttotal: 23.2s\tremaining: 30.3s\n",
      "217:\ttotal: 23.3s\tremaining: 30.2s\n",
      "218:\ttotal: 23.4s\tremaining: 30s\n",
      "219:\ttotal: 23.5s\tremaining: 29.9s\n",
      "220:\ttotal: 23.6s\tremaining: 29.8s\n",
      "221:\ttotal: 23.7s\tremaining: 29.7s\n",
      "222:\ttotal: 23.8s\tremaining: 29.6s\n",
      "223:\ttotal: 23.9s\tremaining: 29.5s\n",
      "224:\ttotal: 24s\tremaining: 29.4s\n",
      "225:\ttotal: 24.1s\tremaining: 29.3s\n",
      "226:\ttotal: 24.2s\tremaining: 29.2s\n",
      "227:\ttotal: 24.4s\tremaining: 29.1s\n",
      "228:\ttotal: 24.5s\tremaining: 29s\n",
      "229:\ttotal: 24.6s\tremaining: 28.8s\n",
      "230:\ttotal: 24.7s\tremaining: 28.7s\n",
      "231:\ttotal: 24.8s\tremaining: 28.6s\n",
      "232:\ttotal: 24.9s\tremaining: 28.5s\n",
      "233:\ttotal: 25s\tremaining: 28.4s\n",
      "234:\ttotal: 25.1s\tremaining: 28.3s\n",
      "235:\ttotal: 25.2s\tremaining: 28.2s\n",
      "236:\ttotal: 25.3s\tremaining: 28.1s\n",
      "237:\ttotal: 25.4s\tremaining: 28s\n",
      "238:\ttotal: 25.5s\tremaining: 27.8s\n",
      "239:\ttotal: 25.6s\tremaining: 27.7s\n",
      "240:\ttotal: 25.7s\tremaining: 27.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241:\ttotal: 25.8s\tremaining: 27.5s\n",
      "242:\ttotal: 25.9s\tremaining: 27.4s\n",
      "243:\ttotal: 26s\tremaining: 27.3s\n",
      "244:\ttotal: 26.1s\tremaining: 27.2s\n",
      "245:\ttotal: 26.2s\tremaining: 27s\n",
      "246:\ttotal: 26.3s\tremaining: 26.9s\n",
      "247:\ttotal: 26.4s\tremaining: 26.8s\n",
      "248:\ttotal: 26.5s\tremaining: 26.7s\n",
      "249:\ttotal: 26.6s\tremaining: 26.6s\n",
      "250:\ttotal: 26.7s\tremaining: 26.5s\n",
      "251:\ttotal: 26.8s\tremaining: 26.4s\n",
      "252:\ttotal: 26.9s\tremaining: 26.3s\n",
      "253:\ttotal: 27s\tremaining: 26.2s\n",
      "254:\ttotal: 27.1s\tremaining: 26s\n",
      "255:\ttotal: 27.2s\tremaining: 25.9s\n",
      "256:\ttotal: 27.3s\tremaining: 25.8s\n",
      "257:\ttotal: 27.4s\tremaining: 25.7s\n",
      "258:\ttotal: 27.5s\tremaining: 25.6s\n",
      "259:\ttotal: 27.6s\tremaining: 25.5s\n",
      "260:\ttotal: 27.7s\tremaining: 25.4s\n",
      "261:\ttotal: 27.8s\tremaining: 25.3s\n",
      "262:\ttotal: 27.9s\tremaining: 25.2s\n",
      "263:\ttotal: 28s\tremaining: 25s\n",
      "264:\ttotal: 28.1s\tremaining: 24.9s\n",
      "265:\ttotal: 28.2s\tremaining: 24.8s\n",
      "266:\ttotal: 28.3s\tremaining: 24.7s\n",
      "267:\ttotal: 28.4s\tremaining: 24.6s\n",
      "268:\ttotal: 28.5s\tremaining: 24.5s\n",
      "269:\ttotal: 28.6s\tremaining: 24.4s\n",
      "270:\ttotal: 28.7s\tremaining: 24.3s\n",
      "271:\ttotal: 28.8s\tremaining: 24.2s\n",
      "272:\ttotal: 28.9s\tremaining: 24.1s\n",
      "273:\ttotal: 29s\tremaining: 24s\n",
      "274:\ttotal: 29.1s\tremaining: 23.9s\n",
      "275:\ttotal: 29.2s\tremaining: 23.7s\n",
      "276:\ttotal: 29.4s\tremaining: 23.6s\n",
      "277:\ttotal: 29.5s\tremaining: 23.5s\n",
      "278:\ttotal: 29.6s\tremaining: 23.4s\n",
      "279:\ttotal: 29.7s\tremaining: 23.3s\n",
      "280:\ttotal: 29.8s\tremaining: 23.2s\n",
      "281:\ttotal: 29.9s\tremaining: 23.1s\n",
      "282:\ttotal: 30s\tremaining: 23s\n",
      "283:\ttotal: 30.1s\tremaining: 22.9s\n",
      "284:\ttotal: 30.2s\tremaining: 22.8s\n",
      "285:\ttotal: 30.3s\tremaining: 22.6s\n",
      "286:\ttotal: 30.4s\tremaining: 22.5s\n",
      "287:\ttotal: 30.4s\tremaining: 22.4s\n",
      "288:\ttotal: 30.5s\tremaining: 22.3s\n",
      "289:\ttotal: 30.7s\tremaining: 22.2s\n",
      "290:\ttotal: 30.8s\tremaining: 22.1s\n",
      "291:\ttotal: 30.9s\tremaining: 22s\n",
      "292:\ttotal: 31s\tremaining: 21.9s\n",
      "293:\ttotal: 31.1s\tremaining: 21.8s\n",
      "294:\ttotal: 31.2s\tremaining: 21.7s\n",
      "295:\ttotal: 31.3s\tremaining: 21.6s\n",
      "296:\ttotal: 31.4s\tremaining: 21.5s\n",
      "297:\ttotal: 31.5s\tremaining: 21.4s\n",
      "298:\ttotal: 31.6s\tremaining: 21.2s\n",
      "299:\ttotal: 31.7s\tremaining: 21.1s\n",
      "300:\ttotal: 31.8s\tremaining: 21s\n",
      "301:\ttotal: 31.9s\tremaining: 20.9s\n",
      "302:\ttotal: 32s\tremaining: 20.8s\n",
      "303:\ttotal: 32.1s\tremaining: 20.7s\n",
      "304:\ttotal: 32.2s\tremaining: 20.6s\n",
      "305:\ttotal: 32.3s\tremaining: 20.5s\n",
      "306:\ttotal: 32.4s\tremaining: 20.4s\n",
      "307:\ttotal: 32.5s\tremaining: 20.3s\n",
      "308:\ttotal: 32.6s\tremaining: 20.2s\n",
      "309:\ttotal: 32.7s\tremaining: 20s\n",
      "310:\ttotal: 32.8s\tremaining: 19.9s\n",
      "311:\ttotal: 32.9s\tremaining: 19.8s\n",
      "312:\ttotal: 33s\tremaining: 19.7s\n",
      "313:\ttotal: 33.1s\tremaining: 19.6s\n",
      "314:\ttotal: 33.2s\tremaining: 19.5s\n",
      "315:\ttotal: 33.3s\tremaining: 19.4s\n",
      "316:\ttotal: 33.4s\tremaining: 19.3s\n",
      "317:\ttotal: 33.5s\tremaining: 19.2s\n",
      "318:\ttotal: 33.6s\tremaining: 19.1s\n",
      "319:\ttotal: 33.7s\tremaining: 19s\n",
      "320:\ttotal: 33.8s\tremaining: 18.9s\n",
      "321:\ttotal: 33.9s\tremaining: 18.8s\n",
      "322:\ttotal: 34s\tremaining: 18.6s\n",
      "323:\ttotal: 34.1s\tremaining: 18.5s\n",
      "324:\ttotal: 34.2s\tremaining: 18.4s\n",
      "325:\ttotal: 34.3s\tremaining: 18.3s\n",
      "326:\ttotal: 34.4s\tremaining: 18.2s\n",
      "327:\ttotal: 34.5s\tremaining: 18.1s\n",
      "328:\ttotal: 34.6s\tremaining: 18s\n",
      "329:\ttotal: 34.7s\tremaining: 17.9s\n",
      "330:\ttotal: 34.8s\tremaining: 17.8s\n",
      "331:\ttotal: 35s\tremaining: 17.7s\n",
      "332:\ttotal: 35.1s\tremaining: 17.6s\n",
      "333:\ttotal: 35.2s\tremaining: 17.5s\n",
      "334:\ttotal: 35.3s\tremaining: 17.4s\n",
      "335:\ttotal: 35.4s\tremaining: 17.3s\n",
      "336:\ttotal: 35.5s\tremaining: 17.2s\n",
      "337:\ttotal: 35.6s\tremaining: 17.1s\n",
      "338:\ttotal: 35.7s\tremaining: 16.9s\n",
      "339:\ttotal: 35.8s\tremaining: 16.8s\n",
      "340:\ttotal: 35.9s\tremaining: 16.7s\n",
      "341:\ttotal: 36s\tremaining: 16.6s\n",
      "342:\ttotal: 36.1s\tremaining: 16.5s\n",
      "343:\ttotal: 36.2s\tremaining: 16.4s\n",
      "344:\ttotal: 36.3s\tremaining: 16.3s\n",
      "345:\ttotal: 36.4s\tremaining: 16.2s\n",
      "346:\ttotal: 36.5s\tremaining: 16.1s\n",
      "347:\ttotal: 36.6s\tremaining: 16s\n",
      "348:\ttotal: 36.7s\tremaining: 15.9s\n",
      "349:\ttotal: 36.8s\tremaining: 15.8s\n",
      "350:\ttotal: 36.9s\tremaining: 15.7s\n",
      "351:\ttotal: 37s\tremaining: 15.6s\n",
      "352:\ttotal: 37.1s\tremaining: 15.5s\n",
      "353:\ttotal: 37.2s\tremaining: 15.3s\n",
      "354:\ttotal: 37.3s\tremaining: 15.2s\n",
      "355:\ttotal: 37.4s\tremaining: 15.1s\n",
      "356:\ttotal: 37.5s\tremaining: 15s\n",
      "357:\ttotal: 37.6s\tremaining: 14.9s\n",
      "358:\ttotal: 37.7s\tremaining: 14.8s\n",
      "359:\ttotal: 37.9s\tremaining: 14.7s\n",
      "360:\ttotal: 38s\tremaining: 14.6s\n",
      "361:\ttotal: 38.1s\tremaining: 14.5s\n",
      "362:\ttotal: 38.2s\tremaining: 14.4s\n",
      "363:\ttotal: 38.3s\tremaining: 14.3s\n",
      "364:\ttotal: 38.4s\tremaining: 14.2s\n",
      "365:\ttotal: 38.5s\tremaining: 14.1s\n",
      "366:\ttotal: 38.6s\tremaining: 14s\n",
      "367:\ttotal: 38.7s\tremaining: 13.9s\n",
      "368:\ttotal: 38.8s\tremaining: 13.8s\n",
      "369:\ttotal: 38.9s\tremaining: 13.7s\n",
      "370:\ttotal: 39s\tremaining: 13.6s\n",
      "371:\ttotal: 39.1s\tremaining: 13.4s\n",
      "372:\ttotal: 39.2s\tremaining: 13.3s\n",
      "373:\ttotal: 39.3s\tremaining: 13.2s\n",
      "374:\ttotal: 39.4s\tremaining: 13.1s\n",
      "375:\ttotal: 39.5s\tremaining: 13s\n",
      "376:\ttotal: 39.6s\tremaining: 12.9s\n",
      "377:\ttotal: 39.7s\tremaining: 12.8s\n",
      "378:\ttotal: 39.8s\tremaining: 12.7s\n",
      "379:\ttotal: 39.9s\tremaining: 12.6s\n",
      "380:\ttotal: 40s\tremaining: 12.5s\n",
      "381:\ttotal: 40.1s\tremaining: 12.4s\n",
      "382:\ttotal: 40.2s\tremaining: 12.3s\n",
      "383:\ttotal: 40.3s\tremaining: 12.2s\n",
      "384:\ttotal: 40.4s\tremaining: 12.1s\n",
      "385:\ttotal: 40.5s\tremaining: 12s\n",
      "386:\ttotal: 40.6s\tremaining: 11.9s\n",
      "387:\ttotal: 40.8s\tremaining: 11.8s\n",
      "388:\ttotal: 40.9s\tremaining: 11.7s\n",
      "389:\ttotal: 41s\tremaining: 11.6s\n",
      "390:\ttotal: 41.1s\tremaining: 11.4s\n",
      "391:\ttotal: 41.2s\tremaining: 11.3s\n",
      "392:\ttotal: 41.3s\tremaining: 11.2s\n",
      "393:\ttotal: 41.4s\tremaining: 11.1s\n",
      "394:\ttotal: 41.5s\tremaining: 11s\n",
      "395:\ttotal: 41.6s\tremaining: 10.9s\n",
      "396:\ttotal: 41.7s\tremaining: 10.8s\n",
      "397:\ttotal: 41.8s\tremaining: 10.7s\n",
      "398:\ttotal: 41.9s\tremaining: 10.6s\n",
      "399:\ttotal: 42s\tremaining: 10.5s\n",
      "400:\ttotal: 42.1s\tremaining: 10.4s\n",
      "401:\ttotal: 42.2s\tremaining: 10.3s\n",
      "402:\ttotal: 42.3s\tremaining: 10.2s\n",
      "403:\ttotal: 42.4s\tremaining: 10.1s\n",
      "404:\ttotal: 42.5s\tremaining: 9.98s\n",
      "405:\ttotal: 42.6s\tremaining: 9.87s\n",
      "406:\ttotal: 42.7s\tremaining: 9.76s\n",
      "407:\ttotal: 42.8s\tremaining: 9.65s\n",
      "408:\ttotal: 42.9s\tremaining: 9.55s\n",
      "409:\ttotal: 43s\tremaining: 9.44s\n",
      "410:\ttotal: 43.1s\tremaining: 9.34s\n",
      "411:\ttotal: 43.2s\tremaining: 9.23s\n",
      "412:\ttotal: 43.3s\tremaining: 9.13s\n",
      "413:\ttotal: 43.4s\tremaining: 9.02s\n",
      "414:\ttotal: 43.5s\tremaining: 8.92s\n",
      "415:\ttotal: 43.6s\tremaining: 8.81s\n",
      "416:\ttotal: 43.8s\tremaining: 8.71s\n",
      "417:\ttotal: 43.9s\tremaining: 8.6s\n",
      "418:\ttotal: 44s\tremaining: 8.5s\n",
      "419:\ttotal: 44.1s\tremaining: 8.39s\n",
      "420:\ttotal: 44.2s\tremaining: 8.29s\n",
      "421:\ttotal: 44.3s\tremaining: 8.18s\n",
      "422:\ttotal: 44.4s\tremaining: 8.07s\n",
      "423:\ttotal: 44.4s\tremaining: 7.97s\n",
      "424:\ttotal: 44.5s\tremaining: 7.86s\n",
      "425:\ttotal: 44.6s\tremaining: 7.76s\n",
      "426:\ttotal: 44.7s\tremaining: 7.65s\n",
      "427:\ttotal: 44.8s\tremaining: 7.54s\n",
      "428:\ttotal: 44.9s\tremaining: 7.44s\n",
      "429:\ttotal: 45s\tremaining: 7.33s\n",
      "430:\ttotal: 45.2s\tremaining: 7.23s\n",
      "431:\ttotal: 45.3s\tremaining: 7.12s\n",
      "432:\ttotal: 45.3s\tremaining: 7.02s\n",
      "433:\ttotal: 45.5s\tremaining: 6.91s\n",
      "434:\ttotal: 45.6s\tremaining: 6.81s\n",
      "435:\ttotal: 45.7s\tremaining: 6.7s\n",
      "436:\ttotal: 45.8s\tremaining: 6.6s\n",
      "437:\ttotal: 45.9s\tremaining: 6.49s\n",
      "438:\ttotal: 46s\tremaining: 6.39s\n",
      "439:\ttotal: 46.1s\tremaining: 6.29s\n",
      "440:\ttotal: 46.2s\tremaining: 6.18s\n",
      "441:\ttotal: 46.3s\tremaining: 6.07s\n",
      "442:\ttotal: 46.4s\tremaining: 5.97s\n",
      "443:\ttotal: 46.5s\tremaining: 5.87s\n",
      "444:\ttotal: 46.6s\tremaining: 5.76s\n",
      "445:\ttotal: 46.7s\tremaining: 5.66s\n",
      "446:\ttotal: 46.8s\tremaining: 5.55s\n",
      "447:\ttotal: 46.9s\tremaining: 5.45s\n",
      "448:\ttotal: 47s\tremaining: 5.34s\n",
      "449:\ttotal: 47.1s\tremaining: 5.23s\n",
      "450:\ttotal: 47.2s\tremaining: 5.13s\n",
      "451:\ttotal: 47.3s\tremaining: 5.03s\n",
      "452:\ttotal: 47.4s\tremaining: 4.92s\n",
      "453:\ttotal: 47.5s\tremaining: 4.82s\n",
      "454:\ttotal: 47.6s\tremaining: 4.71s\n",
      "455:\ttotal: 47.7s\tremaining: 4.6s\n",
      "456:\ttotal: 47.8s\tremaining: 4.5s\n",
      "457:\ttotal: 47.9s\tremaining: 4.39s\n",
      "458:\ttotal: 48s\tremaining: 4.29s\n",
      "459:\ttotal: 48.1s\tremaining: 4.18s\n",
      "460:\ttotal: 48.2s\tremaining: 4.08s\n",
      "461:\ttotal: 48.3s\tremaining: 3.98s\n",
      "462:\ttotal: 48.4s\tremaining: 3.87s\n",
      "463:\ttotal: 48.5s\tremaining: 3.77s\n",
      "464:\ttotal: 48.7s\tremaining: 3.66s\n",
      "465:\ttotal: 48.8s\tremaining: 3.56s\n",
      "466:\ttotal: 48.9s\tremaining: 3.45s\n",
      "467:\ttotal: 49s\tremaining: 3.35s\n",
      "468:\ttotal: 49.1s\tremaining: 3.24s\n",
      "469:\ttotal: 49.2s\tremaining: 3.14s\n",
      "470:\ttotal: 49.3s\tremaining: 3.03s\n",
      "471:\ttotal: 49.4s\tremaining: 2.93s\n",
      "472:\ttotal: 49.5s\tremaining: 2.82s\n",
      "473:\ttotal: 49.6s\tremaining: 2.72s\n",
      "474:\ttotal: 49.7s\tremaining: 2.61s\n",
      "475:\ttotal: 49.8s\tremaining: 2.51s\n",
      "476:\ttotal: 49.9s\tremaining: 2.4s\n",
      "477:\ttotal: 50s\tremaining: 2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478:\ttotal: 50.1s\tremaining: 2.19s\n",
      "479:\ttotal: 50.2s\tremaining: 2.09s\n",
      "480:\ttotal: 50.3s\tremaining: 1.99s\n",
      "481:\ttotal: 50.4s\tremaining: 1.88s\n",
      "482:\ttotal: 50.5s\tremaining: 1.78s\n",
      "483:\ttotal: 50.6s\tremaining: 1.67s\n",
      "484:\ttotal: 50.7s\tremaining: 1.57s\n",
      "485:\ttotal: 50.8s\tremaining: 1.46s\n",
      "486:\ttotal: 50.9s\tremaining: 1.36s\n",
      "487:\ttotal: 51s\tremaining: 1.25s\n",
      "488:\ttotal: 51.1s\tremaining: 1.15s\n",
      "489:\ttotal: 51.2s\tremaining: 1.04s\n",
      "490:\ttotal: 51.3s\tremaining: 940ms\n",
      "491:\ttotal: 51.4s\tremaining: 835ms\n",
      "492:\ttotal: 51.5s\tremaining: 731ms\n",
      "493:\ttotal: 51.6s\tremaining: 626ms\n",
      "494:\ttotal: 51.7s\tremaining: 522ms\n",
      "495:\ttotal: 51.8s\tremaining: 418ms\n",
      "496:\ttotal: 51.9s\tremaining: 313ms\n",
      "497:\ttotal: 52s\tremaining: 209ms\n",
      "498:\ttotal: 52.1s\tremaining: 104ms\n",
      "499:\ttotal: 52.2s\tremaining: 0us\n",
      "0.844770664694331\n",
      "0:\tlearn: 0.6433682\ttotal: 116ms\tremaining: 57.7s\n",
      "1:\tlearn: 0.6055677\ttotal: 227ms\tremaining: 56.5s\n",
      "2:\tlearn: 0.5756723\ttotal: 351ms\tremaining: 58.1s\n",
      "3:\tlearn: 0.5509236\ttotal: 466ms\tremaining: 57.7s\n",
      "4:\tlearn: 0.5320043\ttotal: 587ms\tremaining: 58.1s\n",
      "5:\tlearn: 0.5163781\ttotal: 710ms\tremaining: 58.5s\n",
      "6:\tlearn: 0.5040679\ttotal: 835ms\tremaining: 58.8s\n",
      "7:\tlearn: 0.4943500\ttotal: 949ms\tremaining: 58.4s\n",
      "8:\tlearn: 0.4863709\ttotal: 1.06s\tremaining: 58.1s\n",
      "9:\tlearn: 0.4797748\ttotal: 1.18s\tremaining: 57.6s\n",
      "10:\tlearn: 0.4741508\ttotal: 1.3s\tremaining: 57.7s\n",
      "11:\tlearn: 0.4698623\ttotal: 1.41s\tremaining: 57.4s\n",
      "12:\tlearn: 0.4660902\ttotal: 1.54s\tremaining: 57.6s\n",
      "13:\tlearn: 0.4629027\ttotal: 1.65s\tremaining: 57.4s\n",
      "14:\tlearn: 0.4602136\ttotal: 1.78s\tremaining: 57.6s\n",
      "15:\tlearn: 0.4579619\ttotal: 1.89s\tremaining: 57.3s\n",
      "16:\tlearn: 0.4559548\ttotal: 2.01s\tremaining: 57.2s\n",
      "17:\tlearn: 0.4542762\ttotal: 2.14s\tremaining: 57.2s\n",
      "18:\tlearn: 0.4528897\ttotal: 2.26s\tremaining: 57.1s\n",
      "19:\tlearn: 0.4517149\ttotal: 2.39s\tremaining: 57.3s\n",
      "20:\tlearn: 0.4505855\ttotal: 2.52s\tremaining: 57.5s\n",
      "21:\tlearn: 0.4496446\ttotal: 2.64s\tremaining: 57.3s\n",
      "22:\tlearn: 0.4487794\ttotal: 2.77s\tremaining: 57.3s\n",
      "23:\tlearn: 0.4480902\ttotal: 2.88s\tremaining: 57.1s\n",
      "24:\tlearn: 0.4474715\ttotal: 3s\tremaining: 57s\n",
      "25:\tlearn: 0.4469048\ttotal: 3.12s\tremaining: 56.8s\n",
      "26:\tlearn: 0.4464087\ttotal: 3.24s\tremaining: 56.8s\n",
      "27:\tlearn: 0.4459950\ttotal: 3.35s\tremaining: 56.6s\n",
      "28:\tlearn: 0.4456202\ttotal: 3.48s\tremaining: 56.5s\n",
      "29:\tlearn: 0.4452959\ttotal: 3.59s\tremaining: 56.2s\n",
      "30:\tlearn: 0.4449365\ttotal: 3.72s\tremaining: 56.3s\n",
      "31:\tlearn: 0.4446517\ttotal: 3.83s\tremaining: 56.1s\n",
      "32:\tlearn: 0.4443670\ttotal: 3.95s\tremaining: 55.9s\n",
      "33:\tlearn: 0.4441347\ttotal: 4.07s\tremaining: 55.7s\n",
      "34:\tlearn: 0.4439128\ttotal: 4.17s\tremaining: 55.4s\n",
      "35:\tlearn: 0.4436823\ttotal: 4.29s\tremaining: 55.3s\n",
      "36:\tlearn: 0.4434675\ttotal: 4.42s\tremaining: 55.3s\n",
      "37:\tlearn: 0.4432991\ttotal: 4.54s\tremaining: 55.1s\n",
      "38:\tlearn: 0.4431085\ttotal: 4.65s\tremaining: 55s\n",
      "39:\tlearn: 0.4429174\ttotal: 4.77s\tremaining: 54.8s\n",
      "40:\tlearn: 0.4427606\ttotal: 4.89s\tremaining: 54.8s\n",
      "41:\tlearn: 0.4426309\ttotal: 4.99s\tremaining: 54.5s\n",
      "42:\tlearn: 0.4425031\ttotal: 5.1s\tremaining: 54.2s\n",
      "43:\tlearn: 0.4423564\ttotal: 5.2s\tremaining: 53.9s\n",
      "44:\tlearn: 0.4422089\ttotal: 5.33s\tremaining: 53.9s\n",
      "45:\tlearn: 0.4421044\ttotal: 5.43s\tremaining: 53.6s\n",
      "46:\tlearn: 0.4419958\ttotal: 5.54s\tremaining: 53.4s\n",
      "47:\tlearn: 0.4418848\ttotal: 5.66s\tremaining: 53.3s\n",
      "48:\tlearn: 0.4417708\ttotal: 5.77s\tremaining: 53.1s\n",
      "49:\tlearn: 0.4416746\ttotal: 5.87s\tremaining: 52.8s\n",
      "50:\tlearn: 0.4415463\ttotal: 5.97s\tremaining: 52.6s\n",
      "51:\tlearn: 0.4414481\ttotal: 6.08s\tremaining: 52.3s\n",
      "52:\tlearn: 0.4413335\ttotal: 6.18s\tremaining: 52.1s\n",
      "53:\tlearn: 0.4411947\ttotal: 6.29s\tremaining: 52s\n",
      "54:\tlearn: 0.4410928\ttotal: 6.4s\tremaining: 51.8s\n",
      "55:\tlearn: 0.4409847\ttotal: 6.51s\tremaining: 51.7s\n",
      "56:\tlearn: 0.4408833\ttotal: 6.61s\tremaining: 51.4s\n",
      "57:\tlearn: 0.4407923\ttotal: 6.71s\tremaining: 51.1s\n",
      "58:\tlearn: 0.4406810\ttotal: 6.81s\tremaining: 50.9s\n",
      "59:\tlearn: 0.4405736\ttotal: 6.92s\tremaining: 50.8s\n",
      "60:\tlearn: 0.4404697\ttotal: 7.04s\tremaining: 50.7s\n",
      "61:\tlearn: 0.4403770\ttotal: 7.14s\tremaining: 50.4s\n",
      "62:\tlearn: 0.4402806\ttotal: 7.25s\tremaining: 50.3s\n",
      "63:\tlearn: 0.4401905\ttotal: 7.36s\tremaining: 50.1s\n",
      "64:\tlearn: 0.4400984\ttotal: 7.46s\tremaining: 49.9s\n",
      "65:\tlearn: 0.4400164\ttotal: 7.57s\tremaining: 49.8s\n",
      "66:\tlearn: 0.4399424\ttotal: 7.68s\tremaining: 49.6s\n",
      "67:\tlearn: 0.4398484\ttotal: 7.78s\tremaining: 49.4s\n",
      "68:\tlearn: 0.4397521\ttotal: 7.9s\tremaining: 49.3s\n",
      "69:\tlearn: 0.4396661\ttotal: 8.01s\tremaining: 49.2s\n",
      "70:\tlearn: 0.4395746\ttotal: 8.11s\tremaining: 49s\n",
      "71:\tlearn: 0.4394812\ttotal: 8.22s\tremaining: 48.9s\n",
      "72:\tlearn: 0.4393895\ttotal: 8.33s\tremaining: 48.7s\n",
      "73:\tlearn: 0.4393006\ttotal: 8.43s\tremaining: 48.5s\n",
      "74:\tlearn: 0.4392157\ttotal: 8.54s\tremaining: 48.4s\n",
      "75:\tlearn: 0.4391389\ttotal: 8.63s\tremaining: 48.1s\n",
      "76:\tlearn: 0.4390451\ttotal: 8.73s\tremaining: 48s\n",
      "77:\tlearn: 0.4389522\ttotal: 8.84s\tremaining: 47.8s\n",
      "78:\tlearn: 0.4388683\ttotal: 8.95s\tremaining: 47.7s\n",
      "79:\tlearn: 0.4387897\ttotal: 9.06s\tremaining: 47.5s\n",
      "80:\tlearn: 0.4387050\ttotal: 9.15s\tremaining: 47.4s\n",
      "81:\tlearn: 0.4386149\ttotal: 9.26s\tremaining: 47.2s\n",
      "82:\tlearn: 0.4385320\ttotal: 9.37s\tremaining: 47.1s\n",
      "83:\tlearn: 0.4384574\ttotal: 9.46s\tremaining: 46.9s\n",
      "84:\tlearn: 0.4383639\ttotal: 9.57s\tremaining: 46.7s\n",
      "85:\tlearn: 0.4382921\ttotal: 9.68s\tremaining: 46.6s\n",
      "86:\tlearn: 0.4382330\ttotal: 9.78s\tremaining: 46.4s\n",
      "87:\tlearn: 0.4381491\ttotal: 9.89s\tremaining: 46.3s\n",
      "88:\tlearn: 0.4380879\ttotal: 9.98s\tremaining: 46.1s\n",
      "89:\tlearn: 0.4380209\ttotal: 10.1s\tremaining: 46s\n",
      "90:\tlearn: 0.4379391\ttotal: 10.2s\tremaining: 45.9s\n",
      "91:\tlearn: 0.4378653\ttotal: 10.3s\tremaining: 45.8s\n",
      "92:\tlearn: 0.4377815\ttotal: 10.4s\tremaining: 45.7s\n",
      "93:\tlearn: 0.4377141\ttotal: 10.6s\tremaining: 45.6s\n",
      "94:\tlearn: 0.4376200\ttotal: 10.7s\tremaining: 45.5s\n",
      "95:\tlearn: 0.4375375\ttotal: 10.8s\tremaining: 45.3s\n",
      "96:\tlearn: 0.4374465\ttotal: 10.9s\tremaining: 45.1s\n",
      "97:\tlearn: 0.4373691\ttotal: 11s\tremaining: 45s\n",
      "98:\tlearn: 0.4373024\ttotal: 11.1s\tremaining: 44.8s\n",
      "99:\tlearn: 0.4372364\ttotal: 11.2s\tremaining: 44.6s\n",
      "100:\tlearn: 0.4371594\ttotal: 11.3s\tremaining: 44.5s\n",
      "101:\tlearn: 0.4370823\ttotal: 11.4s\tremaining: 44.3s\n",
      "102:\tlearn: 0.4369984\ttotal: 11.4s\tremaining: 44.1s\n",
      "103:\tlearn: 0.4369264\ttotal: 11.5s\tremaining: 44s\n",
      "104:\tlearn: 0.4368366\ttotal: 11.6s\tremaining: 43.8s\n",
      "105:\tlearn: 0.4367624\ttotal: 11.8s\tremaining: 43.7s\n",
      "106:\tlearn: 0.4366810\ttotal: 11.9s\tremaining: 43.6s\n",
      "107:\tlearn: 0.4366085\ttotal: 12s\tremaining: 43.5s\n",
      "108:\tlearn: 0.4365322\ttotal: 12.1s\tremaining: 43.3s\n",
      "109:\tlearn: 0.4364620\ttotal: 12.2s\tremaining: 43.2s\n",
      "110:\tlearn: 0.4363891\ttotal: 12.3s\tremaining: 43.1s\n",
      "111:\tlearn: 0.4363204\ttotal: 12.4s\tremaining: 43s\n",
      "112:\tlearn: 0.4362511\ttotal: 12.5s\tremaining: 42.8s\n",
      "113:\tlearn: 0.4361747\ttotal: 12.6s\tremaining: 42.6s\n",
      "114:\tlearn: 0.4361043\ttotal: 12.7s\tremaining: 42.5s\n",
      "115:\tlearn: 0.4360290\ttotal: 12.8s\tremaining: 42.4s\n",
      "116:\tlearn: 0.4359577\ttotal: 12.9s\tremaining: 42.2s\n",
      "117:\tlearn: 0.4358939\ttotal: 13s\tremaining: 42.1s\n",
      "118:\tlearn: 0.4358251\ttotal: 13.1s\tremaining: 41.9s\n",
      "119:\tlearn: 0.4357581\ttotal: 13.2s\tremaining: 41.8s\n",
      "120:\tlearn: 0.4356860\ttotal: 13.3s\tremaining: 41.7s\n",
      "121:\tlearn: 0.4356070\ttotal: 13.4s\tremaining: 41.6s\n",
      "122:\tlearn: 0.4355312\ttotal: 13.5s\tremaining: 41.4s\n",
      "123:\tlearn: 0.4354607\ttotal: 13.6s\tremaining: 41.3s\n",
      "124:\tlearn: 0.4353820\ttotal: 13.7s\tremaining: 41.2s\n",
      "125:\tlearn: 0.4353026\ttotal: 13.8s\tremaining: 41.1s\n",
      "126:\tlearn: 0.4352184\ttotal: 13.9s\tremaining: 41s\n",
      "127:\tlearn: 0.4351335\ttotal: 14s\tremaining: 40.8s\n",
      "128:\tlearn: 0.4350485\ttotal: 14.2s\tremaining: 40.7s\n",
      "129:\tlearn: 0.4349799\ttotal: 14.3s\tremaining: 40.6s\n",
      "130:\tlearn: 0.4349023\ttotal: 14.4s\tremaining: 40.4s\n",
      "131:\tlearn: 0.4348307\ttotal: 14.4s\tremaining: 40.3s\n",
      "132:\tlearn: 0.4347547\ttotal: 14.6s\tremaining: 40.2s\n",
      "133:\tlearn: 0.4346733\ttotal: 14.7s\tremaining: 40s\n",
      "134:\tlearn: 0.4346003\ttotal: 14.8s\tremaining: 39.9s\n",
      "135:\tlearn: 0.4345185\ttotal: 14.9s\tremaining: 39.8s\n",
      "136:\tlearn: 0.4344473\ttotal: 15s\tremaining: 39.6s\n",
      "137:\tlearn: 0.4343648\ttotal: 15.1s\tremaining: 39.5s\n",
      "138:\tlearn: 0.4342946\ttotal: 15.2s\tremaining: 39.4s\n",
      "139:\tlearn: 0.4342145\ttotal: 15.3s\tremaining: 39.2s\n",
      "140:\tlearn: 0.4341418\ttotal: 15.4s\tremaining: 39.1s\n",
      "141:\tlearn: 0.4340529\ttotal: 15.5s\tremaining: 39s\n",
      "142:\tlearn: 0.4339720\ttotal: 15.6s\tremaining: 38.9s\n",
      "143:\tlearn: 0.4338893\ttotal: 15.7s\tremaining: 38.7s\n",
      "144:\tlearn: 0.4338120\ttotal: 15.8s\tremaining: 38.6s\n",
      "145:\tlearn: 0.4337398\ttotal: 15.9s\tremaining: 38.5s\n",
      "146:\tlearn: 0.4336674\ttotal: 16s\tremaining: 38.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147:\tlearn: 0.4335933\ttotal: 16.1s\tremaining: 38.3s\n",
      "148:\tlearn: 0.4335129\ttotal: 16.2s\tremaining: 38.2s\n",
      "149:\tlearn: 0.4334424\ttotal: 16.3s\tremaining: 38s\n",
      "150:\tlearn: 0.4333597\ttotal: 16.4s\tremaining: 37.9s\n",
      "151:\tlearn: 0.4332935\ttotal: 16.5s\tremaining: 37.8s\n",
      "152:\tlearn: 0.4332126\ttotal: 16.6s\tremaining: 37.7s\n",
      "153:\tlearn: 0.4331323\ttotal: 16.7s\tremaining: 37.6s\n",
      "154:\tlearn: 0.4330628\ttotal: 16.8s\tremaining: 37.4s\n",
      "155:\tlearn: 0.4329929\ttotal: 16.9s\tremaining: 37.4s\n",
      "156:\tlearn: 0.4329276\ttotal: 17s\tremaining: 37.2s\n",
      "157:\tlearn: 0.4328640\ttotal: 17.1s\tremaining: 37.1s\n",
      "158:\tlearn: 0.4327904\ttotal: 17.2s\tremaining: 36.9s\n",
      "159:\tlearn: 0.4327209\ttotal: 17.3s\tremaining: 36.8s\n",
      "160:\tlearn: 0.4326442\ttotal: 17.4s\tremaining: 36.7s\n",
      "161:\tlearn: 0.4325724\ttotal: 17.5s\tremaining: 36.6s\n",
      "162:\tlearn: 0.4324938\ttotal: 17.6s\tremaining: 36.5s\n",
      "163:\tlearn: 0.4324329\ttotal: 17.8s\tremaining: 36.4s\n",
      "164:\tlearn: 0.4323657\ttotal: 17.9s\tremaining: 36.3s\n",
      "165:\tlearn: 0.4322800\ttotal: 18s\tremaining: 36.1s\n",
      "166:\tlearn: 0.4321936\ttotal: 18.1s\tremaining: 36s\n",
      "167:\tlearn: 0.4321303\ttotal: 18.2s\tremaining: 35.9s\n",
      "168:\tlearn: 0.4320529\ttotal: 18.3s\tremaining: 35.8s\n",
      "169:\tlearn: 0.4319834\ttotal: 18.3s\tremaining: 35.6s\n",
      "170:\tlearn: 0.4319221\ttotal: 18.4s\tremaining: 35.5s\n",
      "171:\tlearn: 0.4318443\ttotal: 18.5s\tremaining: 35.4s\n",
      "172:\tlearn: 0.4317695\ttotal: 18.6s\tremaining: 35.2s\n",
      "173:\tlearn: 0.4317033\ttotal: 18.8s\tremaining: 35.1s\n",
      "174:\tlearn: 0.4316351\ttotal: 18.9s\tremaining: 35s\n",
      "175:\tlearn: 0.4315729\ttotal: 19s\tremaining: 34.9s\n",
      "176:\tlearn: 0.4315018\ttotal: 19.1s\tremaining: 34.8s\n",
      "177:\tlearn: 0.4314265\ttotal: 19.2s\tremaining: 34.7s\n",
      "178:\tlearn: 0.4313459\ttotal: 19.3s\tremaining: 34.5s\n",
      "179:\tlearn: 0.4312699\ttotal: 19.4s\tremaining: 34.4s\n",
      "180:\tlearn: 0.4311907\ttotal: 19.4s\tremaining: 34.3s\n",
      "181:\tlearn: 0.4311194\ttotal: 19.6s\tremaining: 34.2s\n",
      "182:\tlearn: 0.4310559\ttotal: 19.7s\tremaining: 34.1s\n",
      "183:\tlearn: 0.4309737\ttotal: 19.8s\tremaining: 34s\n",
      "184:\tlearn: 0.4309074\ttotal: 19.9s\tremaining: 33.8s\n",
      "185:\tlearn: 0.4308367\ttotal: 20s\tremaining: 33.7s\n",
      "186:\tlearn: 0.4307627\ttotal: 20.1s\tremaining: 33.6s\n",
      "187:\tlearn: 0.4306869\ttotal: 20.2s\tremaining: 33.5s\n",
      "188:\tlearn: 0.4306047\ttotal: 20.3s\tremaining: 33.4s\n",
      "189:\tlearn: 0.4305221\ttotal: 20.4s\tremaining: 33.3s\n",
      "190:\tlearn: 0.4304459\ttotal: 20.6s\tremaining: 33.3s\n",
      "191:\tlearn: 0.4303748\ttotal: 20.7s\tremaining: 33.1s\n",
      "192:\tlearn: 0.4303061\ttotal: 20.8s\tremaining: 33s\n",
      "193:\tlearn: 0.4302462\ttotal: 20.9s\tremaining: 32.9s\n",
      "194:\tlearn: 0.4301828\ttotal: 21s\tremaining: 32.8s\n",
      "195:\tlearn: 0.4301090\ttotal: 21.1s\tremaining: 32.7s\n",
      "196:\tlearn: 0.4300404\ttotal: 21.2s\tremaining: 32.6s\n",
      "197:\tlearn: 0.4299668\ttotal: 21.3s\tremaining: 32.5s\n",
      "198:\tlearn: 0.4298955\ttotal: 21.4s\tremaining: 32.4s\n",
      "199:\tlearn: 0.4298267\ttotal: 21.5s\tremaining: 32.3s\n",
      "200:\tlearn: 0.4297443\ttotal: 21.6s\tremaining: 32.2s\n",
      "201:\tlearn: 0.4296827\ttotal: 21.7s\tremaining: 32s\n",
      "202:\tlearn: 0.4296174\ttotal: 21.8s\tremaining: 31.9s\n",
      "203:\tlearn: 0.4295625\ttotal: 21.9s\tremaining: 31.8s\n",
      "204:\tlearn: 0.4294906\ttotal: 22s\tremaining: 31.7s\n",
      "205:\tlearn: 0.4294219\ttotal: 22.1s\tremaining: 31.6s\n",
      "206:\tlearn: 0.4293537\ttotal: 22.2s\tremaining: 31.4s\n",
      "207:\tlearn: 0.4292767\ttotal: 22.3s\tremaining: 31.3s\n",
      "208:\tlearn: 0.4292082\ttotal: 22.4s\tremaining: 31.2s\n",
      "209:\tlearn: 0.4291369\ttotal: 22.5s\tremaining: 31.1s\n",
      "210:\tlearn: 0.4290722\ttotal: 22.7s\tremaining: 31s\n",
      "211:\tlearn: 0.4290087\ttotal: 22.8s\tremaining: 30.9s\n",
      "212:\tlearn: 0.4289382\ttotal: 22.9s\tremaining: 30.8s\n",
      "213:\tlearn: 0.4288807\ttotal: 23s\tremaining: 30.7s\n",
      "214:\tlearn: 0.4288064\ttotal: 23.1s\tremaining: 30.6s\n",
      "215:\tlearn: 0.4287302\ttotal: 23.2s\tremaining: 30.5s\n",
      "216:\tlearn: 0.4286511\ttotal: 23.3s\tremaining: 30.4s\n",
      "217:\tlearn: 0.4285892\ttotal: 23.4s\tremaining: 30.2s\n",
      "218:\tlearn: 0.4285272\ttotal: 23.5s\tremaining: 30.1s\n",
      "219:\tlearn: 0.4284586\ttotal: 23.6s\tremaining: 30s\n",
      "220:\tlearn: 0.4283878\ttotal: 23.7s\tremaining: 29.9s\n",
      "221:\tlearn: 0.4283194\ttotal: 23.8s\tremaining: 29.8s\n",
      "222:\tlearn: 0.4282507\ttotal: 23.9s\tremaining: 29.7s\n",
      "223:\tlearn: 0.4281646\ttotal: 24s\tremaining: 29.5s\n",
      "224:\tlearn: 0.4280904\ttotal: 24.1s\tremaining: 29.4s\n",
      "225:\tlearn: 0.4280326\ttotal: 24.2s\tremaining: 29.3s\n",
      "226:\tlearn: 0.4279490\ttotal: 24.3s\tremaining: 29.2s\n",
      "227:\tlearn: 0.4278873\ttotal: 24.4s\tremaining: 29.1s\n",
      "228:\tlearn: 0.4278108\ttotal: 24.5s\tremaining: 29s\n",
      "229:\tlearn: 0.4277395\ttotal: 24.7s\tremaining: 28.9s\n",
      "230:\tlearn: 0.4276673\ttotal: 24.8s\tremaining: 28.8s\n",
      "231:\tlearn: 0.4275922\ttotal: 24.9s\tremaining: 28.7s\n",
      "232:\tlearn: 0.4275255\ttotal: 25s\tremaining: 28.6s\n",
      "233:\tlearn: 0.4274537\ttotal: 25.1s\tremaining: 28.5s\n",
      "234:\tlearn: 0.4273904\ttotal: 25.2s\tremaining: 28.4s\n",
      "235:\tlearn: 0.4273215\ttotal: 25.3s\tremaining: 28.3s\n",
      "236:\tlearn: 0.4272601\ttotal: 25.4s\tremaining: 28.2s\n",
      "237:\tlearn: 0.4271860\ttotal: 25.5s\tremaining: 28.1s\n",
      "238:\tlearn: 0.4271232\ttotal: 25.6s\tremaining: 28s\n",
      "239:\tlearn: 0.4270474\ttotal: 25.7s\tremaining: 27.9s\n",
      "240:\tlearn: 0.4269788\ttotal: 25.8s\tremaining: 27.7s\n",
      "241:\tlearn: 0.4269184\ttotal: 25.9s\tremaining: 27.6s\n",
      "242:\tlearn: 0.4268596\ttotal: 26s\tremaining: 27.5s\n",
      "243:\tlearn: 0.4268032\ttotal: 26.1s\tremaining: 27.4s\n",
      "244:\tlearn: 0.4267342\ttotal: 26.2s\tremaining: 27.3s\n",
      "245:\tlearn: 0.4266699\ttotal: 26.3s\tremaining: 27.2s\n",
      "246:\tlearn: 0.4266070\ttotal: 26.4s\tremaining: 27.1s\n",
      "247:\tlearn: 0.4265382\ttotal: 26.6s\tremaining: 27s\n",
      "248:\tlearn: 0.4264811\ttotal: 26.6s\tremaining: 26.9s\n",
      "249:\tlearn: 0.4264120\ttotal: 26.8s\tremaining: 26.8s\n",
      "250:\tlearn: 0.4263478\ttotal: 26.8s\tremaining: 26.6s\n",
      "251:\tlearn: 0.4262768\ttotal: 27s\tremaining: 26.5s\n",
      "252:\tlearn: 0.4262126\ttotal: 27.1s\tremaining: 26.4s\n",
      "253:\tlearn: 0.4261509\ttotal: 27.2s\tremaining: 26.3s\n",
      "254:\tlearn: 0.4260867\ttotal: 27.3s\tremaining: 26.2s\n",
      "255:\tlearn: 0.4260235\ttotal: 27.4s\tremaining: 26.1s\n",
      "256:\tlearn: 0.4259603\ttotal: 27.5s\tremaining: 26s\n",
      "257:\tlearn: 0.4258843\ttotal: 27.6s\tremaining: 25.9s\n",
      "258:\tlearn: 0.4258173\ttotal: 27.7s\tremaining: 25.7s\n",
      "259:\tlearn: 0.4257445\ttotal: 27.8s\tremaining: 25.6s\n",
      "260:\tlearn: 0.4256728\ttotal: 27.9s\tremaining: 25.5s\n",
      "261:\tlearn: 0.4256099\ttotal: 27.9s\tremaining: 25.4s\n",
      "262:\tlearn: 0.4255536\ttotal: 28.1s\tremaining: 25.3s\n",
      "263:\tlearn: 0.4254774\ttotal: 28.2s\tremaining: 25.2s\n",
      "264:\tlearn: 0.4254197\ttotal: 28.3s\tremaining: 25.1s\n",
      "265:\tlearn: 0.4253556\ttotal: 28.4s\tremaining: 25s\n",
      "266:\tlearn: 0.4252935\ttotal: 28.5s\tremaining: 24.9s\n",
      "267:\tlearn: 0.4252354\ttotal: 28.6s\tremaining: 24.8s\n",
      "268:\tlearn: 0.4251668\ttotal: 28.7s\tremaining: 24.7s\n",
      "269:\tlearn: 0.4251008\ttotal: 28.8s\tremaining: 24.5s\n",
      "270:\tlearn: 0.4250402\ttotal: 28.9s\tremaining: 24.4s\n",
      "271:\tlearn: 0.4249743\ttotal: 29s\tremaining: 24.3s\n",
      "272:\tlearn: 0.4249142\ttotal: 29.1s\tremaining: 24.2s\n",
      "273:\tlearn: 0.4248386\ttotal: 29.2s\tremaining: 24.1s\n",
      "274:\tlearn: 0.4247773\ttotal: 29.3s\tremaining: 24s\n",
      "275:\tlearn: 0.4247107\ttotal: 29.4s\tremaining: 23.9s\n",
      "276:\tlearn: 0.4246541\ttotal: 29.6s\tremaining: 23.8s\n",
      "277:\tlearn: 0.4245904\ttotal: 29.7s\tremaining: 23.7s\n",
      "278:\tlearn: 0.4245322\ttotal: 29.8s\tremaining: 23.6s\n",
      "279:\tlearn: 0.4244685\ttotal: 29.9s\tremaining: 23.5s\n",
      "280:\tlearn: 0.4243986\ttotal: 30s\tremaining: 23.4s\n",
      "281:\tlearn: 0.4243339\ttotal: 30.1s\tremaining: 23.3s\n",
      "282:\tlearn: 0.4242830\ttotal: 30.2s\tremaining: 23.1s\n",
      "283:\tlearn: 0.4242235\ttotal: 30.3s\tremaining: 23s\n",
      "284:\tlearn: 0.4241745\ttotal: 30.4s\tremaining: 22.9s\n",
      "285:\tlearn: 0.4241115\ttotal: 30.5s\tremaining: 22.8s\n",
      "286:\tlearn: 0.4240469\ttotal: 30.6s\tremaining: 22.7s\n",
      "287:\tlearn: 0.4239980\ttotal: 30.7s\tremaining: 22.6s\n",
      "288:\tlearn: 0.4239347\ttotal: 30.8s\tremaining: 22.5s\n",
      "289:\tlearn: 0.4238746\ttotal: 30.9s\tremaining: 22.4s\n",
      "290:\tlearn: 0.4238041\ttotal: 31s\tremaining: 22.2s\n",
      "291:\tlearn: 0.4237371\ttotal: 31.1s\tremaining: 22.1s\n",
      "292:\tlearn: 0.4236749\ttotal: 31.2s\tremaining: 22s\n",
      "293:\tlearn: 0.4236115\ttotal: 31.3s\tremaining: 21.9s\n",
      "294:\tlearn: 0.4235511\ttotal: 31.4s\tremaining: 21.8s\n",
      "295:\tlearn: 0.4234997\ttotal: 31.5s\tremaining: 21.7s\n",
      "296:\tlearn: 0.4234352\ttotal: 31.6s\tremaining: 21.6s\n",
      "297:\tlearn: 0.4233816\ttotal: 31.7s\tremaining: 21.5s\n",
      "298:\tlearn: 0.4233184\ttotal: 31.8s\tremaining: 21.4s\n",
      "299:\tlearn: 0.4232624\ttotal: 31.9s\tremaining: 21.3s\n",
      "300:\tlearn: 0.4232018\ttotal: 32s\tremaining: 21.2s\n",
      "301:\tlearn: 0.4231353\ttotal: 32.1s\tremaining: 21.1s\n",
      "302:\tlearn: 0.4230717\ttotal: 32.2s\tremaining: 21s\n",
      "303:\tlearn: 0.4230131\ttotal: 32.3s\tremaining: 20.9s\n",
      "304:\tlearn: 0.4229496\ttotal: 32.5s\tremaining: 20.8s\n",
      "305:\tlearn: 0.4228935\ttotal: 32.6s\tremaining: 20.6s\n",
      "306:\tlearn: 0.4228172\ttotal: 32.7s\tremaining: 20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307:\tlearn: 0.4227627\ttotal: 32.8s\tremaining: 20.4s\n",
      "308:\tlearn: 0.4226960\ttotal: 32.9s\tremaining: 20.3s\n",
      "309:\tlearn: 0.4226288\ttotal: 33s\tremaining: 20.2s\n",
      "310:\tlearn: 0.4225484\ttotal: 33.1s\tremaining: 20.1s\n",
      "311:\tlearn: 0.4224799\ttotal: 33.2s\tremaining: 20s\n",
      "312:\tlearn: 0.4224288\ttotal: 33.3s\tremaining: 19.9s\n",
      "313:\tlearn: 0.4223753\ttotal: 33.4s\tremaining: 19.8s\n",
      "314:\tlearn: 0.4223230\ttotal: 33.5s\tremaining: 19.7s\n",
      "315:\tlearn: 0.4222500\ttotal: 33.6s\tremaining: 19.6s\n",
      "316:\tlearn: 0.4221795\ttotal: 33.7s\tremaining: 19.4s\n",
      "317:\tlearn: 0.4221238\ttotal: 33.8s\tremaining: 19.3s\n",
      "318:\tlearn: 0.4220625\ttotal: 33.9s\tremaining: 19.2s\n",
      "319:\tlearn: 0.4220047\ttotal: 34s\tremaining: 19.1s\n",
      "320:\tlearn: 0.4219619\ttotal: 34.1s\tremaining: 19s\n",
      "321:\tlearn: 0.4219145\ttotal: 34.2s\tremaining: 18.9s\n",
      "322:\tlearn: 0.4218574\ttotal: 34.3s\tremaining: 18.8s\n",
      "323:\tlearn: 0.4218011\ttotal: 34.4s\tremaining: 18.7s\n",
      "324:\tlearn: 0.4217407\ttotal: 34.5s\tremaining: 18.6s\n",
      "325:\tlearn: 0.4216733\ttotal: 34.6s\tremaining: 18.5s\n",
      "326:\tlearn: 0.4216061\ttotal: 34.7s\tremaining: 18.4s\n",
      "327:\tlearn: 0.4215511\ttotal: 34.8s\tremaining: 18.3s\n",
      "328:\tlearn: 0.4215005\ttotal: 34.9s\tremaining: 18.1s\n",
      "329:\tlearn: 0.4214388\ttotal: 35s\tremaining: 18s\n",
      "330:\tlearn: 0.4213657\ttotal: 35.1s\tremaining: 17.9s\n",
      "331:\tlearn: 0.4213081\ttotal: 35.2s\tremaining: 17.8s\n",
      "332:\tlearn: 0.4212664\ttotal: 35.3s\tremaining: 17.7s\n",
      "333:\tlearn: 0.4212030\ttotal: 35.4s\tremaining: 17.6s\n",
      "334:\tlearn: 0.4211384\ttotal: 35.5s\tremaining: 17.5s\n",
      "335:\tlearn: 0.4210770\ttotal: 35.6s\tremaining: 17.4s\n",
      "336:\tlearn: 0.4210222\ttotal: 35.7s\tremaining: 17.3s\n",
      "337:\tlearn: 0.4209611\ttotal: 35.8s\tremaining: 17.1s\n",
      "338:\tlearn: 0.4209021\ttotal: 35.9s\tremaining: 17s\n",
      "339:\tlearn: 0.4208325\ttotal: 36s\tremaining: 16.9s\n",
      "340:\tlearn: 0.4207699\ttotal: 36.1s\tremaining: 16.8s\n",
      "341:\tlearn: 0.4207141\ttotal: 36.2s\tremaining: 16.7s\n",
      "342:\tlearn: 0.4206571\ttotal: 36.3s\tremaining: 16.6s\n",
      "343:\tlearn: 0.4205886\ttotal: 36.4s\tremaining: 16.5s\n",
      "344:\tlearn: 0.4205218\ttotal: 36.5s\tremaining: 16.4s\n",
      "345:\tlearn: 0.4204645\ttotal: 36.6s\tremaining: 16.3s\n",
      "346:\tlearn: 0.4204075\ttotal: 36.7s\tremaining: 16.2s\n",
      "347:\tlearn: 0.4203563\ttotal: 36.8s\tremaining: 16.1s\n",
      "348:\tlearn: 0.4203088\ttotal: 36.9s\tremaining: 16s\n",
      "349:\tlearn: 0.4202426\ttotal: 37s\tremaining: 15.9s\n",
      "350:\tlearn: 0.4201886\ttotal: 37.1s\tremaining: 15.7s\n",
      "351:\tlearn: 0.4201264\ttotal: 37.2s\tremaining: 15.6s\n",
      "352:\tlearn: 0.4200669\ttotal: 37.3s\tremaining: 15.5s\n",
      "353:\tlearn: 0.4200130\ttotal: 37.4s\tremaining: 15.4s\n",
      "354:\tlearn: 0.4199417\ttotal: 37.5s\tremaining: 15.3s\n",
      "355:\tlearn: 0.4198904\ttotal: 37.6s\tremaining: 15.2s\n",
      "356:\tlearn: 0.4198264\ttotal: 37.7s\tremaining: 15.1s\n",
      "357:\tlearn: 0.4197607\ttotal: 37.8s\tremaining: 15s\n",
      "358:\tlearn: 0.4196971\ttotal: 37.9s\tremaining: 14.9s\n",
      "359:\tlearn: 0.4196401\ttotal: 38s\tremaining: 14.8s\n",
      "360:\tlearn: 0.4195721\ttotal: 38.1s\tremaining: 14.7s\n",
      "361:\tlearn: 0.4195130\ttotal: 38.3s\tremaining: 14.6s\n",
      "362:\tlearn: 0.4194605\ttotal: 38.4s\tremaining: 14.5s\n",
      "363:\tlearn: 0.4193902\ttotal: 38.5s\tremaining: 14.4s\n",
      "364:\tlearn: 0.4193190\ttotal: 38.6s\tremaining: 14.3s\n",
      "365:\tlearn: 0.4192606\ttotal: 38.7s\tremaining: 14.2s\n",
      "366:\tlearn: 0.4191942\ttotal: 38.8s\tremaining: 14.1s\n",
      "367:\tlearn: 0.4191375\ttotal: 38.9s\tremaining: 14s\n",
      "368:\tlearn: 0.4190780\ttotal: 39s\tremaining: 13.8s\n",
      "369:\tlearn: 0.4190277\ttotal: 39.1s\tremaining: 13.7s\n",
      "370:\tlearn: 0.4189634\ttotal: 39.2s\tremaining: 13.6s\n",
      "371:\tlearn: 0.4189001\ttotal: 39.3s\tremaining: 13.5s\n",
      "372:\tlearn: 0.4188345\ttotal: 39.4s\tremaining: 13.4s\n",
      "373:\tlearn: 0.4187689\ttotal: 39.5s\tremaining: 13.3s\n",
      "374:\tlearn: 0.4187090\ttotal: 39.6s\tremaining: 13.2s\n",
      "375:\tlearn: 0.4186499\ttotal: 39.7s\tremaining: 13.1s\n",
      "376:\tlearn: 0.4185855\ttotal: 39.8s\tremaining: 13s\n",
      "377:\tlearn: 0.4185283\ttotal: 40s\tremaining: 12.9s\n",
      "378:\tlearn: 0.4184611\ttotal: 40.1s\tremaining: 12.8s\n",
      "379:\tlearn: 0.4183998\ttotal: 40.2s\tremaining: 12.7s\n",
      "380:\tlearn: 0.4183527\ttotal: 40.3s\tremaining: 12.6s\n",
      "381:\tlearn: 0.4182979\ttotal: 40.4s\tremaining: 12.5s\n",
      "382:\tlearn: 0.4182419\ttotal: 40.5s\tremaining: 12.4s\n",
      "383:\tlearn: 0.4181920\ttotal: 40.6s\tremaining: 12.3s\n",
      "384:\tlearn: 0.4181381\ttotal: 40.7s\tremaining: 12.1s\n",
      "385:\tlearn: 0.4180914\ttotal: 40.8s\tremaining: 12s\n",
      "386:\tlearn: 0.4180311\ttotal: 40.9s\tremaining: 11.9s\n",
      "387:\tlearn: 0.4179744\ttotal: 41s\tremaining: 11.8s\n",
      "388:\tlearn: 0.4179285\ttotal: 41.1s\tremaining: 11.7s\n",
      "389:\tlearn: 0.4178724\ttotal: 41.2s\tremaining: 11.6s\n",
      "390:\tlearn: 0.4178174\ttotal: 41.3s\tremaining: 11.5s\n",
      "391:\tlearn: 0.4177607\ttotal: 41.4s\tremaining: 11.4s\n",
      "392:\tlearn: 0.4177011\ttotal: 41.5s\tremaining: 11.3s\n",
      "393:\tlearn: 0.4176432\ttotal: 41.6s\tremaining: 11.2s\n",
      "394:\tlearn: 0.4175836\ttotal: 41.7s\tremaining: 11.1s\n",
      "395:\tlearn: 0.4175307\ttotal: 41.8s\tremaining: 11s\n",
      "396:\tlearn: 0.4174720\ttotal: 41.9s\tremaining: 10.9s\n",
      "397:\tlearn: 0.4174221\ttotal: 42s\tremaining: 10.8s\n",
      "398:\tlearn: 0.4173713\ttotal: 42.1s\tremaining: 10.7s\n",
      "399:\tlearn: 0.4173110\ttotal: 42.2s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4172535\ttotal: 42.3s\tremaining: 10.4s\n",
      "401:\tlearn: 0.4172069\ttotal: 42.4s\tremaining: 10.3s\n",
      "402:\tlearn: 0.4171491\ttotal: 42.5s\tremaining: 10.2s\n",
      "403:\tlearn: 0.4170837\ttotal: 42.6s\tremaining: 10.1s\n",
      "404:\tlearn: 0.4170275\ttotal: 42.7s\tremaining: 10s\n",
      "405:\tlearn: 0.4169744\ttotal: 42.8s\tremaining: 9.91s\n",
      "406:\tlearn: 0.4169246\ttotal: 42.9s\tremaining: 9.8s\n",
      "407:\tlearn: 0.4168712\ttotal: 43s\tremaining: 9.69s\n",
      "408:\tlearn: 0.4168144\ttotal: 43.1s\tremaining: 9.59s\n",
      "409:\tlearn: 0.4167637\ttotal: 43.2s\tremaining: 9.48s\n",
      "410:\tlearn: 0.4167040\ttotal: 43.3s\tremaining: 9.37s\n",
      "411:\tlearn: 0.4166525\ttotal: 43.4s\tremaining: 9.27s\n",
      "412:\tlearn: 0.4165993\ttotal: 43.5s\tremaining: 9.16s\n",
      "413:\tlearn: 0.4165474\ttotal: 43.6s\tremaining: 9.05s\n",
      "414:\tlearn: 0.4165020\ttotal: 43.7s\tremaining: 8.95s\n",
      "415:\tlearn: 0.4164376\ttotal: 43.8s\tremaining: 8.84s\n",
      "416:\tlearn: 0.4163839\ttotal: 43.9s\tremaining: 8.73s\n",
      "417:\tlearn: 0.4163343\ttotal: 44s\tremaining: 8.63s\n",
      "418:\tlearn: 0.4162688\ttotal: 44.1s\tremaining: 8.52s\n",
      "419:\tlearn: 0.4162074\ttotal: 44.2s\tremaining: 8.41s\n",
      "420:\tlearn: 0.4161577\ttotal: 44.3s\tremaining: 8.31s\n",
      "421:\tlearn: 0.4161163\ttotal: 44.4s\tremaining: 8.21s\n",
      "422:\tlearn: 0.4160548\ttotal: 44.5s\tremaining: 8.1s\n",
      "423:\tlearn: 0.4160003\ttotal: 44.6s\tremaining: 7.99s\n",
      "424:\tlearn: 0.4159386\ttotal: 44.7s\tremaining: 7.89s\n",
      "425:\tlearn: 0.4158778\ttotal: 44.8s\tremaining: 7.78s\n",
      "426:\tlearn: 0.4158376\ttotal: 44.9s\tremaining: 7.67s\n",
      "427:\tlearn: 0.4157865\ttotal: 45s\tremaining: 7.57s\n",
      "428:\tlearn: 0.4157312\ttotal: 45.1s\tremaining: 7.46s\n",
      "429:\tlearn: 0.4156816\ttotal: 45.2s\tremaining: 7.36s\n",
      "430:\tlearn: 0.4156261\ttotal: 45.3s\tremaining: 7.25s\n",
      "431:\tlearn: 0.4155785\ttotal: 45.4s\tremaining: 7.14s\n",
      "432:\tlearn: 0.4155279\ttotal: 45.5s\tremaining: 7.04s\n",
      "433:\tlearn: 0.4154709\ttotal: 45.6s\tremaining: 6.93s\n",
      "434:\tlearn: 0.4154101\ttotal: 45.7s\tremaining: 6.83s\n",
      "435:\tlearn: 0.4153479\ttotal: 45.8s\tremaining: 6.72s\n",
      "436:\tlearn: 0.4152817\ttotal: 45.9s\tremaining: 6.62s\n",
      "437:\tlearn: 0.4152247\ttotal: 46s\tremaining: 6.51s\n",
      "438:\tlearn: 0.4151675\ttotal: 46.1s\tremaining: 6.41s\n",
      "439:\tlearn: 0.4151108\ttotal: 46.2s\tremaining: 6.3s\n",
      "440:\tlearn: 0.4150517\ttotal: 46.3s\tremaining: 6.2s\n",
      "441:\tlearn: 0.4149884\ttotal: 46.4s\tremaining: 6.09s\n",
      "442:\tlearn: 0.4149326\ttotal: 46.5s\tremaining: 5.99s\n",
      "443:\tlearn: 0.4148747\ttotal: 46.6s\tremaining: 5.88s\n",
      "444:\tlearn: 0.4148292\ttotal: 46.7s\tremaining: 5.78s\n",
      "445:\tlearn: 0.4147820\ttotal: 46.8s\tremaining: 5.67s\n",
      "446:\tlearn: 0.4147302\ttotal: 46.9s\tremaining: 5.56s\n",
      "447:\tlearn: 0.4146743\ttotal: 47s\tremaining: 5.46s\n",
      "448:\tlearn: 0.4146266\ttotal: 47.1s\tremaining: 5.35s\n",
      "449:\tlearn: 0.4145686\ttotal: 47.2s\tremaining: 5.24s\n",
      "450:\tlearn: 0.4145204\ttotal: 47.3s\tremaining: 5.14s\n",
      "451:\tlearn: 0.4144719\ttotal: 47.4s\tremaining: 5.04s\n",
      "452:\tlearn: 0.4144104\ttotal: 47.5s\tremaining: 4.93s\n",
      "453:\tlearn: 0.4143562\ttotal: 47.6s\tremaining: 4.83s\n",
      "454:\tlearn: 0.4143075\ttotal: 47.7s\tremaining: 4.72s\n",
      "455:\tlearn: 0.4142555\ttotal: 47.8s\tremaining: 4.62s\n",
      "456:\tlearn: 0.4141966\ttotal: 47.9s\tremaining: 4.51s\n",
      "457:\tlearn: 0.4141330\ttotal: 48.1s\tremaining: 4.41s\n",
      "458:\tlearn: 0.4140676\ttotal: 48.2s\tremaining: 4.3s\n",
      "459:\tlearn: 0.4140144\ttotal: 48.3s\tremaining: 4.2s\n",
      "460:\tlearn: 0.4139487\ttotal: 48.4s\tremaining: 4.09s\n",
      "461:\tlearn: 0.4139028\ttotal: 48.5s\tremaining: 3.98s\n",
      "462:\tlearn: 0.4138330\ttotal: 48.6s\tremaining: 3.88s\n",
      "463:\tlearn: 0.4137846\ttotal: 48.7s\tremaining: 3.77s\n",
      "464:\tlearn: 0.4137230\ttotal: 48.8s\tremaining: 3.67s\n",
      "465:\tlearn: 0.4136608\ttotal: 48.9s\tremaining: 3.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466:\tlearn: 0.4136066\ttotal: 49s\tremaining: 3.46s\n",
      "467:\tlearn: 0.4135482\ttotal: 49.1s\tremaining: 3.36s\n",
      "468:\tlearn: 0.4134918\ttotal: 49.2s\tremaining: 3.25s\n",
      "469:\tlearn: 0.4134452\ttotal: 49.3s\tremaining: 3.15s\n",
      "470:\tlearn: 0.4133944\ttotal: 49.4s\tremaining: 3.04s\n",
      "471:\tlearn: 0.4133453\ttotal: 49.5s\tremaining: 2.94s\n",
      "472:\tlearn: 0.4132912\ttotal: 49.6s\tremaining: 2.83s\n",
      "473:\tlearn: 0.4132318\ttotal: 49.7s\tremaining: 2.73s\n",
      "474:\tlearn: 0.4131792\ttotal: 49.8s\tremaining: 2.62s\n",
      "475:\tlearn: 0.4131236\ttotal: 49.9s\tremaining: 2.52s\n",
      "476:\tlearn: 0.4130795\ttotal: 50s\tremaining: 2.41s\n",
      "477:\tlearn: 0.4130343\ttotal: 50.1s\tremaining: 2.31s\n",
      "478:\tlearn: 0.4129856\ttotal: 50.2s\tremaining: 2.2s\n",
      "479:\tlearn: 0.4129125\ttotal: 50.4s\tremaining: 2.1s\n",
      "480:\tlearn: 0.4128647\ttotal: 50.5s\tremaining: 1.99s\n",
      "481:\tlearn: 0.4128080\ttotal: 50.6s\tremaining: 1.89s\n",
      "482:\tlearn: 0.4127619\ttotal: 50.7s\tremaining: 1.78s\n",
      "483:\tlearn: 0.4127002\ttotal: 50.8s\tremaining: 1.68s\n",
      "484:\tlearn: 0.4126441\ttotal: 50.9s\tremaining: 1.57s\n",
      "485:\tlearn: 0.4125920\ttotal: 51s\tremaining: 1.47s\n",
      "486:\tlearn: 0.4125459\ttotal: 51.1s\tremaining: 1.36s\n",
      "487:\tlearn: 0.4124904\ttotal: 51.2s\tremaining: 1.26s\n",
      "488:\tlearn: 0.4124304\ttotal: 51.3s\tremaining: 1.15s\n",
      "489:\tlearn: 0.4123731\ttotal: 51.4s\tremaining: 1.05s\n",
      "490:\tlearn: 0.4123270\ttotal: 51.5s\tremaining: 944ms\n",
      "491:\tlearn: 0.4122738\ttotal: 51.6s\tremaining: 839ms\n",
      "492:\tlearn: 0.4122275\ttotal: 51.7s\tremaining: 734ms\n",
      "493:\tlearn: 0.4121729\ttotal: 51.8s\tremaining: 629ms\n",
      "494:\tlearn: 0.4121056\ttotal: 51.9s\tremaining: 524ms\n",
      "495:\tlearn: 0.4120571\ttotal: 52s\tremaining: 420ms\n",
      "496:\tlearn: 0.4120039\ttotal: 52.1s\tremaining: 315ms\n",
      "497:\tlearn: 0.4119639\ttotal: 52.2s\tremaining: 210ms\n",
      "498:\tlearn: 0.4119238\ttotal: 52.3s\tremaining: 105ms\n",
      "499:\tlearn: 0.4118645\ttotal: 52.4s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8428006492447248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 23:30:38.048770 140266857396032 deprecation.py:506] From /home/trent/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0905 23:30:38.300745 140266857396032 deprecation.py:323] From /home/trent/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 3s 9us/sample - loss: 0.5453 - auc: 0.7805 - val_loss: 0.4737 - val_auc: 0.8161\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4617 - auc: 0.8268 - val_loss: 0.4658 - val_auc: 0.8218\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4518 - auc: 0.8340 - val_loss: 0.4646 - val_auc: 0.8226\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4489 - auc: 0.8364 - val_loss: 0.4637 - val_auc: 0.8231\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4477 - auc: 0.8375 - val_loss: 0.4638 - val_auc: 0.8239\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4476 - auc: 0.8375 - val_loss: 0.4642 - val_auc: 0.8239\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4473 - auc: 0.8378 - val_loss: 0.4643 - val_auc: 0.8249\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4472 - auc: 0.8377 - val_loss: 0.4642 - val_auc: 0.8234\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4473 - auc: 0.8377 - val_loss: 0.4639 - val_auc: 0.8244\n",
      "Epoch 10/100\n",
      "282624/284999 [============================>.] - ETA: 0s - loss: 0.4472 - auc: 0.8377\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4472 - auc: 0.8377 - val_loss: 0.4639 - val_auc: 0.8229\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4470 - auc: 0.8381 - val_loss: 0.4637 - val_auc: 0.8241\n",
      "Epoch 12/100\n",
      "284672/284999 [============================>.] - ETA: 0s - loss: 0.4470 - auc: 0.8380Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4470 - auc: 0.8380 - val_loss: 0.4643 - val_auc: 0.8236\n",
      "Epoch 00012: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.5578 - auc: 0.7759 - val_loss: 0.4718 - val_auc: 0.8184\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4648 - auc: 0.8249 - val_loss: 0.4606 - val_auc: 0.8264\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4529 - auc: 0.8336 - val_loss: 0.4583 - val_auc: 0.8278\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4494 - auc: 0.8364 - val_loss: 0.4571 - val_auc: 0.8294\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8370 - val_loss: 0.4570 - val_auc: 0.8289\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4481 - auc: 0.8370 - val_loss: 0.4571 - val_auc: 0.8287\n",
      "Epoch 7/100\n",
      "284672/284999 [============================>.] - ETA: 0s - loss: 0.4478 - auc: 0.8374\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4478 - auc: 0.8374 - val_loss: 0.4568 - val_auc: 0.8288\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4474 - auc: 0.8379 - val_loss: 0.4566 - val_auc: 0.8291\n",
      "Epoch 9/100\n",
      "280576/284999 [============================>.] - ETA: 0s - loss: 0.4473 - auc: 0.8377Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4474 - auc: 0.8378 - val_loss: 0.4568 - val_auc: 0.8296\n",
      "Epoch 00009: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.5597 - auc: 0.7722 - val_loss: 0.4587 - val_auc: 0.8284\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4680 - auc: 0.8218 - val_loss: 0.4464 - val_auc: 0.8386\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4547 - auc: 0.8319 - val_loss: 0.4433 - val_auc: 0.8413\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4511 - auc: 0.8347 - val_loss: 0.4420 - val_auc: 0.8417\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4496 - auc: 0.8358 - val_loss: 0.4414 - val_auc: 0.8427\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4486 - auc: 0.8366 - val_loss: 0.4413 - val_auc: 0.8434\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4486 - auc: 0.8367 - val_loss: 0.4414 - val_auc: 0.8422\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4485 - auc: 0.8366 - val_loss: 0.4412 - val_auc: 0.8425\n",
      "Epoch 9/100\n",
      "283648/284999 [============================>.] - ETA: 0s - loss: 0.4483 - auc: 0.8369\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8366 - val_loss: 0.4412 - val_auc: 0.8432\n",
      "Epoch 10/100\n",
      "281600/284999 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8372Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8371 - val_loss: 0.4413 - val_auc: 0.8429\n",
      "Epoch 00010: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.5135 - auc: 0.8056 - val_loss: 0.4485 - val_auc: 0.8368\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4577 - auc: 0.8299 - val_loss: 0.4425 - val_auc: 0.8415\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4514 - auc: 0.8346 - val_loss: 0.4410 - val_auc: 0.8428\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4500 - auc: 0.8355 - val_loss: 0.4402 - val_auc: 0.8432\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4488 - auc: 0.8366 - val_loss: 0.4399 - val_auc: 0.8434\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4490 - auc: 0.8365 - val_loss: 0.4402 - val_auc: 0.8432\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4486 - auc: 0.8368 - val_loss: 0.4400 - val_auc: 0.8428\n",
      "Epoch 8/100\n",
      "282624/284999 [============================>.] - ETA: 0s - loss: 0.4484 - auc: 0.8369Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8368 - val_loss: 0.4403 - val_auc: 0.8438\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5977 - auc: 0.7384 - val_loss: 0.4692 - val_auc: 0.8212\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4785 - auc: 0.8151 - val_loss: 0.4515 - val_auc: 0.8339\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4580 - auc: 0.8293 - val_loss: 0.4474 - val_auc: 0.8368\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4518 - auc: 0.8341 - val_loss: 0.4459 - val_auc: 0.8390\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4496 - auc: 0.8360 - val_loss: 0.4460 - val_auc: 0.8388\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4487 - auc: 0.8365 - val_loss: 0.4458 - val_auc: 0.8386\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8370 - val_loss: 0.4457 - val_auc: 0.8392\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8370 - val_loss: 0.4456 - val_auc: 0.8391\n",
      "Epoch 9/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8372Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4479 - auc: 0.8372 - val_loss: 0.4457 - val_auc: 0.8388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5969 - auc: 0.7375 - val_loss: 0.4709 - val_auc: 0.8189\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4778 - auc: 0.8155 - val_loss: 0.4529 - val_auc: 0.8324\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4579 - auc: 0.8293 - val_loss: 0.4481 - val_auc: 0.8376\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4516 - auc: 0.8342 - val_loss: 0.4466 - val_auc: 0.8383\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4493 - auc: 0.8361 - val_loss: 0.4462 - val_auc: 0.8391\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4485 - auc: 0.8366 - val_loss: 0.4461 - val_auc: 0.8386\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8368 - val_loss: 0.4462 - val_auc: 0.8390\n",
      "Epoch 8/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4484 - auc: 0.8368\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8367 - val_loss: 0.4462 - val_auc: 0.8380\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4480 - auc: 0.8371 - val_loss: 0.4461 - val_auc: 0.8389\n",
      "Epoch 10/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8374Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8373 - val_loss: 0.4461 - val_auc: 0.8393\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5300 - auc: 0.7979 - val_loss: 0.4603 - val_auc: 0.8270\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4581 - auc: 0.8297 - val_loss: 0.4538 - val_auc: 0.8317\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4515 - auc: 0.8345 - val_loss: 0.4519 - val_auc: 0.8333\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4492 - auc: 0.8363 - val_loss: 0.4514 - val_auc: 0.8340\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4487 - auc: 0.8366 - val_loss: 0.4513 - val_auc: 0.8338\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8374 - val_loss: 0.4513 - val_auc: 0.8332\n",
      "Epoch 7/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4481 - auc: 0.8371\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8372 - val_loss: 0.4513 - val_auc: 0.8335\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4478 - auc: 0.8375 - val_loss: 0.4512 - val_auc: 0.8348\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4477 - auc: 0.8374 - val_loss: 0.4512 - val_auc: 0.8349\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4477 - auc: 0.8375 - val_loss: 0.4511 - val_auc: 0.8341\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4474 - auc: 0.8376 - val_loss: 0.4512 - val_auc: 0.8338\n",
      "Epoch 12/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4478 - auc: 0.8375\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4477 - auc: 0.8375 - val_loss: 0.4512 - val_auc: 0.8337\n",
      "Epoch 13/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4476 - auc: 0.8377Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4475 - auc: 0.8378 - val_loss: 0.4512 - val_auc: 0.8351\n",
      "Epoch 00013: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5682 - auc: 0.7606 - val_loss: 0.4658 - val_auc: 0.8226\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4701 - auc: 0.8204 - val_loss: 0.4516 - val_auc: 0.8348\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4554 - auc: 0.8313 - val_loss: 0.4476 - val_auc: 0.8379\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4511 - auc: 0.8345 - val_loss: 0.4462 - val_auc: 0.8387\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4495 - auc: 0.8360 - val_loss: 0.4457 - val_auc: 0.8393\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4489 - auc: 0.8366 - val_loss: 0.4455 - val_auc: 0.8398\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4483 - auc: 0.8370 - val_loss: 0.4452 - val_auc: 0.8397\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4479 - auc: 0.8373 - val_loss: 0.4454 - val_auc: 0.8395\n",
      "Epoch 9/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4482 - auc: 0.8370\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8370 - val_loss: 0.4456 - val_auc: 0.8388\n",
      "Epoch 10/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8373Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4478 - auc: 0.8374 - val_loss: 0.4454 - val_auc: 0.8397\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5480 - auc: 0.7833 - val_loss: 0.4509 - val_auc: 0.8358\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4639 - auc: 0.8251 - val_loss: 0.4410 - val_auc: 0.8442\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4534 - auc: 0.8331 - val_loss: 0.4374 - val_auc: 0.8464\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4507 - auc: 0.8349 - val_loss: 0.4368 - val_auc: 0.8469\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4494 - auc: 0.8360 - val_loss: 0.4362 - val_auc: 0.8474\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4492 - auc: 0.8362 - val_loss: 0.4360 - val_auc: 0.8474\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4491 - auc: 0.8362 - val_loss: 0.4358 - val_auc: 0.8478\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4486 - auc: 0.8367 - val_loss: 0.4356 - val_auc: 0.8469\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4487 - auc: 0.8367 - val_loss: 0.4356 - val_auc: 0.8473\n",
      "Epoch 10/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4482 - auc: 0.8370Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4488 - auc: 0.8364 - val_loss: 0.4360 - val_auc: 0.8480\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5462 - auc: 0.7805 - val_loss: 0.4566 - val_auc: 0.8297\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4643 - auc: 0.8248 - val_loss: 0.4471 - val_auc: 0.8379\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4530 - auc: 0.8332 - val_loss: 0.4453 - val_auc: 0.8402\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4500 - auc: 0.8355 - val_loss: 0.4446 - val_auc: 0.8401\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4491 - auc: 0.8362 - val_loss: 0.4447 - val_auc: 0.8386\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8366 - val_loss: 0.4445 - val_auc: 0.8403\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8371 - val_loss: 0.4445 - val_auc: 0.8396\n",
      "Epoch 8/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4480 - auc: 0.8371Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8370 - val_loss: 0.4447 - val_auc: 0.8398\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5288 - auc: 0.7948 - val_loss: 0.4494 - val_auc: 0.8364\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4594 - auc: 0.8285 - val_loss: 0.4427 - val_auc: 0.8415\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4520 - auc: 0.8341 - val_loss: 0.4406 - val_auc: 0.8439\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4496 - auc: 0.8360 - val_loss: 0.4399 - val_auc: 0.8432\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4489 - auc: 0.8364 - val_loss: 0.4399 - val_auc: 0.8437\n",
      "Epoch 6/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4489 - auc: 0.8363\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4489 - auc: 0.8363 - val_loss: 0.4400 - val_auc: 0.8438\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8369 - val_loss: 0.4399 - val_auc: 0.8445\n",
      "Epoch 8/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4483 - auc: 0.8368Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4483 - auc: 0.8369 - val_loss: 0.4397 - val_auc: 0.8442\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5342 - auc: 0.7877 - val_loss: 0.4451 - val_auc: 0.8407\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4617 - auc: 0.8271 - val_loss: 0.4392 - val_auc: 0.8455\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4531 - auc: 0.8333 - val_loss: 0.4381 - val_auc: 0.8456\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4502 - auc: 0.8355 - val_loss: 0.4378 - val_auc: 0.8460\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4490 - auc: 0.8363 - val_loss: 0.4376 - val_auc: 0.8449\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4488 - auc: 0.8367 - val_loss: 0.4379 - val_auc: 0.8463\n",
      "Epoch 7/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4487 - auc: 0.8367Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4487 - auc: 0.8367 - val_loss: 0.4380 - val_auc: 0.8456\n",
      "Epoch 00007: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5494 - auc: 0.7791 - val_loss: 0.4497 - val_auc: 0.8363\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4641 - auc: 0.8248 - val_loss: 0.4398 - val_auc: 0.8441\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4530 - auc: 0.8332 - val_loss: 0.4374 - val_auc: 0.8463\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4506 - auc: 0.8350 - val_loss: 0.4366 - val_auc: 0.8466\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4493 - auc: 0.8361 - val_loss: 0.4364 - val_auc: 0.8469\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4488 - auc: 0.8364 - val_loss: 0.4363 - val_auc: 0.8476\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4486 - auc: 0.8367 - val_loss: 0.4365 - val_auc: 0.8477\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4484 - auc: 0.8367 - val_loss: 0.4365 - val_auc: 0.8474\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8366 - val_loss: 0.4362 - val_auc: 0.8474\n",
      "Epoch 10/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4484 - auc: 0.8369\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8368 - val_loss: 0.4366 - val_auc: 0.8476\n",
      "Epoch 11/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4484 - auc: 0.8368Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4483 - auc: 0.8369 - val_loss: 0.4364 - val_auc: 0.8476\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5671 - auc: 0.7653 - val_loss: 0.4748 - val_auc: 0.8160\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4689 - auc: 0.8213 - val_loss: 0.4601 - val_auc: 0.8265\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4547 - auc: 0.8319 - val_loss: 0.4572 - val_auc: 0.8297\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4506 - auc: 0.8350 - val_loss: 0.4551 - val_auc: 0.8304\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4490 - auc: 0.8364 - val_loss: 0.4549 - val_auc: 0.8315\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4482 - auc: 0.8372 - val_loss: 0.4545 - val_auc: 0.8316\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4479 - auc: 0.8373 - val_loss: 0.4543 - val_auc: 0.8317\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4477 - auc: 0.8374 - val_loss: 0.4541 - val_auc: 0.8322\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4476 - auc: 0.8376 - val_loss: 0.4541 - val_auc: 0.8307\n",
      "Epoch 10/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4473 - auc: 0.8376Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4474 - auc: 0.8377 - val_loss: 0.4542 - val_auc: 0.8314\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5735 - auc: 0.7657 - val_loss: 0.4624 - val_auc: 0.8266\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4695 - auc: 0.8214 - val_loss: 0.4454 - val_auc: 0.8403\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4550 - auc: 0.8318 - val_loss: 0.4418 - val_auc: 0.8429\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4508 - auc: 0.8349 - val_loss: 0.4400 - val_auc: 0.8441\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4494 - auc: 0.8359 - val_loss: 0.4400 - val_auc: 0.8436\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4487 - auc: 0.8366 - val_loss: 0.4395 - val_auc: 0.8436\n",
      "Epoch 7/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4485 - auc: 0.8368\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8367 - val_loss: 0.4392 - val_auc: 0.8441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8371 - val_loss: 0.4393 - val_auc: 0.8446\n",
      "Epoch 9/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4485 - auc: 0.8367Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8370 - val_loss: 0.4392 - val_auc: 0.8445\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5388 - auc: 0.7865 - val_loss: 0.4520 - val_auc: 0.8348\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4623 - auc: 0.8266 - val_loss: 0.4435 - val_auc: 0.8412\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4522 - auc: 0.8338 - val_loss: 0.4415 - val_auc: 0.8437\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4501 - auc: 0.8353 - val_loss: 0.4410 - val_auc: 0.8437\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4491 - auc: 0.8363 - val_loss: 0.4407 - val_auc: 0.8444\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8369 - val_loss: 0.4405 - val_auc: 0.8442\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4486 - auc: 0.8366 - val_loss: 0.4406 - val_auc: 0.8438\n",
      "Epoch 8/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4485 - auc: 0.8369Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8370 - val_loss: 0.4406 - val_auc: 0.8438\n",
      "Epoch 00008: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.5329 - auc: 0.7904 - val_loss: 0.4453 - val_auc: 0.8399\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4605 - auc: 0.8275 - val_loss: 0.4384 - val_auc: 0.8455\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4519 - auc: 0.8340 - val_loss: 0.4361 - val_auc: 0.8487\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4501 - auc: 0.8356 - val_loss: 0.4355 - val_auc: 0.8476\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4493 - auc: 0.8360 - val_loss: 0.4361 - val_auc: 0.8479\n",
      "Epoch 6/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4486 - auc: 0.8365\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4490 - auc: 0.8363 - val_loss: 0.4359 - val_auc: 0.8476\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8367 - val_loss: 0.4353 - val_auc: 0.8478\n",
      "Epoch 8/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4488 - auc: 0.8364Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4489 - auc: 0.8364 - val_loss: 0.4354 - val_auc: 0.8486\n",
      "Epoch 00008: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.5567 - auc: 0.7720 - val_loss: 0.4585 - val_auc: 0.8289\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4667 - auc: 0.8233 - val_loss: 0.4477 - val_auc: 0.8374\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4539 - auc: 0.8324 - val_loss: 0.4455 - val_auc: 0.8387\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4501 - auc: 0.8357 - val_loss: 0.4444 - val_auc: 0.8396\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4488 - auc: 0.8366 - val_loss: 0.4442 - val_auc: 0.8401\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4486 - auc: 0.8367 - val_loss: 0.4444 - val_auc: 0.8399\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4486 - auc: 0.8368 - val_loss: 0.4442 - val_auc: 0.8398\n",
      "Epoch 8/100\n",
      "284672/285001 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8372\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4480 - auc: 0.8371 - val_loss: 0.4442 - val_auc: 0.8394\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4482 - auc: 0.8370 - val_loss: 0.4442 - val_auc: 0.8398\n",
      "Epoch 10/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4482 - auc: 0.8369Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8372 - val_loss: 0.4441 - val_auc: 0.8396\n",
      "Epoch 00010: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.5239 - auc: 0.7981 - val_loss: 0.4505 - val_auc: 0.8348\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4586 - auc: 0.8290 - val_loss: 0.4441 - val_auc: 0.8400\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4518 - auc: 0.8341 - val_loss: 0.4428 - val_auc: 0.8415\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4496 - auc: 0.8359 - val_loss: 0.4423 - val_auc: 0.8415\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4492 - auc: 0.8361 - val_loss: 0.4421 - val_auc: 0.8417\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4488 - auc: 0.8363 - val_loss: 0.4424 - val_auc: 0.8415\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4480 - auc: 0.8372 - val_loss: 0.4421 - val_auc: 0.8413\n",
      "Epoch 8/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4482 - auc: 0.8370Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4484 - auc: 0.8369 - val_loss: 0.4420 - val_auc: 0.8417\n",
      "Epoch 00008: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.5559 - auc: 0.7756 - val_loss: 0.4617 - val_auc: 0.8246\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4644 - auc: 0.8245 - val_loss: 0.4512 - val_auc: 0.8347\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4531 - auc: 0.8332 - val_loss: 0.4488 - val_auc: 0.8358\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4494 - auc: 0.8360 - val_loss: 0.4479 - val_auc: 0.8358\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4485 - auc: 0.8368 - val_loss: 0.4476 - val_auc: 0.8369\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4481 - auc: 0.8372 - val_loss: 0.4475 - val_auc: 0.8376\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4481 - auc: 0.8371 - val_loss: 0.4475 - val_auc: 0.8356\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4479 - auc: 0.8373 - val_loss: 0.4474 - val_auc: 0.8370\n",
      "Epoch 9/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4478 - auc: 0.8374\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4479 - auc: 0.8373 - val_loss: 0.4474 - val_auc: 0.8370\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277504/285001 [============================>.] - ETA: 0s - loss: 0.4479 - auc: 0.8371Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 8us/sample - loss: 0.4477 - auc: 0.8372 - val_loss: 0.4474 - val_auc: 0.8363\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [2:37:14<10:28:59, 9434.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8396988890792387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8310519640669328\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 1.3min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   4.9s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   4.9s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   4.9s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   4.9s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   4.9s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  12.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  12.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  12.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  13.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=  13.6s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  30.4s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  30.6s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  30.5s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  30.5s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  30.4s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total= 1.7min\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  30.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  30.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  30.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  30.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  30.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  12.8s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  13.0s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  13.2s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  12.8s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=  12.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  44.9s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  46.4s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  45.1s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  44.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  45.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  25.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  25.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  25.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  26.1s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  26.7s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 1.1min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 1.1min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 1.2min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 1.1min\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total= 1.1min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  40.9s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  40.6s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  41.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  41.0s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  40.5s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  51.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  51.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  52.9s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  51.2s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  50.5s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   6.8s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   6.7s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   6.7s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   6.6s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   7.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  23.3s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  23.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  23.5s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  23.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  24.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 50.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8326886397139647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 91.9ms\tremaining: 1m 31s\n",
      "1:\ttotal: 167ms\tremaining: 1m 23s\n",
      "2:\ttotal: 249ms\tremaining: 1m 22s\n",
      "3:\ttotal: 340ms\tremaining: 1m 24s\n",
      "4:\ttotal: 413ms\tremaining: 1m 22s\n",
      "5:\ttotal: 492ms\tremaining: 1m 21s\n",
      "6:\ttotal: 583ms\tremaining: 1m 22s\n",
      "7:\ttotal: 667ms\tremaining: 1m 22s\n",
      "8:\ttotal: 746ms\tremaining: 1m 22s\n",
      "9:\ttotal: 830ms\tremaining: 1m 22s\n",
      "10:\ttotal: 916ms\tremaining: 1m 22s\n",
      "11:\ttotal: 996ms\tremaining: 1m 21s\n",
      "12:\ttotal: 1.09s\tremaining: 1m 22s\n",
      "13:\ttotal: 1.16s\tremaining: 1m 21s\n",
      "14:\ttotal: 1.25s\tremaining: 1m 21s\n",
      "15:\ttotal: 1.33s\tremaining: 1m 21s\n",
      "16:\ttotal: 1.41s\tremaining: 1m 21s\n",
      "17:\ttotal: 1.5s\tremaining: 1m 21s\n",
      "18:\ttotal: 1.58s\tremaining: 1m 21s\n",
      "19:\ttotal: 1.67s\tremaining: 1m 21s\n",
      "20:\ttotal: 1.75s\tremaining: 1m 21s\n",
      "21:\ttotal: 1.84s\tremaining: 1m 21s\n",
      "22:\ttotal: 1.92s\tremaining: 1m 21s\n",
      "23:\ttotal: 2s\tremaining: 1m 21s\n",
      "24:\ttotal: 2.08s\tremaining: 1m 21s\n",
      "25:\ttotal: 2.17s\tremaining: 1m 21s\n",
      "26:\ttotal: 2.26s\tremaining: 1m 21s\n",
      "27:\ttotal: 2.34s\tremaining: 1m 21s\n",
      "28:\ttotal: 2.42s\tremaining: 1m 21s\n",
      "29:\ttotal: 2.51s\tremaining: 1m 21s\n",
      "30:\ttotal: 2.6s\tremaining: 1m 21s\n",
      "31:\ttotal: 2.69s\tremaining: 1m 21s\n",
      "32:\ttotal: 2.77s\tremaining: 1m 21s\n",
      "33:\ttotal: 2.86s\tremaining: 1m 21s\n",
      "34:\ttotal: 2.94s\tremaining: 1m 20s\n",
      "35:\ttotal: 3.02s\tremaining: 1m 20s\n",
      "36:\ttotal: 3.1s\tremaining: 1m 20s\n",
      "37:\ttotal: 3.18s\tremaining: 1m 20s\n",
      "38:\ttotal: 3.27s\tremaining: 1m 20s\n",
      "39:\ttotal: 3.35s\tremaining: 1m 20s\n",
      "40:\ttotal: 3.43s\tremaining: 1m 20s\n",
      "41:\ttotal: 3.52s\tremaining: 1m 20s\n",
      "42:\ttotal: 3.6s\tremaining: 1m 20s\n",
      "43:\ttotal: 3.69s\tremaining: 1m 20s\n",
      "44:\ttotal: 3.77s\tremaining: 1m 20s\n",
      "45:\ttotal: 3.86s\tremaining: 1m 20s\n",
      "46:\ttotal: 3.95s\tremaining: 1m 20s\n",
      "47:\ttotal: 4.03s\tremaining: 1m 19s\n",
      "48:\ttotal: 4.12s\tremaining: 1m 20s\n",
      "49:\ttotal: 4.21s\tremaining: 1m 19s\n",
      "50:\ttotal: 4.29s\tremaining: 1m 19s\n",
      "51:\ttotal: 4.39s\tremaining: 1m 19s\n",
      "52:\ttotal: 4.46s\tremaining: 1m 19s\n",
      "53:\ttotal: 4.55s\tremaining: 1m 19s\n",
      "54:\ttotal: 4.64s\tremaining: 1m 19s\n",
      "55:\ttotal: 4.72s\tremaining: 1m 19s\n",
      "56:\ttotal: 4.8s\tremaining: 1m 19s\n",
      "57:\ttotal: 4.89s\tremaining: 1m 19s\n",
      "58:\ttotal: 4.97s\tremaining: 1m 19s\n",
      "59:\ttotal: 5.04s\tremaining: 1m 19s\n",
      "60:\ttotal: 5.13s\tremaining: 1m 19s\n",
      "61:\ttotal: 5.21s\tremaining: 1m 18s\n",
      "62:\ttotal: 5.3s\tremaining: 1m 18s\n",
      "63:\ttotal: 5.39s\tremaining: 1m 18s\n",
      "64:\ttotal: 5.48s\tremaining: 1m 18s\n",
      "65:\ttotal: 5.56s\tremaining: 1m 18s\n",
      "66:\ttotal: 5.65s\tremaining: 1m 18s\n",
      "67:\ttotal: 5.75s\tremaining: 1m 18s\n",
      "68:\ttotal: 5.82s\tremaining: 1m 18s\n",
      "69:\ttotal: 5.91s\tremaining: 1m 18s\n",
      "70:\ttotal: 5.98s\tremaining: 1m 18s\n",
      "71:\ttotal: 6.06s\tremaining: 1m 18s\n",
      "72:\ttotal: 6.14s\tremaining: 1m 18s\n",
      "73:\ttotal: 6.24s\tremaining: 1m 18s\n",
      "74:\ttotal: 6.33s\tremaining: 1m 18s\n",
      "75:\ttotal: 6.42s\tremaining: 1m 18s\n",
      "76:\ttotal: 6.5s\tremaining: 1m 17s\n",
      "77:\ttotal: 6.59s\tremaining: 1m 17s\n",
      "78:\ttotal: 6.68s\tremaining: 1m 17s\n",
      "79:\ttotal: 6.76s\tremaining: 1m 17s\n",
      "80:\ttotal: 6.84s\tremaining: 1m 17s\n",
      "81:\ttotal: 6.94s\tremaining: 1m 17s\n",
      "82:\ttotal: 7.02s\tremaining: 1m 17s\n",
      "83:\ttotal: 7.09s\tremaining: 1m 17s\n",
      "84:\ttotal: 7.18s\tremaining: 1m 17s\n",
      "85:\ttotal: 7.26s\tremaining: 1m 17s\n",
      "86:\ttotal: 7.34s\tremaining: 1m 17s\n",
      "87:\ttotal: 7.42s\tremaining: 1m 16s\n",
      "88:\ttotal: 7.51s\tremaining: 1m 16s\n",
      "89:\ttotal: 7.6s\tremaining: 1m 16s\n",
      "90:\ttotal: 7.69s\tremaining: 1m 16s\n",
      "91:\ttotal: 7.77s\tremaining: 1m 16s\n",
      "92:\ttotal: 7.86s\tremaining: 1m 16s\n",
      "93:\ttotal: 7.95s\tremaining: 1m 16s\n",
      "94:\ttotal: 8.03s\tremaining: 1m 16s\n",
      "95:\ttotal: 8.11s\tremaining: 1m 16s\n",
      "96:\ttotal: 8.2s\tremaining: 1m 16s\n",
      "97:\ttotal: 8.28s\tremaining: 1m 16s\n",
      "98:\ttotal: 8.37s\tremaining: 1m 16s\n",
      "99:\ttotal: 8.46s\tremaining: 1m 16s\n",
      "100:\ttotal: 8.54s\tremaining: 1m 16s\n",
      "101:\ttotal: 8.63s\tremaining: 1m 15s\n",
      "102:\ttotal: 8.72s\tremaining: 1m 15s\n",
      "103:\ttotal: 8.79s\tremaining: 1m 15s\n",
      "104:\ttotal: 8.88s\tremaining: 1m 15s\n",
      "105:\ttotal: 8.97s\tremaining: 1m 15s\n",
      "106:\ttotal: 9.05s\tremaining: 1m 15s\n",
      "107:\ttotal: 9.14s\tremaining: 1m 15s\n",
      "108:\ttotal: 9.22s\tremaining: 1m 15s\n",
      "109:\ttotal: 9.31s\tremaining: 1m 15s\n",
      "110:\ttotal: 9.39s\tremaining: 1m 15s\n",
      "111:\ttotal: 9.48s\tremaining: 1m 15s\n",
      "112:\ttotal: 9.56s\tremaining: 1m 15s\n",
      "113:\ttotal: 9.65s\tremaining: 1m 15s\n",
      "114:\ttotal: 9.74s\tremaining: 1m 14s\n",
      "115:\ttotal: 9.82s\tremaining: 1m 14s\n",
      "116:\ttotal: 9.9s\tremaining: 1m 14s\n",
      "117:\ttotal: 9.99s\tremaining: 1m 14s\n",
      "118:\ttotal: 10.1s\tremaining: 1m 14s\n",
      "119:\ttotal: 10.2s\tremaining: 1m 14s\n",
      "120:\ttotal: 10.2s\tremaining: 1m 14s\n",
      "121:\ttotal: 10.3s\tremaining: 1m 14s\n",
      "122:\ttotal: 10.4s\tremaining: 1m 14s\n",
      "123:\ttotal: 10.5s\tremaining: 1m 14s\n",
      "124:\ttotal: 10.6s\tremaining: 1m 13s\n",
      "125:\ttotal: 10.6s\tremaining: 1m 13s\n",
      "126:\ttotal: 10.7s\tremaining: 1m 13s\n",
      "127:\ttotal: 10.8s\tremaining: 1m 13s\n",
      "128:\ttotal: 10.9s\tremaining: 1m 13s\n",
      "129:\ttotal: 11s\tremaining: 1m 13s\n",
      "130:\ttotal: 11.1s\tremaining: 1m 13s\n",
      "131:\ttotal: 11.1s\tremaining: 1m 13s\n",
      "132:\ttotal: 11.2s\tremaining: 1m 13s\n",
      "133:\ttotal: 11.3s\tremaining: 1m 13s\n",
      "134:\ttotal: 11.4s\tremaining: 1m 12s\n",
      "135:\ttotal: 11.5s\tremaining: 1m 12s\n",
      "136:\ttotal: 11.5s\tremaining: 1m 12s\n",
      "137:\ttotal: 11.6s\tremaining: 1m 12s\n",
      "138:\ttotal: 11.7s\tremaining: 1m 12s\n",
      "139:\ttotal: 11.8s\tremaining: 1m 12s\n",
      "140:\ttotal: 11.9s\tremaining: 1m 12s\n",
      "141:\ttotal: 12s\tremaining: 1m 12s\n",
      "142:\ttotal: 12s\tremaining: 1m 12s\n",
      "143:\ttotal: 12.1s\tremaining: 1m 11s\n",
      "144:\ttotal: 12.2s\tremaining: 1m 11s\n",
      "145:\ttotal: 12.3s\tremaining: 1m 11s\n",
      "146:\ttotal: 12.3s\tremaining: 1m 11s\n",
      "147:\ttotal: 12.4s\tremaining: 1m 11s\n",
      "148:\ttotal: 12.5s\tremaining: 1m 11s\n",
      "149:\ttotal: 12.6s\tremaining: 1m 11s\n",
      "150:\ttotal: 12.7s\tremaining: 1m 11s\n",
      "151:\ttotal: 12.8s\tremaining: 1m 11s\n",
      "152:\ttotal: 12.8s\tremaining: 1m 11s\n",
      "153:\ttotal: 12.9s\tremaining: 1m 10s\n",
      "154:\ttotal: 13s\tremaining: 1m 10s\n",
      "155:\ttotal: 13.1s\tremaining: 1m 10s\n",
      "156:\ttotal: 13.2s\tremaining: 1m 10s\n",
      "157:\ttotal: 13.3s\tremaining: 1m 10s\n",
      "158:\ttotal: 13.3s\tremaining: 1m 10s\n",
      "159:\ttotal: 13.4s\tremaining: 1m 10s\n",
      "160:\ttotal: 13.5s\tremaining: 1m 10s\n",
      "161:\ttotal: 13.6s\tremaining: 1m 10s\n",
      "162:\ttotal: 13.7s\tremaining: 1m 10s\n",
      "163:\ttotal: 13.8s\tremaining: 1m 10s\n",
      "164:\ttotal: 13.8s\tremaining: 1m 10s\n",
      "165:\ttotal: 13.9s\tremaining: 1m 9s\n",
      "166:\ttotal: 14s\tremaining: 1m 9s\n",
      "167:\ttotal: 14.1s\tremaining: 1m 9s\n",
      "168:\ttotal: 14.2s\tremaining: 1m 9s\n",
      "169:\ttotal: 14.2s\tremaining: 1m 9s\n",
      "170:\ttotal: 14.3s\tremaining: 1m 9s\n",
      "171:\ttotal: 14.4s\tremaining: 1m 9s\n",
      "172:\ttotal: 14.5s\tremaining: 1m 9s\n",
      "173:\ttotal: 14.6s\tremaining: 1m 9s\n",
      "174:\ttotal: 14.6s\tremaining: 1m 9s\n",
      "175:\ttotal: 14.7s\tremaining: 1m 8s\n",
      "176:\ttotal: 14.8s\tremaining: 1m 8s\n",
      "177:\ttotal: 14.9s\tremaining: 1m 8s\n",
      "178:\ttotal: 15s\tremaining: 1m 8s\n",
      "179:\ttotal: 15s\tremaining: 1m 8s\n",
      "180:\ttotal: 15.1s\tremaining: 1m 8s\n",
      "181:\ttotal: 15.2s\tremaining: 1m 8s\n",
      "182:\ttotal: 15.2s\tremaining: 1m 8s\n",
      "183:\ttotal: 15.3s\tremaining: 1m 7s\n",
      "184:\ttotal: 15.4s\tremaining: 1m 7s\n",
      "185:\ttotal: 15.5s\tremaining: 1m 7s\n",
      "186:\ttotal: 15.6s\tremaining: 1m 7s\n",
      "187:\ttotal: 15.7s\tremaining: 1m 7s\n",
      "188:\ttotal: 15.7s\tremaining: 1m 7s\n",
      "189:\ttotal: 15.8s\tremaining: 1m 7s\n",
      "190:\ttotal: 15.9s\tremaining: 1m 7s\n",
      "191:\ttotal: 16s\tremaining: 1m 7s\n",
      "192:\ttotal: 16.1s\tremaining: 1m 7s\n",
      "193:\ttotal: 16.1s\tremaining: 1m 7s\n",
      "194:\ttotal: 16.2s\tremaining: 1m 6s\n",
      "195:\ttotal: 16.3s\tremaining: 1m 6s\n",
      "196:\ttotal: 16.4s\tremaining: 1m 6s\n",
      "197:\ttotal: 16.5s\tremaining: 1m 6s\n",
      "198:\ttotal: 16.5s\tremaining: 1m 6s\n",
      "199:\ttotal: 16.6s\tremaining: 1m 6s\n",
      "200:\ttotal: 16.7s\tremaining: 1m 6s\n",
      "201:\ttotal: 16.8s\tremaining: 1m 6s\n",
      "202:\ttotal: 16.9s\tremaining: 1m 6s\n",
      "203:\ttotal: 16.9s\tremaining: 1m 6s\n",
      "204:\ttotal: 17s\tremaining: 1m 5s\n",
      "205:\ttotal: 17.1s\tremaining: 1m 5s\n",
      "206:\ttotal: 17.1s\tremaining: 1m 5s\n",
      "207:\ttotal: 17.2s\tremaining: 1m 5s\n",
      "208:\ttotal: 17.3s\tremaining: 1m 5s\n",
      "209:\ttotal: 17.4s\tremaining: 1m 5s\n",
      "210:\ttotal: 17.5s\tremaining: 1m 5s\n",
      "211:\ttotal: 17.6s\tremaining: 1m 5s\n",
      "212:\ttotal: 17.6s\tremaining: 1m 5s\n",
      "213:\ttotal: 17.7s\tremaining: 1m 5s\n",
      "214:\ttotal: 17.8s\tremaining: 1m 5s\n",
      "215:\ttotal: 17.9s\tremaining: 1m 4s\n",
      "216:\ttotal: 18s\tremaining: 1m 4s\n",
      "217:\ttotal: 18s\tremaining: 1m 4s\n",
      "218:\ttotal: 18.1s\tremaining: 1m 4s\n",
      "219:\ttotal: 18.2s\tremaining: 1m 4s\n",
      "220:\ttotal: 18.3s\tremaining: 1m 4s\n",
      "221:\ttotal: 18.3s\tremaining: 1m 4s\n",
      "222:\ttotal: 18.4s\tremaining: 1m 4s\n",
      "223:\ttotal: 18.5s\tremaining: 1m 4s\n",
      "224:\ttotal: 18.6s\tremaining: 1m 4s\n",
      "225:\ttotal: 18.7s\tremaining: 1m 3s\n",
      "226:\ttotal: 18.7s\tremaining: 1m 3s\n",
      "227:\ttotal: 18.8s\tremaining: 1m 3s\n",
      "228:\ttotal: 18.9s\tremaining: 1m 3s\n",
      "229:\ttotal: 19s\tremaining: 1m 3s\n",
      "230:\ttotal: 19.1s\tremaining: 1m 3s\n",
      "231:\ttotal: 19.1s\tremaining: 1m 3s\n",
      "232:\ttotal: 19.2s\tremaining: 1m 3s\n",
      "233:\ttotal: 19.3s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234:\ttotal: 19.4s\tremaining: 1m 3s\n",
      "235:\ttotal: 19.4s\tremaining: 1m 2s\n",
      "236:\ttotal: 19.5s\tremaining: 1m 2s\n",
      "237:\ttotal: 19.6s\tremaining: 1m 2s\n",
      "238:\ttotal: 19.7s\tremaining: 1m 2s\n",
      "239:\ttotal: 19.8s\tremaining: 1m 2s\n",
      "240:\ttotal: 19.9s\tremaining: 1m 2s\n",
      "241:\ttotal: 19.9s\tremaining: 1m 2s\n",
      "242:\ttotal: 20s\tremaining: 1m 2s\n",
      "243:\ttotal: 20.1s\tremaining: 1m 2s\n",
      "244:\ttotal: 20.2s\tremaining: 1m 2s\n",
      "245:\ttotal: 20.2s\tremaining: 1m 2s\n",
      "246:\ttotal: 20.3s\tremaining: 1m 1s\n",
      "247:\ttotal: 20.4s\tremaining: 1m 1s\n",
      "248:\ttotal: 20.5s\tremaining: 1m 1s\n",
      "249:\ttotal: 20.6s\tremaining: 1m 1s\n",
      "250:\ttotal: 20.6s\tremaining: 1m 1s\n",
      "251:\ttotal: 20.7s\tremaining: 1m 1s\n",
      "252:\ttotal: 20.8s\tremaining: 1m 1s\n",
      "253:\ttotal: 20.9s\tremaining: 1m 1s\n",
      "254:\ttotal: 20.9s\tremaining: 1m 1s\n",
      "255:\ttotal: 21s\tremaining: 1m 1s\n",
      "256:\ttotal: 21.1s\tremaining: 1m\n",
      "257:\ttotal: 21.2s\tremaining: 1m\n",
      "258:\ttotal: 21.3s\tremaining: 1m\n",
      "259:\ttotal: 21.3s\tremaining: 1m\n",
      "260:\ttotal: 21.4s\tremaining: 1m\n",
      "261:\ttotal: 21.5s\tremaining: 1m\n",
      "262:\ttotal: 21.6s\tremaining: 1m\n",
      "263:\ttotal: 21.6s\tremaining: 1m\n",
      "264:\ttotal: 21.7s\tremaining: 1m\n",
      "265:\ttotal: 21.8s\tremaining: 1m\n",
      "266:\ttotal: 21.9s\tremaining: 1m\n",
      "267:\ttotal: 22s\tremaining: 1m\n",
      "268:\ttotal: 22s\tremaining: 59.9s\n",
      "269:\ttotal: 22.1s\tremaining: 59.8s\n",
      "270:\ttotal: 22.2s\tremaining: 59.7s\n",
      "271:\ttotal: 22.3s\tremaining: 59.6s\n",
      "272:\ttotal: 22.4s\tremaining: 59.5s\n",
      "273:\ttotal: 22.4s\tremaining: 59.5s\n",
      "274:\ttotal: 22.5s\tremaining: 59.4s\n",
      "275:\ttotal: 22.6s\tremaining: 59.3s\n",
      "276:\ttotal: 22.7s\tremaining: 59.1s\n",
      "277:\ttotal: 22.7s\tremaining: 59s\n",
      "278:\ttotal: 22.8s\tremaining: 58.9s\n",
      "279:\ttotal: 22.9s\tremaining: 58.8s\n",
      "280:\ttotal: 22.9s\tremaining: 58.7s\n",
      "281:\ttotal: 23s\tremaining: 58.6s\n",
      "282:\ttotal: 23.1s\tremaining: 58.5s\n",
      "283:\ttotal: 23.2s\tremaining: 58.4s\n",
      "284:\ttotal: 23.2s\tremaining: 58.3s\n",
      "285:\ttotal: 23.3s\tremaining: 58.1s\n",
      "286:\ttotal: 23.4s\tremaining: 58s\n",
      "287:\ttotal: 23.4s\tremaining: 57.9s\n",
      "288:\ttotal: 23.5s\tremaining: 57.8s\n",
      "289:\ttotal: 23.6s\tremaining: 57.7s\n",
      "290:\ttotal: 23.7s\tremaining: 57.6s\n",
      "291:\ttotal: 23.7s\tremaining: 57.5s\n",
      "292:\ttotal: 23.8s\tremaining: 57.4s\n",
      "293:\ttotal: 23.9s\tremaining: 57.3s\n",
      "294:\ttotal: 24s\tremaining: 57.3s\n",
      "295:\ttotal: 24s\tremaining: 57.2s\n",
      "296:\ttotal: 24.1s\tremaining: 57.1s\n",
      "297:\ttotal: 24.2s\tremaining: 57s\n",
      "298:\ttotal: 24.3s\tremaining: 56.9s\n",
      "299:\ttotal: 24.3s\tremaining: 56.7s\n",
      "300:\ttotal: 24.4s\tremaining: 56.6s\n",
      "301:\ttotal: 24.4s\tremaining: 56.5s\n",
      "302:\ttotal: 24.5s\tremaining: 56.4s\n",
      "303:\ttotal: 24.6s\tremaining: 56.3s\n",
      "304:\ttotal: 24.7s\tremaining: 56.2s\n",
      "305:\ttotal: 24.7s\tremaining: 56.1s\n",
      "306:\ttotal: 24.8s\tremaining: 56s\n",
      "307:\ttotal: 24.9s\tremaining: 55.9s\n",
      "308:\ttotal: 24.9s\tremaining: 55.8s\n",
      "309:\ttotal: 25s\tremaining: 55.7s\n",
      "310:\ttotal: 25.1s\tremaining: 55.6s\n",
      "311:\ttotal: 25.2s\tremaining: 55.5s\n",
      "312:\ttotal: 25.2s\tremaining: 55.4s\n",
      "313:\ttotal: 25.3s\tremaining: 55.4s\n",
      "314:\ttotal: 25.4s\tremaining: 55.3s\n",
      "315:\ttotal: 25.5s\tremaining: 55.2s\n",
      "316:\ttotal: 25.6s\tremaining: 55.1s\n",
      "317:\ttotal: 25.7s\tremaining: 55.1s\n",
      "318:\ttotal: 25.7s\tremaining: 55s\n",
      "319:\ttotal: 25.8s\tremaining: 54.9s\n",
      "320:\ttotal: 25.9s\tremaining: 54.8s\n",
      "321:\ttotal: 26s\tremaining: 54.7s\n",
      "322:\ttotal: 26.1s\tremaining: 54.6s\n",
      "323:\ttotal: 26.1s\tremaining: 54.5s\n",
      "324:\ttotal: 26.2s\tremaining: 54.4s\n",
      "325:\ttotal: 26.3s\tremaining: 54.3s\n",
      "326:\ttotal: 26.3s\tremaining: 54.2s\n",
      "327:\ttotal: 26.4s\tremaining: 54.1s\n",
      "328:\ttotal: 26.5s\tremaining: 54s\n",
      "329:\ttotal: 26.6s\tremaining: 53.9s\n",
      "330:\ttotal: 26.6s\tremaining: 53.8s\n",
      "331:\ttotal: 26.7s\tremaining: 53.7s\n",
      "332:\ttotal: 26.8s\tremaining: 53.6s\n",
      "333:\ttotal: 26.8s\tremaining: 53.5s\n",
      "334:\ttotal: 26.9s\tremaining: 53.4s\n",
      "335:\ttotal: 27s\tremaining: 53.4s\n",
      "336:\ttotal: 27.1s\tremaining: 53.3s\n",
      "337:\ttotal: 27.2s\tremaining: 53.2s\n",
      "338:\ttotal: 27.2s\tremaining: 53.1s\n",
      "339:\ttotal: 27.3s\tremaining: 53s\n",
      "340:\ttotal: 27.4s\tremaining: 52.9s\n",
      "341:\ttotal: 27.4s\tremaining: 52.8s\n",
      "342:\ttotal: 27.5s\tremaining: 52.7s\n",
      "343:\ttotal: 27.6s\tremaining: 52.7s\n",
      "344:\ttotal: 27.7s\tremaining: 52.6s\n",
      "345:\ttotal: 27.8s\tremaining: 52.5s\n",
      "346:\ttotal: 27.9s\tremaining: 52.5s\n",
      "347:\ttotal: 28s\tremaining: 52.4s\n",
      "348:\ttotal: 28s\tremaining: 52.3s\n",
      "349:\ttotal: 28.1s\tremaining: 52.2s\n",
      "350:\ttotal: 28.2s\tremaining: 52.2s\n",
      "351:\ttotal: 28.3s\tremaining: 52.1s\n",
      "352:\ttotal: 28.4s\tremaining: 52s\n",
      "353:\ttotal: 28.5s\tremaining: 51.9s\n",
      "354:\ttotal: 28.6s\tremaining: 51.9s\n",
      "355:\ttotal: 28.6s\tremaining: 51.8s\n",
      "356:\ttotal: 28.7s\tremaining: 51.7s\n",
      "357:\ttotal: 28.8s\tremaining: 51.6s\n",
      "358:\ttotal: 28.9s\tremaining: 51.6s\n",
      "359:\ttotal: 29s\tremaining: 51.5s\n",
      "360:\ttotal: 29s\tremaining: 51.4s\n",
      "361:\ttotal: 29.1s\tremaining: 51.3s\n",
      "362:\ttotal: 29.2s\tremaining: 51.2s\n",
      "363:\ttotal: 29.2s\tremaining: 51.1s\n",
      "364:\ttotal: 29.3s\tremaining: 51s\n",
      "365:\ttotal: 29.4s\tremaining: 50.9s\n",
      "366:\ttotal: 29.5s\tremaining: 50.8s\n",
      "367:\ttotal: 29.5s\tremaining: 50.7s\n",
      "368:\ttotal: 29.6s\tremaining: 50.7s\n",
      "369:\ttotal: 29.7s\tremaining: 50.6s\n",
      "370:\ttotal: 29.8s\tremaining: 50.5s\n",
      "371:\ttotal: 29.9s\tremaining: 50.4s\n",
      "372:\ttotal: 29.9s\tremaining: 50.3s\n",
      "373:\ttotal: 30s\tremaining: 50.3s\n",
      "374:\ttotal: 30.1s\tremaining: 50.2s\n",
      "375:\ttotal: 30.2s\tremaining: 50.1s\n",
      "376:\ttotal: 30.3s\tremaining: 50s\n",
      "377:\ttotal: 30.3s\tremaining: 49.9s\n",
      "378:\ttotal: 30.4s\tremaining: 49.8s\n",
      "379:\ttotal: 30.5s\tremaining: 49.7s\n",
      "380:\ttotal: 30.5s\tremaining: 49.6s\n",
      "381:\ttotal: 30.6s\tremaining: 49.5s\n",
      "382:\ttotal: 30.7s\tremaining: 49.4s\n",
      "383:\ttotal: 30.8s\tremaining: 49.4s\n",
      "384:\ttotal: 30.9s\tremaining: 49.3s\n",
      "385:\ttotal: 30.9s\tremaining: 49.2s\n",
      "386:\ttotal: 31s\tremaining: 49.1s\n",
      "387:\ttotal: 31.1s\tremaining: 49s\n",
      "388:\ttotal: 31.2s\tremaining: 48.9s\n",
      "389:\ttotal: 31.3s\tremaining: 48.9s\n",
      "390:\ttotal: 31.3s\tremaining: 48.8s\n",
      "391:\ttotal: 31.4s\tremaining: 48.7s\n",
      "392:\ttotal: 31.5s\tremaining: 48.6s\n",
      "393:\ttotal: 31.6s\tremaining: 48.6s\n",
      "394:\ttotal: 31.7s\tremaining: 48.5s\n",
      "395:\ttotal: 31.7s\tremaining: 48.4s\n",
      "396:\ttotal: 31.8s\tremaining: 48.4s\n",
      "397:\ttotal: 31.9s\tremaining: 48.3s\n",
      "398:\ttotal: 32s\tremaining: 48.2s\n",
      "399:\ttotal: 32.1s\tremaining: 48.1s\n",
      "400:\ttotal: 32.1s\tremaining: 48s\n",
      "401:\ttotal: 32.2s\tremaining: 47.9s\n",
      "402:\ttotal: 32.3s\tremaining: 47.8s\n",
      "403:\ttotal: 32.4s\tremaining: 47.7s\n",
      "404:\ttotal: 32.4s\tremaining: 47.7s\n",
      "405:\ttotal: 32.5s\tremaining: 47.6s\n",
      "406:\ttotal: 32.6s\tremaining: 47.5s\n",
      "407:\ttotal: 32.7s\tremaining: 47.4s\n",
      "408:\ttotal: 32.7s\tremaining: 47.3s\n",
      "409:\ttotal: 32.8s\tremaining: 47.2s\n",
      "410:\ttotal: 32.9s\tremaining: 47.1s\n",
      "411:\ttotal: 33s\tremaining: 47s\n",
      "412:\ttotal: 33s\tremaining: 47s\n",
      "413:\ttotal: 33.1s\tremaining: 46.9s\n",
      "414:\ttotal: 33.2s\tremaining: 46.8s\n",
      "415:\ttotal: 33.3s\tremaining: 46.7s\n",
      "416:\ttotal: 33.3s\tremaining: 46.6s\n",
      "417:\ttotal: 33.4s\tremaining: 46.5s\n",
      "418:\ttotal: 33.5s\tremaining: 46.4s\n",
      "419:\ttotal: 33.6s\tremaining: 46.4s\n",
      "420:\ttotal: 33.6s\tremaining: 46.3s\n",
      "421:\ttotal: 33.7s\tremaining: 46.2s\n",
      "422:\ttotal: 33.8s\tremaining: 46.1s\n",
      "423:\ttotal: 33.9s\tremaining: 46s\n",
      "424:\ttotal: 34s\tremaining: 45.9s\n",
      "425:\ttotal: 34s\tremaining: 45.9s\n",
      "426:\ttotal: 34.1s\tremaining: 45.8s\n",
      "427:\ttotal: 34.2s\tremaining: 45.7s\n",
      "428:\ttotal: 34.3s\tremaining: 45.6s\n",
      "429:\ttotal: 34.3s\tremaining: 45.5s\n",
      "430:\ttotal: 34.4s\tremaining: 45.4s\n",
      "431:\ttotal: 34.5s\tremaining: 45.4s\n",
      "432:\ttotal: 34.6s\tremaining: 45.3s\n",
      "433:\ttotal: 34.6s\tremaining: 45.2s\n",
      "434:\ttotal: 34.7s\tremaining: 45.1s\n",
      "435:\ttotal: 34.8s\tremaining: 45s\n",
      "436:\ttotal: 34.9s\tremaining: 44.9s\n",
      "437:\ttotal: 35s\tremaining: 44.9s\n",
      "438:\ttotal: 35s\tremaining: 44.8s\n",
      "439:\ttotal: 35.1s\tremaining: 44.7s\n",
      "440:\ttotal: 35.2s\tremaining: 44.6s\n",
      "441:\ttotal: 35.3s\tremaining: 44.5s\n",
      "442:\ttotal: 35.3s\tremaining: 44.4s\n",
      "443:\ttotal: 35.4s\tremaining: 44.3s\n",
      "444:\ttotal: 35.5s\tremaining: 44.3s\n",
      "445:\ttotal: 35.5s\tremaining: 44.2s\n",
      "446:\ttotal: 35.6s\tremaining: 44.1s\n",
      "447:\ttotal: 35.7s\tremaining: 44s\n",
      "448:\ttotal: 35.8s\tremaining: 43.9s\n",
      "449:\ttotal: 35.9s\tremaining: 43.8s\n",
      "450:\ttotal: 35.9s\tremaining: 43.8s\n",
      "451:\ttotal: 36s\tremaining: 43.7s\n",
      "452:\ttotal: 36.1s\tremaining: 43.6s\n",
      "453:\ttotal: 36.2s\tremaining: 43.5s\n",
      "454:\ttotal: 36.2s\tremaining: 43.4s\n",
      "455:\ttotal: 36.3s\tremaining: 43.3s\n",
      "456:\ttotal: 36.4s\tremaining: 43.2s\n",
      "457:\ttotal: 36.4s\tremaining: 43.1s\n",
      "458:\ttotal: 36.5s\tremaining: 43s\n",
      "459:\ttotal: 36.6s\tremaining: 43s\n",
      "460:\ttotal: 36.7s\tremaining: 42.9s\n",
      "461:\ttotal: 36.8s\tremaining: 42.8s\n",
      "462:\ttotal: 36.8s\tremaining: 42.7s\n",
      "463:\ttotal: 36.9s\tremaining: 42.6s\n",
      "464:\ttotal: 37s\tremaining: 42.6s\n",
      "465:\ttotal: 37.1s\tremaining: 42.5s\n",
      "466:\ttotal: 37.1s\tremaining: 42.4s\n",
      "467:\ttotal: 37.2s\tremaining: 42.3s\n",
      "468:\ttotal: 37.3s\tremaining: 42.2s\n",
      "469:\ttotal: 37.4s\tremaining: 42.1s\n",
      "470:\ttotal: 37.5s\tremaining: 42.1s\n",
      "471:\ttotal: 37.5s\tremaining: 42s\n",
      "472:\ttotal: 37.6s\tremaining: 41.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473:\ttotal: 37.7s\tremaining: 41.8s\n",
      "474:\ttotal: 37.7s\tremaining: 41.7s\n",
      "475:\ttotal: 37.8s\tremaining: 41.6s\n",
      "476:\ttotal: 37.9s\tremaining: 41.5s\n",
      "477:\ttotal: 38s\tremaining: 41.5s\n",
      "478:\ttotal: 38s\tremaining: 41.4s\n",
      "479:\ttotal: 38.1s\tremaining: 41.3s\n",
      "480:\ttotal: 38.2s\tremaining: 41.2s\n",
      "481:\ttotal: 38.3s\tremaining: 41.1s\n",
      "482:\ttotal: 38.4s\tremaining: 41.1s\n",
      "483:\ttotal: 38.4s\tremaining: 41s\n",
      "484:\ttotal: 38.5s\tremaining: 40.9s\n",
      "485:\ttotal: 38.6s\tremaining: 40.8s\n",
      "486:\ttotal: 38.7s\tremaining: 40.7s\n",
      "487:\ttotal: 38.7s\tremaining: 40.6s\n",
      "488:\ttotal: 38.8s\tremaining: 40.6s\n",
      "489:\ttotal: 38.9s\tremaining: 40.5s\n",
      "490:\ttotal: 39s\tremaining: 40.4s\n",
      "491:\ttotal: 39s\tremaining: 40.3s\n",
      "492:\ttotal: 39.1s\tremaining: 40.2s\n",
      "493:\ttotal: 39.2s\tremaining: 40.2s\n",
      "494:\ttotal: 39.3s\tremaining: 40.1s\n",
      "495:\ttotal: 39.4s\tremaining: 40s\n",
      "496:\ttotal: 39.4s\tremaining: 39.9s\n",
      "497:\ttotal: 39.5s\tremaining: 39.8s\n",
      "498:\ttotal: 39.6s\tremaining: 39.7s\n",
      "499:\ttotal: 39.7s\tremaining: 39.7s\n",
      "500:\ttotal: 39.7s\tremaining: 39.6s\n",
      "501:\ttotal: 39.8s\tremaining: 39.5s\n",
      "502:\ttotal: 39.9s\tremaining: 39.4s\n",
      "503:\ttotal: 40s\tremaining: 39.3s\n",
      "504:\ttotal: 40s\tremaining: 39.2s\n",
      "505:\ttotal: 40.1s\tremaining: 39.2s\n",
      "506:\ttotal: 40.2s\tremaining: 39.1s\n",
      "507:\ttotal: 40.3s\tremaining: 39s\n",
      "508:\ttotal: 40.4s\tremaining: 38.9s\n",
      "509:\ttotal: 40.4s\tremaining: 38.9s\n",
      "510:\ttotal: 40.5s\tremaining: 38.8s\n",
      "511:\ttotal: 40.6s\tremaining: 38.7s\n",
      "512:\ttotal: 40.7s\tremaining: 38.6s\n",
      "513:\ttotal: 40.7s\tremaining: 38.5s\n",
      "514:\ttotal: 40.8s\tremaining: 38.4s\n",
      "515:\ttotal: 40.9s\tremaining: 38.4s\n",
      "516:\ttotal: 41s\tremaining: 38.3s\n",
      "517:\ttotal: 41s\tremaining: 38.2s\n",
      "518:\ttotal: 41.1s\tremaining: 38.1s\n",
      "519:\ttotal: 41.2s\tremaining: 38s\n",
      "520:\ttotal: 41.3s\tremaining: 37.9s\n",
      "521:\ttotal: 41.4s\tremaining: 37.9s\n",
      "522:\ttotal: 41.4s\tremaining: 37.8s\n",
      "523:\ttotal: 41.5s\tremaining: 37.7s\n",
      "524:\ttotal: 41.6s\tremaining: 37.6s\n",
      "525:\ttotal: 41.7s\tremaining: 37.6s\n",
      "526:\ttotal: 41.8s\tremaining: 37.5s\n",
      "527:\ttotal: 41.9s\tremaining: 37.4s\n",
      "528:\ttotal: 41.9s\tremaining: 37.3s\n",
      "529:\ttotal: 42s\tremaining: 37.2s\n",
      "530:\ttotal: 42.1s\tremaining: 37.2s\n",
      "531:\ttotal: 42.2s\tremaining: 37.1s\n",
      "532:\ttotal: 42.2s\tremaining: 37s\n",
      "533:\ttotal: 42.3s\tremaining: 36.9s\n",
      "534:\ttotal: 42.4s\tremaining: 36.9s\n",
      "535:\ttotal: 42.5s\tremaining: 36.8s\n",
      "536:\ttotal: 42.6s\tremaining: 36.7s\n",
      "537:\ttotal: 42.7s\tremaining: 36.6s\n",
      "538:\ttotal: 42.8s\tremaining: 36.6s\n",
      "539:\ttotal: 42.8s\tremaining: 36.5s\n",
      "540:\ttotal: 42.9s\tremaining: 36.4s\n",
      "541:\ttotal: 43s\tremaining: 36.3s\n",
      "542:\ttotal: 43.1s\tremaining: 36.3s\n",
      "543:\ttotal: 43.2s\tremaining: 36.2s\n",
      "544:\ttotal: 43.2s\tremaining: 36.1s\n",
      "545:\ttotal: 43.3s\tremaining: 36s\n",
      "546:\ttotal: 43.4s\tremaining: 35.9s\n",
      "547:\ttotal: 43.5s\tremaining: 35.9s\n",
      "548:\ttotal: 43.6s\tremaining: 35.8s\n",
      "549:\ttotal: 43.6s\tremaining: 35.7s\n",
      "550:\ttotal: 43.7s\tremaining: 35.6s\n",
      "551:\ttotal: 43.8s\tremaining: 35.5s\n",
      "552:\ttotal: 43.9s\tremaining: 35.5s\n",
      "553:\ttotal: 43.9s\tremaining: 35.4s\n",
      "554:\ttotal: 44s\tremaining: 35.3s\n",
      "555:\ttotal: 44.1s\tremaining: 35.2s\n",
      "556:\ttotal: 44.2s\tremaining: 35.1s\n",
      "557:\ttotal: 44.2s\tremaining: 35s\n",
      "558:\ttotal: 44.3s\tremaining: 35s\n",
      "559:\ttotal: 44.4s\tremaining: 34.9s\n",
      "560:\ttotal: 44.5s\tremaining: 34.8s\n",
      "561:\ttotal: 44.6s\tremaining: 34.7s\n",
      "562:\ttotal: 44.6s\tremaining: 34.6s\n",
      "563:\ttotal: 44.7s\tremaining: 34.6s\n",
      "564:\ttotal: 44.8s\tremaining: 34.5s\n",
      "565:\ttotal: 44.9s\tremaining: 34.4s\n",
      "566:\ttotal: 44.9s\tremaining: 34.3s\n",
      "567:\ttotal: 45s\tremaining: 34.2s\n",
      "568:\ttotal: 45.1s\tremaining: 34.2s\n",
      "569:\ttotal: 45.2s\tremaining: 34.1s\n",
      "570:\ttotal: 45.3s\tremaining: 34s\n",
      "571:\ttotal: 45.4s\tremaining: 33.9s\n",
      "572:\ttotal: 45.5s\tremaining: 33.9s\n",
      "573:\ttotal: 45.5s\tremaining: 33.8s\n",
      "574:\ttotal: 45.6s\tremaining: 33.7s\n",
      "575:\ttotal: 45.7s\tremaining: 33.6s\n",
      "576:\ttotal: 45.8s\tremaining: 33.6s\n",
      "577:\ttotal: 45.9s\tremaining: 33.5s\n",
      "578:\ttotal: 45.9s\tremaining: 33.4s\n",
      "579:\ttotal: 46s\tremaining: 33.3s\n",
      "580:\ttotal: 46.1s\tremaining: 33.2s\n",
      "581:\ttotal: 46.2s\tremaining: 33.1s\n",
      "582:\ttotal: 46.2s\tremaining: 33.1s\n",
      "583:\ttotal: 46.3s\tremaining: 33s\n",
      "584:\ttotal: 46.4s\tremaining: 32.9s\n",
      "585:\ttotal: 46.5s\tremaining: 32.8s\n",
      "586:\ttotal: 46.6s\tremaining: 32.8s\n",
      "587:\ttotal: 46.6s\tremaining: 32.7s\n",
      "588:\ttotal: 46.7s\tremaining: 32.6s\n",
      "589:\ttotal: 46.8s\tremaining: 32.5s\n",
      "590:\ttotal: 46.8s\tremaining: 32.4s\n",
      "591:\ttotal: 46.9s\tremaining: 32.3s\n",
      "592:\ttotal: 47s\tremaining: 32.3s\n",
      "593:\ttotal: 47.1s\tremaining: 32.2s\n",
      "594:\ttotal: 47.2s\tremaining: 32.1s\n",
      "595:\ttotal: 47.2s\tremaining: 32s\n",
      "596:\ttotal: 47.3s\tremaining: 31.9s\n",
      "597:\ttotal: 47.4s\tremaining: 31.9s\n",
      "598:\ttotal: 47.5s\tremaining: 31.8s\n",
      "599:\ttotal: 47.6s\tremaining: 31.7s\n",
      "600:\ttotal: 47.6s\tremaining: 31.6s\n",
      "601:\ttotal: 47.7s\tremaining: 31.5s\n",
      "602:\ttotal: 47.8s\tremaining: 31.5s\n",
      "603:\ttotal: 47.9s\tremaining: 31.4s\n",
      "604:\ttotal: 47.9s\tremaining: 31.3s\n",
      "605:\ttotal: 48s\tremaining: 31.2s\n",
      "606:\ttotal: 48.1s\tremaining: 31.1s\n",
      "607:\ttotal: 48.2s\tremaining: 31.1s\n",
      "608:\ttotal: 48.3s\tremaining: 31s\n",
      "609:\ttotal: 48.3s\tremaining: 30.9s\n",
      "610:\ttotal: 48.4s\tremaining: 30.8s\n",
      "611:\ttotal: 48.5s\tremaining: 30.7s\n",
      "612:\ttotal: 48.6s\tremaining: 30.7s\n",
      "613:\ttotal: 48.7s\tremaining: 30.6s\n",
      "614:\ttotal: 48.7s\tremaining: 30.5s\n",
      "615:\ttotal: 48.8s\tremaining: 30.4s\n",
      "616:\ttotal: 48.9s\tremaining: 30.3s\n",
      "617:\ttotal: 49s\tremaining: 30.3s\n",
      "618:\ttotal: 49s\tremaining: 30.2s\n",
      "619:\ttotal: 49.1s\tremaining: 30.1s\n",
      "620:\ttotal: 49.2s\tremaining: 30s\n",
      "621:\ttotal: 49.3s\tremaining: 29.9s\n",
      "622:\ttotal: 49.3s\tremaining: 29.9s\n",
      "623:\ttotal: 49.4s\tremaining: 29.8s\n",
      "624:\ttotal: 49.5s\tremaining: 29.7s\n",
      "625:\ttotal: 49.6s\tremaining: 29.6s\n",
      "626:\ttotal: 49.7s\tremaining: 29.6s\n",
      "627:\ttotal: 49.8s\tremaining: 29.5s\n",
      "628:\ttotal: 49.9s\tremaining: 29.4s\n",
      "629:\ttotal: 49.9s\tremaining: 29.3s\n",
      "630:\ttotal: 50s\tremaining: 29.2s\n",
      "631:\ttotal: 50.1s\tremaining: 29.2s\n",
      "632:\ttotal: 50.2s\tremaining: 29.1s\n",
      "633:\ttotal: 50.2s\tremaining: 29s\n",
      "634:\ttotal: 50.3s\tremaining: 28.9s\n",
      "635:\ttotal: 50.4s\tremaining: 28.8s\n",
      "636:\ttotal: 50.5s\tremaining: 28.8s\n",
      "637:\ttotal: 50.5s\tremaining: 28.7s\n",
      "638:\ttotal: 50.6s\tremaining: 28.6s\n",
      "639:\ttotal: 50.7s\tremaining: 28.5s\n",
      "640:\ttotal: 50.8s\tremaining: 28.4s\n",
      "641:\ttotal: 50.8s\tremaining: 28.3s\n",
      "642:\ttotal: 50.9s\tremaining: 28.3s\n",
      "643:\ttotal: 51s\tremaining: 28.2s\n",
      "644:\ttotal: 51.1s\tremaining: 28.1s\n",
      "645:\ttotal: 51.1s\tremaining: 28s\n",
      "646:\ttotal: 51.2s\tremaining: 27.9s\n",
      "647:\ttotal: 51.3s\tremaining: 27.9s\n",
      "648:\ttotal: 51.4s\tremaining: 27.8s\n",
      "649:\ttotal: 51.4s\tremaining: 27.7s\n",
      "650:\ttotal: 51.5s\tremaining: 27.6s\n",
      "651:\ttotal: 51.6s\tremaining: 27.5s\n",
      "652:\ttotal: 51.7s\tremaining: 27.5s\n",
      "653:\ttotal: 51.7s\tremaining: 27.4s\n",
      "654:\ttotal: 51.8s\tremaining: 27.3s\n",
      "655:\ttotal: 51.9s\tremaining: 27.2s\n",
      "656:\ttotal: 52s\tremaining: 27.1s\n",
      "657:\ttotal: 52.1s\tremaining: 27.1s\n",
      "658:\ttotal: 52.1s\tremaining: 27s\n",
      "659:\ttotal: 52.2s\tremaining: 26.9s\n",
      "660:\ttotal: 52.3s\tremaining: 26.8s\n",
      "661:\ttotal: 52.4s\tremaining: 26.7s\n",
      "662:\ttotal: 52.5s\tremaining: 26.7s\n",
      "663:\ttotal: 52.5s\tremaining: 26.6s\n",
      "664:\ttotal: 52.6s\tremaining: 26.5s\n",
      "665:\ttotal: 52.7s\tremaining: 26.4s\n",
      "666:\ttotal: 52.8s\tremaining: 26.4s\n",
      "667:\ttotal: 52.9s\tremaining: 26.3s\n",
      "668:\ttotal: 52.9s\tremaining: 26.2s\n",
      "669:\ttotal: 53s\tremaining: 26.1s\n",
      "670:\ttotal: 53.1s\tremaining: 26s\n",
      "671:\ttotal: 53.2s\tremaining: 26s\n",
      "672:\ttotal: 53.3s\tremaining: 25.9s\n",
      "673:\ttotal: 53.4s\tremaining: 25.8s\n",
      "674:\ttotal: 53.4s\tremaining: 25.7s\n",
      "675:\ttotal: 53.5s\tremaining: 25.6s\n",
      "676:\ttotal: 53.6s\tremaining: 25.6s\n",
      "677:\ttotal: 53.7s\tremaining: 25.5s\n",
      "678:\ttotal: 53.7s\tremaining: 25.4s\n",
      "679:\ttotal: 53.8s\tremaining: 25.3s\n",
      "680:\ttotal: 53.9s\tremaining: 25.2s\n",
      "681:\ttotal: 54s\tremaining: 25.2s\n",
      "682:\ttotal: 54.1s\tremaining: 25.1s\n",
      "683:\ttotal: 54.1s\tremaining: 25s\n",
      "684:\ttotal: 54.2s\tremaining: 24.9s\n",
      "685:\ttotal: 54.3s\tremaining: 24.9s\n",
      "686:\ttotal: 54.4s\tremaining: 24.8s\n",
      "687:\ttotal: 54.5s\tremaining: 24.7s\n",
      "688:\ttotal: 54.5s\tremaining: 24.6s\n",
      "689:\ttotal: 54.6s\tremaining: 24.5s\n",
      "690:\ttotal: 54.7s\tremaining: 24.5s\n",
      "691:\ttotal: 54.8s\tremaining: 24.4s\n",
      "692:\ttotal: 54.8s\tremaining: 24.3s\n",
      "693:\ttotal: 54.9s\tremaining: 24.2s\n",
      "694:\ttotal: 55s\tremaining: 24.1s\n",
      "695:\ttotal: 55.1s\tremaining: 24s\n",
      "696:\ttotal: 55.1s\tremaining: 24s\n",
      "697:\ttotal: 55.2s\tremaining: 23.9s\n",
      "698:\ttotal: 55.3s\tremaining: 23.8s\n",
      "699:\ttotal: 55.4s\tremaining: 23.7s\n",
      "700:\ttotal: 55.4s\tremaining: 23.6s\n",
      "701:\ttotal: 55.5s\tremaining: 23.6s\n",
      "702:\ttotal: 55.6s\tremaining: 23.5s\n",
      "703:\ttotal: 55.7s\tremaining: 23.4s\n",
      "704:\ttotal: 55.8s\tremaining: 23.3s\n",
      "705:\ttotal: 55.8s\tremaining: 23.3s\n",
      "706:\ttotal: 55.9s\tremaining: 23.2s\n",
      "707:\ttotal: 56s\tremaining: 23.1s\n",
      "708:\ttotal: 56.1s\tremaining: 23s\n",
      "709:\ttotal: 56.1s\tremaining: 22.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710:\ttotal: 56.2s\tremaining: 22.8s\n",
      "711:\ttotal: 56.3s\tremaining: 22.8s\n",
      "712:\ttotal: 56.4s\tremaining: 22.7s\n",
      "713:\ttotal: 56.5s\tremaining: 22.6s\n",
      "714:\ttotal: 56.5s\tremaining: 22.5s\n",
      "715:\ttotal: 56.6s\tremaining: 22.5s\n",
      "716:\ttotal: 56.7s\tremaining: 22.4s\n",
      "717:\ttotal: 56.8s\tremaining: 22.3s\n",
      "718:\ttotal: 56.8s\tremaining: 22.2s\n",
      "719:\ttotal: 56.9s\tremaining: 22.1s\n",
      "720:\ttotal: 57s\tremaining: 22.1s\n",
      "721:\ttotal: 57.1s\tremaining: 22s\n",
      "722:\ttotal: 57.2s\tremaining: 21.9s\n",
      "723:\ttotal: 57.2s\tremaining: 21.8s\n",
      "724:\ttotal: 57.3s\tremaining: 21.7s\n",
      "725:\ttotal: 57.4s\tremaining: 21.7s\n",
      "726:\ttotal: 57.5s\tremaining: 21.6s\n",
      "727:\ttotal: 57.5s\tremaining: 21.5s\n",
      "728:\ttotal: 57.6s\tremaining: 21.4s\n",
      "729:\ttotal: 57.7s\tremaining: 21.3s\n",
      "730:\ttotal: 57.8s\tremaining: 21.3s\n",
      "731:\ttotal: 57.8s\tremaining: 21.2s\n",
      "732:\ttotal: 57.9s\tremaining: 21.1s\n",
      "733:\ttotal: 58s\tremaining: 21s\n",
      "734:\ttotal: 58.1s\tremaining: 20.9s\n",
      "735:\ttotal: 58.1s\tremaining: 20.9s\n",
      "736:\ttotal: 58.2s\tremaining: 20.8s\n",
      "737:\ttotal: 58.3s\tremaining: 20.7s\n",
      "738:\ttotal: 58.4s\tremaining: 20.6s\n",
      "739:\ttotal: 58.5s\tremaining: 20.5s\n",
      "740:\ttotal: 58.5s\tremaining: 20.5s\n",
      "741:\ttotal: 58.6s\tremaining: 20.4s\n",
      "742:\ttotal: 58.7s\tremaining: 20.3s\n",
      "743:\ttotal: 58.8s\tremaining: 20.2s\n",
      "744:\ttotal: 58.8s\tremaining: 20.1s\n",
      "745:\ttotal: 58.9s\tremaining: 20.1s\n",
      "746:\ttotal: 59s\tremaining: 20s\n",
      "747:\ttotal: 59.1s\tremaining: 19.9s\n",
      "748:\ttotal: 59.2s\tremaining: 19.8s\n",
      "749:\ttotal: 59.3s\tremaining: 19.8s\n",
      "750:\ttotal: 59.3s\tremaining: 19.7s\n",
      "751:\ttotal: 59.4s\tremaining: 19.6s\n",
      "752:\ttotal: 59.5s\tremaining: 19.5s\n",
      "753:\ttotal: 59.6s\tremaining: 19.4s\n",
      "754:\ttotal: 59.6s\tremaining: 19.4s\n",
      "755:\ttotal: 59.7s\tremaining: 19.3s\n",
      "756:\ttotal: 59.8s\tremaining: 19.2s\n",
      "757:\ttotal: 59.9s\tremaining: 19.1s\n",
      "758:\ttotal: 60s\tremaining: 19s\n",
      "759:\ttotal: 1m\tremaining: 19s\n",
      "760:\ttotal: 1m\tremaining: 18.9s\n",
      "761:\ttotal: 1m\tremaining: 18.8s\n",
      "762:\ttotal: 1m\tremaining: 18.7s\n",
      "763:\ttotal: 1m\tremaining: 18.6s\n",
      "764:\ttotal: 1m\tremaining: 18.6s\n",
      "765:\ttotal: 1m\tremaining: 18.5s\n",
      "766:\ttotal: 1m\tremaining: 18.4s\n",
      "767:\ttotal: 1m\tremaining: 18.3s\n",
      "768:\ttotal: 1m\tremaining: 18.2s\n",
      "769:\ttotal: 1m\tremaining: 18.2s\n",
      "770:\ttotal: 1m\tremaining: 18.1s\n",
      "771:\ttotal: 1m\tremaining: 18s\n",
      "772:\ttotal: 1m 1s\tremaining: 17.9s\n",
      "773:\ttotal: 1m 1s\tremaining: 17.8s\n",
      "774:\ttotal: 1m 1s\tremaining: 17.8s\n",
      "775:\ttotal: 1m 1s\tremaining: 17.7s\n",
      "776:\ttotal: 1m 1s\tremaining: 17.6s\n",
      "777:\ttotal: 1m 1s\tremaining: 17.5s\n",
      "778:\ttotal: 1m 1s\tremaining: 17.4s\n",
      "779:\ttotal: 1m 1s\tremaining: 17.4s\n",
      "780:\ttotal: 1m 1s\tremaining: 17.3s\n",
      "781:\ttotal: 1m 1s\tremaining: 17.2s\n",
      "782:\ttotal: 1m 1s\tremaining: 17.1s\n",
      "783:\ttotal: 1m 1s\tremaining: 17s\n",
      "784:\ttotal: 1m 1s\tremaining: 17s\n",
      "785:\ttotal: 1m 2s\tremaining: 16.9s\n",
      "786:\ttotal: 1m 2s\tremaining: 16.8s\n",
      "787:\ttotal: 1m 2s\tremaining: 16.7s\n",
      "788:\ttotal: 1m 2s\tremaining: 16.6s\n",
      "789:\ttotal: 1m 2s\tremaining: 16.6s\n",
      "790:\ttotal: 1m 2s\tremaining: 16.5s\n",
      "791:\ttotal: 1m 2s\tremaining: 16.4s\n",
      "792:\ttotal: 1m 2s\tremaining: 16.3s\n",
      "793:\ttotal: 1m 2s\tremaining: 16.3s\n",
      "794:\ttotal: 1m 2s\tremaining: 16.2s\n",
      "795:\ttotal: 1m 2s\tremaining: 16.1s\n",
      "796:\ttotal: 1m 2s\tremaining: 16s\n",
      "797:\ttotal: 1m 2s\tremaining: 15.9s\n",
      "798:\ttotal: 1m 3s\tremaining: 15.9s\n",
      "799:\ttotal: 1m 3s\tremaining: 15.8s\n",
      "800:\ttotal: 1m 3s\tremaining: 15.7s\n",
      "801:\ttotal: 1m 3s\tremaining: 15.6s\n",
      "802:\ttotal: 1m 3s\tremaining: 15.5s\n",
      "803:\ttotal: 1m 3s\tremaining: 15.5s\n",
      "804:\ttotal: 1m 3s\tremaining: 15.4s\n",
      "805:\ttotal: 1m 3s\tremaining: 15.3s\n",
      "806:\ttotal: 1m 3s\tremaining: 15.2s\n",
      "807:\ttotal: 1m 3s\tremaining: 15.1s\n",
      "808:\ttotal: 1m 3s\tremaining: 15.1s\n",
      "809:\ttotal: 1m 3s\tremaining: 15s\n",
      "810:\ttotal: 1m 3s\tremaining: 14.9s\n",
      "811:\ttotal: 1m 4s\tremaining: 14.8s\n",
      "812:\ttotal: 1m 4s\tremaining: 14.8s\n",
      "813:\ttotal: 1m 4s\tremaining: 14.7s\n",
      "814:\ttotal: 1m 4s\tremaining: 14.6s\n",
      "815:\ttotal: 1m 4s\tremaining: 14.5s\n",
      "816:\ttotal: 1m 4s\tremaining: 14.4s\n",
      "817:\ttotal: 1m 4s\tremaining: 14.4s\n",
      "818:\ttotal: 1m 4s\tremaining: 14.3s\n",
      "819:\ttotal: 1m 4s\tremaining: 14.2s\n",
      "820:\ttotal: 1m 4s\tremaining: 14.1s\n",
      "821:\ttotal: 1m 4s\tremaining: 14s\n",
      "822:\ttotal: 1m 4s\tremaining: 14s\n",
      "823:\ttotal: 1m 5s\tremaining: 13.9s\n",
      "824:\ttotal: 1m 5s\tremaining: 13.8s\n",
      "825:\ttotal: 1m 5s\tremaining: 13.7s\n",
      "826:\ttotal: 1m 5s\tremaining: 13.7s\n",
      "827:\ttotal: 1m 5s\tremaining: 13.6s\n",
      "828:\ttotal: 1m 5s\tremaining: 13.5s\n",
      "829:\ttotal: 1m 5s\tremaining: 13.4s\n",
      "830:\ttotal: 1m 5s\tremaining: 13.3s\n",
      "831:\ttotal: 1m 5s\tremaining: 13.3s\n",
      "832:\ttotal: 1m 5s\tremaining: 13.2s\n",
      "833:\ttotal: 1m 5s\tremaining: 13.1s\n",
      "834:\ttotal: 1m 5s\tremaining: 13s\n",
      "835:\ttotal: 1m 5s\tremaining: 12.9s\n",
      "836:\ttotal: 1m 6s\tremaining: 12.9s\n",
      "837:\ttotal: 1m 6s\tremaining: 12.8s\n",
      "838:\ttotal: 1m 6s\tremaining: 12.7s\n",
      "839:\ttotal: 1m 6s\tremaining: 12.6s\n",
      "840:\ttotal: 1m 6s\tremaining: 12.5s\n",
      "841:\ttotal: 1m 6s\tremaining: 12.5s\n",
      "842:\ttotal: 1m 6s\tremaining: 12.4s\n",
      "843:\ttotal: 1m 6s\tremaining: 12.3s\n",
      "844:\ttotal: 1m 6s\tremaining: 12.2s\n",
      "845:\ttotal: 1m 6s\tremaining: 12.2s\n",
      "846:\ttotal: 1m 6s\tremaining: 12.1s\n",
      "847:\ttotal: 1m 6s\tremaining: 12s\n",
      "848:\ttotal: 1m 7s\tremaining: 11.9s\n",
      "849:\ttotal: 1m 7s\tremaining: 11.8s\n",
      "850:\ttotal: 1m 7s\tremaining: 11.8s\n",
      "851:\ttotal: 1m 7s\tremaining: 11.7s\n",
      "852:\ttotal: 1m 7s\tremaining: 11.6s\n",
      "853:\ttotal: 1m 7s\tremaining: 11.5s\n",
      "854:\ttotal: 1m 7s\tremaining: 11.4s\n",
      "855:\ttotal: 1m 7s\tremaining: 11.4s\n",
      "856:\ttotal: 1m 7s\tremaining: 11.3s\n",
      "857:\ttotal: 1m 7s\tremaining: 11.2s\n",
      "858:\ttotal: 1m 7s\tremaining: 11.1s\n",
      "859:\ttotal: 1m 7s\tremaining: 11s\n",
      "860:\ttotal: 1m 7s\tremaining: 11s\n",
      "861:\ttotal: 1m 8s\tremaining: 10.9s\n",
      "862:\ttotal: 1m 8s\tremaining: 10.8s\n",
      "863:\ttotal: 1m 8s\tremaining: 10.7s\n",
      "864:\ttotal: 1m 8s\tremaining: 10.7s\n",
      "865:\ttotal: 1m 8s\tremaining: 10.6s\n",
      "866:\ttotal: 1m 8s\tremaining: 10.5s\n",
      "867:\ttotal: 1m 8s\tremaining: 10.4s\n",
      "868:\ttotal: 1m 8s\tremaining: 10.3s\n",
      "869:\ttotal: 1m 8s\tremaining: 10.3s\n",
      "870:\ttotal: 1m 8s\tremaining: 10.2s\n",
      "871:\ttotal: 1m 8s\tremaining: 10.1s\n",
      "872:\ttotal: 1m 8s\tremaining: 10s\n",
      "873:\ttotal: 1m 8s\tremaining: 9.95s\n",
      "874:\ttotal: 1m 9s\tremaining: 9.86s\n",
      "875:\ttotal: 1m 9s\tremaining: 9.78s\n",
      "876:\ttotal: 1m 9s\tremaining: 9.7s\n",
      "877:\ttotal: 1m 9s\tremaining: 9.63s\n",
      "878:\ttotal: 1m 9s\tremaining: 9.54s\n",
      "879:\ttotal: 1m 9s\tremaining: 9.46s\n",
      "880:\ttotal: 1m 9s\tremaining: 9.39s\n",
      "881:\ttotal: 1m 9s\tremaining: 9.31s\n",
      "882:\ttotal: 1m 9s\tremaining: 9.22s\n",
      "883:\ttotal: 1m 9s\tremaining: 9.15s\n",
      "884:\ttotal: 1m 9s\tremaining: 9.07s\n",
      "885:\ttotal: 1m 9s\tremaining: 8.99s\n",
      "886:\ttotal: 1m 9s\tremaining: 8.91s\n",
      "887:\ttotal: 1m 10s\tremaining: 8.83s\n",
      "888:\ttotal: 1m 10s\tremaining: 8.75s\n",
      "889:\ttotal: 1m 10s\tremaining: 8.67s\n",
      "890:\ttotal: 1m 10s\tremaining: 8.59s\n",
      "891:\ttotal: 1m 10s\tremaining: 8.51s\n",
      "892:\ttotal: 1m 10s\tremaining: 8.43s\n",
      "893:\ttotal: 1m 10s\tremaining: 8.36s\n",
      "894:\ttotal: 1m 10s\tremaining: 8.28s\n",
      "895:\ttotal: 1m 10s\tremaining: 8.2s\n",
      "896:\ttotal: 1m 10s\tremaining: 8.12s\n",
      "897:\ttotal: 1m 10s\tremaining: 8.04s\n",
      "898:\ttotal: 1m 10s\tremaining: 7.96s\n",
      "899:\ttotal: 1m 10s\tremaining: 7.88s\n",
      "900:\ttotal: 1m 11s\tremaining: 7.81s\n",
      "901:\ttotal: 1m 11s\tremaining: 7.73s\n",
      "902:\ttotal: 1m 11s\tremaining: 7.65s\n",
      "903:\ttotal: 1m 11s\tremaining: 7.57s\n",
      "904:\ttotal: 1m 11s\tremaining: 7.49s\n",
      "905:\ttotal: 1m 11s\tremaining: 7.41s\n",
      "906:\ttotal: 1m 11s\tremaining: 7.33s\n",
      "907:\ttotal: 1m 11s\tremaining: 7.25s\n",
      "908:\ttotal: 1m 11s\tremaining: 7.17s\n",
      "909:\ttotal: 1m 11s\tremaining: 7.1s\n",
      "910:\ttotal: 1m 11s\tremaining: 7.02s\n",
      "911:\ttotal: 1m 11s\tremaining: 6.94s\n",
      "912:\ttotal: 1m 12s\tremaining: 6.86s\n",
      "913:\ttotal: 1m 12s\tremaining: 6.78s\n",
      "914:\ttotal: 1m 12s\tremaining: 6.7s\n",
      "915:\ttotal: 1m 12s\tremaining: 6.63s\n",
      "916:\ttotal: 1m 12s\tremaining: 6.55s\n",
      "917:\ttotal: 1m 12s\tremaining: 6.47s\n",
      "918:\ttotal: 1m 12s\tremaining: 6.39s\n",
      "919:\ttotal: 1m 12s\tremaining: 6.31s\n",
      "920:\ttotal: 1m 12s\tremaining: 6.23s\n",
      "921:\ttotal: 1m 12s\tremaining: 6.15s\n",
      "922:\ttotal: 1m 12s\tremaining: 6.07s\n",
      "923:\ttotal: 1m 12s\tremaining: 6s\n",
      "924:\ttotal: 1m 12s\tremaining: 5.92s\n",
      "925:\ttotal: 1m 13s\tremaining: 5.84s\n",
      "926:\ttotal: 1m 13s\tremaining: 5.76s\n",
      "927:\ttotal: 1m 13s\tremaining: 5.68s\n",
      "928:\ttotal: 1m 13s\tremaining: 5.6s\n",
      "929:\ttotal: 1m 13s\tremaining: 5.52s\n",
      "930:\ttotal: 1m 13s\tremaining: 5.44s\n",
      "931:\ttotal: 1m 13s\tremaining: 5.36s\n",
      "932:\ttotal: 1m 13s\tremaining: 5.28s\n",
      "933:\ttotal: 1m 13s\tremaining: 5.2s\n",
      "934:\ttotal: 1m 13s\tremaining: 5.12s\n",
      "935:\ttotal: 1m 13s\tremaining: 5.04s\n",
      "936:\ttotal: 1m 13s\tremaining: 4.97s\n",
      "937:\ttotal: 1m 13s\tremaining: 4.89s\n",
      "938:\ttotal: 1m 14s\tremaining: 4.81s\n",
      "939:\ttotal: 1m 14s\tremaining: 4.73s\n",
      "940:\ttotal: 1m 14s\tremaining: 4.65s\n",
      "941:\ttotal: 1m 14s\tremaining: 4.57s\n",
      "942:\ttotal: 1m 14s\tremaining: 4.49s\n",
      "943:\ttotal: 1m 14s\tremaining: 4.41s\n",
      "944:\ttotal: 1m 14s\tremaining: 4.33s\n",
      "945:\ttotal: 1m 14s\tremaining: 4.26s\n",
      "946:\ttotal: 1m 14s\tremaining: 4.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947:\ttotal: 1m 14s\tremaining: 4.1s\n",
      "948:\ttotal: 1m 14s\tremaining: 4.02s\n",
      "949:\ttotal: 1m 14s\tremaining: 3.94s\n",
      "950:\ttotal: 1m 14s\tremaining: 3.86s\n",
      "951:\ttotal: 1m 15s\tremaining: 3.78s\n",
      "952:\ttotal: 1m 15s\tremaining: 3.7s\n",
      "953:\ttotal: 1m 15s\tremaining: 3.63s\n",
      "954:\ttotal: 1m 15s\tremaining: 3.55s\n",
      "955:\ttotal: 1m 15s\tremaining: 3.47s\n",
      "956:\ttotal: 1m 15s\tremaining: 3.39s\n",
      "957:\ttotal: 1m 15s\tremaining: 3.31s\n",
      "958:\ttotal: 1m 15s\tremaining: 3.23s\n",
      "959:\ttotal: 1m 15s\tremaining: 3.15s\n",
      "960:\ttotal: 1m 15s\tremaining: 3.07s\n",
      "961:\ttotal: 1m 15s\tremaining: 2.99s\n",
      "962:\ttotal: 1m 15s\tremaining: 2.92s\n",
      "963:\ttotal: 1m 15s\tremaining: 2.84s\n",
      "964:\ttotal: 1m 16s\tremaining: 2.76s\n",
      "965:\ttotal: 1m 16s\tremaining: 2.68s\n",
      "966:\ttotal: 1m 16s\tremaining: 2.6s\n",
      "967:\ttotal: 1m 16s\tremaining: 2.52s\n",
      "968:\ttotal: 1m 16s\tremaining: 2.44s\n",
      "969:\ttotal: 1m 16s\tremaining: 2.36s\n",
      "970:\ttotal: 1m 16s\tremaining: 2.28s\n",
      "971:\ttotal: 1m 16s\tremaining: 2.21s\n",
      "972:\ttotal: 1m 16s\tremaining: 2.13s\n",
      "973:\ttotal: 1m 16s\tremaining: 2.05s\n",
      "974:\ttotal: 1m 16s\tremaining: 1.97s\n",
      "975:\ttotal: 1m 16s\tremaining: 1.89s\n",
      "976:\ttotal: 1m 16s\tremaining: 1.81s\n",
      "977:\ttotal: 1m 17s\tremaining: 1.73s\n",
      "978:\ttotal: 1m 17s\tremaining: 1.65s\n",
      "979:\ttotal: 1m 17s\tremaining: 1.57s\n",
      "980:\ttotal: 1m 17s\tremaining: 1.5s\n",
      "981:\ttotal: 1m 17s\tremaining: 1.42s\n",
      "982:\ttotal: 1m 17s\tremaining: 1.34s\n",
      "983:\ttotal: 1m 17s\tremaining: 1.26s\n",
      "984:\ttotal: 1m 17s\tremaining: 1.18s\n",
      "985:\ttotal: 1m 17s\tremaining: 1.1s\n",
      "986:\ttotal: 1m 17s\tremaining: 1.02s\n",
      "987:\ttotal: 1m 17s\tremaining: 945ms\n",
      "988:\ttotal: 1m 17s\tremaining: 866ms\n",
      "989:\ttotal: 1m 17s\tremaining: 787ms\n",
      "990:\ttotal: 1m 18s\tremaining: 709ms\n",
      "991:\ttotal: 1m 18s\tremaining: 630ms\n",
      "992:\ttotal: 1m 18s\tremaining: 551ms\n",
      "993:\ttotal: 1m 18s\tremaining: 472ms\n",
      "994:\ttotal: 1m 18s\tremaining: 394ms\n",
      "995:\ttotal: 1m 18s\tremaining: 315ms\n",
      "996:\ttotal: 1m 18s\tremaining: 236ms\n",
      "997:\ttotal: 1m 18s\tremaining: 157ms\n",
      "998:\ttotal: 1m 18s\tremaining: 78.7ms\n",
      "999:\ttotal: 1m 18s\tremaining: 0us\n",
      "0.8327414047430842\n",
      "0:\tlearn: 0.6791924\ttotal: 87.6ms\tremaining: 1m 27s\n",
      "1:\tlearn: 0.6657955\ttotal: 171ms\tremaining: 1m 25s\n",
      "2:\tlearn: 0.6532544\ttotal: 254ms\tremaining: 1m 24s\n",
      "3:\tlearn: 0.6413986\ttotal: 346ms\tremaining: 1m 26s\n",
      "4:\tlearn: 0.6305693\ttotal: 418ms\tremaining: 1m 23s\n",
      "5:\tlearn: 0.6203427\ttotal: 486ms\tremaining: 1m 20s\n",
      "6:\tlearn: 0.6111393\ttotal: 567ms\tremaining: 1m 20s\n",
      "7:\tlearn: 0.6021444\ttotal: 645ms\tremaining: 1m 19s\n",
      "8:\tlearn: 0.5935949\ttotal: 719ms\tremaining: 1m 19s\n",
      "9:\tlearn: 0.5858643\ttotal: 803ms\tremaining: 1m 19s\n",
      "10:\tlearn: 0.5786916\ttotal: 887ms\tremaining: 1m 19s\n",
      "11:\tlearn: 0.5719889\ttotal: 968ms\tremaining: 1m 19s\n",
      "12:\tlearn: 0.5655823\ttotal: 1.05s\tremaining: 1m 19s\n",
      "13:\tlearn: 0.5594688\ttotal: 1.13s\tremaining: 1m 19s\n",
      "14:\tlearn: 0.5540268\ttotal: 1.21s\tremaining: 1m 19s\n",
      "15:\tlearn: 0.5486758\ttotal: 1.29s\tremaining: 1m 19s\n",
      "16:\tlearn: 0.5438066\ttotal: 1.38s\tremaining: 1m 19s\n",
      "17:\tlearn: 0.5390073\ttotal: 1.46s\tremaining: 1m 19s\n",
      "18:\tlearn: 0.5344307\ttotal: 1.55s\tremaining: 1m 20s\n",
      "19:\tlearn: 0.5302841\ttotal: 1.64s\tremaining: 1m 20s\n",
      "20:\tlearn: 0.5264581\ttotal: 1.73s\tremaining: 1m 20s\n",
      "21:\tlearn: 0.5228331\ttotal: 1.82s\tremaining: 1m 20s\n",
      "22:\tlearn: 0.5194720\ttotal: 1.9s\tremaining: 1m 20s\n",
      "23:\tlearn: 0.5162059\ttotal: 1.98s\tremaining: 1m 20s\n",
      "24:\tlearn: 0.5132557\ttotal: 2.07s\tremaining: 1m 20s\n",
      "25:\tlearn: 0.5103123\ttotal: 2.15s\tremaining: 1m 20s\n",
      "26:\tlearn: 0.5075885\ttotal: 2.23s\tremaining: 1m 20s\n",
      "27:\tlearn: 0.5049965\ttotal: 2.31s\tremaining: 1m 20s\n",
      "28:\tlearn: 0.5025266\ttotal: 2.4s\tremaining: 1m 20s\n",
      "29:\tlearn: 0.5002554\ttotal: 2.49s\tremaining: 1m 20s\n",
      "30:\tlearn: 0.4980456\ttotal: 2.58s\tremaining: 1m 20s\n",
      "31:\tlearn: 0.4959612\ttotal: 2.67s\tremaining: 1m 20s\n",
      "32:\tlearn: 0.4940770\ttotal: 2.75s\tremaining: 1m 20s\n",
      "33:\tlearn: 0.4922499\ttotal: 2.83s\tremaining: 1m 20s\n",
      "34:\tlearn: 0.4904779\ttotal: 2.9s\tremaining: 1m 20s\n",
      "35:\tlearn: 0.4887599\ttotal: 2.98s\tremaining: 1m 19s\n",
      "36:\tlearn: 0.4872047\ttotal: 3.06s\tremaining: 1m 19s\n",
      "37:\tlearn: 0.4856722\ttotal: 3.14s\tremaining: 1m 19s\n",
      "38:\tlearn: 0.4843157\ttotal: 3.21s\tremaining: 1m 19s\n",
      "39:\tlearn: 0.4830060\ttotal: 3.29s\tremaining: 1m 18s\n",
      "40:\tlearn: 0.4817096\ttotal: 3.36s\tremaining: 1m 18s\n",
      "41:\tlearn: 0.4804634\ttotal: 3.43s\tremaining: 1m 18s\n",
      "42:\tlearn: 0.4793000\ttotal: 3.51s\tremaining: 1m 18s\n",
      "43:\tlearn: 0.4781896\ttotal: 3.59s\tremaining: 1m 18s\n",
      "44:\tlearn: 0.4772121\ttotal: 3.68s\tremaining: 1m 18s\n",
      "45:\tlearn: 0.4761936\ttotal: 3.76s\tremaining: 1m 18s\n",
      "46:\tlearn: 0.4752528\ttotal: 3.85s\tremaining: 1m 18s\n",
      "47:\tlearn: 0.4743700\ttotal: 3.93s\tremaining: 1m 18s\n",
      "48:\tlearn: 0.4734718\ttotal: 4.03s\tremaining: 1m 18s\n",
      "49:\tlearn: 0.4726482\ttotal: 4.11s\tremaining: 1m 18s\n",
      "50:\tlearn: 0.4718418\ttotal: 4.2s\tremaining: 1m 18s\n",
      "51:\tlearn: 0.4710842\ttotal: 4.29s\tremaining: 1m 18s\n",
      "52:\tlearn: 0.4703828\ttotal: 4.36s\tremaining: 1m 17s\n",
      "53:\tlearn: 0.4697623\ttotal: 4.43s\tremaining: 1m 17s\n",
      "54:\tlearn: 0.4690788\ttotal: 4.51s\tremaining: 1m 17s\n",
      "55:\tlearn: 0.4684453\ttotal: 4.59s\tremaining: 1m 17s\n",
      "56:\tlearn: 0.4678853\ttotal: 4.66s\tremaining: 1m 17s\n",
      "57:\tlearn: 0.4673209\ttotal: 4.76s\tremaining: 1m 17s\n",
      "58:\tlearn: 0.4667884\ttotal: 4.85s\tremaining: 1m 17s\n",
      "59:\tlearn: 0.4662723\ttotal: 4.93s\tremaining: 1m 17s\n",
      "60:\tlearn: 0.4657793\ttotal: 5.02s\tremaining: 1m 17s\n",
      "61:\tlearn: 0.4653042\ttotal: 5.1s\tremaining: 1m 17s\n",
      "62:\tlearn: 0.4648362\ttotal: 5.19s\tremaining: 1m 17s\n",
      "63:\tlearn: 0.4643647\ttotal: 5.28s\tremaining: 1m 17s\n",
      "64:\tlearn: 0.4639743\ttotal: 5.36s\tremaining: 1m 17s\n",
      "65:\tlearn: 0.4635675\ttotal: 5.44s\tremaining: 1m 17s\n",
      "66:\tlearn: 0.4631774\ttotal: 5.53s\tremaining: 1m 17s\n",
      "67:\tlearn: 0.4628141\ttotal: 5.61s\tremaining: 1m 16s\n",
      "68:\tlearn: 0.4624786\ttotal: 5.69s\tremaining: 1m 16s\n",
      "69:\tlearn: 0.4621396\ttotal: 5.77s\tremaining: 1m 16s\n",
      "70:\tlearn: 0.4618178\ttotal: 5.84s\tremaining: 1m 16s\n",
      "71:\tlearn: 0.4615052\ttotal: 5.93s\tremaining: 1m 16s\n",
      "72:\tlearn: 0.4612077\ttotal: 6.02s\tremaining: 1m 16s\n",
      "73:\tlearn: 0.4609305\ttotal: 6.1s\tremaining: 1m 16s\n",
      "74:\tlearn: 0.4606619\ttotal: 6.18s\tremaining: 1m 16s\n",
      "75:\tlearn: 0.4603901\ttotal: 6.27s\tremaining: 1m 16s\n",
      "76:\tlearn: 0.4601231\ttotal: 6.36s\tremaining: 1m 16s\n",
      "77:\tlearn: 0.4598612\ttotal: 6.45s\tremaining: 1m 16s\n",
      "78:\tlearn: 0.4596357\ttotal: 6.53s\tremaining: 1m 16s\n",
      "79:\tlearn: 0.4594129\ttotal: 6.62s\tremaining: 1m 16s\n",
      "80:\tlearn: 0.4592030\ttotal: 6.69s\tremaining: 1m 15s\n",
      "81:\tlearn: 0.4589765\ttotal: 6.78s\tremaining: 1m 15s\n",
      "82:\tlearn: 0.4587680\ttotal: 6.86s\tremaining: 1m 15s\n",
      "83:\tlearn: 0.4585861\ttotal: 6.94s\tremaining: 1m 15s\n",
      "84:\tlearn: 0.4584136\ttotal: 7.02s\tremaining: 1m 15s\n",
      "85:\tlearn: 0.4582348\ttotal: 7.11s\tremaining: 1m 15s\n",
      "86:\tlearn: 0.4580548\ttotal: 7.19s\tremaining: 1m 15s\n",
      "87:\tlearn: 0.4578977\ttotal: 7.27s\tremaining: 1m 15s\n",
      "88:\tlearn: 0.4577485\ttotal: 7.35s\tremaining: 1m 15s\n",
      "89:\tlearn: 0.4576026\ttotal: 7.43s\tremaining: 1m 15s\n",
      "90:\tlearn: 0.4574577\ttotal: 7.52s\tremaining: 1m 15s\n",
      "91:\tlearn: 0.4573190\ttotal: 7.6s\tremaining: 1m 15s\n",
      "92:\tlearn: 0.4571857\ttotal: 7.69s\tremaining: 1m 15s\n",
      "93:\tlearn: 0.4570552\ttotal: 7.78s\tremaining: 1m 14s\n",
      "94:\tlearn: 0.4569246\ttotal: 7.86s\tremaining: 1m 14s\n",
      "95:\tlearn: 0.4568282\ttotal: 7.94s\tremaining: 1m 14s\n",
      "96:\tlearn: 0.4567158\ttotal: 8.04s\tremaining: 1m 14s\n",
      "97:\tlearn: 0.4565974\ttotal: 8.12s\tremaining: 1m 14s\n",
      "98:\tlearn: 0.4565037\ttotal: 8.2s\tremaining: 1m 14s\n",
      "99:\tlearn: 0.4563947\ttotal: 8.28s\tremaining: 1m 14s\n",
      "100:\tlearn: 0.4562876\ttotal: 8.36s\tremaining: 1m 14s\n",
      "101:\tlearn: 0.4561993\ttotal: 8.44s\tremaining: 1m 14s\n",
      "102:\tlearn: 0.4561068\ttotal: 8.53s\tremaining: 1m 14s\n",
      "103:\tlearn: 0.4560103\ttotal: 8.61s\tremaining: 1m 14s\n",
      "104:\tlearn: 0.4559150\ttotal: 8.69s\tremaining: 1m 14s\n",
      "105:\tlearn: 0.4558318\ttotal: 8.77s\tremaining: 1m 14s\n",
      "106:\tlearn: 0.4557486\ttotal: 8.86s\tremaining: 1m 13s\n",
      "107:\tlearn: 0.4556579\ttotal: 8.94s\tremaining: 1m 13s\n",
      "108:\tlearn: 0.4555761\ttotal: 9.03s\tremaining: 1m 13s\n",
      "109:\tlearn: 0.4555008\ttotal: 9.12s\tremaining: 1m 13s\n",
      "110:\tlearn: 0.4554215\ttotal: 9.2s\tremaining: 1m 13s\n",
      "111:\tlearn: 0.4553469\ttotal: 9.3s\tremaining: 1m 13s\n",
      "112:\tlearn: 0.4552821\ttotal: 9.39s\tremaining: 1m 13s\n",
      "113:\tlearn: 0.4552112\ttotal: 9.47s\tremaining: 1m 13s\n",
      "114:\tlearn: 0.4551443\ttotal: 9.57s\tremaining: 1m 13s\n",
      "115:\tlearn: 0.4550745\ttotal: 9.65s\tremaining: 1m 13s\n",
      "116:\tlearn: 0.4550158\ttotal: 9.74s\tremaining: 1m 13s\n",
      "117:\tlearn: 0.4549529\ttotal: 9.82s\tremaining: 1m 13s\n",
      "118:\tlearn: 0.4548918\ttotal: 9.91s\tremaining: 1m 13s\n",
      "119:\tlearn: 0.4548382\ttotal: 9.99s\tremaining: 1m 13s\n",
      "120:\tlearn: 0.4547782\ttotal: 10.1s\tremaining: 1m 13s\n",
      "121:\tlearn: 0.4547278\ttotal: 10.2s\tremaining: 1m 13s\n",
      "122:\tlearn: 0.4546732\ttotal: 10.3s\tremaining: 1m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123:\tlearn: 0.4546221\ttotal: 10.3s\tremaining: 1m 13s\n",
      "124:\tlearn: 0.4545731\ttotal: 10.4s\tremaining: 1m 12s\n",
      "125:\tlearn: 0.4545228\ttotal: 10.5s\tremaining: 1m 12s\n",
      "126:\tlearn: 0.4544842\ttotal: 10.6s\tremaining: 1m 12s\n",
      "127:\tlearn: 0.4544491\ttotal: 10.7s\tremaining: 1m 12s\n",
      "128:\tlearn: 0.4544123\ttotal: 10.7s\tremaining: 1m 12s\n",
      "129:\tlearn: 0.4543724\ttotal: 10.8s\tremaining: 1m 12s\n",
      "130:\tlearn: 0.4543314\ttotal: 10.9s\tremaining: 1m 12s\n",
      "131:\tlearn: 0.4542894\ttotal: 11s\tremaining: 1m 12s\n",
      "132:\tlearn: 0.4542444\ttotal: 11.1s\tremaining: 1m 12s\n",
      "133:\tlearn: 0.4542018\ttotal: 11.2s\tremaining: 1m 12s\n",
      "134:\tlearn: 0.4541638\ttotal: 11.3s\tremaining: 1m 12s\n",
      "135:\tlearn: 0.4541287\ttotal: 11.4s\tremaining: 1m 12s\n",
      "136:\tlearn: 0.4540833\ttotal: 11.4s\tremaining: 1m 12s\n",
      "137:\tlearn: 0.4540437\ttotal: 11.5s\tremaining: 1m 12s\n",
      "138:\tlearn: 0.4540062\ttotal: 11.6s\tremaining: 1m 12s\n",
      "139:\tlearn: 0.4539742\ttotal: 11.7s\tremaining: 1m 11s\n",
      "140:\tlearn: 0.4539448\ttotal: 11.8s\tremaining: 1m 11s\n",
      "141:\tlearn: 0.4539099\ttotal: 11.9s\tremaining: 1m 11s\n",
      "142:\tlearn: 0.4538757\ttotal: 12s\tremaining: 1m 11s\n",
      "143:\tlearn: 0.4538447\ttotal: 12.1s\tremaining: 1m 11s\n",
      "144:\tlearn: 0.4538183\ttotal: 12.2s\tremaining: 1m 11s\n",
      "145:\tlearn: 0.4537928\ttotal: 12.3s\tremaining: 1m 11s\n",
      "146:\tlearn: 0.4537672\ttotal: 12.3s\tremaining: 1m 11s\n",
      "147:\tlearn: 0.4537352\ttotal: 12.4s\tremaining: 1m 11s\n",
      "148:\tlearn: 0.4537034\ttotal: 12.5s\tremaining: 1m 11s\n",
      "149:\tlearn: 0.4536782\ttotal: 12.6s\tremaining: 1m 11s\n",
      "150:\tlearn: 0.4536489\ttotal: 12.7s\tremaining: 1m 11s\n",
      "151:\tlearn: 0.4536232\ttotal: 12.7s\tremaining: 1m 11s\n",
      "152:\tlearn: 0.4535999\ttotal: 12.8s\tremaining: 1m 11s\n",
      "153:\tlearn: 0.4535719\ttotal: 12.9s\tremaining: 1m 11s\n",
      "154:\tlearn: 0.4535460\ttotal: 13s\tremaining: 1m 10s\n",
      "155:\tlearn: 0.4535201\ttotal: 13.1s\tremaining: 1m 10s\n",
      "156:\tlearn: 0.4534938\ttotal: 13.2s\tremaining: 1m 10s\n",
      "157:\tlearn: 0.4534746\ttotal: 13.2s\tremaining: 1m 10s\n",
      "158:\tlearn: 0.4534503\ttotal: 13.3s\tremaining: 1m 10s\n",
      "159:\tlearn: 0.4534209\ttotal: 13.4s\tremaining: 1m 10s\n",
      "160:\tlearn: 0.4534001\ttotal: 13.5s\tremaining: 1m 10s\n",
      "161:\tlearn: 0.4533724\ttotal: 13.6s\tremaining: 1m 10s\n",
      "162:\tlearn: 0.4533539\ttotal: 13.6s\tremaining: 1m 10s\n",
      "163:\tlearn: 0.4533284\ttotal: 13.7s\tremaining: 1m 9s\n",
      "164:\tlearn: 0.4533068\ttotal: 13.8s\tremaining: 1m 9s\n",
      "165:\tlearn: 0.4532864\ttotal: 13.9s\tremaining: 1m 9s\n",
      "166:\tlearn: 0.4532654\ttotal: 14s\tremaining: 1m 9s\n",
      "167:\tlearn: 0.4532439\ttotal: 14s\tremaining: 1m 9s\n",
      "168:\tlearn: 0.4532268\ttotal: 14.1s\tremaining: 1m 9s\n",
      "169:\tlearn: 0.4532093\ttotal: 14.2s\tremaining: 1m 9s\n",
      "170:\tlearn: 0.4531916\ttotal: 14.3s\tremaining: 1m 9s\n",
      "171:\tlearn: 0.4531659\ttotal: 14.4s\tremaining: 1m 9s\n",
      "172:\tlearn: 0.4531431\ttotal: 14.4s\tremaining: 1m 9s\n",
      "173:\tlearn: 0.4531167\ttotal: 14.5s\tremaining: 1m 8s\n",
      "174:\tlearn: 0.4530986\ttotal: 14.6s\tremaining: 1m 8s\n",
      "175:\tlearn: 0.4530796\ttotal: 14.7s\tremaining: 1m 8s\n",
      "176:\tlearn: 0.4530565\ttotal: 14.8s\tremaining: 1m 8s\n",
      "177:\tlearn: 0.4530385\ttotal: 14.8s\tremaining: 1m 8s\n",
      "178:\tlearn: 0.4530182\ttotal: 14.9s\tremaining: 1m 8s\n",
      "179:\tlearn: 0.4530041\ttotal: 15s\tremaining: 1m 8s\n",
      "180:\tlearn: 0.4529839\ttotal: 15.1s\tremaining: 1m 8s\n",
      "181:\tlearn: 0.4529637\ttotal: 15.2s\tremaining: 1m 8s\n",
      "182:\tlearn: 0.4529458\ttotal: 15.3s\tremaining: 1m 8s\n",
      "183:\tlearn: 0.4529296\ttotal: 15.4s\tremaining: 1m 8s\n",
      "184:\tlearn: 0.4529098\ttotal: 15.5s\tremaining: 1m 8s\n",
      "185:\tlearn: 0.4528872\ttotal: 15.6s\tremaining: 1m 8s\n",
      "186:\tlearn: 0.4528707\ttotal: 15.6s\tremaining: 1m 8s\n",
      "187:\tlearn: 0.4528550\ttotal: 15.7s\tremaining: 1m 8s\n",
      "188:\tlearn: 0.4528386\ttotal: 15.8s\tremaining: 1m 7s\n",
      "189:\tlearn: 0.4528187\ttotal: 15.9s\tremaining: 1m 7s\n",
      "190:\tlearn: 0.4528044\ttotal: 16s\tremaining: 1m 7s\n",
      "191:\tlearn: 0.4527907\ttotal: 16.1s\tremaining: 1m 7s\n",
      "192:\tlearn: 0.4527776\ttotal: 16.2s\tremaining: 1m 7s\n",
      "193:\tlearn: 0.4527546\ttotal: 16.3s\tremaining: 1m 7s\n",
      "194:\tlearn: 0.4527341\ttotal: 16.4s\tremaining: 1m 7s\n",
      "195:\tlearn: 0.4527181\ttotal: 16.4s\tremaining: 1m 7s\n",
      "196:\tlearn: 0.4526992\ttotal: 16.5s\tremaining: 1m 7s\n",
      "197:\tlearn: 0.4526827\ttotal: 16.6s\tremaining: 1m 7s\n",
      "198:\tlearn: 0.4526648\ttotal: 16.7s\tremaining: 1m 7s\n",
      "199:\tlearn: 0.4526489\ttotal: 16.8s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.4526314\ttotal: 16.8s\tremaining: 1m 6s\n",
      "201:\tlearn: 0.4526118\ttotal: 16.9s\tremaining: 1m 6s\n",
      "202:\tlearn: 0.4525931\ttotal: 17s\tremaining: 1m 6s\n",
      "203:\tlearn: 0.4525786\ttotal: 17.1s\tremaining: 1m 6s\n",
      "204:\tlearn: 0.4525634\ttotal: 17.1s\tremaining: 1m 6s\n",
      "205:\tlearn: 0.4525490\ttotal: 17.2s\tremaining: 1m 6s\n",
      "206:\tlearn: 0.4525301\ttotal: 17.3s\tremaining: 1m 6s\n",
      "207:\tlearn: 0.4525110\ttotal: 17.4s\tremaining: 1m 6s\n",
      "208:\tlearn: 0.4524928\ttotal: 17.4s\tremaining: 1m 6s\n",
      "209:\tlearn: 0.4524753\ttotal: 17.5s\tremaining: 1m 5s\n",
      "210:\tlearn: 0.4524628\ttotal: 17.6s\tremaining: 1m 5s\n",
      "211:\tlearn: 0.4524443\ttotal: 17.7s\tremaining: 1m 5s\n",
      "212:\tlearn: 0.4524282\ttotal: 17.8s\tremaining: 1m 5s\n",
      "213:\tlearn: 0.4524131\ttotal: 17.9s\tremaining: 1m 5s\n",
      "214:\tlearn: 0.4523986\ttotal: 17.9s\tremaining: 1m 5s\n",
      "215:\tlearn: 0.4523807\ttotal: 18s\tremaining: 1m 5s\n",
      "216:\tlearn: 0.4523644\ttotal: 18.1s\tremaining: 1m 5s\n",
      "217:\tlearn: 0.4523514\ttotal: 18.2s\tremaining: 1m 5s\n",
      "218:\tlearn: 0.4523340\ttotal: 18.3s\tremaining: 1m 5s\n",
      "219:\tlearn: 0.4523183\ttotal: 18.4s\tremaining: 1m 5s\n",
      "220:\tlearn: 0.4523040\ttotal: 18.5s\tremaining: 1m 5s\n",
      "221:\tlearn: 0.4522895\ttotal: 18.5s\tremaining: 1m 4s\n",
      "222:\tlearn: 0.4522734\ttotal: 18.6s\tremaining: 1m 4s\n",
      "223:\tlearn: 0.4522549\ttotal: 18.7s\tremaining: 1m 4s\n",
      "224:\tlearn: 0.4522418\ttotal: 18.8s\tremaining: 1m 4s\n",
      "225:\tlearn: 0.4522264\ttotal: 18.9s\tremaining: 1m 4s\n",
      "226:\tlearn: 0.4522083\ttotal: 19s\tremaining: 1m 4s\n",
      "227:\tlearn: 0.4521907\ttotal: 19.1s\tremaining: 1m 4s\n",
      "228:\tlearn: 0.4521749\ttotal: 19.2s\tremaining: 1m 4s\n",
      "229:\tlearn: 0.4521592\ttotal: 19.3s\tremaining: 1m 4s\n",
      "230:\tlearn: 0.4521456\ttotal: 19.4s\tremaining: 1m 4s\n",
      "231:\tlearn: 0.4521290\ttotal: 19.4s\tremaining: 1m 4s\n",
      "232:\tlearn: 0.4521101\ttotal: 19.5s\tremaining: 1m 4s\n",
      "233:\tlearn: 0.4520931\ttotal: 19.6s\tremaining: 1m 4s\n",
      "234:\tlearn: 0.4520773\ttotal: 19.7s\tremaining: 1m 4s\n",
      "235:\tlearn: 0.4520604\ttotal: 19.8s\tremaining: 1m 4s\n",
      "236:\tlearn: 0.4520453\ttotal: 19.9s\tremaining: 1m 4s\n",
      "237:\tlearn: 0.4520280\ttotal: 20s\tremaining: 1m 4s\n",
      "238:\tlearn: 0.4520138\ttotal: 20.1s\tremaining: 1m 3s\n",
      "239:\tlearn: 0.4519976\ttotal: 20.2s\tremaining: 1m 3s\n",
      "240:\tlearn: 0.4519844\ttotal: 20.2s\tremaining: 1m 3s\n",
      "241:\tlearn: 0.4519702\ttotal: 20.3s\tremaining: 1m 3s\n",
      "242:\tlearn: 0.4519557\ttotal: 20.4s\tremaining: 1m 3s\n",
      "243:\tlearn: 0.4519447\ttotal: 20.5s\tremaining: 1m 3s\n",
      "244:\tlearn: 0.4519309\ttotal: 20.5s\tremaining: 1m 3s\n",
      "245:\tlearn: 0.4519174\ttotal: 20.6s\tremaining: 1m 3s\n",
      "246:\tlearn: 0.4519034\ttotal: 20.7s\tremaining: 1m 3s\n",
      "247:\tlearn: 0.4518868\ttotal: 20.8s\tremaining: 1m 3s\n",
      "248:\tlearn: 0.4518722\ttotal: 20.9s\tremaining: 1m 2s\n",
      "249:\tlearn: 0.4518584\ttotal: 21s\tremaining: 1m 2s\n",
      "250:\tlearn: 0.4518447\ttotal: 21s\tremaining: 1m 2s\n",
      "251:\tlearn: 0.4518318\ttotal: 21.1s\tremaining: 1m 2s\n",
      "252:\tlearn: 0.4518214\ttotal: 21.2s\tremaining: 1m 2s\n",
      "253:\tlearn: 0.4518090\ttotal: 21.3s\tremaining: 1m 2s\n",
      "254:\tlearn: 0.4517956\ttotal: 21.4s\tremaining: 1m 2s\n",
      "255:\tlearn: 0.4517797\ttotal: 21.5s\tremaining: 1m 2s\n",
      "256:\tlearn: 0.4517670\ttotal: 21.5s\tremaining: 1m 2s\n",
      "257:\tlearn: 0.4517545\ttotal: 21.6s\tremaining: 1m 2s\n",
      "258:\tlearn: 0.4517396\ttotal: 21.7s\tremaining: 1m 2s\n",
      "259:\tlearn: 0.4517294\ttotal: 21.8s\tremaining: 1m 2s\n",
      "260:\tlearn: 0.4517146\ttotal: 21.9s\tremaining: 1m 1s\n",
      "261:\tlearn: 0.4517030\ttotal: 21.9s\tremaining: 1m 1s\n",
      "262:\tlearn: 0.4516886\ttotal: 22s\tremaining: 1m 1s\n",
      "263:\tlearn: 0.4516754\ttotal: 22.1s\tremaining: 1m 1s\n",
      "264:\tlearn: 0.4516635\ttotal: 22.1s\tremaining: 1m 1s\n",
      "265:\tlearn: 0.4516521\ttotal: 22.2s\tremaining: 1m 1s\n",
      "266:\tlearn: 0.4516397\ttotal: 22.3s\tremaining: 1m 1s\n",
      "267:\tlearn: 0.4516258\ttotal: 22.4s\tremaining: 1m 1s\n",
      "268:\tlearn: 0.4516119\ttotal: 22.4s\tremaining: 1m\n",
      "269:\tlearn: 0.4515977\ttotal: 22.5s\tremaining: 1m\n",
      "270:\tlearn: 0.4515847\ttotal: 22.6s\tremaining: 1m\n",
      "271:\tlearn: 0.4515745\ttotal: 22.6s\tremaining: 1m\n",
      "272:\tlearn: 0.4515653\ttotal: 22.7s\tremaining: 1m\n",
      "273:\tlearn: 0.4515498\ttotal: 22.8s\tremaining: 1m\n",
      "274:\tlearn: 0.4515352\ttotal: 22.9s\tremaining: 1m\n",
      "275:\tlearn: 0.4515220\ttotal: 22.9s\tremaining: 1m\n",
      "276:\tlearn: 0.4515103\ttotal: 23s\tremaining: 1m\n",
      "277:\tlearn: 0.4514991\ttotal: 23.1s\tremaining: 60s\n",
      "278:\tlearn: 0.4514846\ttotal: 23.2s\tremaining: 59.9s\n",
      "279:\tlearn: 0.4514708\ttotal: 23.3s\tremaining: 59.8s\n",
      "280:\tlearn: 0.4514605\ttotal: 23.3s\tremaining: 59.7s\n",
      "281:\tlearn: 0.4514478\ttotal: 23.4s\tremaining: 59.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282:\tlearn: 0.4514372\ttotal: 23.5s\tremaining: 59.5s\n",
      "283:\tlearn: 0.4514252\ttotal: 23.6s\tremaining: 59.4s\n",
      "284:\tlearn: 0.4514105\ttotal: 23.6s\tremaining: 59.3s\n",
      "285:\tlearn: 0.4514002\ttotal: 23.7s\tremaining: 59.2s\n",
      "286:\tlearn: 0.4513889\ttotal: 23.8s\tremaining: 59.1s\n",
      "287:\tlearn: 0.4513745\ttotal: 23.9s\tremaining: 59s\n",
      "288:\tlearn: 0.4513633\ttotal: 23.9s\tremaining: 58.9s\n",
      "289:\tlearn: 0.4513474\ttotal: 24s\tremaining: 58.8s\n",
      "290:\tlearn: 0.4513346\ttotal: 24.1s\tremaining: 58.7s\n",
      "291:\tlearn: 0.4513216\ttotal: 24.2s\tremaining: 58.6s\n",
      "292:\tlearn: 0.4513066\ttotal: 24.2s\tremaining: 58.5s\n",
      "293:\tlearn: 0.4512950\ttotal: 24.3s\tremaining: 58.4s\n",
      "294:\tlearn: 0.4512798\ttotal: 24.4s\tremaining: 58.3s\n",
      "295:\tlearn: 0.4512690\ttotal: 24.5s\tremaining: 58.2s\n",
      "296:\tlearn: 0.4512573\ttotal: 24.5s\tremaining: 58.1s\n",
      "297:\tlearn: 0.4512476\ttotal: 24.6s\tremaining: 58s\n",
      "298:\tlearn: 0.4512353\ttotal: 24.7s\tremaining: 57.9s\n",
      "299:\tlearn: 0.4512230\ttotal: 24.8s\tremaining: 57.8s\n",
      "300:\tlearn: 0.4512110\ttotal: 24.8s\tremaining: 57.7s\n",
      "301:\tlearn: 0.4511964\ttotal: 24.9s\tremaining: 57.6s\n",
      "302:\tlearn: 0.4511844\ttotal: 25s\tremaining: 57.5s\n",
      "303:\tlearn: 0.4511714\ttotal: 25.1s\tremaining: 57.4s\n",
      "304:\tlearn: 0.4511578\ttotal: 25.1s\tremaining: 57.3s\n",
      "305:\tlearn: 0.4511453\ttotal: 25.2s\tremaining: 57.2s\n",
      "306:\tlearn: 0.4511330\ttotal: 25.3s\tremaining: 57.1s\n",
      "307:\tlearn: 0.4511211\ttotal: 25.4s\tremaining: 57s\n",
      "308:\tlearn: 0.4511060\ttotal: 25.5s\tremaining: 56.9s\n",
      "309:\tlearn: 0.4510886\ttotal: 25.5s\tremaining: 56.8s\n",
      "310:\tlearn: 0.4510767\ttotal: 25.6s\tremaining: 56.7s\n",
      "311:\tlearn: 0.4510657\ttotal: 25.7s\tremaining: 56.6s\n",
      "312:\tlearn: 0.4510544\ttotal: 25.8s\tremaining: 56.5s\n",
      "313:\tlearn: 0.4510409\ttotal: 25.8s\tremaining: 56.4s\n",
      "314:\tlearn: 0.4510282\ttotal: 25.9s\tremaining: 56.3s\n",
      "315:\tlearn: 0.4510135\ttotal: 26s\tremaining: 56.2s\n",
      "316:\tlearn: 0.4510011\ttotal: 26.1s\tremaining: 56.1s\n",
      "317:\tlearn: 0.4509867\ttotal: 26.1s\tremaining: 56s\n",
      "318:\tlearn: 0.4509766\ttotal: 26.2s\tremaining: 55.9s\n",
      "319:\tlearn: 0.4509603\ttotal: 26.3s\tremaining: 55.8s\n",
      "320:\tlearn: 0.4509502\ttotal: 26.3s\tremaining: 55.7s\n",
      "321:\tlearn: 0.4509373\ttotal: 26.4s\tremaining: 55.6s\n",
      "322:\tlearn: 0.4509256\ttotal: 26.5s\tremaining: 55.6s\n",
      "323:\tlearn: 0.4509134\ttotal: 26.6s\tremaining: 55.5s\n",
      "324:\tlearn: 0.4509016\ttotal: 26.7s\tremaining: 55.4s\n",
      "325:\tlearn: 0.4508891\ttotal: 26.8s\tremaining: 55.3s\n",
      "326:\tlearn: 0.4508762\ttotal: 26.9s\tremaining: 55.3s\n",
      "327:\tlearn: 0.4508623\ttotal: 26.9s\tremaining: 55.2s\n",
      "328:\tlearn: 0.4508503\ttotal: 27s\tremaining: 55.1s\n",
      "329:\tlearn: 0.4508408\ttotal: 27.1s\tremaining: 55s\n",
      "330:\tlearn: 0.4508308\ttotal: 27.2s\tremaining: 54.9s\n",
      "331:\tlearn: 0.4508202\ttotal: 27.2s\tremaining: 54.8s\n",
      "332:\tlearn: 0.4508073\ttotal: 27.3s\tremaining: 54.7s\n",
      "333:\tlearn: 0.4507965\ttotal: 27.4s\tremaining: 54.6s\n",
      "334:\tlearn: 0.4507875\ttotal: 27.5s\tremaining: 54.5s\n",
      "335:\tlearn: 0.4507779\ttotal: 27.5s\tremaining: 54.4s\n",
      "336:\tlearn: 0.4507673\ttotal: 27.6s\tremaining: 54.3s\n",
      "337:\tlearn: 0.4507564\ttotal: 27.7s\tremaining: 54.3s\n",
      "338:\tlearn: 0.4507436\ttotal: 27.8s\tremaining: 54.2s\n",
      "339:\tlearn: 0.4507307\ttotal: 27.9s\tremaining: 54.1s\n",
      "340:\tlearn: 0.4507189\ttotal: 27.9s\tremaining: 54s\n",
      "341:\tlearn: 0.4507036\ttotal: 28s\tremaining: 53.9s\n",
      "342:\tlearn: 0.4506930\ttotal: 28.1s\tremaining: 53.8s\n",
      "343:\tlearn: 0.4506810\ttotal: 28.2s\tremaining: 53.7s\n",
      "344:\tlearn: 0.4506708\ttotal: 28.2s\tremaining: 53.6s\n",
      "345:\tlearn: 0.4506607\ttotal: 28.3s\tremaining: 53.5s\n",
      "346:\tlearn: 0.4506525\ttotal: 28.4s\tremaining: 53.4s\n",
      "347:\tlearn: 0.4506413\ttotal: 28.5s\tremaining: 53.3s\n",
      "348:\tlearn: 0.4506315\ttotal: 28.5s\tremaining: 53.2s\n",
      "349:\tlearn: 0.4506228\ttotal: 28.6s\tremaining: 53.1s\n",
      "350:\tlearn: 0.4506124\ttotal: 28.7s\tremaining: 53s\n",
      "351:\tlearn: 0.4506008\ttotal: 28.7s\tremaining: 52.9s\n",
      "352:\tlearn: 0.4505894\ttotal: 28.8s\tremaining: 52.8s\n",
      "353:\tlearn: 0.4505795\ttotal: 28.9s\tremaining: 52.7s\n",
      "354:\tlearn: 0.4505692\ttotal: 28.9s\tremaining: 52.6s\n",
      "355:\tlearn: 0.4505588\ttotal: 29s\tremaining: 52.5s\n",
      "356:\tlearn: 0.4505447\ttotal: 29.1s\tremaining: 52.4s\n",
      "357:\tlearn: 0.4505334\ttotal: 29.2s\tremaining: 52.3s\n",
      "358:\tlearn: 0.4505220\ttotal: 29.2s\tremaining: 52.2s\n",
      "359:\tlearn: 0.4505106\ttotal: 29.3s\tremaining: 52.1s\n",
      "360:\tlearn: 0.4504962\ttotal: 29.4s\tremaining: 52s\n",
      "361:\tlearn: 0.4504847\ttotal: 29.4s\tremaining: 51.9s\n",
      "362:\tlearn: 0.4504736\ttotal: 29.5s\tremaining: 51.8s\n",
      "363:\tlearn: 0.4504646\ttotal: 29.6s\tremaining: 51.7s\n",
      "364:\tlearn: 0.4504539\ttotal: 29.6s\tremaining: 51.6s\n",
      "365:\tlearn: 0.4504407\ttotal: 29.7s\tremaining: 51.5s\n",
      "366:\tlearn: 0.4504316\ttotal: 29.8s\tremaining: 51.4s\n",
      "367:\tlearn: 0.4504164\ttotal: 29.9s\tremaining: 51.3s\n",
      "368:\tlearn: 0.4504052\ttotal: 29.9s\tremaining: 51.2s\n",
      "369:\tlearn: 0.4503916\ttotal: 30s\tremaining: 51.1s\n",
      "370:\tlearn: 0.4503809\ttotal: 30.1s\tremaining: 51s\n",
      "371:\tlearn: 0.4503700\ttotal: 30.2s\tremaining: 50.9s\n",
      "372:\tlearn: 0.4503601\ttotal: 30.3s\tremaining: 50.9s\n",
      "373:\tlearn: 0.4503489\ttotal: 30.3s\tremaining: 50.8s\n",
      "374:\tlearn: 0.4503375\ttotal: 30.4s\tremaining: 50.7s\n",
      "375:\tlearn: 0.4503244\ttotal: 30.5s\tremaining: 50.6s\n",
      "376:\tlearn: 0.4503115\ttotal: 30.6s\tremaining: 50.5s\n",
      "377:\tlearn: 0.4503010\ttotal: 30.7s\tremaining: 50.4s\n",
      "378:\tlearn: 0.4502895\ttotal: 30.7s\tremaining: 50.4s\n",
      "379:\tlearn: 0.4502779\ttotal: 30.8s\tremaining: 50.3s\n",
      "380:\tlearn: 0.4502650\ttotal: 30.9s\tremaining: 50.2s\n",
      "381:\tlearn: 0.4502550\ttotal: 31s\tremaining: 50.1s\n",
      "382:\tlearn: 0.4502437\ttotal: 31s\tremaining: 50s\n",
      "383:\tlearn: 0.4502313\ttotal: 31.1s\tremaining: 49.9s\n",
      "384:\tlearn: 0.4502187\ttotal: 31.2s\tremaining: 49.8s\n",
      "385:\tlearn: 0.4502079\ttotal: 31.3s\tremaining: 49.7s\n",
      "386:\tlearn: 0.4501945\ttotal: 31.3s\tremaining: 49.6s\n",
      "387:\tlearn: 0.4501863\ttotal: 31.4s\tremaining: 49.6s\n",
      "388:\tlearn: 0.4501726\ttotal: 31.5s\tremaining: 49.5s\n",
      "389:\tlearn: 0.4501617\ttotal: 31.6s\tremaining: 49.4s\n",
      "390:\tlearn: 0.4501495\ttotal: 31.7s\tremaining: 49.3s\n",
      "391:\tlearn: 0.4501385\ttotal: 31.7s\tremaining: 49.2s\n",
      "392:\tlearn: 0.4501289\ttotal: 31.8s\tremaining: 49.1s\n",
      "393:\tlearn: 0.4501175\ttotal: 31.9s\tremaining: 49s\n",
      "394:\tlearn: 0.4501055\ttotal: 32s\tremaining: 48.9s\n",
      "395:\tlearn: 0.4500932\ttotal: 32s\tremaining: 48.9s\n",
      "396:\tlearn: 0.4500830\ttotal: 32.1s\tremaining: 48.8s\n",
      "397:\tlearn: 0.4500744\ttotal: 32.2s\tremaining: 48.7s\n",
      "398:\tlearn: 0.4500652\ttotal: 32.3s\tremaining: 48.6s\n",
      "399:\tlearn: 0.4500536\ttotal: 32.3s\tremaining: 48.5s\n",
      "400:\tlearn: 0.4500434\ttotal: 32.4s\tremaining: 48.4s\n",
      "401:\tlearn: 0.4500316\ttotal: 32.5s\tremaining: 48.3s\n",
      "402:\tlearn: 0.4500193\ttotal: 32.6s\tremaining: 48.2s\n",
      "403:\tlearn: 0.4500104\ttotal: 32.6s\tremaining: 48.1s\n",
      "404:\tlearn: 0.4499985\ttotal: 32.7s\tremaining: 48s\n",
      "405:\tlearn: 0.4499873\ttotal: 32.8s\tremaining: 48s\n",
      "406:\tlearn: 0.4499775\ttotal: 32.9s\tremaining: 47.9s\n",
      "407:\tlearn: 0.4499655\ttotal: 33s\tremaining: 47.8s\n",
      "408:\tlearn: 0.4499533\ttotal: 33s\tremaining: 47.7s\n",
      "409:\tlearn: 0.4499417\ttotal: 33.1s\tremaining: 47.6s\n",
      "410:\tlearn: 0.4499295\ttotal: 33.2s\tremaining: 47.6s\n",
      "411:\tlearn: 0.4499178\ttotal: 33.3s\tremaining: 47.5s\n",
      "412:\tlearn: 0.4499062\ttotal: 33.3s\tremaining: 47.4s\n",
      "413:\tlearn: 0.4498969\ttotal: 33.4s\tremaining: 47.3s\n",
      "414:\tlearn: 0.4498874\ttotal: 33.5s\tremaining: 47.2s\n",
      "415:\tlearn: 0.4498761\ttotal: 33.6s\tremaining: 47.1s\n",
      "416:\tlearn: 0.4498642\ttotal: 33.6s\tremaining: 47s\n",
      "417:\tlearn: 0.4498556\ttotal: 33.7s\tremaining: 46.9s\n",
      "418:\tlearn: 0.4498431\ttotal: 33.8s\tremaining: 46.9s\n",
      "419:\tlearn: 0.4498283\ttotal: 33.9s\tremaining: 46.8s\n",
      "420:\tlearn: 0.4498178\ttotal: 33.9s\tremaining: 46.7s\n",
      "421:\tlearn: 0.4498061\ttotal: 34s\tremaining: 46.6s\n",
      "422:\tlearn: 0.4497951\ttotal: 34.1s\tremaining: 46.5s\n",
      "423:\tlearn: 0.4497838\ttotal: 34.2s\tremaining: 46.4s\n",
      "424:\tlearn: 0.4497701\ttotal: 34.2s\tremaining: 46.3s\n",
      "425:\tlearn: 0.4497594\ttotal: 34.3s\tremaining: 46.2s\n",
      "426:\tlearn: 0.4497508\ttotal: 34.4s\tremaining: 46.1s\n",
      "427:\tlearn: 0.4497398\ttotal: 34.5s\tremaining: 46.1s\n",
      "428:\tlearn: 0.4497276\ttotal: 34.5s\tremaining: 46s\n",
      "429:\tlearn: 0.4497165\ttotal: 34.6s\tremaining: 45.9s\n",
      "430:\tlearn: 0.4497060\ttotal: 34.7s\tremaining: 45.8s\n",
      "431:\tlearn: 0.4496954\ttotal: 34.8s\tremaining: 45.7s\n",
      "432:\tlearn: 0.4496843\ttotal: 34.8s\tremaining: 45.6s\n",
      "433:\tlearn: 0.4496720\ttotal: 34.9s\tremaining: 45.5s\n",
      "434:\tlearn: 0.4496636\ttotal: 35s\tremaining: 45.4s\n",
      "435:\tlearn: 0.4496531\ttotal: 35.1s\tremaining: 45.4s\n",
      "436:\tlearn: 0.4496433\ttotal: 35.1s\tremaining: 45.3s\n",
      "437:\tlearn: 0.4496309\ttotal: 35.2s\tremaining: 45.2s\n",
      "438:\tlearn: 0.4496203\ttotal: 35.3s\tremaining: 45.1s\n",
      "439:\tlearn: 0.4496116\ttotal: 35.4s\tremaining: 45s\n",
      "440:\tlearn: 0.4496014\ttotal: 35.5s\tremaining: 45s\n",
      "441:\tlearn: 0.4495880\ttotal: 35.5s\tremaining: 44.9s\n",
      "442:\tlearn: 0.4495805\ttotal: 35.6s\tremaining: 44.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443:\tlearn: 0.4495706\ttotal: 35.7s\tremaining: 44.7s\n",
      "444:\tlearn: 0.4495574\ttotal: 35.8s\tremaining: 44.6s\n",
      "445:\tlearn: 0.4495456\ttotal: 35.8s\tremaining: 44.5s\n",
      "446:\tlearn: 0.4495382\ttotal: 35.9s\tremaining: 44.4s\n",
      "447:\tlearn: 0.4495273\ttotal: 36s\tremaining: 44.4s\n",
      "448:\tlearn: 0.4495190\ttotal: 36.1s\tremaining: 44.3s\n",
      "449:\tlearn: 0.4495084\ttotal: 36.2s\tremaining: 44.2s\n",
      "450:\tlearn: 0.4494964\ttotal: 36.2s\tremaining: 44.1s\n",
      "451:\tlearn: 0.4494856\ttotal: 36.3s\tremaining: 44s\n",
      "452:\tlearn: 0.4494746\ttotal: 36.4s\tremaining: 43.9s\n",
      "453:\tlearn: 0.4494648\ttotal: 36.5s\tremaining: 43.9s\n",
      "454:\tlearn: 0.4494547\ttotal: 36.5s\tremaining: 43.8s\n",
      "455:\tlearn: 0.4494440\ttotal: 36.6s\tremaining: 43.7s\n",
      "456:\tlearn: 0.4494303\ttotal: 36.7s\tremaining: 43.6s\n",
      "457:\tlearn: 0.4494205\ttotal: 36.8s\tremaining: 43.5s\n",
      "458:\tlearn: 0.4494125\ttotal: 36.8s\tremaining: 43.4s\n",
      "459:\tlearn: 0.4494018\ttotal: 36.9s\tremaining: 43.3s\n",
      "460:\tlearn: 0.4493909\ttotal: 37s\tremaining: 43.3s\n",
      "461:\tlearn: 0.4493780\ttotal: 37.1s\tremaining: 43.2s\n",
      "462:\tlearn: 0.4493667\ttotal: 37.1s\tremaining: 43.1s\n",
      "463:\tlearn: 0.4493568\ttotal: 37.2s\tremaining: 43s\n",
      "464:\tlearn: 0.4493442\ttotal: 37.3s\tremaining: 42.9s\n",
      "465:\tlearn: 0.4493316\ttotal: 37.4s\tremaining: 42.8s\n",
      "466:\tlearn: 0.4493194\ttotal: 37.5s\tremaining: 42.8s\n",
      "467:\tlearn: 0.4493060\ttotal: 37.5s\tremaining: 42.7s\n",
      "468:\tlearn: 0.4492954\ttotal: 37.6s\tremaining: 42.6s\n",
      "469:\tlearn: 0.4492827\ttotal: 37.7s\tremaining: 42.5s\n",
      "470:\tlearn: 0.4492710\ttotal: 37.8s\tremaining: 42.4s\n",
      "471:\tlearn: 0.4492586\ttotal: 37.8s\tremaining: 42.3s\n",
      "472:\tlearn: 0.4492470\ttotal: 37.9s\tremaining: 42.2s\n",
      "473:\tlearn: 0.4492364\ttotal: 38s\tremaining: 42.1s\n",
      "474:\tlearn: 0.4492252\ttotal: 38.1s\tremaining: 42.1s\n",
      "475:\tlearn: 0.4492150\ttotal: 38.1s\tremaining: 42s\n",
      "476:\tlearn: 0.4492056\ttotal: 38.2s\tremaining: 41.9s\n",
      "477:\tlearn: 0.4491939\ttotal: 38.3s\tremaining: 41.8s\n",
      "478:\tlearn: 0.4491817\ttotal: 38.4s\tremaining: 41.7s\n",
      "479:\tlearn: 0.4491698\ttotal: 38.4s\tremaining: 41.6s\n",
      "480:\tlearn: 0.4491601\ttotal: 38.5s\tremaining: 41.6s\n",
      "481:\tlearn: 0.4491490\ttotal: 38.6s\tremaining: 41.5s\n",
      "482:\tlearn: 0.4491391\ttotal: 38.7s\tremaining: 41.4s\n",
      "483:\tlearn: 0.4491295\ttotal: 38.7s\tremaining: 41.3s\n",
      "484:\tlearn: 0.4491209\ttotal: 38.8s\tremaining: 41.2s\n",
      "485:\tlearn: 0.4491091\ttotal: 38.9s\tremaining: 41.1s\n",
      "486:\tlearn: 0.4491000\ttotal: 39s\tremaining: 41s\n",
      "487:\tlearn: 0.4490888\ttotal: 39s\tremaining: 40.9s\n",
      "488:\tlearn: 0.4490803\ttotal: 39.1s\tremaining: 40.8s\n",
      "489:\tlearn: 0.4490687\ttotal: 39.1s\tremaining: 40.7s\n",
      "490:\tlearn: 0.4490589\ttotal: 39.2s\tremaining: 40.7s\n",
      "491:\tlearn: 0.4490493\ttotal: 39.3s\tremaining: 40.6s\n",
      "492:\tlearn: 0.4490390\ttotal: 39.4s\tremaining: 40.5s\n",
      "493:\tlearn: 0.4490269\ttotal: 39.5s\tremaining: 40.4s\n",
      "494:\tlearn: 0.4490156\ttotal: 39.5s\tremaining: 40.3s\n",
      "495:\tlearn: 0.4490069\ttotal: 39.6s\tremaining: 40.3s\n",
      "496:\tlearn: 0.4489966\ttotal: 39.7s\tremaining: 40.2s\n",
      "497:\tlearn: 0.4489882\ttotal: 39.8s\tremaining: 40.1s\n",
      "498:\tlearn: 0.4489780\ttotal: 39.9s\tremaining: 40s\n",
      "499:\tlearn: 0.4489672\ttotal: 39.9s\tremaining: 39.9s\n",
      "500:\tlearn: 0.4489569\ttotal: 40s\tremaining: 39.9s\n",
      "501:\tlearn: 0.4489454\ttotal: 40.1s\tremaining: 39.8s\n",
      "502:\tlearn: 0.4489350\ttotal: 40.2s\tremaining: 39.7s\n",
      "503:\tlearn: 0.4489225\ttotal: 40.3s\tremaining: 39.6s\n",
      "504:\tlearn: 0.4489090\ttotal: 40.3s\tremaining: 39.5s\n",
      "505:\tlearn: 0.4489005\ttotal: 40.4s\tremaining: 39.5s\n",
      "506:\tlearn: 0.4488877\ttotal: 40.5s\tremaining: 39.4s\n",
      "507:\tlearn: 0.4488757\ttotal: 40.6s\tremaining: 39.3s\n",
      "508:\tlearn: 0.4488665\ttotal: 40.6s\tremaining: 39.2s\n",
      "509:\tlearn: 0.4488552\ttotal: 40.7s\tremaining: 39.1s\n",
      "510:\tlearn: 0.4488449\ttotal: 40.8s\tremaining: 39s\n",
      "511:\tlearn: 0.4488364\ttotal: 40.8s\tremaining: 38.9s\n",
      "512:\tlearn: 0.4488259\ttotal: 40.9s\tremaining: 38.9s\n",
      "513:\tlearn: 0.4488167\ttotal: 41s\tremaining: 38.8s\n",
      "514:\tlearn: 0.4488052\ttotal: 41.1s\tremaining: 38.7s\n",
      "515:\tlearn: 0.4487930\ttotal: 41.2s\tremaining: 38.6s\n",
      "516:\tlearn: 0.4487821\ttotal: 41.2s\tremaining: 38.5s\n",
      "517:\tlearn: 0.4487704\ttotal: 41.3s\tremaining: 38.4s\n",
      "518:\tlearn: 0.4487581\ttotal: 41.4s\tremaining: 38.4s\n",
      "519:\tlearn: 0.4487473\ttotal: 41.5s\tremaining: 38.3s\n",
      "520:\tlearn: 0.4487348\ttotal: 41.5s\tremaining: 38.2s\n",
      "521:\tlearn: 0.4487234\ttotal: 41.6s\tremaining: 38.1s\n",
      "522:\tlearn: 0.4487107\ttotal: 41.7s\tremaining: 38s\n",
      "523:\tlearn: 0.4487005\ttotal: 41.8s\tremaining: 38s\n",
      "524:\tlearn: 0.4486883\ttotal: 41.9s\tremaining: 37.9s\n",
      "525:\tlearn: 0.4486772\ttotal: 41.9s\tremaining: 37.8s\n",
      "526:\tlearn: 0.4486687\ttotal: 42s\tremaining: 37.7s\n",
      "527:\tlearn: 0.4486553\ttotal: 42.1s\tremaining: 37.6s\n",
      "528:\tlearn: 0.4486440\ttotal: 42.2s\tremaining: 37.6s\n",
      "529:\tlearn: 0.4486335\ttotal: 42.3s\tremaining: 37.5s\n",
      "530:\tlearn: 0.4486229\ttotal: 42.3s\tremaining: 37.4s\n",
      "531:\tlearn: 0.4486115\ttotal: 42.4s\tremaining: 37.3s\n",
      "532:\tlearn: 0.4486000\ttotal: 42.5s\tremaining: 37.2s\n",
      "533:\tlearn: 0.4485887\ttotal: 42.6s\tremaining: 37.2s\n",
      "534:\tlearn: 0.4485775\ttotal: 42.7s\tremaining: 37.1s\n",
      "535:\tlearn: 0.4485649\ttotal: 42.7s\tremaining: 37s\n",
      "536:\tlearn: 0.4485558\ttotal: 42.8s\tremaining: 36.9s\n",
      "537:\tlearn: 0.4485460\ttotal: 42.9s\tremaining: 36.8s\n",
      "538:\tlearn: 0.4485365\ttotal: 42.9s\tremaining: 36.7s\n",
      "539:\tlearn: 0.4485252\ttotal: 43s\tremaining: 36.6s\n",
      "540:\tlearn: 0.4485140\ttotal: 43.1s\tremaining: 36.6s\n",
      "541:\tlearn: 0.4485026\ttotal: 43.2s\tremaining: 36.5s\n",
      "542:\tlearn: 0.4484915\ttotal: 43.3s\tremaining: 36.4s\n",
      "543:\tlearn: 0.4484800\ttotal: 43.3s\tremaining: 36.3s\n",
      "544:\tlearn: 0.4484690\ttotal: 43.4s\tremaining: 36.3s\n",
      "545:\tlearn: 0.4484581\ttotal: 43.5s\tremaining: 36.2s\n",
      "546:\tlearn: 0.4484507\ttotal: 43.6s\tremaining: 36.1s\n",
      "547:\tlearn: 0.4484398\ttotal: 43.7s\tremaining: 36s\n",
      "548:\tlearn: 0.4484305\ttotal: 43.7s\tremaining: 35.9s\n",
      "549:\tlearn: 0.4484207\ttotal: 43.8s\tremaining: 35.8s\n",
      "550:\tlearn: 0.4484100\ttotal: 43.9s\tremaining: 35.8s\n",
      "551:\tlearn: 0.4483986\ttotal: 44s\tremaining: 35.7s\n",
      "552:\tlearn: 0.4483868\ttotal: 44s\tremaining: 35.6s\n",
      "553:\tlearn: 0.4483742\ttotal: 44.1s\tremaining: 35.5s\n",
      "554:\tlearn: 0.4483634\ttotal: 44.2s\tremaining: 35.4s\n",
      "555:\tlearn: 0.4483520\ttotal: 44.3s\tremaining: 35.3s\n",
      "556:\tlearn: 0.4483417\ttotal: 44.3s\tremaining: 35.3s\n",
      "557:\tlearn: 0.4483329\ttotal: 44.4s\tremaining: 35.2s\n",
      "558:\tlearn: 0.4483229\ttotal: 44.5s\tremaining: 35.1s\n",
      "559:\tlearn: 0.4483143\ttotal: 44.5s\tremaining: 35s\n",
      "560:\tlearn: 0.4483038\ttotal: 44.6s\tremaining: 34.9s\n",
      "561:\tlearn: 0.4482914\ttotal: 44.7s\tremaining: 34.8s\n",
      "562:\tlearn: 0.4482816\ttotal: 44.8s\tremaining: 34.8s\n",
      "563:\tlearn: 0.4482736\ttotal: 44.9s\tremaining: 34.7s\n",
      "564:\tlearn: 0.4482641\ttotal: 44.9s\tremaining: 34.6s\n",
      "565:\tlearn: 0.4482529\ttotal: 45s\tremaining: 34.5s\n",
      "566:\tlearn: 0.4482428\ttotal: 45.1s\tremaining: 34.4s\n",
      "567:\tlearn: 0.4482339\ttotal: 45.2s\tremaining: 34.3s\n",
      "568:\tlearn: 0.4482238\ttotal: 45.2s\tremaining: 34.3s\n",
      "569:\tlearn: 0.4482153\ttotal: 45.3s\tremaining: 34.2s\n",
      "570:\tlearn: 0.4482023\ttotal: 45.4s\tremaining: 34.1s\n",
      "571:\tlearn: 0.4481932\ttotal: 45.5s\tremaining: 34s\n",
      "572:\tlearn: 0.4481823\ttotal: 45.5s\tremaining: 33.9s\n",
      "573:\tlearn: 0.4481717\ttotal: 45.6s\tremaining: 33.9s\n",
      "574:\tlearn: 0.4481591\ttotal: 45.7s\tremaining: 33.8s\n",
      "575:\tlearn: 0.4481449\ttotal: 45.8s\tremaining: 33.7s\n",
      "576:\tlearn: 0.4481338\ttotal: 45.9s\tremaining: 33.6s\n",
      "577:\tlearn: 0.4481242\ttotal: 45.9s\tremaining: 33.5s\n",
      "578:\tlearn: 0.4481142\ttotal: 46s\tremaining: 33.5s\n",
      "579:\tlearn: 0.4481056\ttotal: 46.1s\tremaining: 33.4s\n",
      "580:\tlearn: 0.4480951\ttotal: 46.2s\tremaining: 33.3s\n",
      "581:\tlearn: 0.4480869\ttotal: 46.2s\tremaining: 33.2s\n",
      "582:\tlearn: 0.4480772\ttotal: 46.3s\tremaining: 33.1s\n",
      "583:\tlearn: 0.4480674\ttotal: 46.4s\tremaining: 33.1s\n",
      "584:\tlearn: 0.4480588\ttotal: 46.5s\tremaining: 33s\n",
      "585:\tlearn: 0.4480491\ttotal: 46.6s\tremaining: 32.9s\n",
      "586:\tlearn: 0.4480404\ttotal: 46.6s\tremaining: 32.8s\n",
      "587:\tlearn: 0.4480317\ttotal: 46.7s\tremaining: 32.7s\n",
      "588:\tlearn: 0.4480214\ttotal: 46.8s\tremaining: 32.6s\n",
      "589:\tlearn: 0.4480112\ttotal: 46.9s\tremaining: 32.6s\n",
      "590:\tlearn: 0.4479998\ttotal: 46.9s\tremaining: 32.5s\n",
      "591:\tlearn: 0.4479888\ttotal: 47s\tremaining: 32.4s\n",
      "592:\tlearn: 0.4479789\ttotal: 47.1s\tremaining: 32.3s\n",
      "593:\tlearn: 0.4479688\ttotal: 47.2s\tremaining: 32.2s\n",
      "594:\tlearn: 0.4479605\ttotal: 47.2s\tremaining: 32.2s\n",
      "595:\tlearn: 0.4479513\ttotal: 47.3s\tremaining: 32.1s\n",
      "596:\tlearn: 0.4479417\ttotal: 47.4s\tremaining: 32s\n",
      "597:\tlearn: 0.4479329\ttotal: 47.4s\tremaining: 31.9s\n",
      "598:\tlearn: 0.4479190\ttotal: 47.5s\tremaining: 31.8s\n",
      "599:\tlearn: 0.4479088\ttotal: 47.6s\tremaining: 31.7s\n",
      "600:\tlearn: 0.4479008\ttotal: 47.7s\tremaining: 31.7s\n",
      "601:\tlearn: 0.4478881\ttotal: 47.8s\tremaining: 31.6s\n",
      "602:\tlearn: 0.4478770\ttotal: 47.8s\tremaining: 31.5s\n",
      "603:\tlearn: 0.4478671\ttotal: 47.9s\tremaining: 31.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604:\tlearn: 0.4478574\ttotal: 48s\tremaining: 31.3s\n",
      "605:\tlearn: 0.4478447\ttotal: 48.1s\tremaining: 31.2s\n",
      "606:\tlearn: 0.4478348\ttotal: 48.1s\tremaining: 31.2s\n",
      "607:\tlearn: 0.4478247\ttotal: 48.2s\tremaining: 31.1s\n",
      "608:\tlearn: 0.4478135\ttotal: 48.3s\tremaining: 31s\n",
      "609:\tlearn: 0.4478040\ttotal: 48.4s\tremaining: 30.9s\n",
      "610:\tlearn: 0.4477947\ttotal: 48.4s\tremaining: 30.8s\n",
      "611:\tlearn: 0.4477842\ttotal: 48.5s\tremaining: 30.8s\n",
      "612:\tlearn: 0.4477727\ttotal: 48.6s\tremaining: 30.7s\n",
      "613:\tlearn: 0.4477634\ttotal: 48.7s\tremaining: 30.6s\n",
      "614:\tlearn: 0.4477543\ttotal: 48.7s\tremaining: 30.5s\n",
      "615:\tlearn: 0.4477434\ttotal: 48.8s\tremaining: 30.4s\n",
      "616:\tlearn: 0.4477329\ttotal: 48.9s\tremaining: 30.4s\n",
      "617:\tlearn: 0.4477243\ttotal: 49s\tremaining: 30.3s\n",
      "618:\tlearn: 0.4477139\ttotal: 49s\tremaining: 30.2s\n",
      "619:\tlearn: 0.4477025\ttotal: 49.1s\tremaining: 30.1s\n",
      "620:\tlearn: 0.4476917\ttotal: 49.2s\tremaining: 30s\n",
      "621:\tlearn: 0.4476837\ttotal: 49.3s\tremaining: 29.9s\n",
      "622:\tlearn: 0.4476735\ttotal: 49.4s\tremaining: 29.9s\n",
      "623:\tlearn: 0.4476639\ttotal: 49.4s\tremaining: 29.8s\n",
      "624:\tlearn: 0.4476535\ttotal: 49.5s\tremaining: 29.7s\n",
      "625:\tlearn: 0.4476434\ttotal: 49.6s\tremaining: 29.6s\n",
      "626:\tlearn: 0.4476331\ttotal: 49.7s\tremaining: 29.5s\n",
      "627:\tlearn: 0.4476246\ttotal: 49.7s\tremaining: 29.5s\n",
      "628:\tlearn: 0.4476141\ttotal: 49.8s\tremaining: 29.4s\n",
      "629:\tlearn: 0.4476059\ttotal: 49.9s\tremaining: 29.3s\n",
      "630:\tlearn: 0.4475975\ttotal: 50s\tremaining: 29.2s\n",
      "631:\tlearn: 0.4475880\ttotal: 50s\tremaining: 29.1s\n",
      "632:\tlearn: 0.4475800\ttotal: 50.1s\tremaining: 29s\n",
      "633:\tlearn: 0.4475722\ttotal: 50.2s\tremaining: 29s\n",
      "634:\tlearn: 0.4475619\ttotal: 50.3s\tremaining: 28.9s\n",
      "635:\tlearn: 0.4475540\ttotal: 50.3s\tremaining: 28.8s\n",
      "636:\tlearn: 0.4475448\ttotal: 50.4s\tremaining: 28.7s\n",
      "637:\tlearn: 0.4475369\ttotal: 50.5s\tremaining: 28.6s\n",
      "638:\tlearn: 0.4475276\ttotal: 50.5s\tremaining: 28.5s\n",
      "639:\tlearn: 0.4475181\ttotal: 50.6s\tremaining: 28.5s\n",
      "640:\tlearn: 0.4475077\ttotal: 50.7s\tremaining: 28.4s\n",
      "641:\tlearn: 0.4474978\ttotal: 50.8s\tremaining: 28.3s\n",
      "642:\tlearn: 0.4474875\ttotal: 50.8s\tremaining: 28.2s\n",
      "643:\tlearn: 0.4474783\ttotal: 50.9s\tremaining: 28.1s\n",
      "644:\tlearn: 0.4474702\ttotal: 51s\tremaining: 28.1s\n",
      "645:\tlearn: 0.4474618\ttotal: 51.1s\tremaining: 28s\n",
      "646:\tlearn: 0.4474510\ttotal: 51.1s\tremaining: 27.9s\n",
      "647:\tlearn: 0.4474412\ttotal: 51.2s\tremaining: 27.8s\n",
      "648:\tlearn: 0.4474304\ttotal: 51.3s\tremaining: 27.7s\n",
      "649:\tlearn: 0.4474193\ttotal: 51.4s\tremaining: 27.7s\n",
      "650:\tlearn: 0.4474092\ttotal: 51.4s\tremaining: 27.6s\n",
      "651:\tlearn: 0.4473994\ttotal: 51.5s\tremaining: 27.5s\n",
      "652:\tlearn: 0.4473889\ttotal: 51.6s\tremaining: 27.4s\n",
      "653:\tlearn: 0.4473814\ttotal: 51.6s\tremaining: 27.3s\n",
      "654:\tlearn: 0.4473723\ttotal: 51.7s\tremaining: 27.2s\n",
      "655:\tlearn: 0.4473620\ttotal: 51.8s\tremaining: 27.1s\n",
      "656:\tlearn: 0.4473519\ttotal: 51.8s\tremaining: 27.1s\n",
      "657:\tlearn: 0.4473436\ttotal: 51.9s\tremaining: 27s\n",
      "658:\tlearn: 0.4473303\ttotal: 52s\tremaining: 26.9s\n",
      "659:\tlearn: 0.4473202\ttotal: 52.1s\tremaining: 26.8s\n",
      "660:\tlearn: 0.4473128\ttotal: 52.2s\tremaining: 26.8s\n",
      "661:\tlearn: 0.4473046\ttotal: 52.2s\tremaining: 26.7s\n",
      "662:\tlearn: 0.4472950\ttotal: 52.3s\tremaining: 26.6s\n",
      "663:\tlearn: 0.4472854\ttotal: 52.4s\tremaining: 26.5s\n",
      "664:\tlearn: 0.4472757\ttotal: 52.5s\tremaining: 26.4s\n",
      "665:\tlearn: 0.4472661\ttotal: 52.5s\tremaining: 26.3s\n",
      "666:\tlearn: 0.4472552\ttotal: 52.6s\tremaining: 26.3s\n",
      "667:\tlearn: 0.4472462\ttotal: 52.7s\tremaining: 26.2s\n",
      "668:\tlearn: 0.4472388\ttotal: 52.8s\tremaining: 26.1s\n",
      "669:\tlearn: 0.4472305\ttotal: 52.9s\tremaining: 26s\n",
      "670:\tlearn: 0.4472212\ttotal: 52.9s\tremaining: 25.9s\n",
      "671:\tlearn: 0.4472111\ttotal: 53s\tremaining: 25.9s\n",
      "672:\tlearn: 0.4472032\ttotal: 53.1s\tremaining: 25.8s\n",
      "673:\tlearn: 0.4471941\ttotal: 53.2s\tremaining: 25.7s\n",
      "674:\tlearn: 0.4471848\ttotal: 53.2s\tremaining: 25.6s\n",
      "675:\tlearn: 0.4471760\ttotal: 53.3s\tremaining: 25.6s\n",
      "676:\tlearn: 0.4471676\ttotal: 53.4s\tremaining: 25.5s\n",
      "677:\tlearn: 0.4471570\ttotal: 53.5s\tremaining: 25.4s\n",
      "678:\tlearn: 0.4471461\ttotal: 53.5s\tremaining: 25.3s\n",
      "679:\tlearn: 0.4471380\ttotal: 53.6s\tremaining: 25.2s\n",
      "680:\tlearn: 0.4471294\ttotal: 53.7s\tremaining: 25.1s\n",
      "681:\tlearn: 0.4471188\ttotal: 53.8s\tremaining: 25.1s\n",
      "682:\tlearn: 0.4471096\ttotal: 53.8s\tremaining: 25s\n",
      "683:\tlearn: 0.4470995\ttotal: 53.9s\tremaining: 24.9s\n",
      "684:\tlearn: 0.4470877\ttotal: 54s\tremaining: 24.8s\n",
      "685:\tlearn: 0.4470789\ttotal: 54.1s\tremaining: 24.7s\n",
      "686:\tlearn: 0.4470687\ttotal: 54.1s\tremaining: 24.7s\n",
      "687:\tlearn: 0.4470593\ttotal: 54.2s\tremaining: 24.6s\n",
      "688:\tlearn: 0.4470491\ttotal: 54.3s\tremaining: 24.5s\n",
      "689:\tlearn: 0.4470394\ttotal: 54.4s\tremaining: 24.4s\n",
      "690:\tlearn: 0.4470283\ttotal: 54.4s\tremaining: 24.3s\n",
      "691:\tlearn: 0.4470202\ttotal: 54.5s\tremaining: 24.3s\n",
      "692:\tlearn: 0.4470110\ttotal: 54.6s\tremaining: 24.2s\n",
      "693:\tlearn: 0.4470025\ttotal: 54.7s\tremaining: 24.1s\n",
      "694:\tlearn: 0.4469948\ttotal: 54.7s\tremaining: 24s\n",
      "695:\tlearn: 0.4469876\ttotal: 54.8s\tremaining: 23.9s\n",
      "696:\tlearn: 0.4469805\ttotal: 54.9s\tremaining: 23.9s\n",
      "697:\tlearn: 0.4469715\ttotal: 55s\tremaining: 23.8s\n",
      "698:\tlearn: 0.4469626\ttotal: 55s\tremaining: 23.7s\n",
      "699:\tlearn: 0.4469498\ttotal: 55.1s\tremaining: 23.6s\n",
      "700:\tlearn: 0.4469352\ttotal: 55.2s\tremaining: 23.5s\n",
      "701:\tlearn: 0.4469271\ttotal: 55.3s\tremaining: 23.5s\n",
      "702:\tlearn: 0.4469178\ttotal: 55.3s\tremaining: 23.4s\n",
      "703:\tlearn: 0.4469072\ttotal: 55.4s\tremaining: 23.3s\n",
      "704:\tlearn: 0.4468989\ttotal: 55.5s\tremaining: 23.2s\n",
      "705:\tlearn: 0.4468893\ttotal: 55.6s\tremaining: 23.1s\n",
      "706:\tlearn: 0.4468797\ttotal: 55.7s\tremaining: 23.1s\n",
      "707:\tlearn: 0.4468710\ttotal: 55.7s\tremaining: 23s\n",
      "708:\tlearn: 0.4468639\ttotal: 55.8s\tremaining: 22.9s\n",
      "709:\tlearn: 0.4468534\ttotal: 55.9s\tremaining: 22.8s\n",
      "710:\tlearn: 0.4468437\ttotal: 56s\tremaining: 22.8s\n",
      "711:\tlearn: 0.4468325\ttotal: 56.1s\tremaining: 22.7s\n",
      "712:\tlearn: 0.4468234\ttotal: 56.1s\tremaining: 22.6s\n",
      "713:\tlearn: 0.4468120\ttotal: 56.2s\tremaining: 22.5s\n",
      "714:\tlearn: 0.4468018\ttotal: 56.3s\tremaining: 22.4s\n",
      "715:\tlearn: 0.4467923\ttotal: 56.4s\tremaining: 22.4s\n",
      "716:\tlearn: 0.4467823\ttotal: 56.4s\tremaining: 22.3s\n",
      "717:\tlearn: 0.4467713\ttotal: 56.5s\tremaining: 22.2s\n",
      "718:\tlearn: 0.4467612\ttotal: 56.6s\tremaining: 22.1s\n",
      "719:\tlearn: 0.4467489\ttotal: 56.7s\tremaining: 22s\n",
      "720:\tlearn: 0.4467378\ttotal: 56.8s\tremaining: 22s\n",
      "721:\tlearn: 0.4467297\ttotal: 56.8s\tremaining: 21.9s\n",
      "722:\tlearn: 0.4467200\ttotal: 56.9s\tremaining: 21.8s\n",
      "723:\tlearn: 0.4467112\ttotal: 57s\tremaining: 21.7s\n",
      "724:\tlearn: 0.4466976\ttotal: 57s\tremaining: 21.6s\n",
      "725:\tlearn: 0.4466871\ttotal: 57.1s\tremaining: 21.6s\n",
      "726:\tlearn: 0.4466762\ttotal: 57.2s\tremaining: 21.5s\n",
      "727:\tlearn: 0.4466662\ttotal: 57.3s\tremaining: 21.4s\n",
      "728:\tlearn: 0.4466578\ttotal: 57.4s\tremaining: 21.3s\n",
      "729:\tlearn: 0.4466488\ttotal: 57.4s\tremaining: 21.2s\n",
      "730:\tlearn: 0.4466374\ttotal: 57.5s\tremaining: 21.2s\n",
      "731:\tlearn: 0.4466286\ttotal: 57.6s\tremaining: 21.1s\n",
      "732:\tlearn: 0.4466220\ttotal: 57.7s\tremaining: 21s\n",
      "733:\tlearn: 0.4466132\ttotal: 57.7s\tremaining: 20.9s\n",
      "734:\tlearn: 0.4466011\ttotal: 57.8s\tremaining: 20.8s\n",
      "735:\tlearn: 0.4465901\ttotal: 57.9s\tremaining: 20.8s\n",
      "736:\tlearn: 0.4465806\ttotal: 58s\tremaining: 20.7s\n",
      "737:\tlearn: 0.4465720\ttotal: 58s\tremaining: 20.6s\n",
      "738:\tlearn: 0.4465631\ttotal: 58.1s\tremaining: 20.5s\n",
      "739:\tlearn: 0.4465540\ttotal: 58.2s\tremaining: 20.4s\n",
      "740:\tlearn: 0.4465446\ttotal: 58.3s\tremaining: 20.4s\n",
      "741:\tlearn: 0.4465367\ttotal: 58.4s\tremaining: 20.3s\n",
      "742:\tlearn: 0.4465266\ttotal: 58.4s\tremaining: 20.2s\n",
      "743:\tlearn: 0.4465164\ttotal: 58.5s\tremaining: 20.1s\n",
      "744:\tlearn: 0.4465080\ttotal: 58.6s\tremaining: 20s\n",
      "745:\tlearn: 0.4464976\ttotal: 58.6s\tremaining: 20s\n",
      "746:\tlearn: 0.4464888\ttotal: 58.7s\tremaining: 19.9s\n",
      "747:\tlearn: 0.4464799\ttotal: 58.8s\tremaining: 19.8s\n",
      "748:\tlearn: 0.4464707\ttotal: 58.8s\tremaining: 19.7s\n",
      "749:\tlearn: 0.4464602\ttotal: 58.9s\tremaining: 19.6s\n",
      "750:\tlearn: 0.4464498\ttotal: 59s\tremaining: 19.6s\n",
      "751:\tlearn: 0.4464404\ttotal: 59.1s\tremaining: 19.5s\n",
      "752:\tlearn: 0.4464296\ttotal: 59.1s\tremaining: 19.4s\n",
      "753:\tlearn: 0.4464182\ttotal: 59.2s\tremaining: 19.3s\n",
      "754:\tlearn: 0.4464088\ttotal: 59.3s\tremaining: 19.2s\n",
      "755:\tlearn: 0.4464005\ttotal: 59.4s\tremaining: 19.2s\n",
      "756:\tlearn: 0.4463912\ttotal: 59.4s\tremaining: 19.1s\n",
      "757:\tlearn: 0.4463852\ttotal: 59.5s\tremaining: 19s\n",
      "758:\tlearn: 0.4463759\ttotal: 59.6s\tremaining: 18.9s\n",
      "759:\tlearn: 0.4463668\ttotal: 59.7s\tremaining: 18.8s\n",
      "760:\tlearn: 0.4463584\ttotal: 59.7s\tremaining: 18.8s\n",
      "761:\tlearn: 0.4463500\ttotal: 59.8s\tremaining: 18.7s\n",
      "762:\tlearn: 0.4463410\ttotal: 59.9s\tremaining: 18.6s\n",
      "763:\tlearn: 0.4463318\ttotal: 60s\tremaining: 18.5s\n",
      "764:\tlearn: 0.4463228\ttotal: 1m\tremaining: 18.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765:\tlearn: 0.4463122\ttotal: 1m\tremaining: 18.4s\n",
      "766:\tlearn: 0.4463023\ttotal: 1m\tremaining: 18.3s\n",
      "767:\tlearn: 0.4462916\ttotal: 1m\tremaining: 18.2s\n",
      "768:\tlearn: 0.4462828\ttotal: 1m\tremaining: 18.1s\n",
      "769:\tlearn: 0.4462711\ttotal: 1m\tremaining: 18.1s\n",
      "770:\tlearn: 0.4462627\ttotal: 1m\tremaining: 18s\n",
      "771:\tlearn: 0.4462566\ttotal: 1m\tremaining: 17.9s\n",
      "772:\tlearn: 0.4462454\ttotal: 1m\tremaining: 17.8s\n",
      "773:\tlearn: 0.4462371\ttotal: 1m\tremaining: 17.7s\n",
      "774:\tlearn: 0.4462295\ttotal: 1m\tremaining: 17.7s\n",
      "775:\tlearn: 0.4462210\ttotal: 1m\tremaining: 17.6s\n",
      "776:\tlearn: 0.4462121\ttotal: 1m\tremaining: 17.5s\n",
      "777:\tlearn: 0.4462018\ttotal: 1m 1s\tremaining: 17.4s\n",
      "778:\tlearn: 0.4461929\ttotal: 1m 1s\tremaining: 17.3s\n",
      "779:\tlearn: 0.4461828\ttotal: 1m 1s\tremaining: 17.3s\n",
      "780:\tlearn: 0.4461746\ttotal: 1m 1s\tremaining: 17.2s\n",
      "781:\tlearn: 0.4461621\ttotal: 1m 1s\tremaining: 17.1s\n",
      "782:\tlearn: 0.4461522\ttotal: 1m 1s\tremaining: 17s\n",
      "783:\tlearn: 0.4461447\ttotal: 1m 1s\tremaining: 16.9s\n",
      "784:\tlearn: 0.4461351\ttotal: 1m 1s\tremaining: 16.9s\n",
      "785:\tlearn: 0.4461254\ttotal: 1m 1s\tremaining: 16.8s\n",
      "786:\tlearn: 0.4461166\ttotal: 1m 1s\tremaining: 16.7s\n",
      "787:\tlearn: 0.4461077\ttotal: 1m 1s\tremaining: 16.6s\n",
      "788:\tlearn: 0.4460956\ttotal: 1m 1s\tremaining: 16.6s\n",
      "789:\tlearn: 0.4460863\ttotal: 1m 1s\tremaining: 16.5s\n",
      "790:\tlearn: 0.4460793\ttotal: 1m 2s\tremaining: 16.4s\n",
      "791:\tlearn: 0.4460708\ttotal: 1m 2s\tremaining: 16.3s\n",
      "792:\tlearn: 0.4460622\ttotal: 1m 2s\tremaining: 16.2s\n",
      "793:\tlearn: 0.4460522\ttotal: 1m 2s\tremaining: 16.2s\n",
      "794:\tlearn: 0.4460427\ttotal: 1m 2s\tremaining: 16.1s\n",
      "795:\tlearn: 0.4460342\ttotal: 1m 2s\tremaining: 16s\n",
      "796:\tlearn: 0.4460245\ttotal: 1m 2s\tremaining: 15.9s\n",
      "797:\tlearn: 0.4460174\ttotal: 1m 2s\tremaining: 15.8s\n",
      "798:\tlearn: 0.4460077\ttotal: 1m 2s\tremaining: 15.8s\n",
      "799:\tlearn: 0.4459991\ttotal: 1m 2s\tremaining: 15.7s\n",
      "800:\tlearn: 0.4459899\ttotal: 1m 2s\tremaining: 15.6s\n",
      "801:\tlearn: 0.4459783\ttotal: 1m 2s\tremaining: 15.5s\n",
      "802:\tlearn: 0.4459687\ttotal: 1m 2s\tremaining: 15.4s\n",
      "803:\tlearn: 0.4459595\ttotal: 1m 3s\tremaining: 15.4s\n",
      "804:\tlearn: 0.4459515\ttotal: 1m 3s\tremaining: 15.3s\n",
      "805:\tlearn: 0.4459442\ttotal: 1m 3s\tremaining: 15.2s\n",
      "806:\tlearn: 0.4459357\ttotal: 1m 3s\tremaining: 15.1s\n",
      "807:\tlearn: 0.4459257\ttotal: 1m 3s\tremaining: 15.1s\n",
      "808:\tlearn: 0.4459174\ttotal: 1m 3s\tremaining: 15s\n",
      "809:\tlearn: 0.4459099\ttotal: 1m 3s\tremaining: 14.9s\n",
      "810:\tlearn: 0.4458989\ttotal: 1m 3s\tremaining: 14.8s\n",
      "811:\tlearn: 0.4458929\ttotal: 1m 3s\tremaining: 14.7s\n",
      "812:\tlearn: 0.4458831\ttotal: 1m 3s\tremaining: 14.7s\n",
      "813:\tlearn: 0.4458740\ttotal: 1m 3s\tremaining: 14.6s\n",
      "814:\tlearn: 0.4458662\ttotal: 1m 3s\tremaining: 14.5s\n",
      "815:\tlearn: 0.4458580\ttotal: 1m 3s\tremaining: 14.4s\n",
      "816:\tlearn: 0.4458487\ttotal: 1m 4s\tremaining: 14.3s\n",
      "817:\tlearn: 0.4458417\ttotal: 1m 4s\tremaining: 14.3s\n",
      "818:\tlearn: 0.4458325\ttotal: 1m 4s\tremaining: 14.2s\n",
      "819:\tlearn: 0.4458233\ttotal: 1m 4s\tremaining: 14.1s\n",
      "820:\tlearn: 0.4458148\ttotal: 1m 4s\tremaining: 14s\n",
      "821:\tlearn: 0.4458057\ttotal: 1m 4s\tremaining: 13.9s\n",
      "822:\tlearn: 0.4457960\ttotal: 1m 4s\tremaining: 13.9s\n",
      "823:\tlearn: 0.4457886\ttotal: 1m 4s\tremaining: 13.8s\n",
      "824:\tlearn: 0.4457778\ttotal: 1m 4s\tremaining: 13.7s\n",
      "825:\tlearn: 0.4457662\ttotal: 1m 4s\tremaining: 13.6s\n",
      "826:\tlearn: 0.4457553\ttotal: 1m 4s\tremaining: 13.6s\n",
      "827:\tlearn: 0.4457441\ttotal: 1m 4s\tremaining: 13.5s\n",
      "828:\tlearn: 0.4457360\ttotal: 1m 4s\tremaining: 13.4s\n",
      "829:\tlearn: 0.4457256\ttotal: 1m 5s\tremaining: 13.3s\n",
      "830:\tlearn: 0.4457174\ttotal: 1m 5s\tremaining: 13.2s\n",
      "831:\tlearn: 0.4457083\ttotal: 1m 5s\tremaining: 13.2s\n",
      "832:\tlearn: 0.4457004\ttotal: 1m 5s\tremaining: 13.1s\n",
      "833:\tlearn: 0.4456910\ttotal: 1m 5s\tremaining: 13s\n",
      "834:\tlearn: 0.4456797\ttotal: 1m 5s\tremaining: 12.9s\n",
      "835:\tlearn: 0.4456705\ttotal: 1m 5s\tremaining: 12.9s\n",
      "836:\tlearn: 0.4456620\ttotal: 1m 5s\tremaining: 12.8s\n",
      "837:\tlearn: 0.4456528\ttotal: 1m 5s\tremaining: 12.7s\n",
      "838:\tlearn: 0.4456434\ttotal: 1m 5s\tremaining: 12.6s\n",
      "839:\tlearn: 0.4456345\ttotal: 1m 5s\tremaining: 12.5s\n",
      "840:\tlearn: 0.4456255\ttotal: 1m 5s\tremaining: 12.5s\n",
      "841:\tlearn: 0.4456168\ttotal: 1m 5s\tremaining: 12.4s\n",
      "842:\tlearn: 0.4456057\ttotal: 1m 6s\tremaining: 12.3s\n",
      "843:\tlearn: 0.4455958\ttotal: 1m 6s\tremaining: 12.2s\n",
      "844:\tlearn: 0.4455850\ttotal: 1m 6s\tremaining: 12.1s\n",
      "845:\tlearn: 0.4455772\ttotal: 1m 6s\tremaining: 12.1s\n",
      "846:\tlearn: 0.4455679\ttotal: 1m 6s\tremaining: 12s\n",
      "847:\tlearn: 0.4455598\ttotal: 1m 6s\tremaining: 11.9s\n",
      "848:\tlearn: 0.4455508\ttotal: 1m 6s\tremaining: 11.8s\n",
      "849:\tlearn: 0.4455429\ttotal: 1m 6s\tremaining: 11.8s\n",
      "850:\tlearn: 0.4455335\ttotal: 1m 6s\tremaining: 11.7s\n",
      "851:\tlearn: 0.4455239\ttotal: 1m 6s\tremaining: 11.6s\n",
      "852:\tlearn: 0.4455166\ttotal: 1m 6s\tremaining: 11.5s\n",
      "853:\tlearn: 0.4455026\ttotal: 1m 6s\tremaining: 11.4s\n",
      "854:\tlearn: 0.4454951\ttotal: 1m 6s\tremaining: 11.4s\n",
      "855:\tlearn: 0.4454833\ttotal: 1m 7s\tremaining: 11.3s\n",
      "856:\tlearn: 0.4454736\ttotal: 1m 7s\tremaining: 11.2s\n",
      "857:\tlearn: 0.4454639\ttotal: 1m 7s\tremaining: 11.1s\n",
      "858:\tlearn: 0.4454544\ttotal: 1m 7s\tremaining: 11.1s\n",
      "859:\tlearn: 0.4454469\ttotal: 1m 7s\tremaining: 11s\n",
      "860:\tlearn: 0.4454369\ttotal: 1m 7s\tremaining: 10.9s\n",
      "861:\tlearn: 0.4454262\ttotal: 1m 7s\tremaining: 10.8s\n",
      "862:\tlearn: 0.4454182\ttotal: 1m 7s\tremaining: 10.7s\n",
      "863:\tlearn: 0.4454114\ttotal: 1m 7s\tremaining: 10.7s\n",
      "864:\tlearn: 0.4454007\ttotal: 1m 7s\tremaining: 10.6s\n",
      "865:\tlearn: 0.4453910\ttotal: 1m 7s\tremaining: 10.5s\n",
      "866:\tlearn: 0.4453804\ttotal: 1m 7s\tremaining: 10.4s\n",
      "867:\tlearn: 0.4453698\ttotal: 1m 8s\tremaining: 10.3s\n",
      "868:\tlearn: 0.4453600\ttotal: 1m 8s\tremaining: 10.3s\n",
      "869:\tlearn: 0.4453512\ttotal: 1m 8s\tremaining: 10.2s\n",
      "870:\tlearn: 0.4453418\ttotal: 1m 8s\tremaining: 10.1s\n",
      "871:\tlearn: 0.4453343\ttotal: 1m 8s\tremaining: 10s\n",
      "872:\tlearn: 0.4453237\ttotal: 1m 8s\tremaining: 9.95s\n",
      "873:\tlearn: 0.4453129\ttotal: 1m 8s\tremaining: 9.87s\n",
      "874:\tlearn: 0.4453055\ttotal: 1m 8s\tremaining: 9.79s\n",
      "875:\tlearn: 0.4452980\ttotal: 1m 8s\tremaining: 9.71s\n",
      "876:\tlearn: 0.4452888\ttotal: 1m 8s\tremaining: 9.64s\n",
      "877:\tlearn: 0.4452811\ttotal: 1m 8s\tremaining: 9.56s\n",
      "878:\tlearn: 0.4452712\ttotal: 1m 8s\tremaining: 9.48s\n",
      "879:\tlearn: 0.4452632\ttotal: 1m 8s\tremaining: 9.4s\n",
      "880:\tlearn: 0.4452556\ttotal: 1m 9s\tremaining: 9.32s\n",
      "881:\tlearn: 0.4452454\ttotal: 1m 9s\tremaining: 9.24s\n",
      "882:\tlearn: 0.4452359\ttotal: 1m 9s\tremaining: 9.16s\n",
      "883:\tlearn: 0.4452279\ttotal: 1m 9s\tremaining: 9.09s\n",
      "884:\tlearn: 0.4452184\ttotal: 1m 9s\tremaining: 9.01s\n",
      "885:\tlearn: 0.4452097\ttotal: 1m 9s\tremaining: 8.93s\n",
      "886:\tlearn: 0.4451985\ttotal: 1m 9s\tremaining: 8.85s\n",
      "887:\tlearn: 0.4451872\ttotal: 1m 9s\tremaining: 8.78s\n",
      "888:\tlearn: 0.4451788\ttotal: 1m 9s\tremaining: 8.7s\n",
      "889:\tlearn: 0.4451696\ttotal: 1m 9s\tremaining: 8.62s\n",
      "890:\tlearn: 0.4451621\ttotal: 1m 9s\tremaining: 8.54s\n",
      "891:\tlearn: 0.4451537\ttotal: 1m 9s\tremaining: 8.46s\n",
      "892:\tlearn: 0.4451430\ttotal: 1m 9s\tremaining: 8.38s\n",
      "893:\tlearn: 0.4451325\ttotal: 1m 10s\tremaining: 8.3s\n",
      "894:\tlearn: 0.4451232\ttotal: 1m 10s\tremaining: 8.22s\n",
      "895:\tlearn: 0.4451155\ttotal: 1m 10s\tremaining: 8.14s\n",
      "896:\tlearn: 0.4451071\ttotal: 1m 10s\tremaining: 8.07s\n",
      "897:\tlearn: 0.4450989\ttotal: 1m 10s\tremaining: 7.99s\n",
      "898:\tlearn: 0.4450897\ttotal: 1m 10s\tremaining: 7.91s\n",
      "899:\tlearn: 0.4450832\ttotal: 1m 10s\tremaining: 7.83s\n",
      "900:\tlearn: 0.4450729\ttotal: 1m 10s\tremaining: 7.75s\n",
      "901:\tlearn: 0.4450652\ttotal: 1m 10s\tremaining: 7.67s\n",
      "902:\tlearn: 0.4450526\ttotal: 1m 10s\tremaining: 7.59s\n",
      "903:\tlearn: 0.4450420\ttotal: 1m 10s\tremaining: 7.52s\n",
      "904:\tlearn: 0.4450299\ttotal: 1m 10s\tremaining: 7.44s\n",
      "905:\tlearn: 0.4450235\ttotal: 1m 10s\tremaining: 7.36s\n",
      "906:\tlearn: 0.4450159\ttotal: 1m 11s\tremaining: 7.28s\n",
      "907:\tlearn: 0.4450081\ttotal: 1m 11s\tremaining: 7.2s\n",
      "908:\tlearn: 0.4449984\ttotal: 1m 11s\tremaining: 7.13s\n",
      "909:\tlearn: 0.4449890\ttotal: 1m 11s\tremaining: 7.05s\n",
      "910:\tlearn: 0.4449774\ttotal: 1m 11s\tremaining: 6.97s\n",
      "911:\tlearn: 0.4449688\ttotal: 1m 11s\tremaining: 6.89s\n",
      "912:\tlearn: 0.4449597\ttotal: 1m 11s\tremaining: 6.81s\n",
      "913:\tlearn: 0.4449498\ttotal: 1m 11s\tremaining: 6.74s\n",
      "914:\tlearn: 0.4449410\ttotal: 1m 11s\tremaining: 6.66s\n",
      "915:\tlearn: 0.4449333\ttotal: 1m 11s\tremaining: 6.58s\n",
      "916:\tlearn: 0.4449232\ttotal: 1m 11s\tremaining: 6.5s\n",
      "917:\tlearn: 0.4449167\ttotal: 1m 11s\tremaining: 6.42s\n",
      "918:\tlearn: 0.4449071\ttotal: 1m 12s\tremaining: 6.35s\n",
      "919:\tlearn: 0.4449005\ttotal: 1m 12s\tremaining: 6.27s\n",
      "920:\tlearn: 0.4448923\ttotal: 1m 12s\tremaining: 6.19s\n",
      "921:\tlearn: 0.4448833\ttotal: 1m 12s\tremaining: 6.11s\n",
      "922:\tlearn: 0.4448746\ttotal: 1m 12s\tremaining: 6.03s\n",
      "923:\tlearn: 0.4448653\ttotal: 1m 12s\tremaining: 5.96s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924:\tlearn: 0.4448580\ttotal: 1m 12s\tremaining: 5.88s\n",
      "925:\tlearn: 0.4448511\ttotal: 1m 12s\tremaining: 5.8s\n",
      "926:\tlearn: 0.4448423\ttotal: 1m 12s\tremaining: 5.72s\n",
      "927:\tlearn: 0.4448347\ttotal: 1m 12s\tremaining: 5.64s\n",
      "928:\tlearn: 0.4448238\ttotal: 1m 12s\tremaining: 5.57s\n",
      "929:\tlearn: 0.4448156\ttotal: 1m 12s\tremaining: 5.49s\n",
      "930:\tlearn: 0.4448067\ttotal: 1m 12s\tremaining: 5.41s\n",
      "931:\tlearn: 0.4447997\ttotal: 1m 13s\tremaining: 5.33s\n",
      "932:\tlearn: 0.4447902\ttotal: 1m 13s\tremaining: 5.25s\n",
      "933:\tlearn: 0.4447830\ttotal: 1m 13s\tremaining: 5.17s\n",
      "934:\tlearn: 0.4447725\ttotal: 1m 13s\tremaining: 5.09s\n",
      "935:\tlearn: 0.4447646\ttotal: 1m 13s\tremaining: 5.01s\n",
      "936:\tlearn: 0.4447563\ttotal: 1m 13s\tremaining: 4.94s\n",
      "937:\tlearn: 0.4447485\ttotal: 1m 13s\tremaining: 4.86s\n",
      "938:\tlearn: 0.4447410\ttotal: 1m 13s\tremaining: 4.78s\n",
      "939:\tlearn: 0.4447310\ttotal: 1m 13s\tremaining: 4.7s\n",
      "940:\tlearn: 0.4447226\ttotal: 1m 13s\tremaining: 4.62s\n",
      "941:\tlearn: 0.4447152\ttotal: 1m 13s\tremaining: 4.54s\n",
      "942:\tlearn: 0.4447067\ttotal: 1m 13s\tremaining: 4.46s\n",
      "943:\tlearn: 0.4446979\ttotal: 1m 13s\tremaining: 4.39s\n",
      "944:\tlearn: 0.4446899\ttotal: 1m 14s\tremaining: 4.31s\n",
      "945:\tlearn: 0.4446791\ttotal: 1m 14s\tremaining: 4.23s\n",
      "946:\tlearn: 0.4446691\ttotal: 1m 14s\tremaining: 4.15s\n",
      "947:\tlearn: 0.4446599\ttotal: 1m 14s\tremaining: 4.07s\n",
      "948:\tlearn: 0.4446503\ttotal: 1m 14s\tremaining: 3.99s\n",
      "949:\tlearn: 0.4446414\ttotal: 1m 14s\tremaining: 3.92s\n",
      "950:\tlearn: 0.4446318\ttotal: 1m 14s\tremaining: 3.84s\n",
      "951:\tlearn: 0.4446265\ttotal: 1m 14s\tremaining: 3.76s\n",
      "952:\tlearn: 0.4446176\ttotal: 1m 14s\tremaining: 3.68s\n",
      "953:\tlearn: 0.4446096\ttotal: 1m 14s\tremaining: 3.6s\n",
      "954:\tlearn: 0.4446009\ttotal: 1m 14s\tremaining: 3.52s\n",
      "955:\tlearn: 0.4445906\ttotal: 1m 14s\tremaining: 3.44s\n",
      "956:\tlearn: 0.4445845\ttotal: 1m 14s\tremaining: 3.37s\n",
      "957:\tlearn: 0.4445761\ttotal: 1m 15s\tremaining: 3.29s\n",
      "958:\tlearn: 0.4445694\ttotal: 1m 15s\tremaining: 3.21s\n",
      "959:\tlearn: 0.4445619\ttotal: 1m 15s\tremaining: 3.13s\n",
      "960:\tlearn: 0.4445533\ttotal: 1m 15s\tremaining: 3.05s\n",
      "961:\tlearn: 0.4445452\ttotal: 1m 15s\tremaining: 2.97s\n",
      "962:\tlearn: 0.4445357\ttotal: 1m 15s\tremaining: 2.9s\n",
      "963:\tlearn: 0.4445270\ttotal: 1m 15s\tremaining: 2.82s\n",
      "964:\tlearn: 0.4445182\ttotal: 1m 15s\tremaining: 2.74s\n",
      "965:\tlearn: 0.4445065\ttotal: 1m 15s\tremaining: 2.66s\n",
      "966:\tlearn: 0.4444985\ttotal: 1m 15s\tremaining: 2.58s\n",
      "967:\tlearn: 0.4444888\ttotal: 1m 15s\tremaining: 2.5s\n",
      "968:\tlearn: 0.4444798\ttotal: 1m 15s\tremaining: 2.43s\n",
      "969:\tlearn: 0.4444728\ttotal: 1m 15s\tremaining: 2.35s\n",
      "970:\tlearn: 0.4444650\ttotal: 1m 15s\tremaining: 2.27s\n",
      "971:\tlearn: 0.4444561\ttotal: 1m 16s\tremaining: 2.19s\n",
      "972:\tlearn: 0.4444476\ttotal: 1m 16s\tremaining: 2.11s\n",
      "973:\tlearn: 0.4444379\ttotal: 1m 16s\tremaining: 2.03s\n",
      "974:\tlearn: 0.4444288\ttotal: 1m 16s\tremaining: 1.96s\n",
      "975:\tlearn: 0.4444207\ttotal: 1m 16s\tremaining: 1.88s\n",
      "976:\tlearn: 0.4444133\ttotal: 1m 16s\tremaining: 1.8s\n",
      "977:\tlearn: 0.4444051\ttotal: 1m 16s\tremaining: 1.72s\n",
      "978:\tlearn: 0.4443986\ttotal: 1m 16s\tremaining: 1.64s\n",
      "979:\tlearn: 0.4443870\ttotal: 1m 16s\tremaining: 1.56s\n",
      "980:\tlearn: 0.4443794\ttotal: 1m 16s\tremaining: 1.49s\n",
      "981:\tlearn: 0.4443701\ttotal: 1m 16s\tremaining: 1.41s\n",
      "982:\tlearn: 0.4443592\ttotal: 1m 16s\tremaining: 1.33s\n",
      "983:\tlearn: 0.4443496\ttotal: 1m 17s\tremaining: 1.25s\n",
      "984:\tlearn: 0.4443406\ttotal: 1m 17s\tremaining: 1.17s\n",
      "985:\tlearn: 0.4443295\ttotal: 1m 17s\tremaining: 1.09s\n",
      "986:\tlearn: 0.4443208\ttotal: 1m 17s\tremaining: 1.02s\n",
      "987:\tlearn: 0.4443148\ttotal: 1m 17s\tremaining: 939ms\n",
      "988:\tlearn: 0.4443072\ttotal: 1m 17s\tremaining: 861ms\n",
      "989:\tlearn: 0.4442966\ttotal: 1m 17s\tremaining: 783ms\n",
      "990:\tlearn: 0.4442874\ttotal: 1m 17s\tremaining: 704ms\n",
      "991:\tlearn: 0.4442785\ttotal: 1m 17s\tremaining: 626ms\n",
      "992:\tlearn: 0.4442709\ttotal: 1m 17s\tremaining: 548ms\n",
      "993:\tlearn: 0.4442620\ttotal: 1m 17s\tremaining: 470ms\n",
      "994:\tlearn: 0.4442541\ttotal: 1m 17s\tremaining: 391ms\n",
      "995:\tlearn: 0.4442462\ttotal: 1m 17s\tremaining: 313ms\n",
      "996:\tlearn: 0.4442382\ttotal: 1m 18s\tremaining: 235ms\n",
      "997:\tlearn: 0.4442280\ttotal: 1m 18s\tremaining: 157ms\n",
      "998:\tlearn: 0.4442155\ttotal: 1m 18s\tremaining: 78.3ms\n",
      "999:\tlearn: 0.4442060\ttotal: 1m 18s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8316517472133599\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5579 - auc: 0.7698 - val_loss: 0.4860 - val_auc: 0.8042\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4763 - auc: 0.8132 - val_loss: 0.4753 - val_auc: 0.8124\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4644 - auc: 0.8226 - val_loss: 0.4728 - val_auc: 0.8153\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4612 - auc: 0.8252 - val_loss: 0.4718 - val_auc: 0.8153\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4601 - auc: 0.8260 - val_loss: 0.4714 - val_auc: 0.8158\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4598 - auc: 0.8262 - val_loss: 0.4717 - val_auc: 0.8164\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4594 - auc: 0.8268 - val_loss: 0.4718 - val_auc: 0.8159\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4595 - auc: 0.8268 - val_loss: 0.4712 - val_auc: 0.8164\n",
      "Epoch 9/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4595 - auc: 0.8267\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4594 - auc: 0.8269 - val_loss: 0.4715 - val_auc: 0.8154\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4595 - auc: 0.8268 - val_loss: 0.4712 - val_auc: 0.8179\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4591 - auc: 0.8270 - val_loss: 0.4713 - val_auc: 0.8163\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4595 - auc: 0.8268 - val_loss: 0.4714 - val_auc: 0.8170\n",
      "Epoch 13/100\n",
      "280576/284999 [============================>.] - ETA: 0s - loss: 0.4593 - auc: 0.8268\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4593 - auc: 0.8268 - val_loss: 0.4714 - val_auc: 0.8163\n",
      "Epoch 14/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4591 - auc: 0.8270 - val_loss: 0.4714 - val_auc: 0.8169\n",
      "Epoch 15/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4594 - auc: 0.8268Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4594 - auc: 0.8268 - val_loss: 0.4714 - val_auc: 0.8168\n",
      "Epoch 00015: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5891 - auc: 0.7463 - val_loss: 0.4866 - val_auc: 0.8028\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4817 - auc: 0.8090 - val_loss: 0.4716 - val_auc: 0.8167\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4667 - auc: 0.8207 - val_loss: 0.4685 - val_auc: 0.8181\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4623 - auc: 0.8243 - val_loss: 0.4675 - val_auc: 0.8199\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4608 - auc: 0.8257 - val_loss: 0.4674 - val_auc: 0.8200\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4598 - auc: 0.8263 - val_loss: 0.4670 - val_auc: 0.8191\n",
      "Epoch 7/100\n",
      "281600/284999 [============================>.] - ETA: 0s - loss: 0.4599 - auc: 0.8264\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4601 - auc: 0.8260 - val_loss: 0.4669 - val_auc: 0.8196\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4598 - auc: 0.8264 - val_loss: 0.4670 - val_auc: 0.8201\n",
      "Epoch 9/100\n",
      "280576/284999 [============================>.] - ETA: 0s - loss: 0.4602 - auc: 0.8261Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4600 - auc: 0.8262 - val_loss: 0.4670 - val_auc: 0.8194\n",
      "Epoch 00009: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6130 - auc: 0.7387 - val_loss: 0.4794 - val_auc: 0.8103\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4852 - auc: 0.8058 - val_loss: 0.4584 - val_auc: 0.8284\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4676 - auc: 0.8198 - val_loss: 0.4537 - val_auc: 0.8319\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4634 - auc: 0.8234 - val_loss: 0.4522 - val_auc: 0.8335\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4615 - auc: 0.8249 - val_loss: 0.4515 - val_auc: 0.8340\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4611 - auc: 0.8253 - val_loss: 0.4514 - val_auc: 0.8341\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4604 - auc: 0.8258 - val_loss: 0.4511 - val_auc: 0.8342\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4607 - auc: 0.8258 - val_loss: 0.4510 - val_auc: 0.8346\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4610 - auc: 0.8254 - val_loss: 0.4508 - val_auc: 0.8339\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8259 - val_loss: 0.4508 - val_auc: 0.8337\n",
      "Epoch 11/100\n",
      "281600/284999 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8261\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4605 - auc: 0.8259 - val_loss: 0.4510 - val_auc: 0.8343\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4606 - auc: 0.8258 - val_loss: 0.4511 - val_auc: 0.8346\n",
      "Epoch 13/100\n",
      "283648/284999 [============================>.] - ETA: 0s - loss: 0.4604 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4604 - auc: 0.8259 - val_loss: 0.4510 - val_auc: 0.8340\n",
      "Epoch 00013: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6332 - auc: 0.7151 - val_loss: 0.4838 - val_auc: 0.8073\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4978 - auc: 0.7977 - val_loss: 0.4612 - val_auc: 0.8247\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4550 - val_auc: 0.8313\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4653 - auc: 0.8217 - val_loss: 0.4523 - val_auc: 0.8329\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4625 - auc: 0.8241 - val_loss: 0.4513 - val_auc: 0.8345\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4614 - auc: 0.8251 - val_loss: 0.4509 - val_auc: 0.8340\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4609 - auc: 0.8255 - val_loss: 0.4506 - val_auc: 0.8343\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4611 - auc: 0.8253 - val_loss: 0.4506 - val_auc: 0.8349\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4608 - auc: 0.8257 - val_loss: 0.4505 - val_auc: 0.8340\n",
      "Epoch 10/100\n",
      "277504/284999 [============================>.] - ETA: 0s - loss: 0.4609 - auc: 0.8257Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4608 - auc: 0.8256 - val_loss: 0.4506 - val_auc: 0.8342\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5405 - auc: 0.7968 - val_loss: 0.4669 - val_auc: 0.8237\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4695 - auc: 0.8194 - val_loss: 0.4571 - val_auc: 0.8289\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4625 - auc: 0.8243 - val_loss: 0.4550 - val_auc: 0.8309\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8258 - val_loss: 0.4547 - val_auc: 0.8313\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8255 - val_loss: 0.4544 - val_auc: 0.8309\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8260 - val_loss: 0.4546 - val_auc: 0.8312\n",
      "Epoch 7/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4605 - auc: 0.8258\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8260 - val_loss: 0.4547 - val_auc: 0.8313\n",
      "Epoch 8/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4605 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8260 - val_loss: 0.4546 - val_auc: 0.8309\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5279 - auc: 0.7965 - val_loss: 0.4645 - val_auc: 0.8226\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4695 - auc: 0.8190 - val_loss: 0.4589 - val_auc: 0.8276\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4629 - auc: 0.8239 - val_loss: 0.4575 - val_auc: 0.8281\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4614 - auc: 0.8251 - val_loss: 0.4571 - val_auc: 0.8292\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4610 - auc: 0.8255 - val_loss: 0.4569 - val_auc: 0.8298\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8257 - val_loss: 0.4570 - val_auc: 0.8293\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8257 - val_loss: 0.4569 - val_auc: 0.8295\n",
      "Epoch 8/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8261\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4601 - auc: 0.8262 - val_loss: 0.4567 - val_auc: 0.8290\n",
      "Epoch 9/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4601 - auc: 0.8262Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8258 - val_loss: 0.4568 - val_auc: 0.8291\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5545 - auc: 0.7748 - val_loss: 0.4735 - val_auc: 0.8143\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4741 - auc: 0.8153 - val_loss: 0.4637 - val_auc: 0.8224\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4638 - auc: 0.8232 - val_loss: 0.4616 - val_auc: 0.8249\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4615 - auc: 0.8252 - val_loss: 0.4609 - val_auc: 0.8253\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8257 - val_loss: 0.4607 - val_auc: 0.8250\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8258 - val_loss: 0.4607 - val_auc: 0.8248\n",
      "Epoch 7/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4602 - auc: 0.8262\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8264 - val_loss: 0.4607 - val_auc: 0.8253\n",
      "Epoch 8/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4601 - auc: 0.8263Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4601 - auc: 0.8263 - val_loss: 0.4605 - val_auc: 0.8247\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5699 - auc: 0.7661 - val_loss: 0.4720 - val_auc: 0.8175\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4763 - auc: 0.8134 - val_loss: 0.4601 - val_auc: 0.8261\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4647 - auc: 0.8225 - val_loss: 0.4571 - val_auc: 0.8294\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4619 - auc: 0.8246 - val_loss: 0.4565 - val_auc: 0.8303\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4560 - val_auc: 0.8303\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4601 - auc: 0.8260 - val_loss: 0.4560 - val_auc: 0.8311\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8262 - val_loss: 0.4560 - val_auc: 0.8311\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8260 - val_loss: 0.4557 - val_auc: 0.8307\n",
      "Epoch 9/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8259\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8258 - val_loss: 0.4561 - val_auc: 0.8300\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4600 - auc: 0.8262 - val_loss: 0.4560 - val_auc: 0.8307\n",
      "Epoch 11/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4600 - auc: 0.8264Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8260 - val_loss: 0.4562 - val_auc: 0.8289\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5662 - auc: 0.7580 - val_loss: 0.4625 - val_auc: 0.8260\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4787 - auc: 0.8113 - val_loss: 0.4500 - val_auc: 0.8360\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8214 - val_loss: 0.4472 - val_auc: 0.8390\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4626 - auc: 0.8240 - val_loss: 0.4464 - val_auc: 0.8383\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4615 - auc: 0.8249 - val_loss: 0.4464 - val_auc: 0.8391\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4612 - auc: 0.8251 - val_loss: 0.4461 - val_auc: 0.8397\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4462 - val_auc: 0.8396\n",
      "Epoch 8/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4607 - auc: 0.8257Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4607 - auc: 0.8256 - val_loss: 0.4456 - val_auc: 0.8385\n",
      "Epoch 00008: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5609 - auc: 0.7726 - val_loss: 0.4707 - val_auc: 0.8175\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4761 - auc: 0.8136 - val_loss: 0.4589 - val_auc: 0.8277\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4653 - auc: 0.8219 - val_loss: 0.4557 - val_auc: 0.8306\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4620 - auc: 0.8245 - val_loss: 0.4545 - val_auc: 0.8312\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4611 - auc: 0.8254 - val_loss: 0.4540 - val_auc: 0.8316\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8258 - val_loss: 0.4541 - val_auc: 0.8320\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4538 - val_auc: 0.8322\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8261 - val_loss: 0.4536 - val_auc: 0.8323\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4605 - auc: 0.8258 - val_loss: 0.4536 - val_auc: 0.8316\n",
      "Epoch 10/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4601 - auc: 0.8262\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8260 - val_loss: 0.4538 - val_auc: 0.8319\n",
      "Epoch 11/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4604 - auc: 0.8259Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8257 - val_loss: 0.4537 - val_auc: 0.8324\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5953 - auc: 0.7419 - val_loss: 0.4782 - val_auc: 0.8108\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4864 - auc: 0.8057 - val_loss: 0.4588 - val_auc: 0.8280\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4682 - auc: 0.8192 - val_loss: 0.4534 - val_auc: 0.8319\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4628 - auc: 0.8238 - val_loss: 0.4516 - val_auc: 0.8339\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4613 - auc: 0.8251 - val_loss: 0.4511 - val_auc: 0.8336\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8256 - val_loss: 0.4509 - val_auc: 0.8338\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4612 - auc: 0.8252 - val_loss: 0.4510 - val_auc: 0.8345\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4511 - val_auc: 0.8336\n",
      "Epoch 9/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4609 - auc: 0.8254Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4609 - auc: 0.8254 - val_loss: 0.4508 - val_auc: 0.8348\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5759 - auc: 0.7557 - val_loss: 0.4710 - val_auc: 0.8177\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4808 - auc: 0.8093 - val_loss: 0.4560 - val_auc: 0.8303\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4668 - auc: 0.8204 - val_loss: 0.4516 - val_auc: 0.8337\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4627 - auc: 0.8240 - val_loss: 0.4502 - val_auc: 0.8350\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4618 - auc: 0.8247 - val_loss: 0.4498 - val_auc: 0.8351\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4613 - auc: 0.8251 - val_loss: 0.4496 - val_auc: 0.8353\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4609 - auc: 0.8254 - val_loss: 0.4495 - val_auc: 0.8357\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8260 - val_loss: 0.4495 - val_auc: 0.8351\n",
      "Epoch 9/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4604 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8258 - val_loss: 0.4494 - val_auc: 0.8345\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5831 - auc: 0.7507 - val_loss: 0.4694 - val_auc: 0.8180\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4815 - auc: 0.8090 - val_loss: 0.4547 - val_auc: 0.8320\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4670 - auc: 0.8203 - val_loss: 0.4511 - val_auc: 0.8344\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4631 - auc: 0.8236 - val_loss: 0.4503 - val_auc: 0.8352\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4612 - auc: 0.8253 - val_loss: 0.4499 - val_auc: 0.8355\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4609 - auc: 0.8255 - val_loss: 0.4497 - val_auc: 0.8367\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8256 - val_loss: 0.4499 - val_auc: 0.8352\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8257 - val_loss: 0.4500 - val_auc: 0.8356\n",
      "Epoch 9/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4605 - auc: 0.8259\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8258 - val_loss: 0.4498 - val_auc: 0.8362\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8256 - val_loss: 0.4497 - val_auc: 0.8360\n",
      "Epoch 11/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8261Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8259 - val_loss: 0.4498 - val_auc: 0.8359\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6537 - auc: 0.6917 - val_loss: 0.5123 - val_auc: 0.7821\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5032 - auc: 0.7921 - val_loss: 0.4799 - val_auc: 0.8072\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4748 - auc: 0.8136 - val_loss: 0.4703 - val_auc: 0.8168\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4658 - auc: 0.8214 - val_loss: 0.4668 - val_auc: 0.8202\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4620 - auc: 0.8245 - val_loss: 0.4656 - val_auc: 0.8212\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4608 - auc: 0.8256 - val_loss: 0.4650 - val_auc: 0.8225\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8260 - val_loss: 0.4648 - val_auc: 0.8220\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4598 - auc: 0.8264 - val_loss: 0.4646 - val_auc: 0.8233\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4600 - auc: 0.8265 - val_loss: 0.4646 - val_auc: 0.8218\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4599 - auc: 0.8263 - val_loss: 0.4647 - val_auc: 0.8228\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8261Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4600 - auc: 0.8264 - val_loss: 0.4647 - val_auc: 0.8226\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 8us/sample - loss: 0.5935 - auc: 0.7400 - val_loss: 0.4719 - val_auc: 0.8175\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4804 - auc: 0.8102 - val_loss: 0.4561 - val_auc: 0.8303\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4665 - auc: 0.8208 - val_loss: 0.4530 - val_auc: 0.8322\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4630 - auc: 0.8238 - val_loss: 0.4520 - val_auc: 0.8335\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4613 - auc: 0.8251 - val_loss: 0.4517 - val_auc: 0.8335\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4613 - auc: 0.8252 - val_loss: 0.4517 - val_auc: 0.8342\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8256 - val_loss: 0.4520 - val_auc: 0.8336\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4517 - val_auc: 0.8339\n",
      "Epoch 9/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4604 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8258 - val_loss: 0.4516 - val_auc: 0.8339\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5880 - auc: 0.7444 - val_loss: 0.4775 - val_auc: 0.8118\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4841 - auc: 0.8069 - val_loss: 0.4589 - val_auc: 0.8289\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4679 - auc: 0.8195 - val_loss: 0.4541 - val_auc: 0.8320\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4630 - auc: 0.8236 - val_loss: 0.4529 - val_auc: 0.8336\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4616 - auc: 0.8248 - val_loss: 0.4522 - val_auc: 0.8349\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4608 - auc: 0.8256 - val_loss: 0.4520 - val_auc: 0.8343\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8257 - val_loss: 0.4521 - val_auc: 0.8338\n",
      "Epoch 8/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8259\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8259 - val_loss: 0.4519 - val_auc: 0.8336\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8255 - val_loss: 0.4521 - val_auc: 0.8344\n",
      "Epoch 10/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4603 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4602 - auc: 0.8261 - val_loss: 0.4519 - val_auc: 0.8340\n",
      "Epoch 00010: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5440 - auc: 0.7839 - val_loss: 0.4599 - val_auc: 0.8282\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4727 - auc: 0.8165 - val_loss: 0.4504 - val_auc: 0.8356\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4641 - auc: 0.8229 - val_loss: 0.4484 - val_auc: 0.8369\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4617 - auc: 0.8247 - val_loss: 0.4476 - val_auc: 0.8377\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4609 - auc: 0.8255 - val_loss: 0.4476 - val_auc: 0.8377\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4610 - auc: 0.8254 - val_loss: 0.4473 - val_auc: 0.8378\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4609 - auc: 0.8256 - val_loss: 0.4475 - val_auc: 0.8369\n",
      "Epoch 8/100\n",
      "281600/285001 [============================>.] - ETA: 0s - loss: 0.4605 - auc: 0.8257Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8256 - val_loss: 0.4478 - val_auc: 0.8373\n",
      "Epoch 00008: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5420 - auc: 0.7880 - val_loss: 0.4652 - val_auc: 0.8220\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4712 - auc: 0.8177 - val_loss: 0.4574 - val_auc: 0.8280\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4634 - auc: 0.8236 - val_loss: 0.4559 - val_auc: 0.8290\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4611 - auc: 0.8254 - val_loss: 0.4555 - val_auc: 0.8291\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4607 - auc: 0.8257 - val_loss: 0.4555 - val_auc: 0.8299\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4603 - auc: 0.8260 - val_loss: 0.4556 - val_auc: 0.8295\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4606 - auc: 0.8259 - val_loss: 0.4556 - val_auc: 0.8294\n",
      "Epoch 8/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4607 - auc: 0.8259Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8259 - val_loss: 0.4555 - val_auc: 0.8299\n",
      "Epoch 00008: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5542 - auc: 0.7764 - val_loss: 0.4678 - val_auc: 0.8210\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4739 - auc: 0.8157 - val_loss: 0.4572 - val_auc: 0.8293\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4640 - auc: 0.8232 - val_loss: 0.4553 - val_auc: 0.8300\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4616 - auc: 0.8249 - val_loss: 0.4544 - val_auc: 0.8301\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4612 - auc: 0.8251 - val_loss: 0.4543 - val_auc: 0.8307\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8260 - val_loss: 0.4543 - val_auc: 0.8308\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8258 - val_loss: 0.4546 - val_auc: 0.8307\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8258 - val_loss: 0.4543 - val_auc: 0.8315\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4604 - auc: 0.8259 - val_loss: 0.4544 - val_auc: 0.8309\n",
      "Epoch 10/100\n",
      "282624/285001 [============================>.] - ETA: 0s - loss: 0.4605 - auc: 0.8260Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8257 - val_loss: 0.4545 - val_auc: 0.8304\n",
      "Epoch 00010: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5594 - auc: 0.7721 - val_loss: 0.4751 - val_auc: 0.8130\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4748 - auc: 0.8146 - val_loss: 0.4634 - val_auc: 0.8233\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4639 - auc: 0.8231 - val_loss: 0.4607 - val_auc: 0.8254\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4616 - auc: 0.8249 - val_loss: 0.4598 - val_auc: 0.8264\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4603 - auc: 0.8261 - val_loss: 0.4595 - val_auc: 0.8266\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8258 - val_loss: 0.4593 - val_auc: 0.8261\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4606 - auc: 0.8256 - val_loss: 0.4592 - val_auc: 0.8265\n",
      "Epoch 8/100\n",
      "278528/285001 [============================>.] - ETA: 0s - loss: 0.4604 - auc: 0.8259\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4605 - auc: 0.8259 - val_loss: 0.4595 - val_auc: 0.8262\n",
      "Epoch 9/100\n",
      "281600/285001 [============================>.] - ETA: 0s - loss: 0.4599 - auc: 0.8263Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4600 - auc: 0.8264 - val_loss: 0.4593 - val_auc: 0.8257\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [4:12:10<6:55:38, 8313.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8302015925989231\n",
      "0.8288563586880852\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  39.6s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  40.0s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  37.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  38.9s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  37.2s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   2.6s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   2.5s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   2.5s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   2.6s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   2.5s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  39.4s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  39.7s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  39.7s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  39.9s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  39.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   7.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   7.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   7.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   7.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   7.7s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  14.4s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  14.8s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  14.8s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  14.6s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=  14.6s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  49.2s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  49.0s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  49.4s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  50.4s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  50.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  16.1s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  16.0s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  15.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  16.1s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  16.0s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   7.8s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   8.2s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   8.2s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   7.9s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   7.9s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  24.2s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  23.6s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  23.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  23.7s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  23.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  15.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  15.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  15.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  15.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  15.5s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  37.4s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  37.3s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  36.9s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  37.7s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  36.7s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  24.3s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  24.8s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  24.7s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  24.9s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  24.6s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  30.7s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  31.3s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  31.2s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  30.8s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  30.4s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   4.1s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   4.1s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   4.1s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   4.2s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   4.2s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  13.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  13.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  13.3s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  13.1s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8303396637932685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 64.7ms\tremaining: 1m 4s\n",
      "1:\ttotal: 128ms\tremaining: 1m 3s\n",
      "2:\ttotal: 188ms\tremaining: 1m 2s\n",
      "3:\ttotal: 252ms\tremaining: 1m 2s\n",
      "4:\ttotal: 321ms\tremaining: 1m 3s\n",
      "5:\ttotal: 377ms\tremaining: 1m 2s\n",
      "6:\ttotal: 433ms\tremaining: 1m 1s\n",
      "7:\ttotal: 491ms\tremaining: 1m\n",
      "8:\ttotal: 551ms\tremaining: 1m\n",
      "9:\ttotal: 609ms\tremaining: 1m\n",
      "10:\ttotal: 665ms\tremaining: 59.8s\n",
      "11:\ttotal: 721ms\tremaining: 59.4s\n",
      "12:\ttotal: 787ms\tremaining: 59.8s\n",
      "13:\ttotal: 860ms\tremaining: 1m\n",
      "14:\ttotal: 917ms\tremaining: 1m\n",
      "15:\ttotal: 975ms\tremaining: 60s\n",
      "16:\ttotal: 1.04s\tremaining: 1m\n",
      "17:\ttotal: 1.1s\tremaining: 1m\n",
      "18:\ttotal: 1.17s\tremaining: 1m\n",
      "19:\ttotal: 1.23s\tremaining: 1m\n",
      "20:\ttotal: 1.3s\tremaining: 1m\n",
      "21:\ttotal: 1.36s\tremaining: 1m\n",
      "22:\ttotal: 1.42s\tremaining: 1m\n",
      "23:\ttotal: 1.48s\tremaining: 1m\n",
      "24:\ttotal: 1.55s\tremaining: 1m\n",
      "25:\ttotal: 1.61s\tremaining: 1m\n",
      "26:\ttotal: 1.67s\tremaining: 1m\n",
      "27:\ttotal: 1.74s\tremaining: 1m\n",
      "28:\ttotal: 1.81s\tremaining: 1m\n",
      "29:\ttotal: 1.88s\tremaining: 1m\n",
      "30:\ttotal: 1.94s\tremaining: 1m\n",
      "31:\ttotal: 2s\tremaining: 1m\n",
      "32:\ttotal: 2.07s\tremaining: 1m\n",
      "33:\ttotal: 2.14s\tremaining: 1m\n",
      "34:\ttotal: 2.2s\tremaining: 1m\n",
      "35:\ttotal: 2.27s\tremaining: 1m\n",
      "36:\ttotal: 2.34s\tremaining: 1m\n",
      "37:\ttotal: 2.4s\tremaining: 1m\n",
      "38:\ttotal: 2.47s\tremaining: 1m\n",
      "39:\ttotal: 2.55s\tremaining: 1m 1s\n",
      "40:\ttotal: 2.62s\tremaining: 1m 1s\n",
      "41:\ttotal: 2.68s\tremaining: 1m 1s\n",
      "42:\ttotal: 2.74s\tremaining: 1m 1s\n",
      "43:\ttotal: 2.82s\tremaining: 1m 1s\n",
      "44:\ttotal: 2.88s\tremaining: 1m 1s\n",
      "45:\ttotal: 2.96s\tremaining: 1m 1s\n",
      "46:\ttotal: 3.02s\tremaining: 1m 1s\n",
      "47:\ttotal: 3.09s\tremaining: 1m 1s\n",
      "48:\ttotal: 3.16s\tremaining: 1m 1s\n",
      "49:\ttotal: 3.24s\tremaining: 1m 1s\n",
      "50:\ttotal: 3.3s\tremaining: 1m 1s\n",
      "51:\ttotal: 3.36s\tremaining: 1m 1s\n",
      "52:\ttotal: 3.41s\tremaining: 1m\n",
      "53:\ttotal: 3.48s\tremaining: 1m\n",
      "54:\ttotal: 3.54s\tremaining: 1m\n",
      "55:\ttotal: 3.62s\tremaining: 1m\n",
      "56:\ttotal: 3.68s\tremaining: 1m\n",
      "57:\ttotal: 3.75s\tremaining: 1m\n",
      "58:\ttotal: 3.81s\tremaining: 1m\n",
      "59:\ttotal: 3.88s\tremaining: 1m\n",
      "60:\ttotal: 3.94s\tremaining: 1m\n",
      "61:\ttotal: 4s\tremaining: 1m\n",
      "62:\ttotal: 4.05s\tremaining: 1m\n",
      "63:\ttotal: 4.11s\tremaining: 1m\n",
      "64:\ttotal: 4.18s\tremaining: 1m\n",
      "65:\ttotal: 4.24s\tremaining: 60s\n",
      "66:\ttotal: 4.3s\tremaining: 59.8s\n",
      "67:\ttotal: 4.35s\tremaining: 59.7s\n",
      "68:\ttotal: 4.41s\tremaining: 59.5s\n",
      "69:\ttotal: 4.47s\tremaining: 59.4s\n",
      "70:\ttotal: 4.53s\tremaining: 59.3s\n",
      "71:\ttotal: 4.6s\tremaining: 59.3s\n",
      "72:\ttotal: 4.66s\tremaining: 59.2s\n",
      "73:\ttotal: 4.73s\tremaining: 59.2s\n",
      "74:\ttotal: 4.8s\tremaining: 59.2s\n",
      "75:\ttotal: 4.86s\tremaining: 59.1s\n",
      "76:\ttotal: 4.91s\tremaining: 58.9s\n",
      "77:\ttotal: 4.99s\tremaining: 59s\n",
      "78:\ttotal: 5.06s\tremaining: 59s\n",
      "79:\ttotal: 5.13s\tremaining: 59s\n",
      "80:\ttotal: 5.19s\tremaining: 58.8s\n",
      "81:\ttotal: 5.25s\tremaining: 58.8s\n",
      "82:\ttotal: 5.32s\tremaining: 58.8s\n",
      "83:\ttotal: 5.39s\tremaining: 58.8s\n",
      "84:\ttotal: 5.45s\tremaining: 58.6s\n",
      "85:\ttotal: 5.52s\tremaining: 58.6s\n",
      "86:\ttotal: 5.59s\tremaining: 58.7s\n",
      "87:\ttotal: 5.65s\tremaining: 58.6s\n",
      "88:\ttotal: 5.72s\tremaining: 58.5s\n",
      "89:\ttotal: 5.79s\tremaining: 58.6s\n",
      "90:\ttotal: 5.86s\tremaining: 58.5s\n",
      "91:\ttotal: 5.92s\tremaining: 58.4s\n",
      "92:\ttotal: 5.98s\tremaining: 58.3s\n",
      "93:\ttotal: 6.04s\tremaining: 58.2s\n",
      "94:\ttotal: 6.1s\tremaining: 58.1s\n",
      "95:\ttotal: 6.17s\tremaining: 58.1s\n",
      "96:\ttotal: 6.22s\tremaining: 57.9s\n",
      "97:\ttotal: 6.29s\tremaining: 57.9s\n",
      "98:\ttotal: 6.34s\tremaining: 57.7s\n",
      "99:\ttotal: 6.4s\tremaining: 57.6s\n",
      "100:\ttotal: 6.47s\tremaining: 57.6s\n",
      "101:\ttotal: 6.53s\tremaining: 57.5s\n",
      "102:\ttotal: 6.59s\tremaining: 57.4s\n",
      "103:\ttotal: 6.65s\tremaining: 57.3s\n",
      "104:\ttotal: 6.72s\tremaining: 57.3s\n",
      "105:\ttotal: 6.78s\tremaining: 57.1s\n",
      "106:\ttotal: 6.83s\tremaining: 57s\n",
      "107:\ttotal: 6.89s\tremaining: 56.9s\n",
      "108:\ttotal: 6.95s\tremaining: 56.8s\n",
      "109:\ttotal: 7.01s\tremaining: 56.7s\n",
      "110:\ttotal: 7.07s\tremaining: 56.6s\n",
      "111:\ttotal: 7.13s\tremaining: 56.5s\n",
      "112:\ttotal: 7.2s\tremaining: 56.5s\n",
      "113:\ttotal: 7.25s\tremaining: 56.4s\n",
      "114:\ttotal: 7.31s\tremaining: 56.3s\n",
      "115:\ttotal: 7.38s\tremaining: 56.2s\n",
      "116:\ttotal: 7.44s\tremaining: 56.2s\n",
      "117:\ttotal: 7.51s\tremaining: 56.1s\n",
      "118:\ttotal: 7.57s\tremaining: 56s\n",
      "119:\ttotal: 7.62s\tremaining: 55.9s\n",
      "120:\ttotal: 7.69s\tremaining: 55.9s\n",
      "121:\ttotal: 7.74s\tremaining: 55.7s\n",
      "122:\ttotal: 7.81s\tremaining: 55.7s\n",
      "123:\ttotal: 7.86s\tremaining: 55.5s\n",
      "124:\ttotal: 7.92s\tremaining: 55.5s\n",
      "125:\ttotal: 7.98s\tremaining: 55.4s\n",
      "126:\ttotal: 8.04s\tremaining: 55.3s\n",
      "127:\ttotal: 8.1s\tremaining: 55.2s\n",
      "128:\ttotal: 8.16s\tremaining: 55.1s\n",
      "129:\ttotal: 8.22s\tremaining: 55s\n",
      "130:\ttotal: 8.29s\tremaining: 55s\n",
      "131:\ttotal: 8.34s\tremaining: 54.8s\n",
      "132:\ttotal: 8.4s\tremaining: 54.8s\n",
      "133:\ttotal: 8.46s\tremaining: 54.7s\n",
      "134:\ttotal: 8.52s\tremaining: 54.6s\n",
      "135:\ttotal: 8.59s\tremaining: 54.6s\n",
      "136:\ttotal: 8.66s\tremaining: 54.6s\n",
      "137:\ttotal: 8.72s\tremaining: 54.4s\n",
      "138:\ttotal: 8.77s\tremaining: 54.3s\n",
      "139:\ttotal: 8.82s\tremaining: 54.2s\n",
      "140:\ttotal: 8.9s\tremaining: 54.2s\n",
      "141:\ttotal: 8.96s\tremaining: 54.1s\n",
      "142:\ttotal: 9.01s\tremaining: 54s\n",
      "143:\ttotal: 9.08s\tremaining: 54s\n",
      "144:\ttotal: 9.14s\tremaining: 53.9s\n",
      "145:\ttotal: 9.2s\tremaining: 53.8s\n",
      "146:\ttotal: 9.25s\tremaining: 53.7s\n",
      "147:\ttotal: 9.32s\tremaining: 53.6s\n",
      "148:\ttotal: 9.38s\tremaining: 53.6s\n",
      "149:\ttotal: 9.44s\tremaining: 53.5s\n",
      "150:\ttotal: 9.5s\tremaining: 53.4s\n",
      "151:\ttotal: 9.56s\tremaining: 53.3s\n",
      "152:\ttotal: 9.62s\tremaining: 53.2s\n",
      "153:\ttotal: 9.68s\tremaining: 53.2s\n",
      "154:\ttotal: 9.74s\tremaining: 53.1s\n",
      "155:\ttotal: 9.8s\tremaining: 53s\n",
      "156:\ttotal: 9.87s\tremaining: 53s\n",
      "157:\ttotal: 9.94s\tremaining: 52.9s\n",
      "158:\ttotal: 9.99s\tremaining: 52.9s\n",
      "159:\ttotal: 10.1s\tremaining: 52.8s\n",
      "160:\ttotal: 10.1s\tremaining: 52.7s\n",
      "161:\ttotal: 10.2s\tremaining: 52.7s\n",
      "162:\ttotal: 10.2s\tremaining: 52.6s\n",
      "163:\ttotal: 10.3s\tremaining: 52.5s\n",
      "164:\ttotal: 10.4s\tremaining: 52.5s\n",
      "165:\ttotal: 10.4s\tremaining: 52.4s\n",
      "166:\ttotal: 10.5s\tremaining: 52.4s\n",
      "167:\ttotal: 10.6s\tremaining: 52.3s\n",
      "168:\ttotal: 10.6s\tremaining: 52.3s\n",
      "169:\ttotal: 10.7s\tremaining: 52.2s\n",
      "170:\ttotal: 10.8s\tremaining: 52.1s\n",
      "171:\ttotal: 10.8s\tremaining: 52.1s\n",
      "172:\ttotal: 10.9s\tremaining: 52s\n",
      "173:\ttotal: 10.9s\tremaining: 51.9s\n",
      "174:\ttotal: 11s\tremaining: 51.8s\n",
      "175:\ttotal: 11s\tremaining: 51.7s\n",
      "176:\ttotal: 11.1s\tremaining: 51.6s\n",
      "177:\ttotal: 11.2s\tremaining: 51.6s\n",
      "178:\ttotal: 11.2s\tremaining: 51.5s\n",
      "179:\ttotal: 11.3s\tremaining: 51.5s\n",
      "180:\ttotal: 11.4s\tremaining: 51.5s\n",
      "181:\ttotal: 11.4s\tremaining: 51.4s\n",
      "182:\ttotal: 11.5s\tremaining: 51.4s\n",
      "183:\ttotal: 11.6s\tremaining: 51.3s\n",
      "184:\ttotal: 11.6s\tremaining: 51.3s\n",
      "185:\ttotal: 11.7s\tremaining: 51.2s\n",
      "186:\ttotal: 11.8s\tremaining: 51.1s\n",
      "187:\ttotal: 11.8s\tremaining: 51.1s\n",
      "188:\ttotal: 11.9s\tremaining: 51s\n",
      "189:\ttotal: 11.9s\tremaining: 50.9s\n",
      "190:\ttotal: 12s\tremaining: 50.8s\n",
      "191:\ttotal: 12.1s\tremaining: 50.8s\n",
      "192:\ttotal: 12.1s\tremaining: 50.7s\n",
      "193:\ttotal: 12.2s\tremaining: 50.6s\n",
      "194:\ttotal: 12.3s\tremaining: 50.6s\n",
      "195:\ttotal: 12.3s\tremaining: 50.5s\n",
      "196:\ttotal: 12.4s\tremaining: 50.5s\n",
      "197:\ttotal: 12.4s\tremaining: 50.4s\n",
      "198:\ttotal: 12.5s\tremaining: 50.3s\n",
      "199:\ttotal: 12.6s\tremaining: 50.2s\n",
      "200:\ttotal: 12.6s\tremaining: 50.2s\n",
      "201:\ttotal: 12.7s\tremaining: 50.2s\n",
      "202:\ttotal: 12.8s\tremaining: 50.1s\n",
      "203:\ttotal: 12.8s\tremaining: 50s\n",
      "204:\ttotal: 12.9s\tremaining: 50s\n",
      "205:\ttotal: 12.9s\tremaining: 49.9s\n",
      "206:\ttotal: 13s\tremaining: 49.8s\n",
      "207:\ttotal: 13.1s\tremaining: 49.7s\n",
      "208:\ttotal: 13.1s\tremaining: 49.6s\n",
      "209:\ttotal: 13.2s\tremaining: 49.6s\n",
      "210:\ttotal: 13.2s\tremaining: 49.5s\n",
      "211:\ttotal: 13.3s\tremaining: 49.4s\n",
      "212:\ttotal: 13.4s\tremaining: 49.4s\n",
      "213:\ttotal: 13.4s\tremaining: 49.3s\n",
      "214:\ttotal: 13.5s\tremaining: 49.2s\n",
      "215:\ttotal: 13.5s\tremaining: 49.1s\n",
      "216:\ttotal: 13.6s\tremaining: 49.1s\n",
      "217:\ttotal: 13.7s\tremaining: 49s\n",
      "218:\ttotal: 13.7s\tremaining: 48.9s\n",
      "219:\ttotal: 13.8s\tremaining: 48.8s\n",
      "220:\ttotal: 13.8s\tremaining: 48.7s\n",
      "221:\ttotal: 13.9s\tremaining: 48.7s\n",
      "222:\ttotal: 14s\tremaining: 48.6s\n",
      "223:\ttotal: 14s\tremaining: 48.5s\n",
      "224:\ttotal: 14.1s\tremaining: 48.5s\n",
      "225:\ttotal: 14.1s\tremaining: 48.4s\n",
      "226:\ttotal: 14.2s\tremaining: 48.3s\n",
      "227:\ttotal: 14.2s\tremaining: 48.2s\n",
      "228:\ttotal: 14.3s\tremaining: 48.2s\n",
      "229:\ttotal: 14.4s\tremaining: 48.1s\n",
      "230:\ttotal: 14.4s\tremaining: 48s\n",
      "231:\ttotal: 14.5s\tremaining: 47.9s\n",
      "232:\ttotal: 14.5s\tremaining: 47.9s\n",
      "233:\ttotal: 14.6s\tremaining: 47.8s\n",
      "234:\ttotal: 14.7s\tremaining: 47.8s\n",
      "235:\ttotal: 14.8s\tremaining: 47.8s\n",
      "236:\ttotal: 14.8s\tremaining: 47.7s\n",
      "237:\ttotal: 14.9s\tremaining: 47.6s\n",
      "238:\ttotal: 14.9s\tremaining: 47.5s\n",
      "239:\ttotal: 15s\tremaining: 47.5s\n",
      "240:\ttotal: 15s\tremaining: 47.4s\n",
      "241:\ttotal: 15.1s\tremaining: 47.3s\n",
      "242:\ttotal: 15.2s\tremaining: 47.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243:\ttotal: 15.2s\tremaining: 47.2s\n",
      "244:\ttotal: 15.3s\tremaining: 47.1s\n",
      "245:\ttotal: 15.3s\tremaining: 47s\n",
      "246:\ttotal: 15.4s\tremaining: 46.9s\n",
      "247:\ttotal: 15.5s\tremaining: 46.9s\n",
      "248:\ttotal: 15.5s\tremaining: 46.9s\n",
      "249:\ttotal: 15.6s\tremaining: 46.8s\n",
      "250:\ttotal: 15.6s\tremaining: 46.7s\n",
      "251:\ttotal: 15.7s\tremaining: 46.6s\n",
      "252:\ttotal: 15.8s\tremaining: 46.6s\n",
      "253:\ttotal: 15.8s\tremaining: 46.5s\n",
      "254:\ttotal: 15.9s\tremaining: 46.4s\n",
      "255:\ttotal: 15.9s\tremaining: 46.3s\n",
      "256:\ttotal: 16s\tremaining: 46.2s\n",
      "257:\ttotal: 16.1s\tremaining: 46.2s\n",
      "258:\ttotal: 16.1s\tremaining: 46.1s\n",
      "259:\ttotal: 16.2s\tremaining: 46s\n",
      "260:\ttotal: 16.2s\tremaining: 46s\n",
      "261:\ttotal: 16.3s\tremaining: 45.9s\n",
      "262:\ttotal: 16.3s\tremaining: 45.8s\n",
      "263:\ttotal: 16.4s\tremaining: 45.8s\n",
      "264:\ttotal: 16.5s\tremaining: 45.7s\n",
      "265:\ttotal: 16.5s\tremaining: 45.6s\n",
      "266:\ttotal: 16.6s\tremaining: 45.5s\n",
      "267:\ttotal: 16.6s\tremaining: 45.4s\n",
      "268:\ttotal: 16.7s\tremaining: 45.4s\n",
      "269:\ttotal: 16.8s\tremaining: 45.3s\n",
      "270:\ttotal: 16.8s\tremaining: 45.3s\n",
      "271:\ttotal: 16.9s\tremaining: 45.2s\n",
      "272:\ttotal: 17s\tremaining: 45.1s\n",
      "273:\ttotal: 17s\tremaining: 45.1s\n",
      "274:\ttotal: 17.1s\tremaining: 45s\n",
      "275:\ttotal: 17.1s\tremaining: 44.9s\n",
      "276:\ttotal: 17.2s\tremaining: 44.8s\n",
      "277:\ttotal: 17.2s\tremaining: 44.8s\n",
      "278:\ttotal: 17.3s\tremaining: 44.7s\n",
      "279:\ttotal: 17.4s\tremaining: 44.6s\n",
      "280:\ttotal: 17.4s\tremaining: 44.6s\n",
      "281:\ttotal: 17.5s\tremaining: 44.5s\n",
      "282:\ttotal: 17.5s\tremaining: 44.4s\n",
      "283:\ttotal: 17.6s\tremaining: 44.4s\n",
      "284:\ttotal: 17.7s\tremaining: 44.3s\n",
      "285:\ttotal: 17.7s\tremaining: 44.3s\n",
      "286:\ttotal: 17.8s\tremaining: 44.2s\n",
      "287:\ttotal: 17.9s\tremaining: 44.2s\n",
      "288:\ttotal: 17.9s\tremaining: 44.1s\n",
      "289:\ttotal: 18s\tremaining: 44s\n",
      "290:\ttotal: 18s\tremaining: 43.9s\n",
      "291:\ttotal: 18.1s\tremaining: 43.9s\n",
      "292:\ttotal: 18.1s\tremaining: 43.8s\n",
      "293:\ttotal: 18.2s\tremaining: 43.7s\n",
      "294:\ttotal: 18.3s\tremaining: 43.7s\n",
      "295:\ttotal: 18.3s\tremaining: 43.6s\n",
      "296:\ttotal: 18.4s\tremaining: 43.5s\n",
      "297:\ttotal: 18.4s\tremaining: 43.4s\n",
      "298:\ttotal: 18.5s\tremaining: 43.4s\n",
      "299:\ttotal: 18.6s\tremaining: 43.3s\n",
      "300:\ttotal: 18.6s\tremaining: 43.2s\n",
      "301:\ttotal: 18.7s\tremaining: 43.1s\n",
      "302:\ttotal: 18.7s\tremaining: 43.1s\n",
      "303:\ttotal: 18.8s\tremaining: 43s\n",
      "304:\ttotal: 18.8s\tremaining: 42.9s\n",
      "305:\ttotal: 18.9s\tremaining: 42.9s\n",
      "306:\ttotal: 19s\tremaining: 42.8s\n",
      "307:\ttotal: 19s\tremaining: 42.8s\n",
      "308:\ttotal: 19.1s\tremaining: 42.7s\n",
      "309:\ttotal: 19.1s\tremaining: 42.6s\n",
      "310:\ttotal: 19.2s\tremaining: 42.6s\n",
      "311:\ttotal: 19.3s\tremaining: 42.5s\n",
      "312:\ttotal: 19.3s\tremaining: 42.4s\n",
      "313:\ttotal: 19.4s\tremaining: 42.4s\n",
      "314:\ttotal: 19.4s\tremaining: 42.3s\n",
      "315:\ttotal: 19.5s\tremaining: 42.2s\n",
      "316:\ttotal: 19.6s\tremaining: 42.2s\n",
      "317:\ttotal: 19.6s\tremaining: 42.1s\n",
      "318:\ttotal: 19.7s\tremaining: 42s\n",
      "319:\ttotal: 19.7s\tremaining: 42s\n",
      "320:\ttotal: 19.8s\tremaining: 41.9s\n",
      "321:\ttotal: 19.9s\tremaining: 41.8s\n",
      "322:\ttotal: 19.9s\tremaining: 41.7s\n",
      "323:\ttotal: 20s\tremaining: 41.7s\n",
      "324:\ttotal: 20s\tremaining: 41.6s\n",
      "325:\ttotal: 20.1s\tremaining: 41.6s\n",
      "326:\ttotal: 20.2s\tremaining: 41.5s\n",
      "327:\ttotal: 20.3s\tremaining: 41.5s\n",
      "328:\ttotal: 20.3s\tremaining: 41.5s\n",
      "329:\ttotal: 20.4s\tremaining: 41.4s\n",
      "330:\ttotal: 20.5s\tremaining: 41.4s\n",
      "331:\ttotal: 20.6s\tremaining: 41.4s\n",
      "332:\ttotal: 20.6s\tremaining: 41.3s\n",
      "333:\ttotal: 20.7s\tremaining: 41.3s\n",
      "334:\ttotal: 20.8s\tremaining: 41.2s\n",
      "335:\ttotal: 20.8s\tremaining: 41.1s\n",
      "336:\ttotal: 20.9s\tremaining: 41.1s\n",
      "337:\ttotal: 20.9s\tremaining: 41s\n",
      "338:\ttotal: 21s\tremaining: 40.9s\n",
      "339:\ttotal: 21.1s\tremaining: 40.9s\n",
      "340:\ttotal: 21.1s\tremaining: 40.8s\n",
      "341:\ttotal: 21.2s\tremaining: 40.7s\n",
      "342:\ttotal: 21.2s\tremaining: 40.7s\n",
      "343:\ttotal: 21.3s\tremaining: 40.6s\n",
      "344:\ttotal: 21.4s\tremaining: 40.5s\n",
      "345:\ttotal: 21.4s\tremaining: 40.5s\n",
      "346:\ttotal: 21.5s\tremaining: 40.4s\n",
      "347:\ttotal: 21.5s\tremaining: 40.3s\n",
      "348:\ttotal: 21.6s\tremaining: 40.3s\n",
      "349:\ttotal: 21.7s\tremaining: 40.2s\n",
      "350:\ttotal: 21.7s\tremaining: 40.2s\n",
      "351:\ttotal: 21.8s\tremaining: 40.1s\n",
      "352:\ttotal: 21.9s\tremaining: 40.1s\n",
      "353:\ttotal: 21.9s\tremaining: 40.1s\n",
      "354:\ttotal: 22s\tremaining: 40s\n",
      "355:\ttotal: 22.1s\tremaining: 39.9s\n",
      "356:\ttotal: 22.1s\tremaining: 39.9s\n",
      "357:\ttotal: 22.2s\tremaining: 39.8s\n",
      "358:\ttotal: 22.2s\tremaining: 39.7s\n",
      "359:\ttotal: 22.3s\tremaining: 39.6s\n",
      "360:\ttotal: 22.4s\tremaining: 39.6s\n",
      "361:\ttotal: 22.4s\tremaining: 39.5s\n",
      "362:\ttotal: 22.5s\tremaining: 39.4s\n",
      "363:\ttotal: 22.5s\tremaining: 39.4s\n",
      "364:\ttotal: 22.6s\tremaining: 39.3s\n",
      "365:\ttotal: 22.7s\tremaining: 39.3s\n",
      "366:\ttotal: 22.7s\tremaining: 39.2s\n",
      "367:\ttotal: 22.8s\tremaining: 39.2s\n",
      "368:\ttotal: 22.9s\tremaining: 39.1s\n",
      "369:\ttotal: 22.9s\tremaining: 39s\n",
      "370:\ttotal: 23s\tremaining: 39s\n",
      "371:\ttotal: 23s\tremaining: 38.9s\n",
      "372:\ttotal: 23.1s\tremaining: 38.8s\n",
      "373:\ttotal: 23.2s\tremaining: 38.8s\n",
      "374:\ttotal: 23.2s\tremaining: 38.7s\n",
      "375:\ttotal: 23.3s\tremaining: 38.7s\n",
      "376:\ttotal: 23.3s\tremaining: 38.6s\n",
      "377:\ttotal: 23.4s\tremaining: 38.5s\n",
      "378:\ttotal: 23.5s\tremaining: 38.4s\n",
      "379:\ttotal: 23.5s\tremaining: 38.4s\n",
      "380:\ttotal: 23.6s\tremaining: 38.3s\n",
      "381:\ttotal: 23.6s\tremaining: 38.2s\n",
      "382:\ttotal: 23.7s\tremaining: 38.2s\n",
      "383:\ttotal: 23.8s\tremaining: 38.1s\n",
      "384:\ttotal: 23.8s\tremaining: 38s\n",
      "385:\ttotal: 23.9s\tremaining: 38s\n",
      "386:\ttotal: 23.9s\tremaining: 37.9s\n",
      "387:\ttotal: 24s\tremaining: 37.8s\n",
      "388:\ttotal: 24.1s\tremaining: 37.8s\n",
      "389:\ttotal: 24.1s\tremaining: 37.7s\n",
      "390:\ttotal: 24.2s\tremaining: 37.7s\n",
      "391:\ttotal: 24.2s\tremaining: 37.6s\n",
      "392:\ttotal: 24.3s\tremaining: 37.5s\n",
      "393:\ttotal: 24.4s\tremaining: 37.5s\n",
      "394:\ttotal: 24.4s\tremaining: 37.4s\n",
      "395:\ttotal: 24.5s\tremaining: 37.3s\n",
      "396:\ttotal: 24.5s\tremaining: 37.3s\n",
      "397:\ttotal: 24.6s\tremaining: 37.2s\n",
      "398:\ttotal: 24.7s\tremaining: 37.1s\n",
      "399:\ttotal: 24.7s\tremaining: 37.1s\n",
      "400:\ttotal: 24.8s\tremaining: 37s\n",
      "401:\ttotal: 24.9s\tremaining: 37s\n",
      "402:\ttotal: 24.9s\tremaining: 36.9s\n",
      "403:\ttotal: 25s\tremaining: 36.8s\n",
      "404:\ttotal: 25s\tremaining: 36.8s\n",
      "405:\ttotal: 25.1s\tremaining: 36.7s\n",
      "406:\ttotal: 25.2s\tremaining: 36.6s\n",
      "407:\ttotal: 25.2s\tremaining: 36.6s\n",
      "408:\ttotal: 25.3s\tremaining: 36.5s\n",
      "409:\ttotal: 25.3s\tremaining: 36.4s\n",
      "410:\ttotal: 25.4s\tremaining: 36.4s\n",
      "411:\ttotal: 25.4s\tremaining: 36.3s\n",
      "412:\ttotal: 25.5s\tremaining: 36.3s\n",
      "413:\ttotal: 25.6s\tremaining: 36.2s\n",
      "414:\ttotal: 25.6s\tremaining: 36.1s\n",
      "415:\ttotal: 25.7s\tremaining: 36.1s\n",
      "416:\ttotal: 25.8s\tremaining: 36s\n",
      "417:\ttotal: 25.8s\tremaining: 36s\n",
      "418:\ttotal: 25.9s\tremaining: 35.9s\n",
      "419:\ttotal: 26s\tremaining: 35.8s\n",
      "420:\ttotal: 26s\tremaining: 35.8s\n",
      "421:\ttotal: 26.1s\tremaining: 35.7s\n",
      "422:\ttotal: 26.2s\tremaining: 35.7s\n",
      "423:\ttotal: 26.2s\tremaining: 35.6s\n",
      "424:\ttotal: 26.3s\tremaining: 35.5s\n",
      "425:\ttotal: 26.3s\tremaining: 35.5s\n",
      "426:\ttotal: 26.4s\tremaining: 35.4s\n",
      "427:\ttotal: 26.4s\tremaining: 35.3s\n",
      "428:\ttotal: 26.5s\tremaining: 35.3s\n",
      "429:\ttotal: 26.5s\tremaining: 35.2s\n",
      "430:\ttotal: 26.6s\tremaining: 35.1s\n",
      "431:\ttotal: 26.7s\tremaining: 35s\n",
      "432:\ttotal: 26.7s\tremaining: 35s\n",
      "433:\ttotal: 26.8s\tremaining: 34.9s\n",
      "434:\ttotal: 26.8s\tremaining: 34.9s\n",
      "435:\ttotal: 26.9s\tremaining: 34.8s\n",
      "436:\ttotal: 27s\tremaining: 34.7s\n",
      "437:\ttotal: 27s\tremaining: 34.7s\n",
      "438:\ttotal: 27.1s\tremaining: 34.6s\n",
      "439:\ttotal: 27.1s\tremaining: 34.5s\n",
      "440:\ttotal: 27.2s\tremaining: 34.5s\n",
      "441:\ttotal: 27.2s\tremaining: 34.4s\n",
      "442:\ttotal: 27.3s\tremaining: 34.3s\n",
      "443:\ttotal: 27.4s\tremaining: 34.3s\n",
      "444:\ttotal: 27.4s\tremaining: 34.2s\n",
      "445:\ttotal: 27.5s\tremaining: 34.1s\n",
      "446:\ttotal: 27.5s\tremaining: 34.1s\n",
      "447:\ttotal: 27.6s\tremaining: 34s\n",
      "448:\ttotal: 27.7s\tremaining: 34s\n",
      "449:\ttotal: 27.7s\tremaining: 33.9s\n",
      "450:\ttotal: 27.8s\tremaining: 33.8s\n",
      "451:\ttotal: 27.8s\tremaining: 33.8s\n",
      "452:\ttotal: 27.9s\tremaining: 33.7s\n",
      "453:\ttotal: 27.9s\tremaining: 33.6s\n",
      "454:\ttotal: 28s\tremaining: 33.5s\n",
      "455:\ttotal: 28.1s\tremaining: 33.5s\n",
      "456:\ttotal: 28.1s\tremaining: 33.4s\n",
      "457:\ttotal: 28.2s\tremaining: 33.4s\n",
      "458:\ttotal: 28.3s\tremaining: 33.3s\n",
      "459:\ttotal: 28.3s\tremaining: 33.2s\n",
      "460:\ttotal: 28.4s\tremaining: 33.2s\n",
      "461:\ttotal: 28.4s\tremaining: 33.1s\n",
      "462:\ttotal: 28.5s\tremaining: 33.1s\n",
      "463:\ttotal: 28.6s\tremaining: 33s\n",
      "464:\ttotal: 28.6s\tremaining: 32.9s\n",
      "465:\ttotal: 28.7s\tremaining: 32.9s\n",
      "466:\ttotal: 28.8s\tremaining: 32.8s\n",
      "467:\ttotal: 28.8s\tremaining: 32.8s\n",
      "468:\ttotal: 28.9s\tremaining: 32.7s\n",
      "469:\ttotal: 28.9s\tremaining: 32.6s\n",
      "470:\ttotal: 29s\tremaining: 32.6s\n",
      "471:\ttotal: 29s\tremaining: 32.5s\n",
      "472:\ttotal: 29.1s\tremaining: 32.4s\n",
      "473:\ttotal: 29.2s\tremaining: 32.4s\n",
      "474:\ttotal: 29.2s\tremaining: 32.3s\n",
      "475:\ttotal: 29.3s\tremaining: 32.2s\n",
      "476:\ttotal: 29.4s\tremaining: 32.2s\n",
      "477:\ttotal: 29.4s\tremaining: 32.1s\n",
      "478:\ttotal: 29.5s\tremaining: 32.1s\n",
      "479:\ttotal: 29.5s\tremaining: 32s\n",
      "480:\ttotal: 29.6s\tremaining: 31.9s\n",
      "481:\ttotal: 29.6s\tremaining: 31.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482:\ttotal: 29.7s\tremaining: 31.8s\n",
      "483:\ttotal: 29.8s\tremaining: 31.7s\n",
      "484:\ttotal: 29.8s\tremaining: 31.7s\n",
      "485:\ttotal: 29.9s\tremaining: 31.6s\n",
      "486:\ttotal: 29.9s\tremaining: 31.5s\n",
      "487:\ttotal: 30s\tremaining: 31.5s\n",
      "488:\ttotal: 30.1s\tremaining: 31.4s\n",
      "489:\ttotal: 30.1s\tremaining: 31.4s\n",
      "490:\ttotal: 30.2s\tremaining: 31.3s\n",
      "491:\ttotal: 30.3s\tremaining: 31.2s\n",
      "492:\ttotal: 30.3s\tremaining: 31.2s\n",
      "493:\ttotal: 30.4s\tremaining: 31.1s\n",
      "494:\ttotal: 30.4s\tremaining: 31s\n",
      "495:\ttotal: 30.5s\tremaining: 31s\n",
      "496:\ttotal: 30.5s\tremaining: 30.9s\n",
      "497:\ttotal: 30.6s\tremaining: 30.8s\n",
      "498:\ttotal: 30.7s\tremaining: 30.8s\n",
      "499:\ttotal: 30.7s\tremaining: 30.7s\n",
      "500:\ttotal: 30.8s\tremaining: 30.7s\n",
      "501:\ttotal: 30.8s\tremaining: 30.6s\n",
      "502:\ttotal: 30.9s\tremaining: 30.6s\n",
      "503:\ttotal: 31s\tremaining: 30.5s\n",
      "504:\ttotal: 31s\tremaining: 30.4s\n",
      "505:\ttotal: 31.1s\tremaining: 30.4s\n",
      "506:\ttotal: 31.2s\tremaining: 30.3s\n",
      "507:\ttotal: 31.2s\tremaining: 30.2s\n",
      "508:\ttotal: 31.3s\tremaining: 30.2s\n",
      "509:\ttotal: 31.3s\tremaining: 30.1s\n",
      "510:\ttotal: 31.4s\tremaining: 30.1s\n",
      "511:\ttotal: 31.5s\tremaining: 30s\n",
      "512:\ttotal: 31.5s\tremaining: 29.9s\n",
      "513:\ttotal: 31.6s\tremaining: 29.9s\n",
      "514:\ttotal: 31.7s\tremaining: 29.8s\n",
      "515:\ttotal: 31.7s\tremaining: 29.7s\n",
      "516:\ttotal: 31.8s\tremaining: 29.7s\n",
      "517:\ttotal: 31.8s\tremaining: 29.6s\n",
      "518:\ttotal: 31.9s\tremaining: 29.6s\n",
      "519:\ttotal: 32s\tremaining: 29.5s\n",
      "520:\ttotal: 32s\tremaining: 29.4s\n",
      "521:\ttotal: 32.1s\tremaining: 29.4s\n",
      "522:\ttotal: 32.1s\tremaining: 29.3s\n",
      "523:\ttotal: 32.2s\tremaining: 29.2s\n",
      "524:\ttotal: 32.2s\tremaining: 29.2s\n",
      "525:\ttotal: 32.3s\tremaining: 29.1s\n",
      "526:\ttotal: 32.4s\tremaining: 29s\n",
      "527:\ttotal: 32.4s\tremaining: 29s\n",
      "528:\ttotal: 32.5s\tremaining: 28.9s\n",
      "529:\ttotal: 32.5s\tremaining: 28.9s\n",
      "530:\ttotal: 32.6s\tremaining: 28.8s\n",
      "531:\ttotal: 32.7s\tremaining: 28.7s\n",
      "532:\ttotal: 32.7s\tremaining: 28.7s\n",
      "533:\ttotal: 32.8s\tremaining: 28.6s\n",
      "534:\ttotal: 32.8s\tremaining: 28.6s\n",
      "535:\ttotal: 32.9s\tremaining: 28.5s\n",
      "536:\ttotal: 33s\tremaining: 28.4s\n",
      "537:\ttotal: 33s\tremaining: 28.3s\n",
      "538:\ttotal: 33.1s\tremaining: 28.3s\n",
      "539:\ttotal: 33.1s\tremaining: 28.2s\n",
      "540:\ttotal: 33.2s\tremaining: 28.2s\n",
      "541:\ttotal: 33.2s\tremaining: 28.1s\n",
      "542:\ttotal: 33.3s\tremaining: 28s\n",
      "543:\ttotal: 33.4s\tremaining: 28s\n",
      "544:\ttotal: 33.4s\tremaining: 27.9s\n",
      "545:\ttotal: 33.5s\tremaining: 27.8s\n",
      "546:\ttotal: 33.5s\tremaining: 27.8s\n",
      "547:\ttotal: 33.6s\tremaining: 27.7s\n",
      "548:\ttotal: 33.7s\tremaining: 27.6s\n",
      "549:\ttotal: 33.7s\tremaining: 27.6s\n",
      "550:\ttotal: 33.8s\tremaining: 27.5s\n",
      "551:\ttotal: 33.8s\tremaining: 27.5s\n",
      "552:\ttotal: 33.9s\tremaining: 27.4s\n",
      "553:\ttotal: 34s\tremaining: 27.3s\n",
      "554:\ttotal: 34s\tremaining: 27.3s\n",
      "555:\ttotal: 34.1s\tremaining: 27.2s\n",
      "556:\ttotal: 34.2s\tremaining: 27.2s\n",
      "557:\ttotal: 34.2s\tremaining: 27.1s\n",
      "558:\ttotal: 34.3s\tremaining: 27s\n",
      "559:\ttotal: 34.3s\tremaining: 27s\n",
      "560:\ttotal: 34.4s\tremaining: 26.9s\n",
      "561:\ttotal: 34.5s\tremaining: 26.9s\n",
      "562:\ttotal: 34.5s\tremaining: 26.8s\n",
      "563:\ttotal: 34.6s\tremaining: 26.7s\n",
      "564:\ttotal: 34.7s\tremaining: 26.7s\n",
      "565:\ttotal: 34.7s\tremaining: 26.6s\n",
      "566:\ttotal: 34.8s\tremaining: 26.6s\n",
      "567:\ttotal: 34.8s\tremaining: 26.5s\n",
      "568:\ttotal: 34.9s\tremaining: 26.4s\n",
      "569:\ttotal: 35s\tremaining: 26.4s\n",
      "570:\ttotal: 35s\tremaining: 26.3s\n",
      "571:\ttotal: 35.1s\tremaining: 26.2s\n",
      "572:\ttotal: 35.1s\tremaining: 26.2s\n",
      "573:\ttotal: 35.2s\tremaining: 26.1s\n",
      "574:\ttotal: 35.3s\tremaining: 26.1s\n",
      "575:\ttotal: 35.3s\tremaining: 26s\n",
      "576:\ttotal: 35.4s\tremaining: 25.9s\n",
      "577:\ttotal: 35.4s\tremaining: 25.9s\n",
      "578:\ttotal: 35.5s\tremaining: 25.8s\n",
      "579:\ttotal: 35.5s\tremaining: 25.7s\n",
      "580:\ttotal: 35.6s\tremaining: 25.7s\n",
      "581:\ttotal: 35.7s\tremaining: 25.6s\n",
      "582:\ttotal: 35.7s\tremaining: 25.6s\n",
      "583:\ttotal: 35.8s\tremaining: 25.5s\n",
      "584:\ttotal: 35.9s\tremaining: 25.4s\n",
      "585:\ttotal: 35.9s\tremaining: 25.4s\n",
      "586:\ttotal: 36s\tremaining: 25.3s\n",
      "587:\ttotal: 36s\tremaining: 25.3s\n",
      "588:\ttotal: 36.1s\tremaining: 25.2s\n",
      "589:\ttotal: 36.2s\tremaining: 25.1s\n",
      "590:\ttotal: 36.2s\tremaining: 25.1s\n",
      "591:\ttotal: 36.3s\tremaining: 25s\n",
      "592:\ttotal: 36.3s\tremaining: 24.9s\n",
      "593:\ttotal: 36.4s\tremaining: 24.9s\n",
      "594:\ttotal: 36.5s\tremaining: 24.8s\n",
      "595:\ttotal: 36.5s\tremaining: 24.8s\n",
      "596:\ttotal: 36.6s\tremaining: 24.7s\n",
      "597:\ttotal: 36.6s\tremaining: 24.6s\n",
      "598:\ttotal: 36.7s\tremaining: 24.6s\n",
      "599:\ttotal: 36.8s\tremaining: 24.5s\n",
      "600:\ttotal: 36.8s\tremaining: 24.4s\n",
      "601:\ttotal: 36.9s\tremaining: 24.4s\n",
      "602:\ttotal: 36.9s\tremaining: 24.3s\n",
      "603:\ttotal: 37s\tremaining: 24.3s\n",
      "604:\ttotal: 37.1s\tremaining: 24.2s\n",
      "605:\ttotal: 37.1s\tremaining: 24.1s\n",
      "606:\ttotal: 37.2s\tremaining: 24.1s\n",
      "607:\ttotal: 37.3s\tremaining: 24s\n",
      "608:\ttotal: 37.3s\tremaining: 24s\n",
      "609:\ttotal: 37.4s\tremaining: 23.9s\n",
      "610:\ttotal: 37.5s\tremaining: 23.8s\n",
      "611:\ttotal: 37.5s\tremaining: 23.8s\n",
      "612:\ttotal: 37.6s\tremaining: 23.7s\n",
      "613:\ttotal: 37.6s\tremaining: 23.7s\n",
      "614:\ttotal: 37.7s\tremaining: 23.6s\n",
      "615:\ttotal: 37.7s\tremaining: 23.5s\n",
      "616:\ttotal: 37.8s\tremaining: 23.5s\n",
      "617:\ttotal: 37.9s\tremaining: 23.4s\n",
      "618:\ttotal: 37.9s\tremaining: 23.3s\n",
      "619:\ttotal: 38s\tremaining: 23.3s\n",
      "620:\ttotal: 38s\tremaining: 23.2s\n",
      "621:\ttotal: 38.1s\tremaining: 23.2s\n",
      "622:\ttotal: 38.2s\tremaining: 23.1s\n",
      "623:\ttotal: 38.2s\tremaining: 23s\n",
      "624:\ttotal: 38.3s\tremaining: 23s\n",
      "625:\ttotal: 38.3s\tremaining: 22.9s\n",
      "626:\ttotal: 38.4s\tremaining: 22.9s\n",
      "627:\ttotal: 38.5s\tremaining: 22.8s\n",
      "628:\ttotal: 38.6s\tremaining: 22.7s\n",
      "629:\ttotal: 38.6s\tremaining: 22.7s\n",
      "630:\ttotal: 38.7s\tremaining: 22.6s\n",
      "631:\ttotal: 38.7s\tremaining: 22.6s\n",
      "632:\ttotal: 38.8s\tremaining: 22.5s\n",
      "633:\ttotal: 38.9s\tremaining: 22.4s\n",
      "634:\ttotal: 38.9s\tremaining: 22.4s\n",
      "635:\ttotal: 39s\tremaining: 22.3s\n",
      "636:\ttotal: 39.1s\tremaining: 22.3s\n",
      "637:\ttotal: 39.1s\tremaining: 22.2s\n",
      "638:\ttotal: 39.2s\tremaining: 22.1s\n",
      "639:\ttotal: 39.2s\tremaining: 22.1s\n",
      "640:\ttotal: 39.3s\tremaining: 22s\n",
      "641:\ttotal: 39.3s\tremaining: 21.9s\n",
      "642:\ttotal: 39.4s\tremaining: 21.9s\n",
      "643:\ttotal: 39.5s\tremaining: 21.8s\n",
      "644:\ttotal: 39.5s\tremaining: 21.8s\n",
      "645:\ttotal: 39.6s\tremaining: 21.7s\n",
      "646:\ttotal: 39.7s\tremaining: 21.6s\n",
      "647:\ttotal: 39.7s\tremaining: 21.6s\n",
      "648:\ttotal: 39.8s\tremaining: 21.5s\n",
      "649:\ttotal: 39.8s\tremaining: 21.5s\n",
      "650:\ttotal: 39.9s\tremaining: 21.4s\n",
      "651:\ttotal: 40s\tremaining: 21.3s\n",
      "652:\ttotal: 40s\tremaining: 21.3s\n",
      "653:\ttotal: 40.1s\tremaining: 21.2s\n",
      "654:\ttotal: 40.2s\tremaining: 21.1s\n",
      "655:\ttotal: 40.2s\tremaining: 21.1s\n",
      "656:\ttotal: 40.3s\tremaining: 21s\n",
      "657:\ttotal: 40.3s\tremaining: 21s\n",
      "658:\ttotal: 40.4s\tremaining: 20.9s\n",
      "659:\ttotal: 40.5s\tremaining: 20.8s\n",
      "660:\ttotal: 40.5s\tremaining: 20.8s\n",
      "661:\ttotal: 40.6s\tremaining: 20.7s\n",
      "662:\ttotal: 40.7s\tremaining: 20.7s\n",
      "663:\ttotal: 40.7s\tremaining: 20.6s\n",
      "664:\ttotal: 40.8s\tremaining: 20.5s\n",
      "665:\ttotal: 40.8s\tremaining: 20.5s\n",
      "666:\ttotal: 40.9s\tremaining: 20.4s\n",
      "667:\ttotal: 41s\tremaining: 20.4s\n",
      "668:\ttotal: 41s\tremaining: 20.3s\n",
      "669:\ttotal: 41.1s\tremaining: 20.2s\n",
      "670:\ttotal: 41.2s\tremaining: 20.2s\n",
      "671:\ttotal: 41.2s\tremaining: 20.1s\n",
      "672:\ttotal: 41.3s\tremaining: 20.1s\n",
      "673:\ttotal: 41.3s\tremaining: 20s\n",
      "674:\ttotal: 41.4s\tremaining: 19.9s\n",
      "675:\ttotal: 41.5s\tremaining: 19.9s\n",
      "676:\ttotal: 41.5s\tremaining: 19.8s\n",
      "677:\ttotal: 41.6s\tremaining: 19.7s\n",
      "678:\ttotal: 41.7s\tremaining: 19.7s\n",
      "679:\ttotal: 41.7s\tremaining: 19.6s\n",
      "680:\ttotal: 41.8s\tremaining: 19.6s\n",
      "681:\ttotal: 41.8s\tremaining: 19.5s\n",
      "682:\ttotal: 41.9s\tremaining: 19.4s\n",
      "683:\ttotal: 42s\tremaining: 19.4s\n",
      "684:\ttotal: 42s\tremaining: 19.3s\n",
      "685:\ttotal: 42.1s\tremaining: 19.3s\n",
      "686:\ttotal: 42.2s\tremaining: 19.2s\n",
      "687:\ttotal: 42.2s\tremaining: 19.1s\n",
      "688:\ttotal: 42.3s\tremaining: 19.1s\n",
      "689:\ttotal: 42.3s\tremaining: 19s\n",
      "690:\ttotal: 42.4s\tremaining: 19s\n",
      "691:\ttotal: 42.5s\tremaining: 18.9s\n",
      "692:\ttotal: 42.5s\tremaining: 18.8s\n",
      "693:\ttotal: 42.6s\tremaining: 18.8s\n",
      "694:\ttotal: 42.7s\tremaining: 18.7s\n",
      "695:\ttotal: 42.7s\tremaining: 18.7s\n",
      "696:\ttotal: 42.8s\tremaining: 18.6s\n",
      "697:\ttotal: 42.8s\tremaining: 18.5s\n",
      "698:\ttotal: 42.9s\tremaining: 18.5s\n",
      "699:\ttotal: 43s\tremaining: 18.4s\n",
      "700:\ttotal: 43s\tremaining: 18.3s\n",
      "701:\ttotal: 43.1s\tremaining: 18.3s\n",
      "702:\ttotal: 43.1s\tremaining: 18.2s\n",
      "703:\ttotal: 43.2s\tremaining: 18.2s\n",
      "704:\ttotal: 43.3s\tremaining: 18.1s\n",
      "705:\ttotal: 43.3s\tremaining: 18s\n",
      "706:\ttotal: 43.4s\tremaining: 18s\n",
      "707:\ttotal: 43.4s\tremaining: 17.9s\n",
      "708:\ttotal: 43.5s\tremaining: 17.9s\n",
      "709:\ttotal: 43.6s\tremaining: 17.8s\n",
      "710:\ttotal: 43.6s\tremaining: 17.7s\n",
      "711:\ttotal: 43.7s\tremaining: 17.7s\n",
      "712:\ttotal: 43.7s\tremaining: 17.6s\n",
      "713:\ttotal: 43.8s\tremaining: 17.5s\n",
      "714:\ttotal: 43.9s\tremaining: 17.5s\n",
      "715:\ttotal: 43.9s\tremaining: 17.4s\n",
      "716:\ttotal: 44s\tremaining: 17.4s\n",
      "717:\ttotal: 44s\tremaining: 17.3s\n",
      "718:\ttotal: 44.1s\tremaining: 17.2s\n",
      "719:\ttotal: 44.2s\tremaining: 17.2s\n",
      "720:\ttotal: 44.2s\tremaining: 17.1s\n",
      "721:\ttotal: 44.3s\tremaining: 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722:\ttotal: 44.3s\tremaining: 17s\n",
      "723:\ttotal: 44.4s\tremaining: 16.9s\n",
      "724:\ttotal: 44.5s\tremaining: 16.9s\n",
      "725:\ttotal: 44.5s\tremaining: 16.8s\n",
      "726:\ttotal: 44.6s\tremaining: 16.7s\n",
      "727:\ttotal: 44.7s\tremaining: 16.7s\n",
      "728:\ttotal: 44.7s\tremaining: 16.6s\n",
      "729:\ttotal: 44.8s\tremaining: 16.6s\n",
      "730:\ttotal: 44.8s\tremaining: 16.5s\n",
      "731:\ttotal: 44.9s\tremaining: 16.4s\n",
      "732:\ttotal: 45s\tremaining: 16.4s\n",
      "733:\ttotal: 45s\tremaining: 16.3s\n",
      "734:\ttotal: 45.1s\tremaining: 16.3s\n",
      "735:\ttotal: 45.1s\tremaining: 16.2s\n",
      "736:\ttotal: 45.2s\tremaining: 16.1s\n",
      "737:\ttotal: 45.3s\tremaining: 16.1s\n",
      "738:\ttotal: 45.3s\tremaining: 16s\n",
      "739:\ttotal: 45.4s\tremaining: 15.9s\n",
      "740:\ttotal: 45.4s\tremaining: 15.9s\n",
      "741:\ttotal: 45.5s\tremaining: 15.8s\n",
      "742:\ttotal: 45.6s\tremaining: 15.8s\n",
      "743:\ttotal: 45.6s\tremaining: 15.7s\n",
      "744:\ttotal: 45.7s\tremaining: 15.6s\n",
      "745:\ttotal: 45.7s\tremaining: 15.6s\n",
      "746:\ttotal: 45.8s\tremaining: 15.5s\n",
      "747:\ttotal: 45.9s\tremaining: 15.5s\n",
      "748:\ttotal: 45.9s\tremaining: 15.4s\n",
      "749:\ttotal: 46s\tremaining: 15.3s\n",
      "750:\ttotal: 46.1s\tremaining: 15.3s\n",
      "751:\ttotal: 46.1s\tremaining: 15.2s\n",
      "752:\ttotal: 46.2s\tremaining: 15.1s\n",
      "753:\ttotal: 46.2s\tremaining: 15.1s\n",
      "754:\ttotal: 46.3s\tremaining: 15s\n",
      "755:\ttotal: 46.4s\tremaining: 15s\n",
      "756:\ttotal: 46.5s\tremaining: 14.9s\n",
      "757:\ttotal: 46.5s\tremaining: 14.8s\n",
      "758:\ttotal: 46.6s\tremaining: 14.8s\n",
      "759:\ttotal: 46.6s\tremaining: 14.7s\n",
      "760:\ttotal: 46.7s\tremaining: 14.7s\n",
      "761:\ttotal: 46.7s\tremaining: 14.6s\n",
      "762:\ttotal: 46.8s\tremaining: 14.5s\n",
      "763:\ttotal: 46.9s\tremaining: 14.5s\n",
      "764:\ttotal: 46.9s\tremaining: 14.4s\n",
      "765:\ttotal: 47s\tremaining: 14.4s\n",
      "766:\ttotal: 47.1s\tremaining: 14.3s\n",
      "767:\ttotal: 47.1s\tremaining: 14.2s\n",
      "768:\ttotal: 47.2s\tremaining: 14.2s\n",
      "769:\ttotal: 47.2s\tremaining: 14.1s\n",
      "770:\ttotal: 47.3s\tremaining: 14.1s\n",
      "771:\ttotal: 47.4s\tremaining: 14s\n",
      "772:\ttotal: 47.4s\tremaining: 13.9s\n",
      "773:\ttotal: 47.5s\tremaining: 13.9s\n",
      "774:\ttotal: 47.6s\tremaining: 13.8s\n",
      "775:\ttotal: 47.6s\tremaining: 13.7s\n",
      "776:\ttotal: 47.7s\tremaining: 13.7s\n",
      "777:\ttotal: 47.7s\tremaining: 13.6s\n",
      "778:\ttotal: 47.8s\tremaining: 13.6s\n",
      "779:\ttotal: 47.9s\tremaining: 13.5s\n",
      "780:\ttotal: 47.9s\tremaining: 13.4s\n",
      "781:\ttotal: 48s\tremaining: 13.4s\n",
      "782:\ttotal: 48s\tremaining: 13.3s\n",
      "783:\ttotal: 48.1s\tremaining: 13.3s\n",
      "784:\ttotal: 48.2s\tremaining: 13.2s\n",
      "785:\ttotal: 48.2s\tremaining: 13.1s\n",
      "786:\ttotal: 48.3s\tremaining: 13.1s\n",
      "787:\ttotal: 48.4s\tremaining: 13s\n",
      "788:\ttotal: 48.4s\tremaining: 12.9s\n",
      "789:\ttotal: 48.5s\tremaining: 12.9s\n",
      "790:\ttotal: 48.5s\tremaining: 12.8s\n",
      "791:\ttotal: 48.6s\tremaining: 12.8s\n",
      "792:\ttotal: 48.7s\tremaining: 12.7s\n",
      "793:\ttotal: 48.7s\tremaining: 12.6s\n",
      "794:\ttotal: 48.8s\tremaining: 12.6s\n",
      "795:\ttotal: 48.9s\tremaining: 12.5s\n",
      "796:\ttotal: 48.9s\tremaining: 12.5s\n",
      "797:\ttotal: 49s\tremaining: 12.4s\n",
      "798:\ttotal: 49s\tremaining: 12.3s\n",
      "799:\ttotal: 49.1s\tremaining: 12.3s\n",
      "800:\ttotal: 49.2s\tremaining: 12.2s\n",
      "801:\ttotal: 49.2s\tremaining: 12.1s\n",
      "802:\ttotal: 49.3s\tremaining: 12.1s\n",
      "803:\ttotal: 49.4s\tremaining: 12s\n",
      "804:\ttotal: 49.4s\tremaining: 12s\n",
      "805:\ttotal: 49.5s\tremaining: 11.9s\n",
      "806:\ttotal: 49.5s\tremaining: 11.8s\n",
      "807:\ttotal: 49.6s\tremaining: 11.8s\n",
      "808:\ttotal: 49.7s\tremaining: 11.7s\n",
      "809:\ttotal: 49.7s\tremaining: 11.7s\n",
      "810:\ttotal: 49.8s\tremaining: 11.6s\n",
      "811:\ttotal: 49.8s\tremaining: 11.5s\n",
      "812:\ttotal: 49.9s\tremaining: 11.5s\n",
      "813:\ttotal: 50s\tremaining: 11.4s\n",
      "814:\ttotal: 50s\tremaining: 11.4s\n",
      "815:\ttotal: 50.1s\tremaining: 11.3s\n",
      "816:\ttotal: 50.1s\tremaining: 11.2s\n",
      "817:\ttotal: 50.2s\tremaining: 11.2s\n",
      "818:\ttotal: 50.3s\tremaining: 11.1s\n",
      "819:\ttotal: 50.3s\tremaining: 11s\n",
      "820:\ttotal: 50.4s\tremaining: 11s\n",
      "821:\ttotal: 50.4s\tremaining: 10.9s\n",
      "822:\ttotal: 50.5s\tremaining: 10.9s\n",
      "823:\ttotal: 50.5s\tremaining: 10.8s\n",
      "824:\ttotal: 50.6s\tremaining: 10.7s\n",
      "825:\ttotal: 50.7s\tremaining: 10.7s\n",
      "826:\ttotal: 50.7s\tremaining: 10.6s\n",
      "827:\ttotal: 50.8s\tremaining: 10.5s\n",
      "828:\ttotal: 50.8s\tremaining: 10.5s\n",
      "829:\ttotal: 50.9s\tremaining: 10.4s\n",
      "830:\ttotal: 51s\tremaining: 10.4s\n",
      "831:\ttotal: 51s\tremaining: 10.3s\n",
      "832:\ttotal: 51.1s\tremaining: 10.2s\n",
      "833:\ttotal: 51.1s\tremaining: 10.2s\n",
      "834:\ttotal: 51.2s\tremaining: 10.1s\n",
      "835:\ttotal: 51.3s\tremaining: 10.1s\n",
      "836:\ttotal: 51.3s\tremaining: 9.99s\n",
      "837:\ttotal: 51.4s\tremaining: 9.93s\n",
      "838:\ttotal: 51.4s\tremaining: 9.87s\n",
      "839:\ttotal: 51.5s\tremaining: 9.81s\n",
      "840:\ttotal: 51.6s\tremaining: 9.75s\n",
      "841:\ttotal: 51.6s\tremaining: 9.69s\n",
      "842:\ttotal: 51.7s\tremaining: 9.63s\n",
      "843:\ttotal: 51.7s\tremaining: 9.56s\n",
      "844:\ttotal: 51.8s\tremaining: 9.5s\n",
      "845:\ttotal: 51.9s\tremaining: 9.44s\n",
      "846:\ttotal: 51.9s\tremaining: 9.38s\n",
      "847:\ttotal: 52s\tremaining: 9.32s\n",
      "848:\ttotal: 52.1s\tremaining: 9.26s\n",
      "849:\ttotal: 52.1s\tremaining: 9.2s\n",
      "850:\ttotal: 52.2s\tremaining: 9.14s\n",
      "851:\ttotal: 52.2s\tremaining: 9.07s\n",
      "852:\ttotal: 52.3s\tremaining: 9.01s\n",
      "853:\ttotal: 52.4s\tremaining: 8.95s\n",
      "854:\ttotal: 52.4s\tremaining: 8.89s\n",
      "855:\ttotal: 52.5s\tremaining: 8.83s\n",
      "856:\ttotal: 52.6s\tremaining: 8.77s\n",
      "857:\ttotal: 52.6s\tremaining: 8.71s\n",
      "858:\ttotal: 52.7s\tremaining: 8.65s\n",
      "859:\ttotal: 52.7s\tremaining: 8.59s\n",
      "860:\ttotal: 52.8s\tremaining: 8.52s\n",
      "861:\ttotal: 52.9s\tremaining: 8.46s\n",
      "862:\ttotal: 52.9s\tremaining: 8.4s\n",
      "863:\ttotal: 53s\tremaining: 8.34s\n",
      "864:\ttotal: 53s\tremaining: 8.28s\n",
      "865:\ttotal: 53.1s\tremaining: 8.22s\n",
      "866:\ttotal: 53.2s\tremaining: 8.16s\n",
      "867:\ttotal: 53.2s\tremaining: 8.1s\n",
      "868:\ttotal: 53.3s\tremaining: 8.04s\n",
      "869:\ttotal: 53.4s\tremaining: 7.98s\n",
      "870:\ttotal: 53.5s\tremaining: 7.92s\n",
      "871:\ttotal: 53.5s\tremaining: 7.85s\n",
      "872:\ttotal: 53.6s\tremaining: 7.79s\n",
      "873:\ttotal: 53.6s\tremaining: 7.73s\n",
      "874:\ttotal: 53.7s\tremaining: 7.67s\n",
      "875:\ttotal: 53.8s\tremaining: 7.61s\n",
      "876:\ttotal: 53.8s\tremaining: 7.55s\n",
      "877:\ttotal: 53.9s\tremaining: 7.49s\n",
      "878:\ttotal: 53.9s\tremaining: 7.42s\n",
      "879:\ttotal: 54s\tremaining: 7.36s\n",
      "880:\ttotal: 54s\tremaining: 7.3s\n",
      "881:\ttotal: 54.1s\tremaining: 7.24s\n",
      "882:\ttotal: 54.2s\tremaining: 7.18s\n",
      "883:\ttotal: 54.2s\tremaining: 7.12s\n",
      "884:\ttotal: 54.3s\tremaining: 7.05s\n",
      "885:\ttotal: 54.4s\tremaining: 6.99s\n",
      "886:\ttotal: 54.4s\tremaining: 6.93s\n",
      "887:\ttotal: 54.5s\tremaining: 6.87s\n",
      "888:\ttotal: 54.5s\tremaining: 6.81s\n",
      "889:\ttotal: 54.6s\tremaining: 6.75s\n",
      "890:\ttotal: 54.7s\tremaining: 6.69s\n",
      "891:\ttotal: 54.7s\tremaining: 6.63s\n",
      "892:\ttotal: 54.8s\tremaining: 6.56s\n",
      "893:\ttotal: 54.9s\tremaining: 6.5s\n",
      "894:\ttotal: 54.9s\tremaining: 6.44s\n",
      "895:\ttotal: 55s\tremaining: 6.38s\n",
      "896:\ttotal: 55s\tremaining: 6.32s\n",
      "897:\ttotal: 55.1s\tremaining: 6.26s\n",
      "898:\ttotal: 55.2s\tremaining: 6.2s\n",
      "899:\ttotal: 55.2s\tremaining: 6.13s\n",
      "900:\ttotal: 55.3s\tremaining: 6.07s\n",
      "901:\ttotal: 55.3s\tremaining: 6.01s\n",
      "902:\ttotal: 55.4s\tremaining: 5.95s\n",
      "903:\ttotal: 55.5s\tremaining: 5.89s\n",
      "904:\ttotal: 55.5s\tremaining: 5.83s\n",
      "905:\ttotal: 55.6s\tremaining: 5.77s\n",
      "906:\ttotal: 55.7s\tremaining: 5.71s\n",
      "907:\ttotal: 55.7s\tremaining: 5.64s\n",
      "908:\ttotal: 55.8s\tremaining: 5.58s\n",
      "909:\ttotal: 55.9s\tremaining: 5.52s\n",
      "910:\ttotal: 55.9s\tremaining: 5.46s\n",
      "911:\ttotal: 56s\tremaining: 5.4s\n",
      "912:\ttotal: 56s\tremaining: 5.34s\n",
      "913:\ttotal: 56.1s\tremaining: 5.28s\n",
      "914:\ttotal: 56.1s\tremaining: 5.21s\n",
      "915:\ttotal: 56.2s\tremaining: 5.15s\n",
      "916:\ttotal: 56.3s\tremaining: 5.09s\n",
      "917:\ttotal: 56.3s\tremaining: 5.03s\n",
      "918:\ttotal: 56.4s\tremaining: 4.97s\n",
      "919:\ttotal: 56.4s\tremaining: 4.91s\n",
      "920:\ttotal: 56.5s\tremaining: 4.84s\n",
      "921:\ttotal: 56.6s\tremaining: 4.78s\n",
      "922:\ttotal: 56.6s\tremaining: 4.72s\n",
      "923:\ttotal: 56.7s\tremaining: 4.66s\n",
      "924:\ttotal: 56.7s\tremaining: 4.6s\n",
      "925:\ttotal: 56.8s\tremaining: 4.54s\n",
      "926:\ttotal: 56.9s\tremaining: 4.48s\n",
      "927:\ttotal: 56.9s\tremaining: 4.42s\n",
      "928:\ttotal: 57s\tremaining: 4.36s\n",
      "929:\ttotal: 57.1s\tremaining: 4.29s\n",
      "930:\ttotal: 57.1s\tremaining: 4.23s\n",
      "931:\ttotal: 57.2s\tremaining: 4.17s\n",
      "932:\ttotal: 57.3s\tremaining: 4.11s\n",
      "933:\ttotal: 57.3s\tremaining: 4.05s\n",
      "934:\ttotal: 57.4s\tremaining: 3.99s\n",
      "935:\ttotal: 57.4s\tremaining: 3.93s\n",
      "936:\ttotal: 57.5s\tremaining: 3.87s\n",
      "937:\ttotal: 57.6s\tremaining: 3.8s\n",
      "938:\ttotal: 57.6s\tremaining: 3.74s\n",
      "939:\ttotal: 57.7s\tremaining: 3.68s\n",
      "940:\ttotal: 57.7s\tremaining: 3.62s\n",
      "941:\ttotal: 57.8s\tremaining: 3.56s\n",
      "942:\ttotal: 57.9s\tremaining: 3.5s\n",
      "943:\ttotal: 57.9s\tremaining: 3.44s\n",
      "944:\ttotal: 58s\tremaining: 3.37s\n",
      "945:\ttotal: 58s\tremaining: 3.31s\n",
      "946:\ttotal: 58.1s\tremaining: 3.25s\n",
      "947:\ttotal: 58.2s\tremaining: 3.19s\n",
      "948:\ttotal: 58.2s\tremaining: 3.13s\n",
      "949:\ttotal: 58.3s\tremaining: 3.07s\n",
      "950:\ttotal: 58.3s\tremaining: 3s\n",
      "951:\ttotal: 58.4s\tremaining: 2.94s\n",
      "952:\ttotal: 58.5s\tremaining: 2.88s\n",
      "953:\ttotal: 58.5s\tremaining: 2.82s\n",
      "954:\ttotal: 58.6s\tremaining: 2.76s\n",
      "955:\ttotal: 58.6s\tremaining: 2.7s\n",
      "956:\ttotal: 58.7s\tremaining: 2.64s\n",
      "957:\ttotal: 58.8s\tremaining: 2.58s\n",
      "958:\ttotal: 58.8s\tremaining: 2.51s\n",
      "959:\ttotal: 58.9s\tremaining: 2.45s\n",
      "960:\ttotal: 58.9s\tremaining: 2.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961:\ttotal: 59s\tremaining: 2.33s\n",
      "962:\ttotal: 59.1s\tremaining: 2.27s\n",
      "963:\ttotal: 59.1s\tremaining: 2.21s\n",
      "964:\ttotal: 59.2s\tremaining: 2.15s\n",
      "965:\ttotal: 59.3s\tremaining: 2.08s\n",
      "966:\ttotal: 59.3s\tremaining: 2.02s\n",
      "967:\ttotal: 59.4s\tremaining: 1.96s\n",
      "968:\ttotal: 59.4s\tremaining: 1.9s\n",
      "969:\ttotal: 59.5s\tremaining: 1.84s\n",
      "970:\ttotal: 59.5s\tremaining: 1.78s\n",
      "971:\ttotal: 59.6s\tremaining: 1.72s\n",
      "972:\ttotal: 59.7s\tremaining: 1.66s\n",
      "973:\ttotal: 59.7s\tremaining: 1.59s\n",
      "974:\ttotal: 59.8s\tremaining: 1.53s\n",
      "975:\ttotal: 59.8s\tremaining: 1.47s\n",
      "976:\ttotal: 59.9s\tremaining: 1.41s\n",
      "977:\ttotal: 60s\tremaining: 1.35s\n",
      "978:\ttotal: 1m\tremaining: 1.29s\n",
      "979:\ttotal: 1m\tremaining: 1.23s\n",
      "980:\ttotal: 1m\tremaining: 1.16s\n",
      "981:\ttotal: 1m\tremaining: 1.1s\n",
      "982:\ttotal: 1m\tremaining: 1.04s\n",
      "983:\ttotal: 1m\tremaining: 981ms\n",
      "984:\ttotal: 1m\tremaining: 920ms\n",
      "985:\ttotal: 1m\tremaining: 858ms\n",
      "986:\ttotal: 1m\tremaining: 797ms\n",
      "987:\ttotal: 1m\tremaining: 736ms\n",
      "988:\ttotal: 1m\tremaining: 674ms\n",
      "989:\ttotal: 1m\tremaining: 613ms\n",
      "990:\ttotal: 1m\tremaining: 552ms\n",
      "991:\ttotal: 1m\tremaining: 490ms\n",
      "992:\ttotal: 1m\tremaining: 429ms\n",
      "993:\ttotal: 1m\tremaining: 368ms\n",
      "994:\ttotal: 1m\tremaining: 307ms\n",
      "995:\ttotal: 1m 1s\tremaining: 245ms\n",
      "996:\ttotal: 1m 1s\tremaining: 184ms\n",
      "997:\ttotal: 1m 1s\tremaining: 123ms\n",
      "998:\ttotal: 1m 1s\tremaining: 61.3ms\n",
      "999:\ttotal: 1m 1s\tremaining: 0us\n",
      "0.830637330244502\n",
      "0:\tlearn: 0.6781288\ttotal: 63.1ms\tremaining: 1m 3s\n",
      "1:\tlearn: 0.6642554\ttotal: 117ms\tremaining: 58.4s\n",
      "2:\tlearn: 0.6512395\ttotal: 174ms\tremaining: 57.7s\n",
      "3:\tlearn: 0.6388460\ttotal: 232ms\tremaining: 57.7s\n",
      "4:\tlearn: 0.6275972\ttotal: 300ms\tremaining: 59.6s\n",
      "5:\tlearn: 0.6170811\ttotal: 359ms\tremaining: 59.5s\n",
      "6:\tlearn: 0.6073098\ttotal: 418ms\tremaining: 59.3s\n",
      "7:\tlearn: 0.5981609\ttotal: 486ms\tremaining: 1m\n",
      "8:\tlearn: 0.5898387\ttotal: 556ms\tremaining: 1m 1s\n",
      "9:\tlearn: 0.5820529\ttotal: 612ms\tremaining: 1m\n",
      "10:\tlearn: 0.5746355\ttotal: 668ms\tremaining: 1m\n",
      "11:\tlearn: 0.5676719\ttotal: 732ms\tremaining: 1m\n",
      "12:\tlearn: 0.5612332\ttotal: 795ms\tremaining: 1m\n",
      "13:\tlearn: 0.5551550\ttotal: 861ms\tremaining: 1m\n",
      "14:\tlearn: 0.5496216\ttotal: 925ms\tremaining: 1m\n",
      "15:\tlearn: 0.5444020\ttotal: 981ms\tremaining: 1m\n",
      "16:\tlearn: 0.5393129\ttotal: 1.05s\tremaining: 1m\n",
      "17:\tlearn: 0.5346707\ttotal: 1.1s\tremaining: 1m\n",
      "18:\tlearn: 0.5302673\ttotal: 1.17s\tremaining: 1m\n",
      "19:\tlearn: 0.5261193\ttotal: 1.24s\tremaining: 1m\n",
      "20:\tlearn: 0.5222497\ttotal: 1.3s\tremaining: 1m\n",
      "21:\tlearn: 0.5185129\ttotal: 1.36s\tremaining: 1m\n",
      "22:\tlearn: 0.5150909\ttotal: 1.43s\tremaining: 1m\n",
      "23:\tlearn: 0.5119970\ttotal: 1.5s\tremaining: 1m\n",
      "24:\tlearn: 0.5091303\ttotal: 1.57s\tremaining: 1m 1s\n",
      "25:\tlearn: 0.5064082\ttotal: 1.63s\tremaining: 1m 1s\n",
      "26:\tlearn: 0.5037391\ttotal: 1.69s\tremaining: 1m\n",
      "27:\tlearn: 0.5011713\ttotal: 1.75s\tremaining: 1m\n",
      "28:\tlearn: 0.4987568\ttotal: 1.83s\tremaining: 1m 1s\n",
      "29:\tlearn: 0.4965223\ttotal: 1.9s\tremaining: 1m 1s\n",
      "30:\tlearn: 0.4945472\ttotal: 1.95s\tremaining: 1m 1s\n",
      "31:\tlearn: 0.4925839\ttotal: 2.01s\tremaining: 1m\n",
      "32:\tlearn: 0.4906882\ttotal: 2.08s\tremaining: 1m 1s\n",
      "33:\tlearn: 0.4889461\ttotal: 2.14s\tremaining: 1m\n",
      "34:\tlearn: 0.4872841\ttotal: 2.2s\tremaining: 1m\n",
      "35:\tlearn: 0.4857599\ttotal: 2.26s\tremaining: 1m\n",
      "36:\tlearn: 0.4842653\ttotal: 2.33s\tremaining: 1m\n",
      "37:\tlearn: 0.4829232\ttotal: 2.4s\tremaining: 1m\n",
      "38:\tlearn: 0.4816303\ttotal: 2.46s\tremaining: 1m\n",
      "39:\tlearn: 0.4803767\ttotal: 2.51s\tremaining: 1m\n",
      "40:\tlearn: 0.4792582\ttotal: 2.58s\tremaining: 1m\n",
      "41:\tlearn: 0.4781693\ttotal: 2.64s\tremaining: 1m\n",
      "42:\tlearn: 0.4771832\ttotal: 2.71s\tremaining: 1m\n",
      "43:\tlearn: 0.4761160\ttotal: 2.76s\tremaining: 1m\n",
      "44:\tlearn: 0.4751735\ttotal: 2.83s\tremaining: 1m\n",
      "45:\tlearn: 0.4743297\ttotal: 2.89s\tremaining: 59.9s\n",
      "46:\tlearn: 0.4734809\ttotal: 2.95s\tremaining: 59.8s\n",
      "47:\tlearn: 0.4726446\ttotal: 3s\tremaining: 59.6s\n",
      "48:\tlearn: 0.4718938\ttotal: 3.07s\tremaining: 59.5s\n",
      "49:\tlearn: 0.4711603\ttotal: 3.12s\tremaining: 59.3s\n",
      "50:\tlearn: 0.4704919\ttotal: 3.18s\tremaining: 59.2s\n",
      "51:\tlearn: 0.4698537\ttotal: 3.23s\tremaining: 59s\n",
      "52:\tlearn: 0.4692665\ttotal: 3.3s\tremaining: 59s\n",
      "53:\tlearn: 0.4686869\ttotal: 3.36s\tremaining: 58.9s\n",
      "54:\tlearn: 0.4681371\ttotal: 3.42s\tremaining: 58.7s\n",
      "55:\tlearn: 0.4675857\ttotal: 3.48s\tremaining: 58.6s\n",
      "56:\tlearn: 0.4670829\ttotal: 3.54s\tremaining: 58.6s\n",
      "57:\tlearn: 0.4665819\ttotal: 3.6s\tremaining: 58.5s\n",
      "58:\tlearn: 0.4661176\ttotal: 3.67s\tremaining: 58.6s\n",
      "59:\tlearn: 0.4656877\ttotal: 3.73s\tremaining: 58.5s\n",
      "60:\tlearn: 0.4652450\ttotal: 3.81s\tremaining: 58.6s\n",
      "61:\tlearn: 0.4648594\ttotal: 3.87s\tremaining: 58.5s\n",
      "62:\tlearn: 0.4644958\ttotal: 3.92s\tremaining: 58.3s\n",
      "63:\tlearn: 0.4641263\ttotal: 3.98s\tremaining: 58.2s\n",
      "64:\tlearn: 0.4637936\ttotal: 4.05s\tremaining: 58.3s\n",
      "65:\tlearn: 0.4634715\ttotal: 4.11s\tremaining: 58.2s\n",
      "66:\tlearn: 0.4631522\ttotal: 4.17s\tremaining: 58.1s\n",
      "67:\tlearn: 0.4628796\ttotal: 4.24s\tremaining: 58.1s\n",
      "68:\tlearn: 0.4625950\ttotal: 4.3s\tremaining: 58s\n",
      "69:\tlearn: 0.4623227\ttotal: 4.36s\tremaining: 58s\n",
      "70:\tlearn: 0.4620755\ttotal: 4.42s\tremaining: 57.9s\n",
      "71:\tlearn: 0.4618387\ttotal: 4.48s\tremaining: 57.8s\n",
      "72:\tlearn: 0.4616305\ttotal: 4.54s\tremaining: 57.7s\n",
      "73:\tlearn: 0.4614177\ttotal: 4.6s\tremaining: 57.6s\n",
      "74:\tlearn: 0.4612074\ttotal: 4.66s\tremaining: 57.5s\n",
      "75:\tlearn: 0.4609965\ttotal: 4.73s\tremaining: 57.5s\n",
      "76:\tlearn: 0.4608039\ttotal: 4.8s\tremaining: 57.6s\n",
      "77:\tlearn: 0.4606253\ttotal: 4.87s\tremaining: 57.5s\n",
      "78:\tlearn: 0.4604408\ttotal: 4.92s\tremaining: 57.4s\n",
      "79:\tlearn: 0.4602508\ttotal: 4.99s\tremaining: 57.3s\n",
      "80:\tlearn: 0.4600721\ttotal: 5.05s\tremaining: 57.4s\n",
      "81:\tlearn: 0.4599111\ttotal: 5.11s\tremaining: 57.2s\n",
      "82:\tlearn: 0.4597632\ttotal: 5.17s\tremaining: 57.1s\n",
      "83:\tlearn: 0.4596215\ttotal: 5.23s\tremaining: 57.1s\n",
      "84:\tlearn: 0.4594902\ttotal: 5.3s\tremaining: 57.1s\n",
      "85:\tlearn: 0.4593510\ttotal: 5.37s\tremaining: 57.1s\n",
      "86:\tlearn: 0.4592319\ttotal: 5.45s\tremaining: 57.2s\n",
      "87:\tlearn: 0.4591037\ttotal: 5.52s\tremaining: 57.2s\n",
      "88:\tlearn: 0.4590003\ttotal: 5.58s\tremaining: 57.1s\n",
      "89:\tlearn: 0.4588969\ttotal: 5.63s\tremaining: 57s\n",
      "90:\tlearn: 0.4587853\ttotal: 5.69s\tremaining: 56.9s\n",
      "91:\tlearn: 0.4586801\ttotal: 5.76s\tremaining: 56.9s\n",
      "92:\tlearn: 0.4585707\ttotal: 5.82s\tremaining: 56.8s\n",
      "93:\tlearn: 0.4584719\ttotal: 5.88s\tremaining: 56.7s\n",
      "94:\tlearn: 0.4583872\ttotal: 5.94s\tremaining: 56.6s\n",
      "95:\tlearn: 0.4583194\ttotal: 6.01s\tremaining: 56.6s\n",
      "96:\tlearn: 0.4582155\ttotal: 6.07s\tremaining: 56.5s\n",
      "97:\tlearn: 0.4581433\ttotal: 6.12s\tremaining: 56.4s\n",
      "98:\tlearn: 0.4580756\ttotal: 6.19s\tremaining: 56.3s\n",
      "99:\tlearn: 0.4580102\ttotal: 6.27s\tremaining: 56.4s\n",
      "100:\tlearn: 0.4579317\ttotal: 6.33s\tremaining: 56.4s\n",
      "101:\tlearn: 0.4578620\ttotal: 6.4s\tremaining: 56.3s\n",
      "102:\tlearn: 0.4577956\ttotal: 6.47s\tremaining: 56.3s\n",
      "103:\tlearn: 0.4577277\ttotal: 6.54s\tremaining: 56.3s\n",
      "104:\tlearn: 0.4576633\ttotal: 6.6s\tremaining: 56.3s\n",
      "105:\tlearn: 0.4575956\ttotal: 6.67s\tremaining: 56.2s\n",
      "106:\tlearn: 0.4575348\ttotal: 6.73s\tremaining: 56.2s\n",
      "107:\tlearn: 0.4574780\ttotal: 6.8s\tremaining: 56.2s\n",
      "108:\tlearn: 0.4574141\ttotal: 6.86s\tremaining: 56.1s\n",
      "109:\tlearn: 0.4573606\ttotal: 6.92s\tremaining: 56s\n",
      "110:\tlearn: 0.4573010\ttotal: 6.99s\tremaining: 56s\n",
      "111:\tlearn: 0.4572433\ttotal: 7.06s\tremaining: 56s\n",
      "112:\tlearn: 0.4571958\ttotal: 7.11s\tremaining: 55.8s\n",
      "113:\tlearn: 0.4571450\ttotal: 7.17s\tremaining: 55.7s\n",
      "114:\tlearn: 0.4571001\ttotal: 7.23s\tremaining: 55.7s\n",
      "115:\tlearn: 0.4570495\ttotal: 7.3s\tremaining: 55.7s\n",
      "116:\tlearn: 0.4569997\ttotal: 7.37s\tremaining: 55.6s\n",
      "117:\tlearn: 0.4569459\ttotal: 7.42s\tremaining: 55.5s\n",
      "118:\tlearn: 0.4569021\ttotal: 7.49s\tremaining: 55.4s\n",
      "119:\tlearn: 0.4568583\ttotal: 7.56s\tremaining: 55.4s\n",
      "120:\tlearn: 0.4568152\ttotal: 7.63s\tremaining: 55.4s\n",
      "121:\tlearn: 0.4567733\ttotal: 7.7s\tremaining: 55.4s\n",
      "122:\tlearn: 0.4567338\ttotal: 7.76s\tremaining: 55.3s\n",
      "123:\tlearn: 0.4566992\ttotal: 7.82s\tremaining: 55.2s\n",
      "124:\tlearn: 0.4566485\ttotal: 7.88s\tremaining: 55.1s\n",
      "125:\tlearn: 0.4565996\ttotal: 7.94s\tremaining: 55.1s\n",
      "126:\tlearn: 0.4565656\ttotal: 8.01s\tremaining: 55.1s\n",
      "127:\tlearn: 0.4565255\ttotal: 8.08s\tremaining: 55.1s\n",
      "128:\tlearn: 0.4564990\ttotal: 8.14s\tremaining: 54.9s\n",
      "129:\tlearn: 0.4564669\ttotal: 8.2s\tremaining: 54.9s\n",
      "130:\tlearn: 0.4564377\ttotal: 8.27s\tremaining: 54.8s\n",
      "131:\tlearn: 0.4564075\ttotal: 8.34s\tremaining: 54.8s\n",
      "132:\tlearn: 0.4563725\ttotal: 8.4s\tremaining: 54.7s\n",
      "133:\tlearn: 0.4563464\ttotal: 8.46s\tremaining: 54.7s\n",
      "134:\tlearn: 0.4563112\ttotal: 8.51s\tremaining: 54.5s\n",
      "135:\tlearn: 0.4562801\ttotal: 8.57s\tremaining: 54.5s\n",
      "136:\tlearn: 0.4562528\ttotal: 8.63s\tremaining: 54.4s\n",
      "137:\tlearn: 0.4562107\ttotal: 8.69s\tremaining: 54.3s\n",
      "138:\tlearn: 0.4561799\ttotal: 8.76s\tremaining: 54.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139:\tlearn: 0.4561533\ttotal: 8.82s\tremaining: 54.2s\n",
      "140:\tlearn: 0.4561193\ttotal: 8.88s\tremaining: 54.1s\n",
      "141:\tlearn: 0.4560916\ttotal: 8.94s\tremaining: 54s\n",
      "142:\tlearn: 0.4560721\ttotal: 9s\tremaining: 54s\n",
      "143:\tlearn: 0.4560455\ttotal: 9.06s\tremaining: 53.9s\n",
      "144:\tlearn: 0.4560122\ttotal: 9.12s\tremaining: 53.8s\n",
      "145:\tlearn: 0.4559782\ttotal: 9.18s\tremaining: 53.7s\n",
      "146:\tlearn: 0.4559548\ttotal: 9.24s\tremaining: 53.6s\n",
      "147:\tlearn: 0.4559277\ttotal: 9.3s\tremaining: 53.6s\n",
      "148:\tlearn: 0.4559001\ttotal: 9.36s\tremaining: 53.5s\n",
      "149:\tlearn: 0.4558747\ttotal: 9.42s\tremaining: 53.4s\n",
      "150:\tlearn: 0.4558525\ttotal: 9.48s\tremaining: 53.3s\n",
      "151:\tlearn: 0.4558258\ttotal: 9.54s\tremaining: 53.2s\n",
      "152:\tlearn: 0.4558046\ttotal: 9.6s\tremaining: 53.1s\n",
      "153:\tlearn: 0.4557846\ttotal: 9.65s\tremaining: 53s\n",
      "154:\tlearn: 0.4557614\ttotal: 9.71s\tremaining: 52.9s\n",
      "155:\tlearn: 0.4557330\ttotal: 9.78s\tremaining: 52.9s\n",
      "156:\tlearn: 0.4557092\ttotal: 9.83s\tremaining: 52.8s\n",
      "157:\tlearn: 0.4556891\ttotal: 9.89s\tremaining: 52.7s\n",
      "158:\tlearn: 0.4556670\ttotal: 9.96s\tremaining: 52.7s\n",
      "159:\tlearn: 0.4556378\ttotal: 10s\tremaining: 52.7s\n",
      "160:\tlearn: 0.4556196\ttotal: 10.1s\tremaining: 52.7s\n",
      "161:\tlearn: 0.4555935\ttotal: 10.2s\tremaining: 52.6s\n",
      "162:\tlearn: 0.4555708\ttotal: 10.2s\tremaining: 52.5s\n",
      "163:\tlearn: 0.4555531\ttotal: 10.3s\tremaining: 52.5s\n",
      "164:\tlearn: 0.4555313\ttotal: 10.4s\tremaining: 52.5s\n",
      "165:\tlearn: 0.4555056\ttotal: 10.4s\tremaining: 52.4s\n",
      "166:\tlearn: 0.4554876\ttotal: 10.5s\tremaining: 52.3s\n",
      "167:\tlearn: 0.4554674\ttotal: 10.5s\tremaining: 52.2s\n",
      "168:\tlearn: 0.4554500\ttotal: 10.6s\tremaining: 52.2s\n",
      "169:\tlearn: 0.4554307\ttotal: 10.7s\tremaining: 52.1s\n",
      "170:\tlearn: 0.4554061\ttotal: 10.7s\tremaining: 52.1s\n",
      "171:\tlearn: 0.4553911\ttotal: 10.8s\tremaining: 52s\n",
      "172:\tlearn: 0.4553735\ttotal: 10.9s\tremaining: 51.9s\n",
      "173:\tlearn: 0.4553531\ttotal: 10.9s\tremaining: 51.8s\n",
      "174:\tlearn: 0.4553348\ttotal: 11s\tremaining: 51.8s\n",
      "175:\tlearn: 0.4553180\ttotal: 11s\tremaining: 51.7s\n",
      "176:\tlearn: 0.4552994\ttotal: 11.1s\tremaining: 51.6s\n",
      "177:\tlearn: 0.4552716\ttotal: 11.2s\tremaining: 51.5s\n",
      "178:\tlearn: 0.4552542\ttotal: 11.2s\tremaining: 51.5s\n",
      "179:\tlearn: 0.4552368\ttotal: 11.3s\tremaining: 51.4s\n",
      "180:\tlearn: 0.4552209\ttotal: 11.4s\tremaining: 51.4s\n",
      "181:\tlearn: 0.4552044\ttotal: 11.4s\tremaining: 51.3s\n",
      "182:\tlearn: 0.4551885\ttotal: 11.5s\tremaining: 51.2s\n",
      "183:\tlearn: 0.4551729\ttotal: 11.5s\tremaining: 51.1s\n",
      "184:\tlearn: 0.4551536\ttotal: 11.6s\tremaining: 51s\n",
      "185:\tlearn: 0.4551345\ttotal: 11.6s\tremaining: 50.9s\n",
      "186:\tlearn: 0.4551183\ttotal: 11.7s\tremaining: 50.9s\n",
      "187:\tlearn: 0.4551049\ttotal: 11.8s\tremaining: 50.8s\n",
      "188:\tlearn: 0.4550833\ttotal: 11.8s\tremaining: 50.7s\n",
      "189:\tlearn: 0.4550694\ttotal: 11.9s\tremaining: 50.6s\n",
      "190:\tlearn: 0.4550460\ttotal: 11.9s\tremaining: 50.5s\n",
      "191:\tlearn: 0.4550294\ttotal: 12s\tremaining: 50.5s\n",
      "192:\tlearn: 0.4550015\ttotal: 12s\tremaining: 50.4s\n",
      "193:\tlearn: 0.4549867\ttotal: 12.1s\tremaining: 50.3s\n",
      "194:\tlearn: 0.4549722\ttotal: 12.2s\tremaining: 50.3s\n",
      "195:\tlearn: 0.4549504\ttotal: 12.2s\tremaining: 50.2s\n",
      "196:\tlearn: 0.4549307\ttotal: 12.3s\tremaining: 50.1s\n",
      "197:\tlearn: 0.4549115\ttotal: 12.4s\tremaining: 50s\n",
      "198:\tlearn: 0.4548868\ttotal: 12.4s\tremaining: 50s\n",
      "199:\tlearn: 0.4548733\ttotal: 12.5s\tremaining: 49.9s\n",
      "200:\tlearn: 0.4548563\ttotal: 12.5s\tremaining: 49.8s\n",
      "201:\tlearn: 0.4548417\ttotal: 12.6s\tremaining: 49.7s\n",
      "202:\tlearn: 0.4548260\ttotal: 12.6s\tremaining: 49.6s\n",
      "203:\tlearn: 0.4548101\ttotal: 12.7s\tremaining: 49.6s\n",
      "204:\tlearn: 0.4547959\ttotal: 12.8s\tremaining: 49.5s\n",
      "205:\tlearn: 0.4547803\ttotal: 12.8s\tremaining: 49.4s\n",
      "206:\tlearn: 0.4547626\ttotal: 12.9s\tremaining: 49.4s\n",
      "207:\tlearn: 0.4547465\ttotal: 12.9s\tremaining: 49.3s\n",
      "208:\tlearn: 0.4547284\ttotal: 13s\tremaining: 49.2s\n",
      "209:\tlearn: 0.4547137\ttotal: 13.1s\tremaining: 49.1s\n",
      "210:\tlearn: 0.4547000\ttotal: 13.1s\tremaining: 49.1s\n",
      "211:\tlearn: 0.4546831\ttotal: 13.2s\tremaining: 49s\n",
      "212:\tlearn: 0.4546676\ttotal: 13.2s\tremaining: 48.9s\n",
      "213:\tlearn: 0.4546506\ttotal: 13.3s\tremaining: 48.8s\n",
      "214:\tlearn: 0.4546322\ttotal: 13.3s\tremaining: 48.7s\n",
      "215:\tlearn: 0.4546147\ttotal: 13.4s\tremaining: 48.6s\n",
      "216:\tlearn: 0.4545997\ttotal: 13.5s\tremaining: 48.6s\n",
      "217:\tlearn: 0.4545882\ttotal: 13.5s\tremaining: 48.5s\n",
      "218:\tlearn: 0.4545719\ttotal: 13.6s\tremaining: 48.4s\n",
      "219:\tlearn: 0.4545577\ttotal: 13.6s\tremaining: 48.3s\n",
      "220:\tlearn: 0.4545427\ttotal: 13.7s\tremaining: 48.2s\n",
      "221:\tlearn: 0.4545289\ttotal: 13.7s\tremaining: 48.1s\n",
      "222:\tlearn: 0.4545156\ttotal: 13.8s\tremaining: 48s\n",
      "223:\tlearn: 0.4545026\ttotal: 13.8s\tremaining: 48s\n",
      "224:\tlearn: 0.4544887\ttotal: 13.9s\tremaining: 47.9s\n",
      "225:\tlearn: 0.4544733\ttotal: 14s\tremaining: 47.8s\n",
      "226:\tlearn: 0.4544602\ttotal: 14s\tremaining: 47.7s\n",
      "227:\tlearn: 0.4544476\ttotal: 14.1s\tremaining: 47.7s\n",
      "228:\tlearn: 0.4544325\ttotal: 14.1s\tremaining: 47.6s\n",
      "229:\tlearn: 0.4544207\ttotal: 14.2s\tremaining: 47.5s\n",
      "230:\tlearn: 0.4544082\ttotal: 14.3s\tremaining: 47.4s\n",
      "231:\tlearn: 0.4543923\ttotal: 14.3s\tremaining: 47.4s\n",
      "232:\tlearn: 0.4543765\ttotal: 14.4s\tremaining: 47.3s\n",
      "233:\tlearn: 0.4543622\ttotal: 14.4s\tremaining: 47.2s\n",
      "234:\tlearn: 0.4543516\ttotal: 14.5s\tremaining: 47.2s\n",
      "235:\tlearn: 0.4543414\ttotal: 14.5s\tremaining: 47.1s\n",
      "236:\tlearn: 0.4543212\ttotal: 14.6s\tremaining: 47s\n",
      "237:\tlearn: 0.4543100\ttotal: 14.7s\tremaining: 46.9s\n",
      "238:\tlearn: 0.4542980\ttotal: 14.7s\tremaining: 46.9s\n",
      "239:\tlearn: 0.4542859\ttotal: 14.8s\tremaining: 46.8s\n",
      "240:\tlearn: 0.4542740\ttotal: 14.8s\tremaining: 46.8s\n",
      "241:\tlearn: 0.4542604\ttotal: 14.9s\tremaining: 46.7s\n",
      "242:\tlearn: 0.4542459\ttotal: 15s\tremaining: 46.6s\n",
      "243:\tlearn: 0.4542332\ttotal: 15s\tremaining: 46.5s\n",
      "244:\tlearn: 0.4542197\ttotal: 15.1s\tremaining: 46.5s\n",
      "245:\tlearn: 0.4542063\ttotal: 15.1s\tremaining: 46.4s\n",
      "246:\tlearn: 0.4541929\ttotal: 15.2s\tremaining: 46.4s\n",
      "247:\tlearn: 0.4541820\ttotal: 15.3s\tremaining: 46.3s\n",
      "248:\tlearn: 0.4541686\ttotal: 15.3s\tremaining: 46.2s\n",
      "249:\tlearn: 0.4541555\ttotal: 15.4s\tremaining: 46.2s\n",
      "250:\tlearn: 0.4541400\ttotal: 15.5s\tremaining: 46.1s\n",
      "251:\tlearn: 0.4541183\ttotal: 15.5s\tremaining: 46s\n",
      "252:\tlearn: 0.4541060\ttotal: 15.6s\tremaining: 45.9s\n",
      "253:\tlearn: 0.4540917\ttotal: 15.6s\tremaining: 45.9s\n",
      "254:\tlearn: 0.4540794\ttotal: 15.7s\tremaining: 45.8s\n",
      "255:\tlearn: 0.4540669\ttotal: 15.7s\tremaining: 45.7s\n",
      "256:\tlearn: 0.4540492\ttotal: 15.8s\tremaining: 45.7s\n",
      "257:\tlearn: 0.4540366\ttotal: 15.8s\tremaining: 45.6s\n",
      "258:\tlearn: 0.4540268\ttotal: 15.9s\tremaining: 45.5s\n",
      "259:\tlearn: 0.4540124\ttotal: 16s\tremaining: 45.5s\n",
      "260:\tlearn: 0.4540023\ttotal: 16s\tremaining: 45.4s\n",
      "261:\tlearn: 0.4539896\ttotal: 16.1s\tremaining: 45.3s\n",
      "262:\tlearn: 0.4539740\ttotal: 16.2s\tremaining: 45.3s\n",
      "263:\tlearn: 0.4539642\ttotal: 16.2s\tremaining: 45.2s\n",
      "264:\tlearn: 0.4539521\ttotal: 16.3s\tremaining: 45.1s\n",
      "265:\tlearn: 0.4539414\ttotal: 16.3s\tremaining: 45s\n",
      "266:\tlearn: 0.4539311\ttotal: 16.4s\tremaining: 45s\n",
      "267:\tlearn: 0.4539199\ttotal: 16.4s\tremaining: 44.9s\n",
      "268:\tlearn: 0.4539101\ttotal: 16.5s\tremaining: 44.8s\n",
      "269:\tlearn: 0.4538990\ttotal: 16.5s\tremaining: 44.7s\n",
      "270:\tlearn: 0.4538883\ttotal: 16.6s\tremaining: 44.7s\n",
      "271:\tlearn: 0.4538761\ttotal: 16.7s\tremaining: 44.6s\n",
      "272:\tlearn: 0.4538655\ttotal: 16.7s\tremaining: 44.5s\n",
      "273:\tlearn: 0.4538546\ttotal: 16.8s\tremaining: 44.5s\n",
      "274:\tlearn: 0.4538463\ttotal: 16.8s\tremaining: 44.4s\n",
      "275:\tlearn: 0.4538342\ttotal: 16.9s\tremaining: 44.3s\n",
      "276:\tlearn: 0.4538227\ttotal: 16.9s\tremaining: 44.2s\n",
      "277:\tlearn: 0.4538134\ttotal: 17s\tremaining: 44.2s\n",
      "278:\tlearn: 0.4538012\ttotal: 17.1s\tremaining: 44.1s\n",
      "279:\tlearn: 0.4537889\ttotal: 17.1s\tremaining: 44s\n",
      "280:\tlearn: 0.4537794\ttotal: 17.2s\tremaining: 43.9s\n",
      "281:\tlearn: 0.4537665\ttotal: 17.2s\tremaining: 43.9s\n",
      "282:\tlearn: 0.4537544\ttotal: 17.3s\tremaining: 43.8s\n",
      "283:\tlearn: 0.4537442\ttotal: 17.4s\tremaining: 43.8s\n",
      "284:\tlearn: 0.4537332\ttotal: 17.4s\tremaining: 43.7s\n",
      "285:\tlearn: 0.4537204\ttotal: 17.5s\tremaining: 43.6s\n",
      "286:\tlearn: 0.4537077\ttotal: 17.5s\tremaining: 43.6s\n",
      "287:\tlearn: 0.4536994\ttotal: 17.6s\tremaining: 43.5s\n",
      "288:\tlearn: 0.4536877\ttotal: 17.7s\tremaining: 43.4s\n",
      "289:\tlearn: 0.4536753\ttotal: 17.7s\tremaining: 43.4s\n",
      "290:\tlearn: 0.4536649\ttotal: 17.8s\tremaining: 43.3s\n",
      "291:\tlearn: 0.4536532\ttotal: 17.8s\tremaining: 43.2s\n",
      "292:\tlearn: 0.4536406\ttotal: 17.9s\tremaining: 43.2s\n",
      "293:\tlearn: 0.4536303\ttotal: 17.9s\tremaining: 43.1s\n",
      "294:\tlearn: 0.4536205\ttotal: 18s\tremaining: 43s\n",
      "295:\tlearn: 0.4536065\ttotal: 18.1s\tremaining: 43s\n",
      "296:\tlearn: 0.4535981\ttotal: 18.1s\tremaining: 42.9s\n",
      "297:\tlearn: 0.4535869\ttotal: 18.2s\tremaining: 42.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298:\tlearn: 0.4535727\ttotal: 18.2s\tremaining: 42.7s\n",
      "299:\tlearn: 0.4535613\ttotal: 18.3s\tremaining: 42.7s\n",
      "300:\tlearn: 0.4535504\ttotal: 18.4s\tremaining: 42.6s\n",
      "301:\tlearn: 0.4535314\ttotal: 18.4s\tremaining: 42.6s\n",
      "302:\tlearn: 0.4535243\ttotal: 18.5s\tremaining: 42.5s\n",
      "303:\tlearn: 0.4535120\ttotal: 18.5s\tremaining: 42.5s\n",
      "304:\tlearn: 0.4535021\ttotal: 18.6s\tremaining: 42.4s\n",
      "305:\tlearn: 0.4534928\ttotal: 18.7s\tremaining: 42.3s\n",
      "306:\tlearn: 0.4534813\ttotal: 18.7s\tremaining: 42.3s\n",
      "307:\tlearn: 0.4534705\ttotal: 18.8s\tremaining: 42.2s\n",
      "308:\tlearn: 0.4534607\ttotal: 18.8s\tremaining: 42.1s\n",
      "309:\tlearn: 0.4534496\ttotal: 18.9s\tremaining: 42.1s\n",
      "310:\tlearn: 0.4534379\ttotal: 19s\tremaining: 42s\n",
      "311:\tlearn: 0.4534255\ttotal: 19s\tremaining: 42s\n",
      "312:\tlearn: 0.4534161\ttotal: 19.1s\tremaining: 41.9s\n",
      "313:\tlearn: 0.4534072\ttotal: 19.1s\tremaining: 41.8s\n",
      "314:\tlearn: 0.4533957\ttotal: 19.2s\tremaining: 41.8s\n",
      "315:\tlearn: 0.4533835\ttotal: 19.3s\tremaining: 41.7s\n",
      "316:\tlearn: 0.4533754\ttotal: 19.3s\tremaining: 41.6s\n",
      "317:\tlearn: 0.4533645\ttotal: 19.4s\tremaining: 41.5s\n",
      "318:\tlearn: 0.4533547\ttotal: 19.4s\tremaining: 41.5s\n",
      "319:\tlearn: 0.4533363\ttotal: 19.5s\tremaining: 41.4s\n",
      "320:\tlearn: 0.4533280\ttotal: 19.5s\tremaining: 41.3s\n",
      "321:\tlearn: 0.4533191\ttotal: 19.6s\tremaining: 41.3s\n",
      "322:\tlearn: 0.4533094\ttotal: 19.7s\tremaining: 41.2s\n",
      "323:\tlearn: 0.4532955\ttotal: 19.7s\tremaining: 41.1s\n",
      "324:\tlearn: 0.4532866\ttotal: 19.8s\tremaining: 41.1s\n",
      "325:\tlearn: 0.4532798\ttotal: 19.8s\tremaining: 41s\n",
      "326:\tlearn: 0.4532714\ttotal: 19.9s\tremaining: 40.9s\n",
      "327:\tlearn: 0.4532624\ttotal: 20s\tremaining: 40.9s\n",
      "328:\tlearn: 0.4532553\ttotal: 20s\tremaining: 40.9s\n",
      "329:\tlearn: 0.4532447\ttotal: 20.1s\tremaining: 40.8s\n",
      "330:\tlearn: 0.4532356\ttotal: 20.2s\tremaining: 40.7s\n",
      "331:\tlearn: 0.4532236\ttotal: 20.2s\tremaining: 40.7s\n",
      "332:\tlearn: 0.4532141\ttotal: 20.3s\tremaining: 40.6s\n",
      "333:\tlearn: 0.4532032\ttotal: 20.3s\tremaining: 40.6s\n",
      "334:\tlearn: 0.4531938\ttotal: 20.4s\tremaining: 40.5s\n",
      "335:\tlearn: 0.4531825\ttotal: 20.5s\tremaining: 40.4s\n",
      "336:\tlearn: 0.4531731\ttotal: 20.5s\tremaining: 40.4s\n",
      "337:\tlearn: 0.4531606\ttotal: 20.6s\tremaining: 40.3s\n",
      "338:\tlearn: 0.4531509\ttotal: 20.7s\tremaining: 40.3s\n",
      "339:\tlearn: 0.4531420\ttotal: 20.7s\tremaining: 40.2s\n",
      "340:\tlearn: 0.4531263\ttotal: 20.8s\tremaining: 40.1s\n",
      "341:\tlearn: 0.4531181\ttotal: 20.8s\tremaining: 40.1s\n",
      "342:\tlearn: 0.4531095\ttotal: 20.9s\tremaining: 40s\n",
      "343:\tlearn: 0.4531009\ttotal: 21s\tremaining: 40s\n",
      "344:\tlearn: 0.4530936\ttotal: 21s\tremaining: 39.9s\n",
      "345:\tlearn: 0.4530878\ttotal: 21.1s\tremaining: 39.8s\n",
      "346:\tlearn: 0.4530757\ttotal: 21.1s\tremaining: 39.8s\n",
      "347:\tlearn: 0.4530650\ttotal: 21.2s\tremaining: 39.7s\n",
      "348:\tlearn: 0.4530555\ttotal: 21.2s\tremaining: 39.6s\n",
      "349:\tlearn: 0.4530460\ttotal: 21.3s\tremaining: 39.6s\n",
      "350:\tlearn: 0.4530351\ttotal: 21.4s\tremaining: 39.5s\n",
      "351:\tlearn: 0.4530263\ttotal: 21.4s\tremaining: 39.4s\n",
      "352:\tlearn: 0.4530159\ttotal: 21.5s\tremaining: 39.4s\n",
      "353:\tlearn: 0.4530054\ttotal: 21.5s\tremaining: 39.3s\n",
      "354:\tlearn: 0.4529957\ttotal: 21.6s\tremaining: 39.3s\n",
      "355:\tlearn: 0.4529875\ttotal: 21.7s\tremaining: 39.2s\n",
      "356:\tlearn: 0.4529795\ttotal: 21.7s\tremaining: 39.1s\n",
      "357:\tlearn: 0.4529704\ttotal: 21.8s\tremaining: 39.1s\n",
      "358:\tlearn: 0.4529625\ttotal: 21.9s\tremaining: 39s\n",
      "359:\tlearn: 0.4529536\ttotal: 21.9s\tremaining: 39s\n",
      "360:\tlearn: 0.4529464\ttotal: 22s\tremaining: 38.9s\n",
      "361:\tlearn: 0.4529354\ttotal: 22s\tremaining: 38.8s\n",
      "362:\tlearn: 0.4529251\ttotal: 22.1s\tremaining: 38.8s\n",
      "363:\tlearn: 0.4529162\ttotal: 22.2s\tremaining: 38.7s\n",
      "364:\tlearn: 0.4529062\ttotal: 22.2s\tremaining: 38.6s\n",
      "365:\tlearn: 0.4528982\ttotal: 22.3s\tremaining: 38.6s\n",
      "366:\tlearn: 0.4528879\ttotal: 22.3s\tremaining: 38.5s\n",
      "367:\tlearn: 0.4528793\ttotal: 22.4s\tremaining: 38.4s\n",
      "368:\tlearn: 0.4528702\ttotal: 22.4s\tremaining: 38.4s\n",
      "369:\tlearn: 0.4528621\ttotal: 22.5s\tremaining: 38.3s\n",
      "370:\tlearn: 0.4528548\ttotal: 22.6s\tremaining: 38.2s\n",
      "371:\tlearn: 0.4528463\ttotal: 22.6s\tremaining: 38.2s\n",
      "372:\tlearn: 0.4528360\ttotal: 22.7s\tremaining: 38.1s\n",
      "373:\tlearn: 0.4528273\ttotal: 22.7s\tremaining: 38s\n",
      "374:\tlearn: 0.4528191\ttotal: 22.8s\tremaining: 38s\n",
      "375:\tlearn: 0.4528101\ttotal: 22.8s\tremaining: 37.9s\n",
      "376:\tlearn: 0.4527959\ttotal: 22.9s\tremaining: 37.9s\n",
      "377:\tlearn: 0.4527864\ttotal: 23s\tremaining: 37.8s\n",
      "378:\tlearn: 0.4527785\ttotal: 23s\tremaining: 37.7s\n",
      "379:\tlearn: 0.4527697\ttotal: 23.1s\tremaining: 37.7s\n",
      "380:\tlearn: 0.4527616\ttotal: 23.1s\tremaining: 37.6s\n",
      "381:\tlearn: 0.4527526\ttotal: 23.2s\tremaining: 37.5s\n",
      "382:\tlearn: 0.4527420\ttotal: 23.3s\tremaining: 37.5s\n",
      "383:\tlearn: 0.4527347\ttotal: 23.3s\tremaining: 37.4s\n",
      "384:\tlearn: 0.4527220\ttotal: 23.4s\tremaining: 37.3s\n",
      "385:\tlearn: 0.4527140\ttotal: 23.4s\tremaining: 37.3s\n",
      "386:\tlearn: 0.4527004\ttotal: 23.5s\tremaining: 37.2s\n",
      "387:\tlearn: 0.4526897\ttotal: 23.5s\tremaining: 37.1s\n",
      "388:\tlearn: 0.4526804\ttotal: 23.6s\tremaining: 37.1s\n",
      "389:\tlearn: 0.4526708\ttotal: 23.7s\tremaining: 37s\n",
      "390:\tlearn: 0.4526641\ttotal: 23.7s\tremaining: 37s\n",
      "391:\tlearn: 0.4526542\ttotal: 23.8s\tremaining: 36.9s\n",
      "392:\tlearn: 0.4526429\ttotal: 23.9s\tremaining: 36.8s\n",
      "393:\tlearn: 0.4526331\ttotal: 23.9s\tremaining: 36.8s\n",
      "394:\tlearn: 0.4526240\ttotal: 24s\tremaining: 36.7s\n",
      "395:\tlearn: 0.4526166\ttotal: 24s\tremaining: 36.7s\n",
      "396:\tlearn: 0.4526078\ttotal: 24.1s\tremaining: 36.6s\n",
      "397:\tlearn: 0.4525973\ttotal: 24.2s\tremaining: 36.6s\n",
      "398:\tlearn: 0.4525873\ttotal: 24.2s\tremaining: 36.5s\n",
      "399:\tlearn: 0.4525788\ttotal: 24.3s\tremaining: 36.5s\n",
      "400:\tlearn: 0.4525712\ttotal: 24.4s\tremaining: 36.4s\n",
      "401:\tlearn: 0.4525606\ttotal: 24.4s\tremaining: 36.3s\n",
      "402:\tlearn: 0.4525524\ttotal: 24.5s\tremaining: 36.3s\n",
      "403:\tlearn: 0.4525442\ttotal: 24.5s\tremaining: 36.2s\n",
      "404:\tlearn: 0.4525371\ttotal: 24.6s\tremaining: 36.1s\n",
      "405:\tlearn: 0.4525264\ttotal: 24.7s\tremaining: 36.1s\n",
      "406:\tlearn: 0.4525203\ttotal: 24.7s\tremaining: 36s\n",
      "407:\tlearn: 0.4525116\ttotal: 24.8s\tremaining: 35.9s\n",
      "408:\tlearn: 0.4525001\ttotal: 24.8s\tremaining: 35.9s\n",
      "409:\tlearn: 0.4524912\ttotal: 24.9s\tremaining: 35.8s\n",
      "410:\tlearn: 0.4524803\ttotal: 24.9s\tremaining: 35.7s\n",
      "411:\tlearn: 0.4524700\ttotal: 25s\tremaining: 35.7s\n",
      "412:\tlearn: 0.4524614\ttotal: 25.1s\tremaining: 35.6s\n",
      "413:\tlearn: 0.4524538\ttotal: 25.1s\tremaining: 35.6s\n",
      "414:\tlearn: 0.4524437\ttotal: 25.2s\tremaining: 35.5s\n",
      "415:\tlearn: 0.4524367\ttotal: 25.2s\tremaining: 35.4s\n",
      "416:\tlearn: 0.4524291\ttotal: 25.3s\tremaining: 35.4s\n",
      "417:\tlearn: 0.4524170\ttotal: 25.4s\tremaining: 35.3s\n",
      "418:\tlearn: 0.4524099\ttotal: 25.4s\tremaining: 35.2s\n",
      "419:\tlearn: 0.4524005\ttotal: 25.5s\tremaining: 35.2s\n",
      "420:\tlearn: 0.4523865\ttotal: 25.5s\tremaining: 35.1s\n",
      "421:\tlearn: 0.4523769\ttotal: 25.6s\tremaining: 35s\n",
      "422:\tlearn: 0.4523697\ttotal: 25.6s\tremaining: 35s\n",
      "423:\tlearn: 0.4523577\ttotal: 25.7s\tremaining: 34.9s\n",
      "424:\tlearn: 0.4523478\ttotal: 25.8s\tremaining: 34.8s\n",
      "425:\tlearn: 0.4523391\ttotal: 25.8s\tremaining: 34.8s\n",
      "426:\tlearn: 0.4523319\ttotal: 25.9s\tremaining: 34.7s\n",
      "427:\tlearn: 0.4523222\ttotal: 25.9s\tremaining: 34.7s\n",
      "428:\tlearn: 0.4523115\ttotal: 26s\tremaining: 34.6s\n",
      "429:\tlearn: 0.4523037\ttotal: 26.1s\tremaining: 34.5s\n",
      "430:\tlearn: 0.4522971\ttotal: 26.1s\tremaining: 34.5s\n",
      "431:\tlearn: 0.4522856\ttotal: 26.2s\tremaining: 34.4s\n",
      "432:\tlearn: 0.4522697\ttotal: 26.2s\tremaining: 34.3s\n",
      "433:\tlearn: 0.4522610\ttotal: 26.3s\tremaining: 34.3s\n",
      "434:\tlearn: 0.4522513\ttotal: 26.3s\tremaining: 34.2s\n",
      "435:\tlearn: 0.4522423\ttotal: 26.4s\tremaining: 34.2s\n",
      "436:\tlearn: 0.4522285\ttotal: 26.5s\tremaining: 34.1s\n",
      "437:\tlearn: 0.4522148\ttotal: 26.5s\tremaining: 34s\n",
      "438:\tlearn: 0.4522026\ttotal: 26.6s\tremaining: 34s\n",
      "439:\tlearn: 0.4521945\ttotal: 26.6s\tremaining: 33.9s\n",
      "440:\tlearn: 0.4521849\ttotal: 26.7s\tremaining: 33.8s\n",
      "441:\tlearn: 0.4521765\ttotal: 26.8s\tremaining: 33.8s\n",
      "442:\tlearn: 0.4521668\ttotal: 26.8s\tremaining: 33.7s\n",
      "443:\tlearn: 0.4521545\ttotal: 26.9s\tremaining: 33.7s\n",
      "444:\tlearn: 0.4521444\ttotal: 26.9s\tremaining: 33.6s\n",
      "445:\tlearn: 0.4521340\ttotal: 27s\tremaining: 33.6s\n",
      "446:\tlearn: 0.4521270\ttotal: 27.1s\tremaining: 33.5s\n",
      "447:\tlearn: 0.4521181\ttotal: 27.1s\tremaining: 33.4s\n",
      "448:\tlearn: 0.4521097\ttotal: 27.2s\tremaining: 33.4s\n",
      "449:\tlearn: 0.4520970\ttotal: 27.3s\tremaining: 33.3s\n",
      "450:\tlearn: 0.4520854\ttotal: 27.3s\tremaining: 33.3s\n",
      "451:\tlearn: 0.4520758\ttotal: 27.4s\tremaining: 33.2s\n",
      "452:\tlearn: 0.4520674\ttotal: 27.4s\tremaining: 33.1s\n",
      "453:\tlearn: 0.4520581\ttotal: 27.5s\tremaining: 33.1s\n",
      "454:\tlearn: 0.4520480\ttotal: 27.6s\tremaining: 33s\n",
      "455:\tlearn: 0.4520373\ttotal: 27.6s\tremaining: 33s\n",
      "456:\tlearn: 0.4520257\ttotal: 27.7s\tremaining: 32.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457:\tlearn: 0.4520178\ttotal: 27.7s\tremaining: 32.8s\n",
      "458:\tlearn: 0.4520083\ttotal: 27.8s\tremaining: 32.8s\n",
      "459:\tlearn: 0.4520001\ttotal: 27.9s\tremaining: 32.7s\n",
      "460:\tlearn: 0.4519936\ttotal: 27.9s\tremaining: 32.7s\n",
      "461:\tlearn: 0.4519836\ttotal: 28s\tremaining: 32.6s\n",
      "462:\tlearn: 0.4519730\ttotal: 28.1s\tremaining: 32.6s\n",
      "463:\tlearn: 0.4519635\ttotal: 28.1s\tremaining: 32.5s\n",
      "464:\tlearn: 0.4519536\ttotal: 28.2s\tremaining: 32.4s\n",
      "465:\tlearn: 0.4519418\ttotal: 28.2s\tremaining: 32.4s\n",
      "466:\tlearn: 0.4519336\ttotal: 28.3s\tremaining: 32.3s\n",
      "467:\tlearn: 0.4519239\ttotal: 28.4s\tremaining: 32.2s\n",
      "468:\tlearn: 0.4519157\ttotal: 28.4s\tremaining: 32.2s\n",
      "469:\tlearn: 0.4519056\ttotal: 28.5s\tremaining: 32.1s\n",
      "470:\tlearn: 0.4518979\ttotal: 28.5s\tremaining: 32s\n",
      "471:\tlearn: 0.4518906\ttotal: 28.6s\tremaining: 32s\n",
      "472:\tlearn: 0.4518810\ttotal: 28.7s\tremaining: 31.9s\n",
      "473:\tlearn: 0.4518707\ttotal: 28.7s\tremaining: 31.9s\n",
      "474:\tlearn: 0.4518560\ttotal: 28.8s\tremaining: 31.8s\n",
      "475:\tlearn: 0.4518494\ttotal: 28.8s\tremaining: 31.8s\n",
      "476:\tlearn: 0.4518417\ttotal: 28.9s\tremaining: 31.7s\n",
      "477:\tlearn: 0.4518317\ttotal: 29s\tremaining: 31.6s\n",
      "478:\tlearn: 0.4518213\ttotal: 29s\tremaining: 31.6s\n",
      "479:\tlearn: 0.4518083\ttotal: 29.1s\tremaining: 31.5s\n",
      "480:\tlearn: 0.4517998\ttotal: 29.1s\tremaining: 31.4s\n",
      "481:\tlearn: 0.4517908\ttotal: 29.2s\tremaining: 31.4s\n",
      "482:\tlearn: 0.4517844\ttotal: 29.3s\tremaining: 31.3s\n",
      "483:\tlearn: 0.4517748\ttotal: 29.3s\tremaining: 31.3s\n",
      "484:\tlearn: 0.4517660\ttotal: 29.4s\tremaining: 31.2s\n",
      "485:\tlearn: 0.4517573\ttotal: 29.4s\tremaining: 31.1s\n",
      "486:\tlearn: 0.4517498\ttotal: 29.5s\tremaining: 31.1s\n",
      "487:\tlearn: 0.4517397\ttotal: 29.6s\tremaining: 31s\n",
      "488:\tlearn: 0.4517308\ttotal: 29.6s\tremaining: 30.9s\n",
      "489:\tlearn: 0.4517207\ttotal: 29.7s\tremaining: 30.9s\n",
      "490:\tlearn: 0.4517139\ttotal: 29.7s\tremaining: 30.8s\n",
      "491:\tlearn: 0.4517057\ttotal: 29.8s\tremaining: 30.8s\n",
      "492:\tlearn: 0.4516938\ttotal: 29.8s\tremaining: 30.7s\n",
      "493:\tlearn: 0.4516825\ttotal: 29.9s\tremaining: 30.6s\n",
      "494:\tlearn: 0.4516747\ttotal: 30s\tremaining: 30.6s\n",
      "495:\tlearn: 0.4516654\ttotal: 30s\tremaining: 30.5s\n",
      "496:\tlearn: 0.4516565\ttotal: 30.1s\tremaining: 30.5s\n",
      "497:\tlearn: 0.4516472\ttotal: 30.2s\tremaining: 30.4s\n",
      "498:\tlearn: 0.4516366\ttotal: 30.2s\tremaining: 30.3s\n",
      "499:\tlearn: 0.4516297\ttotal: 30.3s\tremaining: 30.3s\n",
      "500:\tlearn: 0.4516197\ttotal: 30.3s\tremaining: 30.2s\n",
      "501:\tlearn: 0.4516109\ttotal: 30.4s\tremaining: 30.2s\n",
      "502:\tlearn: 0.4516033\ttotal: 30.5s\tremaining: 30.1s\n",
      "503:\tlearn: 0.4515926\ttotal: 30.5s\tremaining: 30s\n",
      "504:\tlearn: 0.4515847\ttotal: 30.6s\tremaining: 30s\n",
      "505:\tlearn: 0.4515783\ttotal: 30.6s\tremaining: 29.9s\n",
      "506:\tlearn: 0.4515684\ttotal: 30.7s\tremaining: 29.9s\n",
      "507:\tlearn: 0.4515587\ttotal: 30.8s\tremaining: 29.8s\n",
      "508:\tlearn: 0.4515499\ttotal: 30.8s\tremaining: 29.7s\n",
      "509:\tlearn: 0.4515399\ttotal: 30.9s\tremaining: 29.7s\n",
      "510:\tlearn: 0.4515313\ttotal: 30.9s\tremaining: 29.6s\n",
      "511:\tlearn: 0.4515239\ttotal: 31s\tremaining: 29.5s\n",
      "512:\tlearn: 0.4515161\ttotal: 31.1s\tremaining: 29.5s\n",
      "513:\tlearn: 0.4515091\ttotal: 31.1s\tremaining: 29.4s\n",
      "514:\tlearn: 0.4515018\ttotal: 31.2s\tremaining: 29.4s\n",
      "515:\tlearn: 0.4514928\ttotal: 31.3s\tremaining: 29.3s\n",
      "516:\tlearn: 0.4514830\ttotal: 31.3s\tremaining: 29.3s\n",
      "517:\tlearn: 0.4514740\ttotal: 31.4s\tremaining: 29.2s\n",
      "518:\tlearn: 0.4514635\ttotal: 31.4s\tremaining: 29.1s\n",
      "519:\tlearn: 0.4514502\ttotal: 31.5s\tremaining: 29.1s\n",
      "520:\tlearn: 0.4514421\ttotal: 31.6s\tremaining: 29s\n",
      "521:\tlearn: 0.4514337\ttotal: 31.6s\tremaining: 29s\n",
      "522:\tlearn: 0.4514248\ttotal: 31.7s\tremaining: 28.9s\n",
      "523:\tlearn: 0.4514158\ttotal: 31.7s\tremaining: 28.8s\n",
      "524:\tlearn: 0.4514080\ttotal: 31.8s\tremaining: 28.8s\n",
      "525:\tlearn: 0.4513953\ttotal: 31.9s\tremaining: 28.7s\n",
      "526:\tlearn: 0.4513870\ttotal: 31.9s\tremaining: 28.7s\n",
      "527:\tlearn: 0.4513776\ttotal: 32s\tremaining: 28.6s\n",
      "528:\tlearn: 0.4513694\ttotal: 32.1s\tremaining: 28.5s\n",
      "529:\tlearn: 0.4513611\ttotal: 32.1s\tremaining: 28.5s\n",
      "530:\tlearn: 0.4513536\ttotal: 32.2s\tremaining: 28.4s\n",
      "531:\tlearn: 0.4513460\ttotal: 32.3s\tremaining: 28.4s\n",
      "532:\tlearn: 0.4513378\ttotal: 32.3s\tremaining: 28.3s\n",
      "533:\tlearn: 0.4513315\ttotal: 32.4s\tremaining: 28.2s\n",
      "534:\tlearn: 0.4513221\ttotal: 32.4s\tremaining: 28.2s\n",
      "535:\tlearn: 0.4513156\ttotal: 32.5s\tremaining: 28.1s\n",
      "536:\tlearn: 0.4513053\ttotal: 32.5s\tremaining: 28s\n",
      "537:\tlearn: 0.4512959\ttotal: 32.6s\tremaining: 28s\n",
      "538:\tlearn: 0.4512877\ttotal: 32.6s\tremaining: 27.9s\n",
      "539:\tlearn: 0.4512788\ttotal: 32.7s\tremaining: 27.9s\n",
      "540:\tlearn: 0.4512714\ttotal: 32.8s\tremaining: 27.8s\n",
      "541:\tlearn: 0.4512637\ttotal: 32.8s\tremaining: 27.7s\n",
      "542:\tlearn: 0.4512556\ttotal: 32.9s\tremaining: 27.7s\n",
      "543:\tlearn: 0.4512460\ttotal: 32.9s\tremaining: 27.6s\n",
      "544:\tlearn: 0.4512366\ttotal: 33s\tremaining: 27.5s\n",
      "545:\tlearn: 0.4512306\ttotal: 33.1s\tremaining: 27.5s\n",
      "546:\tlearn: 0.4512234\ttotal: 33.1s\tremaining: 27.4s\n",
      "547:\tlearn: 0.4512128\ttotal: 33.2s\tremaining: 27.4s\n",
      "548:\tlearn: 0.4512067\ttotal: 33.2s\tremaining: 27.3s\n",
      "549:\tlearn: 0.4511929\ttotal: 33.3s\tremaining: 27.3s\n",
      "550:\tlearn: 0.4511846\ttotal: 33.4s\tremaining: 27.2s\n",
      "551:\tlearn: 0.4511758\ttotal: 33.4s\tremaining: 27.1s\n",
      "552:\tlearn: 0.4511686\ttotal: 33.5s\tremaining: 27.1s\n",
      "553:\tlearn: 0.4511603\ttotal: 33.5s\tremaining: 27s\n",
      "554:\tlearn: 0.4511531\ttotal: 33.6s\tremaining: 26.9s\n",
      "555:\tlearn: 0.4511450\ttotal: 33.7s\tremaining: 26.9s\n",
      "556:\tlearn: 0.4511371\ttotal: 33.7s\tremaining: 26.8s\n",
      "557:\tlearn: 0.4511291\ttotal: 33.8s\tremaining: 26.8s\n",
      "558:\tlearn: 0.4511217\ttotal: 33.8s\tremaining: 26.7s\n",
      "559:\tlearn: 0.4511109\ttotal: 33.9s\tremaining: 26.6s\n",
      "560:\tlearn: 0.4511008\ttotal: 34s\tremaining: 26.6s\n",
      "561:\tlearn: 0.4510908\ttotal: 34s\tremaining: 26.5s\n",
      "562:\tlearn: 0.4510806\ttotal: 34.1s\tremaining: 26.5s\n",
      "563:\tlearn: 0.4510712\ttotal: 34.2s\tremaining: 26.4s\n",
      "564:\tlearn: 0.4510637\ttotal: 34.2s\tremaining: 26.3s\n",
      "565:\tlearn: 0.4510556\ttotal: 34.3s\tremaining: 26.3s\n",
      "566:\tlearn: 0.4510472\ttotal: 34.4s\tremaining: 26.2s\n",
      "567:\tlearn: 0.4510392\ttotal: 34.4s\tremaining: 26.2s\n",
      "568:\tlearn: 0.4510322\ttotal: 34.5s\tremaining: 26.1s\n",
      "569:\tlearn: 0.4510243\ttotal: 34.6s\tremaining: 26.1s\n",
      "570:\tlearn: 0.4510161\ttotal: 34.6s\tremaining: 26s\n",
      "571:\tlearn: 0.4510076\ttotal: 34.7s\tremaining: 26s\n",
      "572:\tlearn: 0.4509993\ttotal: 34.7s\tremaining: 25.9s\n",
      "573:\tlearn: 0.4509868\ttotal: 34.8s\tremaining: 25.8s\n",
      "574:\tlearn: 0.4509794\ttotal: 34.9s\tremaining: 25.8s\n",
      "575:\tlearn: 0.4509721\ttotal: 34.9s\tremaining: 25.7s\n",
      "576:\tlearn: 0.4509626\ttotal: 35s\tremaining: 25.6s\n",
      "577:\tlearn: 0.4509546\ttotal: 35s\tremaining: 25.6s\n",
      "578:\tlearn: 0.4509458\ttotal: 35.1s\tremaining: 25.5s\n",
      "579:\tlearn: 0.4509362\ttotal: 35.2s\tremaining: 25.5s\n",
      "580:\tlearn: 0.4509272\ttotal: 35.2s\tremaining: 25.4s\n",
      "581:\tlearn: 0.4509175\ttotal: 35.3s\tremaining: 25.3s\n",
      "582:\tlearn: 0.4509099\ttotal: 35.4s\tremaining: 25.3s\n",
      "583:\tlearn: 0.4509017\ttotal: 35.4s\tremaining: 25.2s\n",
      "584:\tlearn: 0.4508939\ttotal: 35.5s\tremaining: 25.2s\n",
      "585:\tlearn: 0.4508844\ttotal: 35.6s\tremaining: 25.1s\n",
      "586:\tlearn: 0.4508741\ttotal: 35.6s\tremaining: 25.1s\n",
      "587:\tlearn: 0.4508668\ttotal: 35.7s\tremaining: 25s\n",
      "588:\tlearn: 0.4508582\ttotal: 35.7s\tremaining: 24.9s\n",
      "589:\tlearn: 0.4508517\ttotal: 35.8s\tremaining: 24.9s\n",
      "590:\tlearn: 0.4508428\ttotal: 35.9s\tremaining: 24.8s\n",
      "591:\tlearn: 0.4508350\ttotal: 35.9s\tremaining: 24.8s\n",
      "592:\tlearn: 0.4508276\ttotal: 36s\tremaining: 24.7s\n",
      "593:\tlearn: 0.4508171\ttotal: 36.1s\tremaining: 24.6s\n",
      "594:\tlearn: 0.4508092\ttotal: 36.1s\tremaining: 24.6s\n",
      "595:\tlearn: 0.4508020\ttotal: 36.2s\tremaining: 24.5s\n",
      "596:\tlearn: 0.4507952\ttotal: 36.2s\tremaining: 24.5s\n",
      "597:\tlearn: 0.4507866\ttotal: 36.3s\tremaining: 24.4s\n",
      "598:\tlearn: 0.4507756\ttotal: 36.4s\tremaining: 24.3s\n",
      "599:\tlearn: 0.4507686\ttotal: 36.4s\tremaining: 24.3s\n",
      "600:\tlearn: 0.4507613\ttotal: 36.5s\tremaining: 24.2s\n",
      "601:\tlearn: 0.4507522\ttotal: 36.5s\tremaining: 24.2s\n",
      "602:\tlearn: 0.4507435\ttotal: 36.6s\tremaining: 24.1s\n",
      "603:\tlearn: 0.4507343\ttotal: 36.7s\tremaining: 24s\n",
      "604:\tlearn: 0.4507253\ttotal: 36.7s\tremaining: 24s\n",
      "605:\tlearn: 0.4507196\ttotal: 36.8s\tremaining: 23.9s\n",
      "606:\tlearn: 0.4507127\ttotal: 36.9s\tremaining: 23.9s\n",
      "607:\tlearn: 0.4507046\ttotal: 36.9s\tremaining: 23.8s\n",
      "608:\tlearn: 0.4506974\ttotal: 37s\tremaining: 23.8s\n",
      "609:\tlearn: 0.4506881\ttotal: 37.1s\tremaining: 23.7s\n",
      "610:\tlearn: 0.4506808\ttotal: 37.1s\tremaining: 23.6s\n",
      "611:\tlearn: 0.4506746\ttotal: 37.2s\tremaining: 23.6s\n",
      "612:\tlearn: 0.4506662\ttotal: 37.3s\tremaining: 23.5s\n",
      "613:\tlearn: 0.4506574\ttotal: 37.3s\tremaining: 23.5s\n",
      "614:\tlearn: 0.4506488\ttotal: 37.4s\tremaining: 23.4s\n",
      "615:\tlearn: 0.4506393\ttotal: 37.4s\tremaining: 23.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616:\tlearn: 0.4506303\ttotal: 37.5s\tremaining: 23.3s\n",
      "617:\tlearn: 0.4506220\ttotal: 37.6s\tremaining: 23.2s\n",
      "618:\tlearn: 0.4506148\ttotal: 37.6s\tremaining: 23.2s\n",
      "619:\tlearn: 0.4506070\ttotal: 37.7s\tremaining: 23.1s\n",
      "620:\tlearn: 0.4505970\ttotal: 37.8s\tremaining: 23s\n",
      "621:\tlearn: 0.4505871\ttotal: 37.8s\tremaining: 23s\n",
      "622:\tlearn: 0.4505772\ttotal: 37.9s\tremaining: 22.9s\n",
      "623:\tlearn: 0.4505691\ttotal: 37.9s\tremaining: 22.9s\n",
      "624:\tlearn: 0.4505619\ttotal: 38s\tremaining: 22.8s\n",
      "625:\tlearn: 0.4505523\ttotal: 38.1s\tremaining: 22.7s\n",
      "626:\tlearn: 0.4505434\ttotal: 38.1s\tremaining: 22.7s\n",
      "627:\tlearn: 0.4505377\ttotal: 38.2s\tremaining: 22.6s\n",
      "628:\tlearn: 0.4505315\ttotal: 38.2s\tremaining: 22.6s\n",
      "629:\tlearn: 0.4505231\ttotal: 38.3s\tremaining: 22.5s\n",
      "630:\tlearn: 0.4505159\ttotal: 38.4s\tremaining: 22.4s\n",
      "631:\tlearn: 0.4505056\ttotal: 38.4s\tremaining: 22.4s\n",
      "632:\tlearn: 0.4504947\ttotal: 38.5s\tremaining: 22.3s\n",
      "633:\tlearn: 0.4504884\ttotal: 38.5s\tremaining: 22.2s\n",
      "634:\tlearn: 0.4504793\ttotal: 38.6s\tremaining: 22.2s\n",
      "635:\tlearn: 0.4504708\ttotal: 38.7s\tremaining: 22.1s\n",
      "636:\tlearn: 0.4504625\ttotal: 38.7s\tremaining: 22.1s\n",
      "637:\tlearn: 0.4504548\ttotal: 38.8s\tremaining: 22s\n",
      "638:\tlearn: 0.4504451\ttotal: 38.8s\tremaining: 21.9s\n",
      "639:\tlearn: 0.4504353\ttotal: 38.9s\tremaining: 21.9s\n",
      "640:\tlearn: 0.4504277\ttotal: 39s\tremaining: 21.8s\n",
      "641:\tlearn: 0.4504188\ttotal: 39s\tremaining: 21.8s\n",
      "642:\tlearn: 0.4504109\ttotal: 39.1s\tremaining: 21.7s\n",
      "643:\tlearn: 0.4504007\ttotal: 39.1s\tremaining: 21.6s\n",
      "644:\tlearn: 0.4503913\ttotal: 39.2s\tremaining: 21.6s\n",
      "645:\tlearn: 0.4503834\ttotal: 39.3s\tremaining: 21.5s\n",
      "646:\tlearn: 0.4503736\ttotal: 39.3s\tremaining: 21.5s\n",
      "647:\tlearn: 0.4503674\ttotal: 39.4s\tremaining: 21.4s\n",
      "648:\tlearn: 0.4503587\ttotal: 39.5s\tremaining: 21.3s\n",
      "649:\tlearn: 0.4503505\ttotal: 39.5s\tremaining: 21.3s\n",
      "650:\tlearn: 0.4503420\ttotal: 39.6s\tremaining: 21.2s\n",
      "651:\tlearn: 0.4503320\ttotal: 39.6s\tremaining: 21.2s\n",
      "652:\tlearn: 0.4503244\ttotal: 39.7s\tremaining: 21.1s\n",
      "653:\tlearn: 0.4503159\ttotal: 39.8s\tremaining: 21s\n",
      "654:\tlearn: 0.4503076\ttotal: 39.8s\tremaining: 21s\n",
      "655:\tlearn: 0.4503012\ttotal: 39.9s\tremaining: 20.9s\n",
      "656:\tlearn: 0.4502928\ttotal: 39.9s\tremaining: 20.8s\n",
      "657:\tlearn: 0.4502847\ttotal: 40s\tremaining: 20.8s\n",
      "658:\tlearn: 0.4502748\ttotal: 40.1s\tremaining: 20.7s\n",
      "659:\tlearn: 0.4502676\ttotal: 40.1s\tremaining: 20.7s\n",
      "660:\tlearn: 0.4502608\ttotal: 40.2s\tremaining: 20.6s\n",
      "661:\tlearn: 0.4502496\ttotal: 40.2s\tremaining: 20.5s\n",
      "662:\tlearn: 0.4502421\ttotal: 40.3s\tremaining: 20.5s\n",
      "663:\tlearn: 0.4502349\ttotal: 40.4s\tremaining: 20.4s\n",
      "664:\tlearn: 0.4502273\ttotal: 40.4s\tremaining: 20.4s\n",
      "665:\tlearn: 0.4502185\ttotal: 40.5s\tremaining: 20.3s\n",
      "666:\tlearn: 0.4502132\ttotal: 40.5s\tremaining: 20.2s\n",
      "667:\tlearn: 0.4501999\ttotal: 40.6s\tremaining: 20.2s\n",
      "668:\tlearn: 0.4501915\ttotal: 40.7s\tremaining: 20.1s\n",
      "669:\tlearn: 0.4501845\ttotal: 40.7s\tremaining: 20.1s\n",
      "670:\tlearn: 0.4501777\ttotal: 40.8s\tremaining: 20s\n",
      "671:\tlearn: 0.4501688\ttotal: 40.9s\tremaining: 20s\n",
      "672:\tlearn: 0.4501626\ttotal: 40.9s\tremaining: 19.9s\n",
      "673:\tlearn: 0.4501567\ttotal: 41s\tremaining: 19.8s\n",
      "674:\tlearn: 0.4501510\ttotal: 41s\tremaining: 19.8s\n",
      "675:\tlearn: 0.4501431\ttotal: 41.1s\tremaining: 19.7s\n",
      "676:\tlearn: 0.4501359\ttotal: 41.2s\tremaining: 19.6s\n",
      "677:\tlearn: 0.4501291\ttotal: 41.2s\tremaining: 19.6s\n",
      "678:\tlearn: 0.4501183\ttotal: 41.3s\tremaining: 19.5s\n",
      "679:\tlearn: 0.4501115\ttotal: 41.4s\tremaining: 19.5s\n",
      "680:\tlearn: 0.4501036\ttotal: 41.4s\tremaining: 19.4s\n",
      "681:\tlearn: 0.4500945\ttotal: 41.5s\tremaining: 19.3s\n",
      "682:\tlearn: 0.4500874\ttotal: 41.5s\tremaining: 19.3s\n",
      "683:\tlearn: 0.4500790\ttotal: 41.6s\tremaining: 19.2s\n",
      "684:\tlearn: 0.4500715\ttotal: 41.6s\tremaining: 19.1s\n",
      "685:\tlearn: 0.4500650\ttotal: 41.7s\tremaining: 19.1s\n",
      "686:\tlearn: 0.4500567\ttotal: 41.8s\tremaining: 19s\n",
      "687:\tlearn: 0.4500514\ttotal: 41.8s\tremaining: 19s\n",
      "688:\tlearn: 0.4500424\ttotal: 41.9s\tremaining: 18.9s\n",
      "689:\tlearn: 0.4500343\ttotal: 41.9s\tremaining: 18.8s\n",
      "690:\tlearn: 0.4500238\ttotal: 42s\tremaining: 18.8s\n",
      "691:\tlearn: 0.4500170\ttotal: 42.1s\tremaining: 18.7s\n",
      "692:\tlearn: 0.4500094\ttotal: 42.1s\tremaining: 18.7s\n",
      "693:\tlearn: 0.4499998\ttotal: 42.2s\tremaining: 18.6s\n",
      "694:\tlearn: 0.4499916\ttotal: 42.2s\tremaining: 18.5s\n",
      "695:\tlearn: 0.4499855\ttotal: 42.3s\tremaining: 18.5s\n",
      "696:\tlearn: 0.4499788\ttotal: 42.4s\tremaining: 18.4s\n",
      "697:\tlearn: 0.4499705\ttotal: 42.4s\tremaining: 18.4s\n",
      "698:\tlearn: 0.4499620\ttotal: 42.5s\tremaining: 18.3s\n",
      "699:\tlearn: 0.4499546\ttotal: 42.5s\tremaining: 18.2s\n",
      "700:\tlearn: 0.4499471\ttotal: 42.6s\tremaining: 18.2s\n",
      "701:\tlearn: 0.4499400\ttotal: 42.6s\tremaining: 18.1s\n",
      "702:\tlearn: 0.4499281\ttotal: 42.7s\tremaining: 18s\n",
      "703:\tlearn: 0.4499223\ttotal: 42.8s\tremaining: 18s\n",
      "704:\tlearn: 0.4499172\ttotal: 42.8s\tremaining: 17.9s\n",
      "705:\tlearn: 0.4499089\ttotal: 42.9s\tremaining: 17.9s\n",
      "706:\tlearn: 0.4499018\ttotal: 42.9s\tremaining: 17.8s\n",
      "707:\tlearn: 0.4498945\ttotal: 43s\tremaining: 17.7s\n",
      "708:\tlearn: 0.4498862\ttotal: 43.1s\tremaining: 17.7s\n",
      "709:\tlearn: 0.4498771\ttotal: 43.1s\tremaining: 17.6s\n",
      "710:\tlearn: 0.4498668\ttotal: 43.2s\tremaining: 17.5s\n",
      "711:\tlearn: 0.4498572\ttotal: 43.2s\tremaining: 17.5s\n",
      "712:\tlearn: 0.4498495\ttotal: 43.3s\tremaining: 17.4s\n",
      "713:\tlearn: 0.4498416\ttotal: 43.4s\tremaining: 17.4s\n",
      "714:\tlearn: 0.4498344\ttotal: 43.4s\tremaining: 17.3s\n",
      "715:\tlearn: 0.4498260\ttotal: 43.5s\tremaining: 17.3s\n",
      "716:\tlearn: 0.4498185\ttotal: 43.6s\tremaining: 17.2s\n",
      "717:\tlearn: 0.4498102\ttotal: 43.6s\tremaining: 17.1s\n",
      "718:\tlearn: 0.4498035\ttotal: 43.7s\tremaining: 17.1s\n",
      "719:\tlearn: 0.4497958\ttotal: 43.7s\tremaining: 17s\n",
      "720:\tlearn: 0.4497897\ttotal: 43.8s\tremaining: 17s\n",
      "721:\tlearn: 0.4497836\ttotal: 43.9s\tremaining: 16.9s\n",
      "722:\tlearn: 0.4497723\ttotal: 43.9s\tremaining: 16.8s\n",
      "723:\tlearn: 0.4497605\ttotal: 44s\tremaining: 16.8s\n",
      "724:\tlearn: 0.4497554\ttotal: 44s\tremaining: 16.7s\n",
      "725:\tlearn: 0.4497466\ttotal: 44.1s\tremaining: 16.6s\n",
      "726:\tlearn: 0.4497401\ttotal: 44.2s\tremaining: 16.6s\n",
      "727:\tlearn: 0.4497321\ttotal: 44.2s\tremaining: 16.5s\n",
      "728:\tlearn: 0.4497251\ttotal: 44.3s\tremaining: 16.5s\n",
      "729:\tlearn: 0.4497176\ttotal: 44.3s\tremaining: 16.4s\n",
      "730:\tlearn: 0.4497098\ttotal: 44.4s\tremaining: 16.3s\n",
      "731:\tlearn: 0.4497031\ttotal: 44.5s\tremaining: 16.3s\n",
      "732:\tlearn: 0.4496949\ttotal: 44.5s\tremaining: 16.2s\n",
      "733:\tlearn: 0.4496877\ttotal: 44.6s\tremaining: 16.2s\n",
      "734:\tlearn: 0.4496814\ttotal: 44.6s\tremaining: 16.1s\n",
      "735:\tlearn: 0.4496736\ttotal: 44.7s\tremaining: 16s\n",
      "736:\tlearn: 0.4496662\ttotal: 44.8s\tremaining: 16s\n",
      "737:\tlearn: 0.4496579\ttotal: 44.8s\tremaining: 15.9s\n",
      "738:\tlearn: 0.4496483\ttotal: 44.9s\tremaining: 15.8s\n",
      "739:\tlearn: 0.4496407\ttotal: 44.9s\tremaining: 15.8s\n",
      "740:\tlearn: 0.4496332\ttotal: 45s\tremaining: 15.7s\n",
      "741:\tlearn: 0.4496254\ttotal: 45.1s\tremaining: 15.7s\n",
      "742:\tlearn: 0.4496169\ttotal: 45.1s\tremaining: 15.6s\n",
      "743:\tlearn: 0.4496092\ttotal: 45.2s\tremaining: 15.5s\n",
      "744:\tlearn: 0.4496031\ttotal: 45.2s\tremaining: 15.5s\n",
      "745:\tlearn: 0.4495975\ttotal: 45.3s\tremaining: 15.4s\n",
      "746:\tlearn: 0.4495925\ttotal: 45.4s\tremaining: 15.4s\n",
      "747:\tlearn: 0.4495863\ttotal: 45.4s\tremaining: 15.3s\n",
      "748:\tlearn: 0.4495778\ttotal: 45.5s\tremaining: 15.2s\n",
      "749:\tlearn: 0.4495698\ttotal: 45.5s\tremaining: 15.2s\n",
      "750:\tlearn: 0.4495642\ttotal: 45.6s\tremaining: 15.1s\n",
      "751:\tlearn: 0.4495541\ttotal: 45.7s\tremaining: 15.1s\n",
      "752:\tlearn: 0.4495470\ttotal: 45.7s\tremaining: 15s\n",
      "753:\tlearn: 0.4495391\ttotal: 45.8s\tremaining: 14.9s\n",
      "754:\tlearn: 0.4495306\ttotal: 45.8s\tremaining: 14.9s\n",
      "755:\tlearn: 0.4495234\ttotal: 45.9s\tremaining: 14.8s\n",
      "756:\tlearn: 0.4495155\ttotal: 46s\tremaining: 14.8s\n",
      "757:\tlearn: 0.4495079\ttotal: 46s\tremaining: 14.7s\n",
      "758:\tlearn: 0.4495003\ttotal: 46.1s\tremaining: 14.6s\n",
      "759:\tlearn: 0.4494919\ttotal: 46.1s\tremaining: 14.6s\n",
      "760:\tlearn: 0.4494852\ttotal: 46.2s\tremaining: 14.5s\n",
      "761:\tlearn: 0.4494761\ttotal: 46.3s\tremaining: 14.4s\n",
      "762:\tlearn: 0.4494680\ttotal: 46.3s\tremaining: 14.4s\n",
      "763:\tlearn: 0.4494625\ttotal: 46.4s\tremaining: 14.3s\n",
      "764:\tlearn: 0.4494555\ttotal: 46.4s\tremaining: 14.3s\n",
      "765:\tlearn: 0.4494464\ttotal: 46.5s\tremaining: 14.2s\n",
      "766:\tlearn: 0.4494420\ttotal: 46.6s\tremaining: 14.1s\n",
      "767:\tlearn: 0.4494323\ttotal: 46.6s\tremaining: 14.1s\n",
      "768:\tlearn: 0.4494265\ttotal: 46.7s\tremaining: 14s\n",
      "769:\tlearn: 0.4494196\ttotal: 46.7s\tremaining: 14s\n",
      "770:\tlearn: 0.4494137\ttotal: 46.8s\tremaining: 13.9s\n",
      "771:\tlearn: 0.4494058\ttotal: 46.9s\tremaining: 13.8s\n",
      "772:\tlearn: 0.4493998\ttotal: 46.9s\tremaining: 13.8s\n",
      "773:\tlearn: 0.4493901\ttotal: 47s\tremaining: 13.7s\n",
      "774:\tlearn: 0.4493833\ttotal: 47.1s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775:\tlearn: 0.4493790\ttotal: 47.1s\tremaining: 13.6s\n",
      "776:\tlearn: 0.4493716\ttotal: 47.2s\tremaining: 13.5s\n",
      "777:\tlearn: 0.4493635\ttotal: 47.3s\tremaining: 13.5s\n",
      "778:\tlearn: 0.4493570\ttotal: 47.3s\tremaining: 13.4s\n",
      "779:\tlearn: 0.4493484\ttotal: 47.4s\tremaining: 13.4s\n",
      "780:\tlearn: 0.4493401\ttotal: 47.4s\tremaining: 13.3s\n",
      "781:\tlearn: 0.4493341\ttotal: 47.5s\tremaining: 13.2s\n",
      "782:\tlearn: 0.4493257\ttotal: 47.5s\tremaining: 13.2s\n",
      "783:\tlearn: 0.4493179\ttotal: 47.6s\tremaining: 13.1s\n",
      "784:\tlearn: 0.4493073\ttotal: 47.7s\tremaining: 13.1s\n",
      "785:\tlearn: 0.4492975\ttotal: 47.7s\tremaining: 13s\n",
      "786:\tlearn: 0.4492910\ttotal: 47.8s\tremaining: 12.9s\n",
      "787:\tlearn: 0.4492848\ttotal: 47.9s\tremaining: 12.9s\n",
      "788:\tlearn: 0.4492783\ttotal: 47.9s\tremaining: 12.8s\n",
      "789:\tlearn: 0.4492695\ttotal: 48s\tremaining: 12.8s\n",
      "790:\tlearn: 0.4492598\ttotal: 48s\tremaining: 12.7s\n",
      "791:\tlearn: 0.4492532\ttotal: 48.1s\tremaining: 12.6s\n",
      "792:\tlearn: 0.4492482\ttotal: 48.1s\tremaining: 12.6s\n",
      "793:\tlearn: 0.4492411\ttotal: 48.2s\tremaining: 12.5s\n",
      "794:\tlearn: 0.4492320\ttotal: 48.3s\tremaining: 12.4s\n",
      "795:\tlearn: 0.4492254\ttotal: 48.3s\tremaining: 12.4s\n",
      "796:\tlearn: 0.4492185\ttotal: 48.4s\tremaining: 12.3s\n",
      "797:\tlearn: 0.4492099\ttotal: 48.4s\tremaining: 12.3s\n",
      "798:\tlearn: 0.4492036\ttotal: 48.5s\tremaining: 12.2s\n",
      "799:\tlearn: 0.4491966\ttotal: 48.6s\tremaining: 12.1s\n",
      "800:\tlearn: 0.4491918\ttotal: 48.6s\tremaining: 12.1s\n",
      "801:\tlearn: 0.4491847\ttotal: 48.7s\tremaining: 12s\n",
      "802:\tlearn: 0.4491786\ttotal: 48.8s\tremaining: 12s\n",
      "803:\tlearn: 0.4491714\ttotal: 48.8s\tremaining: 11.9s\n",
      "804:\tlearn: 0.4491631\ttotal: 48.9s\tremaining: 11.8s\n",
      "805:\tlearn: 0.4491568\ttotal: 48.9s\tremaining: 11.8s\n",
      "806:\tlearn: 0.4491485\ttotal: 49s\tremaining: 11.7s\n",
      "807:\tlearn: 0.4491410\ttotal: 49.1s\tremaining: 11.7s\n",
      "808:\tlearn: 0.4491357\ttotal: 49.1s\tremaining: 11.6s\n",
      "809:\tlearn: 0.4491315\ttotal: 49.2s\tremaining: 11.5s\n",
      "810:\tlearn: 0.4491249\ttotal: 49.2s\tremaining: 11.5s\n",
      "811:\tlearn: 0.4491178\ttotal: 49.3s\tremaining: 11.4s\n",
      "812:\tlearn: 0.4491096\ttotal: 49.4s\tremaining: 11.4s\n",
      "813:\tlearn: 0.4491028\ttotal: 49.4s\tremaining: 11.3s\n",
      "814:\tlearn: 0.4490961\ttotal: 49.5s\tremaining: 11.2s\n",
      "815:\tlearn: 0.4490902\ttotal: 49.6s\tremaining: 11.2s\n",
      "816:\tlearn: 0.4490795\ttotal: 49.6s\tremaining: 11.1s\n",
      "817:\tlearn: 0.4490729\ttotal: 49.7s\tremaining: 11.1s\n",
      "818:\tlearn: 0.4490655\ttotal: 49.8s\tremaining: 11s\n",
      "819:\tlearn: 0.4490586\ttotal: 49.8s\tremaining: 10.9s\n",
      "820:\tlearn: 0.4490495\ttotal: 49.9s\tremaining: 10.9s\n",
      "821:\tlearn: 0.4490430\ttotal: 49.9s\tremaining: 10.8s\n",
      "822:\tlearn: 0.4490341\ttotal: 50s\tremaining: 10.8s\n",
      "823:\tlearn: 0.4490281\ttotal: 50.1s\tremaining: 10.7s\n",
      "824:\tlearn: 0.4490206\ttotal: 50.1s\tremaining: 10.6s\n",
      "825:\tlearn: 0.4490129\ttotal: 50.2s\tremaining: 10.6s\n",
      "826:\tlearn: 0.4490047\ttotal: 50.3s\tremaining: 10.5s\n",
      "827:\tlearn: 0.4489977\ttotal: 50.3s\tremaining: 10.5s\n",
      "828:\tlearn: 0.4489898\ttotal: 50.4s\tremaining: 10.4s\n",
      "829:\tlearn: 0.4489831\ttotal: 50.5s\tremaining: 10.3s\n",
      "830:\tlearn: 0.4489772\ttotal: 50.5s\tremaining: 10.3s\n",
      "831:\tlearn: 0.4489702\ttotal: 50.6s\tremaining: 10.2s\n",
      "832:\tlearn: 0.4489641\ttotal: 50.6s\tremaining: 10.2s\n",
      "833:\tlearn: 0.4489557\ttotal: 50.7s\tremaining: 10.1s\n",
      "834:\tlearn: 0.4489474\ttotal: 50.8s\tremaining: 10s\n",
      "835:\tlearn: 0.4489401\ttotal: 50.8s\tremaining: 9.97s\n",
      "836:\tlearn: 0.4489326\ttotal: 50.9s\tremaining: 9.91s\n",
      "837:\tlearn: 0.4489273\ttotal: 51s\tremaining: 9.85s\n",
      "838:\tlearn: 0.4489208\ttotal: 51s\tremaining: 9.79s\n",
      "839:\tlearn: 0.4489148\ttotal: 51.1s\tremaining: 9.73s\n",
      "840:\tlearn: 0.4489079\ttotal: 51.1s\tremaining: 9.67s\n",
      "841:\tlearn: 0.4489021\ttotal: 51.2s\tremaining: 9.61s\n",
      "842:\tlearn: 0.4488941\ttotal: 51.3s\tremaining: 9.55s\n",
      "843:\tlearn: 0.4488870\ttotal: 51.3s\tremaining: 9.49s\n",
      "844:\tlearn: 0.4488807\ttotal: 51.4s\tremaining: 9.43s\n",
      "845:\tlearn: 0.4488738\ttotal: 51.5s\tremaining: 9.37s\n",
      "846:\tlearn: 0.4488658\ttotal: 51.6s\tremaining: 9.31s\n",
      "847:\tlearn: 0.4488584\ttotal: 51.6s\tremaining: 9.25s\n",
      "848:\tlearn: 0.4488519\ttotal: 51.7s\tremaining: 9.19s\n",
      "849:\tlearn: 0.4488452\ttotal: 51.7s\tremaining: 9.13s\n",
      "850:\tlearn: 0.4488390\ttotal: 51.8s\tremaining: 9.07s\n",
      "851:\tlearn: 0.4488311\ttotal: 51.8s\tremaining: 9.01s\n",
      "852:\tlearn: 0.4488251\ttotal: 51.9s\tremaining: 8.94s\n",
      "853:\tlearn: 0.4488181\ttotal: 52s\tremaining: 8.88s\n",
      "854:\tlearn: 0.4488087\ttotal: 52s\tremaining: 8.82s\n",
      "855:\tlearn: 0.4488027\ttotal: 52.1s\tremaining: 8.76s\n",
      "856:\tlearn: 0.4487956\ttotal: 52.1s\tremaining: 8.7s\n",
      "857:\tlearn: 0.4487888\ttotal: 52.2s\tremaining: 8.64s\n",
      "858:\tlearn: 0.4487807\ttotal: 52.3s\tremaining: 8.58s\n",
      "859:\tlearn: 0.4487731\ttotal: 52.3s\tremaining: 8.52s\n",
      "860:\tlearn: 0.4487647\ttotal: 52.4s\tremaining: 8.46s\n",
      "861:\tlearn: 0.4487581\ttotal: 52.5s\tremaining: 8.4s\n",
      "862:\tlearn: 0.4487516\ttotal: 52.5s\tremaining: 8.34s\n",
      "863:\tlearn: 0.4487438\ttotal: 52.6s\tremaining: 8.28s\n",
      "864:\tlearn: 0.4487369\ttotal: 52.6s\tremaining: 8.21s\n",
      "865:\tlearn: 0.4487277\ttotal: 52.7s\tremaining: 8.15s\n",
      "866:\tlearn: 0.4487220\ttotal: 52.8s\tremaining: 8.09s\n",
      "867:\tlearn: 0.4487149\ttotal: 52.8s\tremaining: 8.03s\n",
      "868:\tlearn: 0.4487072\ttotal: 52.9s\tremaining: 7.97s\n",
      "869:\tlearn: 0.4486994\ttotal: 52.9s\tremaining: 7.91s\n",
      "870:\tlearn: 0.4486931\ttotal: 53s\tremaining: 7.85s\n",
      "871:\tlearn: 0.4486883\ttotal: 53s\tremaining: 7.79s\n",
      "872:\tlearn: 0.4486827\ttotal: 53.1s\tremaining: 7.73s\n",
      "873:\tlearn: 0.4486761\ttotal: 53.2s\tremaining: 7.66s\n",
      "874:\tlearn: 0.4486702\ttotal: 53.2s\tremaining: 7.6s\n",
      "875:\tlearn: 0.4486627\ttotal: 53.3s\tremaining: 7.54s\n",
      "876:\tlearn: 0.4486556\ttotal: 53.3s\tremaining: 7.48s\n",
      "877:\tlearn: 0.4486471\ttotal: 53.4s\tremaining: 7.42s\n",
      "878:\tlearn: 0.4486398\ttotal: 53.5s\tremaining: 7.36s\n",
      "879:\tlearn: 0.4486300\ttotal: 53.5s\tremaining: 7.3s\n",
      "880:\tlearn: 0.4486235\ttotal: 53.6s\tremaining: 7.24s\n",
      "881:\tlearn: 0.4486149\ttotal: 53.6s\tremaining: 7.18s\n",
      "882:\tlearn: 0.4486062\ttotal: 53.7s\tremaining: 7.12s\n",
      "883:\tlearn: 0.4485981\ttotal: 53.8s\tremaining: 7.05s\n",
      "884:\tlearn: 0.4485911\ttotal: 53.8s\tremaining: 6.99s\n",
      "885:\tlearn: 0.4485846\ttotal: 53.9s\tremaining: 6.93s\n",
      "886:\tlearn: 0.4485797\ttotal: 53.9s\tremaining: 6.87s\n",
      "887:\tlearn: 0.4485748\ttotal: 54s\tremaining: 6.81s\n",
      "888:\tlearn: 0.4485668\ttotal: 54.1s\tremaining: 6.75s\n",
      "889:\tlearn: 0.4485608\ttotal: 54.1s\tremaining: 6.69s\n",
      "890:\tlearn: 0.4485533\ttotal: 54.2s\tremaining: 6.63s\n",
      "891:\tlearn: 0.4485464\ttotal: 54.2s\tremaining: 6.57s\n",
      "892:\tlearn: 0.4485385\ttotal: 54.3s\tremaining: 6.5s\n",
      "893:\tlearn: 0.4485332\ttotal: 54.4s\tremaining: 6.44s\n",
      "894:\tlearn: 0.4485262\ttotal: 54.4s\tremaining: 6.38s\n",
      "895:\tlearn: 0.4485188\ttotal: 54.5s\tremaining: 6.32s\n",
      "896:\tlearn: 0.4485102\ttotal: 54.6s\tremaining: 6.26s\n",
      "897:\tlearn: 0.4485025\ttotal: 54.6s\tremaining: 6.21s\n",
      "898:\tlearn: 0.4484962\ttotal: 54.7s\tremaining: 6.14s\n",
      "899:\tlearn: 0.4484886\ttotal: 54.8s\tremaining: 6.08s\n",
      "900:\tlearn: 0.4484831\ttotal: 54.8s\tremaining: 6.02s\n",
      "901:\tlearn: 0.4484754\ttotal: 54.9s\tremaining: 5.96s\n",
      "902:\tlearn: 0.4484690\ttotal: 54.9s\tremaining: 5.9s\n",
      "903:\tlearn: 0.4484631\ttotal: 55s\tremaining: 5.84s\n",
      "904:\tlearn: 0.4484557\ttotal: 55s\tremaining: 5.78s\n",
      "905:\tlearn: 0.4484449\ttotal: 55.1s\tremaining: 5.72s\n",
      "906:\tlearn: 0.4484384\ttotal: 55.2s\tremaining: 5.66s\n",
      "907:\tlearn: 0.4484300\ttotal: 55.2s\tremaining: 5.6s\n",
      "908:\tlearn: 0.4484230\ttotal: 55.3s\tremaining: 5.54s\n",
      "909:\tlearn: 0.4484164\ttotal: 55.4s\tremaining: 5.48s\n",
      "910:\tlearn: 0.4484101\ttotal: 55.4s\tremaining: 5.42s\n",
      "911:\tlearn: 0.4484034\ttotal: 55.5s\tremaining: 5.35s\n",
      "912:\tlearn: 0.4483981\ttotal: 55.5s\tremaining: 5.29s\n",
      "913:\tlearn: 0.4483902\ttotal: 55.6s\tremaining: 5.23s\n",
      "914:\tlearn: 0.4483838\ttotal: 55.7s\tremaining: 5.17s\n",
      "915:\tlearn: 0.4483779\ttotal: 55.7s\tremaining: 5.11s\n",
      "916:\tlearn: 0.4483705\ttotal: 55.8s\tremaining: 5.05s\n",
      "917:\tlearn: 0.4483624\ttotal: 55.8s\tremaining: 4.99s\n",
      "918:\tlearn: 0.4483559\ttotal: 55.9s\tremaining: 4.93s\n",
      "919:\tlearn: 0.4483485\ttotal: 56s\tremaining: 4.87s\n",
      "920:\tlearn: 0.4483390\ttotal: 56s\tremaining: 4.8s\n",
      "921:\tlearn: 0.4483316\ttotal: 56.1s\tremaining: 4.74s\n",
      "922:\tlearn: 0.4483237\ttotal: 56.1s\tremaining: 4.68s\n",
      "923:\tlearn: 0.4483172\ttotal: 56.2s\tremaining: 4.62s\n",
      "924:\tlearn: 0.4483121\ttotal: 56.2s\tremaining: 4.56s\n",
      "925:\tlearn: 0.4483052\ttotal: 56.3s\tremaining: 4.5s\n",
      "926:\tlearn: 0.4482970\ttotal: 56.4s\tremaining: 4.44s\n",
      "927:\tlearn: 0.4482886\ttotal: 56.4s\tremaining: 4.38s\n",
      "928:\tlearn: 0.4482797\ttotal: 56.5s\tremaining: 4.32s\n",
      "929:\tlearn: 0.4482752\ttotal: 56.6s\tremaining: 4.26s\n",
      "930:\tlearn: 0.4482666\ttotal: 56.6s\tremaining: 4.2s\n",
      "931:\tlearn: 0.4482578\ttotal: 56.7s\tremaining: 4.14s\n",
      "932:\tlearn: 0.4482511\ttotal: 56.8s\tremaining: 4.08s\n",
      "933:\tlearn: 0.4482462\ttotal: 56.8s\tremaining: 4.01s\n",
      "934:\tlearn: 0.4482396\ttotal: 56.9s\tremaining: 3.95s\n",
      "935:\tlearn: 0.4482314\ttotal: 56.9s\tremaining: 3.89s\n",
      "936:\tlearn: 0.4482249\ttotal: 57s\tremaining: 3.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937:\tlearn: 0.4482174\ttotal: 57.1s\tremaining: 3.77s\n",
      "938:\tlearn: 0.4482085\ttotal: 57.1s\tremaining: 3.71s\n",
      "939:\tlearn: 0.4482018\ttotal: 57.2s\tremaining: 3.65s\n",
      "940:\tlearn: 0.4481940\ttotal: 57.3s\tremaining: 3.59s\n",
      "941:\tlearn: 0.4481872\ttotal: 57.3s\tremaining: 3.53s\n",
      "942:\tlearn: 0.4481781\ttotal: 57.4s\tremaining: 3.47s\n",
      "943:\tlearn: 0.4481718\ttotal: 57.4s\tremaining: 3.41s\n",
      "944:\tlearn: 0.4481645\ttotal: 57.5s\tremaining: 3.35s\n",
      "945:\tlearn: 0.4481571\ttotal: 57.6s\tremaining: 3.29s\n",
      "946:\tlearn: 0.4481476\ttotal: 57.6s\tremaining: 3.23s\n",
      "947:\tlearn: 0.4481419\ttotal: 57.7s\tremaining: 3.16s\n",
      "948:\tlearn: 0.4481380\ttotal: 57.8s\tremaining: 3.1s\n",
      "949:\tlearn: 0.4481303\ttotal: 57.8s\tremaining: 3.04s\n",
      "950:\tlearn: 0.4481248\ttotal: 57.9s\tremaining: 2.98s\n",
      "951:\tlearn: 0.4481169\ttotal: 57.9s\tremaining: 2.92s\n",
      "952:\tlearn: 0.4481090\ttotal: 58s\tremaining: 2.86s\n",
      "953:\tlearn: 0.4481024\ttotal: 58.1s\tremaining: 2.8s\n",
      "954:\tlearn: 0.4480950\ttotal: 58.1s\tremaining: 2.74s\n",
      "955:\tlearn: 0.4480872\ttotal: 58.2s\tremaining: 2.68s\n",
      "956:\tlearn: 0.4480790\ttotal: 58.3s\tremaining: 2.62s\n",
      "957:\tlearn: 0.4480701\ttotal: 58.3s\tremaining: 2.56s\n",
      "958:\tlearn: 0.4480640\ttotal: 58.4s\tremaining: 2.5s\n",
      "959:\tlearn: 0.4480515\ttotal: 58.4s\tremaining: 2.43s\n",
      "960:\tlearn: 0.4480449\ttotal: 58.5s\tremaining: 2.37s\n",
      "961:\tlearn: 0.4480386\ttotal: 58.5s\tremaining: 2.31s\n",
      "962:\tlearn: 0.4480316\ttotal: 58.6s\tremaining: 2.25s\n",
      "963:\tlearn: 0.4480243\ttotal: 58.7s\tremaining: 2.19s\n",
      "964:\tlearn: 0.4480179\ttotal: 58.7s\tremaining: 2.13s\n",
      "965:\tlearn: 0.4480106\ttotal: 58.8s\tremaining: 2.07s\n",
      "966:\tlearn: 0.4480035\ttotal: 58.9s\tremaining: 2.01s\n",
      "967:\tlearn: 0.4479967\ttotal: 58.9s\tremaining: 1.95s\n",
      "968:\tlearn: 0.4479898\ttotal: 59s\tremaining: 1.89s\n",
      "969:\tlearn: 0.4479834\ttotal: 59s\tremaining: 1.82s\n",
      "970:\tlearn: 0.4479760\ttotal: 59.1s\tremaining: 1.76s\n",
      "971:\tlearn: 0.4479678\ttotal: 59.2s\tremaining: 1.7s\n",
      "972:\tlearn: 0.4479606\ttotal: 59.2s\tremaining: 1.64s\n",
      "973:\tlearn: 0.4479521\ttotal: 59.3s\tremaining: 1.58s\n",
      "974:\tlearn: 0.4479418\ttotal: 59.3s\tremaining: 1.52s\n",
      "975:\tlearn: 0.4479363\ttotal: 59.4s\tremaining: 1.46s\n",
      "976:\tlearn: 0.4479298\ttotal: 59.5s\tremaining: 1.4s\n",
      "977:\tlearn: 0.4479224\ttotal: 59.5s\tremaining: 1.34s\n",
      "978:\tlearn: 0.4479146\ttotal: 59.6s\tremaining: 1.28s\n",
      "979:\tlearn: 0.4479072\ttotal: 59.6s\tremaining: 1.22s\n",
      "980:\tlearn: 0.4479015\ttotal: 59.7s\tremaining: 1.16s\n",
      "981:\tlearn: 0.4478954\ttotal: 59.8s\tremaining: 1.09s\n",
      "982:\tlearn: 0.4478874\ttotal: 59.8s\tremaining: 1.03s\n",
      "983:\tlearn: 0.4478774\ttotal: 59.9s\tremaining: 974ms\n",
      "984:\tlearn: 0.4478714\ttotal: 60s\tremaining: 913ms\n",
      "985:\tlearn: 0.4478630\ttotal: 1m\tremaining: 852ms\n",
      "986:\tlearn: 0.4478586\ttotal: 1m\tremaining: 791ms\n",
      "987:\tlearn: 0.4478510\ttotal: 1m\tremaining: 730ms\n",
      "988:\tlearn: 0.4478415\ttotal: 1m\tremaining: 670ms\n",
      "989:\tlearn: 0.4478334\ttotal: 1m\tremaining: 609ms\n",
      "990:\tlearn: 0.4478273\ttotal: 1m\tremaining: 548ms\n",
      "991:\tlearn: 0.4478218\ttotal: 1m\tremaining: 487ms\n",
      "992:\tlearn: 0.4478146\ttotal: 1m\tremaining: 426ms\n",
      "993:\tlearn: 0.4478065\ttotal: 1m\tremaining: 365ms\n",
      "994:\tlearn: 0.4477984\ttotal: 1m\tremaining: 304ms\n",
      "995:\tlearn: 0.4477911\ttotal: 1m\tremaining: 244ms\n",
      "996:\tlearn: 0.4477838\ttotal: 1m\tremaining: 183ms\n",
      "997:\tlearn: 0.4477775\ttotal: 1m\tremaining: 122ms\n",
      "998:\tlearn: 0.4477704\ttotal: 1m\tremaining: 60.9ms\n",
      "999:\tlearn: 0.4477639\ttotal: 1m\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8301194383342222\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5746 - auc: 0.7622 - val_loss: 0.4991 - val_auc: 0.7951\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4857 - auc: 0.8060 - val_loss: 0.4815 - val_auc: 0.8083\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4717 - auc: 0.8167 - val_loss: 0.4764 - val_auc: 0.8128\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4672 - auc: 0.8208 - val_loss: 0.4747 - val_auc: 0.8139\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8217 - val_loss: 0.4743 - val_auc: 0.8143\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8220 - val_loss: 0.4743 - val_auc: 0.8147\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8217 - val_loss: 0.4742 - val_auc: 0.8145\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4654 - auc: 0.8222 - val_loss: 0.4741 - val_auc: 0.8140\n",
      "Epoch 9/100\n",
      "282624/284999 [============================>.] - ETA: 0s - loss: 0.4653 - auc: 0.8222Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4653 - auc: 0.8221 - val_loss: 0.4742 - val_auc: 0.8142\n",
      "Epoch 00009: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.8792 - auc: 0.5062 - val_loss: 0.5603 - val_auc: 0.7346\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5697 - auc: 0.7410 - val_loss: 0.5089 - val_auc: 0.7840\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5162 - auc: 0.7801 - val_loss: 0.4887 - val_auc: 0.8003\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4921 - auc: 0.7983 - val_loss: 0.4793 - val_auc: 0.8089\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4795 - auc: 0.8091 - val_loss: 0.4747 - val_auc: 0.8134\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4728 - auc: 0.8151 - val_loss: 0.4721 - val_auc: 0.8158\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4699 - auc: 0.8178 - val_loss: 0.4708 - val_auc: 0.8166\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4676 - auc: 0.8200 - val_loss: 0.4701 - val_auc: 0.8173\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4665 - auc: 0.8212 - val_loss: 0.4696 - val_auc: 0.8172\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4695 - val_auc: 0.8182\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4656 - auc: 0.8220 - val_loss: 0.4693 - val_auc: 0.8176\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4651 - auc: 0.8224 - val_loss: 0.4694 - val_auc: 0.8190\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4653 - auc: 0.8224 - val_loss: 0.4694 - val_auc: 0.8174\n",
      "Epoch 14/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4652 - auc: 0.8223 - val_loss: 0.4693 - val_auc: 0.8176\n",
      "Epoch 15/100\n",
      "283648/284999 [============================>.] - ETA: 0s - loss: 0.4654 - auc: 0.8223\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4653 - auc: 0.8224 - val_loss: 0.4693 - val_auc: 0.8190\n",
      "Epoch 16/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4652 - auc: 0.8224 - val_loss: 0.4693 - val_auc: 0.8187\n",
      "Epoch 17/100\n",
      "279552/284999 [============================>.] - ETA: 0s - loss: 0.4651 - auc: 0.8225Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4649 - auc: 0.8227 - val_loss: 0.4693 - val_auc: 0.8184\n",
      "Epoch 00017: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6082 - auc: 0.7246 - val_loss: 0.4879 - val_auc: 0.8038\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5015 - auc: 0.7923 - val_loss: 0.4674 - val_auc: 0.8198\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4792 - auc: 0.8099 - val_loss: 0.4605 - val_auc: 0.8263\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4714 - auc: 0.8167 - val_loss: 0.4578 - val_auc: 0.8302\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4686 - auc: 0.8193 - val_loss: 0.4563 - val_auc: 0.8296\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4676 - auc: 0.8200 - val_loss: 0.4558 - val_auc: 0.8305\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4667 - auc: 0.8211 - val_loss: 0.4557 - val_auc: 0.8314\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4557 - val_auc: 0.8313\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4661 - auc: 0.8216 - val_loss: 0.4554 - val_auc: 0.8318\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4555 - val_auc: 0.8314\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4657 - auc: 0.8220 - val_loss: 0.4554 - val_auc: 0.8314\n",
      "Epoch 12/100\n",
      "281600/284999 [============================>.] - ETA: 0s - loss: 0.4664 - auc: 0.8213Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4555 - val_auc: 0.8319\n",
      "Epoch 00012: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6258 - auc: 0.7219 - val_loss: 0.4928 - val_auc: 0.7997\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5072 - auc: 0.7888 - val_loss: 0.4684 - val_auc: 0.8204\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4814 - auc: 0.8083 - val_loss: 0.4607 - val_auc: 0.8263\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4730 - auc: 0.8153 - val_loss: 0.4577 - val_auc: 0.8299\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4689 - auc: 0.8189 - val_loss: 0.4560 - val_auc: 0.8310\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4671 - auc: 0.8206 - val_loss: 0.4556 - val_auc: 0.8308\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4667 - auc: 0.8210 - val_loss: 0.4553 - val_auc: 0.8314\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4665 - auc: 0.8211 - val_loss: 0.4552 - val_auc: 0.8321\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4553 - val_auc: 0.8314\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8218 - val_loss: 0.4551 - val_auc: 0.8314\n",
      "Epoch 11/100\n",
      "276480/284999 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8217\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4550 - val_auc: 0.8316\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8220 - val_loss: 0.4550 - val_auc: 0.8316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4656 - auc: 0.8220Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8218 - val_loss: 0.4551 - val_auc: 0.8316\n",
      "Epoch 00013: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5491 - auc: 0.7905 - val_loss: 0.4737 - val_auc: 0.8192\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4786 - auc: 0.8124 - val_loss: 0.4629 - val_auc: 0.8244\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4692 - auc: 0.8189 - val_loss: 0.4606 - val_auc: 0.8262\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4671 - auc: 0.8205 - val_loss: 0.4599 - val_auc: 0.8271\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8215 - val_loss: 0.4596 - val_auc: 0.8268\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8215 - val_loss: 0.4596 - val_auc: 0.8281\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8214 - val_loss: 0.4597 - val_auc: 0.8284\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8219 - val_loss: 0.4596 - val_auc: 0.8280\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4596 - val_auc: 0.8282\n",
      "Epoch 10/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8217\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4594 - val_auc: 0.8274\n",
      "Epoch 11/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4655 - auc: 0.8222Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8223 - val_loss: 0.4595 - val_auc: 0.8277\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6308 - auc: 0.6945 - val_loss: 0.5012 - val_auc: 0.7907\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5114 - auc: 0.7847 - val_loss: 0.4768 - val_auc: 0.8113\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4842 - auc: 0.8053 - val_loss: 0.4674 - val_auc: 0.8207\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4736 - auc: 0.8146 - val_loss: 0.4633 - val_auc: 0.8249\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4690 - auc: 0.8187 - val_loss: 0.4615 - val_auc: 0.8265\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4672 - auc: 0.8206 - val_loss: 0.4609 - val_auc: 0.8268\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4606 - val_auc: 0.8269\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4605 - val_auc: 0.8271\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8219 - val_loss: 0.4603 - val_auc: 0.8281\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8217 - val_loss: 0.4602 - val_auc: 0.8272\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8220 - val_loss: 0.4604 - val_auc: 0.8276\n",
      "Epoch 12/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4658 - auc: 0.8219\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4658 - auc: 0.8218 - val_loss: 0.4602 - val_auc: 0.8275\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8216 - val_loss: 0.4604 - val_auc: 0.8274\n",
      "Epoch 14/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4655 - auc: 0.8220Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4656 - auc: 0.8220 - val_loss: 0.4604 - val_auc: 0.8279\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6579 - auc: 0.6804 - val_loss: 0.5146 - val_auc: 0.7821\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5235 - auc: 0.7776 - val_loss: 0.4861 - val_auc: 0.8041\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4910 - auc: 0.8000 - val_loss: 0.4739 - val_auc: 0.8140\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4769 - auc: 0.8117 - val_loss: 0.4687 - val_auc: 0.8196\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4710 - auc: 0.8171 - val_loss: 0.4663 - val_auc: 0.8210\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4681 - auc: 0.8194 - val_loss: 0.4652 - val_auc: 0.8221\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8214 - val_loss: 0.4647 - val_auc: 0.8234\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8217 - val_loss: 0.4646 - val_auc: 0.8232\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8219 - val_loss: 0.4646 - val_auc: 0.8232\n",
      "Epoch 10/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4654 - auc: 0.8222\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8221 - val_loss: 0.4646 - val_auc: 0.8222\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8221 - val_loss: 0.4645 - val_auc: 0.8227\n",
      "Epoch 12/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4653 - auc: 0.8222Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4653 - auc: 0.8222 - val_loss: 0.4645 - val_auc: 0.8226\n",
      "Epoch 00012: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5613 - auc: 0.7727 - val_loss: 0.4787 - val_auc: 0.8134\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4844 - auc: 0.8072 - val_loss: 0.4649 - val_auc: 0.8232\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4715 - auc: 0.8168 - val_loss: 0.4617 - val_auc: 0.8264\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4677 - auc: 0.8201 - val_loss: 0.4605 - val_auc: 0.8267\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8212 - val_loss: 0.4600 - val_auc: 0.8275\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4665 - auc: 0.8212 - val_loss: 0.4598 - val_auc: 0.8275\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8214 - val_loss: 0.4598 - val_auc: 0.8284\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8217 - val_loss: 0.4595 - val_auc: 0.8278\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8218 - val_loss: 0.4597 - val_auc: 0.8278\n",
      "Epoch 10/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4654 - auc: 0.8221Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4653 - auc: 0.8223 - val_loss: 0.4595 - val_auc: 0.8282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.7482 - auc: 0.6041 - val_loss: 0.5309 - val_auc: 0.7684\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5513 - auc: 0.7572 - val_loss: 0.4877 - val_auc: 0.8036\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5057 - auc: 0.7879 - val_loss: 0.4684 - val_auc: 0.8204\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4844 - auc: 0.8050 - val_loss: 0.4593 - val_auc: 0.8284\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4748 - auc: 0.8137 - val_loss: 0.4551 - val_auc: 0.8330\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4707 - auc: 0.8173 - val_loss: 0.4528 - val_auc: 0.8352\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4685 - auc: 0.8192 - val_loss: 0.4517 - val_auc: 0.8360\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4672 - auc: 0.8205 - val_loss: 0.4509 - val_auc: 0.8358\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4666 - auc: 0.8212 - val_loss: 0.4506 - val_auc: 0.8368\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4504 - val_auc: 0.8370\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4503 - val_auc: 0.8369\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8213 - val_loss: 0.4506 - val_auc: 0.8365\n",
      "Epoch 13/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4666 - auc: 0.8211\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4506 - val_auc: 0.8364\n",
      "Epoch 14/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4660 - auc: 0.8217Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8218 - val_loss: 0.4503 - val_auc: 0.8369\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6105 - auc: 0.6969 - val_loss: 0.4898 - val_auc: 0.8026\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5016 - auc: 0.7923 - val_loss: 0.4709 - val_auc: 0.8184\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4814 - auc: 0.8081 - val_loss: 0.4641 - val_auc: 0.8241\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4732 - auc: 0.8151 - val_loss: 0.4611 - val_auc: 0.8269\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4694 - auc: 0.8185 - val_loss: 0.4596 - val_auc: 0.8282\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4671 - auc: 0.8207 - val_loss: 0.4591 - val_auc: 0.8283\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4667 - auc: 0.8209 - val_loss: 0.4587 - val_auc: 0.8293\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4664 - auc: 0.8211 - val_loss: 0.4585 - val_auc: 0.8282\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8217 - val_loss: 0.4584 - val_auc: 0.8285\n",
      "Epoch 10/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4660 - auc: 0.8217\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4584 - val_auc: 0.8291\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8218 - val_loss: 0.4583 - val_auc: 0.8294\n",
      "Epoch 12/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4657 - auc: 0.8220Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8219 - val_loss: 0.4583 - val_auc: 0.8295\n",
      "Epoch 00012: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6213 - auc: 0.7206 - val_loss: 0.4975 - val_auc: 0.7948\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5028 - auc: 0.7907 - val_loss: 0.4686 - val_auc: 0.8198\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4789 - auc: 0.8098 - val_loss: 0.4597 - val_auc: 0.8276\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4708 - auc: 0.8172 - val_loss: 0.4561 - val_auc: 0.8302\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4680 - auc: 0.8196 - val_loss: 0.4548 - val_auc: 0.8331\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4671 - auc: 0.8203 - val_loss: 0.4541 - val_auc: 0.8324\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4666 - auc: 0.8210 - val_loss: 0.4539 - val_auc: 0.8331\n",
      "Epoch 8/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4660 - auc: 0.8216\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4660 - auc: 0.8215 - val_loss: 0.4537 - val_auc: 0.8324\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4667 - auc: 0.8210 - val_loss: 0.4537 - val_auc: 0.8335\n",
      "Epoch 10/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8216Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4659 - auc: 0.8217 - val_loss: 0.4536 - val_auc: 0.8334\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6036 - auc: 0.7332 - val_loss: 0.4854 - val_auc: 0.8048\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5016 - auc: 0.7922 - val_loss: 0.4659 - val_auc: 0.8216\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4793 - auc: 0.8097 - val_loss: 0.4590 - val_auc: 0.8283\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4720 - auc: 0.8160 - val_loss: 0.4564 - val_auc: 0.8306\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4684 - auc: 0.8192 - val_loss: 0.4552 - val_auc: 0.8313\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4674 - auc: 0.8203 - val_loss: 0.4546 - val_auc: 0.8327\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4667 - auc: 0.8210 - val_loss: 0.4546 - val_auc: 0.8325\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4541 - val_auc: 0.8325\n",
      "Epoch 9/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4664 - auc: 0.8214\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4662 - auc: 0.8215 - val_loss: 0.4542 - val_auc: 0.8326\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4658 - auc: 0.8218 - val_loss: 0.4541 - val_auc: 0.8323\n",
      "Epoch 11/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4657 - auc: 0.8218Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4656 - auc: 0.8221 - val_loss: 0.4542 - val_auc: 0.8324\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.6312 - auc: 0.7011 - val_loss: 0.4960 - val_auc: 0.7962\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5106 - auc: 0.7843 - val_loss: 0.4701 - val_auc: 0.8189\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4838 - auc: 0.8056 - val_loss: 0.4605 - val_auc: 0.8278\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8140 - val_loss: 0.4566 - val_auc: 0.8317\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4697 - auc: 0.8182 - val_loss: 0.4541 - val_auc: 0.8335\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4680 - auc: 0.8198 - val_loss: 0.4533 - val_auc: 0.8339\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4669 - auc: 0.8208 - val_loss: 0.4526 - val_auc: 0.8344\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4525 - val_auc: 0.8354\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8216 - val_loss: 0.4522 - val_auc: 0.8347\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4520 - val_auc: 0.8341\n",
      "Epoch 11/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4664 - auc: 0.8213\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4520 - val_auc: 0.8354\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8217 - val_loss: 0.4522 - val_auc: 0.8350\n",
      "Epoch 13/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4658 - auc: 0.8216Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8216 - val_loss: 0.4523 - val_auc: 0.8346\n",
      "Epoch 00013: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6107 - auc: 0.7298 - val_loss: 0.4990 - val_auc: 0.7927\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5008 - auc: 0.7930 - val_loss: 0.4780 - val_auc: 0.8107\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4789 - auc: 0.8100 - val_loss: 0.4714 - val_auc: 0.8173\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4706 - auc: 0.8173 - val_loss: 0.4692 - val_auc: 0.8191\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4677 - auc: 0.8198 - val_loss: 0.4683 - val_auc: 0.8196\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8212 - val_loss: 0.4680 - val_auc: 0.8206\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4657 - auc: 0.8219 - val_loss: 0.4679 - val_auc: 0.8194\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4655 - auc: 0.8221 - val_loss: 0.4679 - val_auc: 0.8192\n",
      "Epoch 9/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4652 - auc: 0.8222\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4652 - auc: 0.8222 - val_loss: 0.4678 - val_auc: 0.8205\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4652 - auc: 0.8221 - val_loss: 0.4679 - val_auc: 0.8199\n",
      "Epoch 11/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4655 - auc: 0.8220Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4655 - auc: 0.8220 - val_loss: 0.4679 - val_auc: 0.8196\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6132 - auc: 0.7148 - val_loss: 0.4896 - val_auc: 0.8010\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5030 - auc: 0.7906 - val_loss: 0.4665 - val_auc: 0.8226\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4797 - auc: 0.8093 - val_loss: 0.4596 - val_auc: 0.8280\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4717 - auc: 0.8164 - val_loss: 0.4566 - val_auc: 0.8301\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4689 - auc: 0.8190 - val_loss: 0.4554 - val_auc: 0.8318\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4673 - auc: 0.8204 - val_loss: 0.4546 - val_auc: 0.8326\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4668 - auc: 0.8210 - val_loss: 0.4547 - val_auc: 0.8319\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4542 - val_auc: 0.8328\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4666 - auc: 0.8211 - val_loss: 0.4542 - val_auc: 0.8324\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8214 - val_loss: 0.4543 - val_auc: 0.8328\n",
      "Epoch 11/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4661 - auc: 0.8215\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4543 - val_auc: 0.8327\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8217 - val_loss: 0.4543 - val_auc: 0.8319\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4542 - val_auc: 0.8332\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4658 - auc: 0.8219 - val_loss: 0.4543 - val_auc: 0.8320\n",
      "Epoch 15/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8215Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4662 - auc: 0.8213 - val_loss: 0.4544 - val_auc: 0.8334\n",
      "Epoch 00015: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6609 - auc: 0.6991 - val_loss: 0.5095 - val_auc: 0.7859\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5148 - auc: 0.7821 - val_loss: 0.4742 - val_auc: 0.8161\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4828 - auc: 0.8068 - val_loss: 0.4626 - val_auc: 0.8261\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4725 - auc: 0.8159 - val_loss: 0.4583 - val_auc: 0.8297\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4685 - auc: 0.8192 - val_loss: 0.4565 - val_auc: 0.8311\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4672 - auc: 0.8206 - val_loss: 0.4561 - val_auc: 0.8324\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4668 - auc: 0.8208 - val_loss: 0.4558 - val_auc: 0.8319\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4663 - auc: 0.8213 - val_loss: 0.4555 - val_auc: 0.8320\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8216 - val_loss: 0.4556 - val_auc: 0.8326\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4557 - val_auc: 0.8323\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4663 - auc: 0.8213Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4662 - auc: 0.8214 - val_loss: 0.4555 - val_auc: 0.8315\n",
      "Epoch 00011: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6227 - auc: 0.7144 - val_loss: 0.4872 - val_auc: 0.8043\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5061 - auc: 0.7888 - val_loss: 0.4619 - val_auc: 0.8267\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4817 - auc: 0.8078 - val_loss: 0.4545 - val_auc: 0.8335\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4730 - auc: 0.8154 - val_loss: 0.4515 - val_auc: 0.8350\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4694 - auc: 0.8186 - val_loss: 0.4499 - val_auc: 0.8366\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4673 - auc: 0.8202 - val_loss: 0.4497 - val_auc: 0.8368\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4668 - auc: 0.8210 - val_loss: 0.4495 - val_auc: 0.8371\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4669 - auc: 0.8209 - val_loss: 0.4491 - val_auc: 0.8381\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4664 - auc: 0.8213 - val_loss: 0.4494 - val_auc: 0.8370\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4668 - auc: 0.8209 - val_loss: 0.4495 - val_auc: 0.8380\n",
      "Epoch 11/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4665 - auc: 0.8210\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4666 - auc: 0.8209 - val_loss: 0.4492 - val_auc: 0.8374\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4664 - auc: 0.8212 - val_loss: 0.4493 - val_auc: 0.8370\n",
      "Epoch 13/100\n",
      "280576/285001 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8217Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4658 - auc: 0.8218 - val_loss: 0.4491 - val_auc: 0.8374\n",
      "Epoch 00013: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6918 - auc: 0.6420 - val_loss: 0.5112 - val_auc: 0.7843\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5307 - auc: 0.7739 - val_loss: 0.4822 - val_auc: 0.8087\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4968 - auc: 0.7963 - val_loss: 0.4699 - val_auc: 0.8189\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4806 - auc: 0.8088 - val_loss: 0.4642 - val_auc: 0.8240\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4734 - auc: 0.8148 - val_loss: 0.4614 - val_auc: 0.8259\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4690 - auc: 0.8188 - val_loss: 0.4601 - val_auc: 0.8276\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4678 - auc: 0.8200 - val_loss: 0.4597 - val_auc: 0.8272\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4670 - auc: 0.8207 - val_loss: 0.4594 - val_auc: 0.8274\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4594 - val_auc: 0.8277\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8218 - val_loss: 0.4593 - val_auc: 0.8273\n",
      "Epoch 11/100\n",
      "276480/285001 [============================>.] - ETA: 0s - loss: 0.4656 - auc: 0.8219Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4658 - auc: 0.8218 - val_loss: 0.4594 - val_auc: 0.8281\n",
      "Epoch 00011: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6473 - auc: 0.6803 - val_loss: 0.5021 - val_auc: 0.7889\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5115 - auc: 0.7835 - val_loss: 0.4743 - val_auc: 0.8137\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4841 - auc: 0.8055 - val_loss: 0.4649 - val_auc: 0.8226\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8146 - val_loss: 0.4606 - val_auc: 0.8269\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4695 - auc: 0.8184 - val_loss: 0.4586 - val_auc: 0.8285\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4673 - auc: 0.8204 - val_loss: 0.4576 - val_auc: 0.8297\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4664 - auc: 0.8213 - val_loss: 0.4572 - val_auc: 0.8295\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8216 - val_loss: 0.4571 - val_auc: 0.8304\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8215 - val_loss: 0.4569 - val_auc: 0.8306\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4659 - auc: 0.8219 - val_loss: 0.4570 - val_auc: 0.8297\n",
      "Epoch 11/100\n",
      "277504/285001 [============================>.] - ETA: 0s - loss: 0.4659 - auc: 0.8216Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4660 - auc: 0.8216 - val_loss: 0.4569 - val_auc: 0.8302\n",
      "Epoch 00011: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6244 - auc: 0.7154 - val_loss: 0.5008 - val_auc: 0.7934\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5058 - auc: 0.7896 - val_loss: 0.4762 - val_auc: 0.8134\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4804 - auc: 0.8090 - val_loss: 0.4679 - val_auc: 0.8202\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4720 - auc: 0.8164 - val_loss: 0.4645 - val_auc: 0.8233\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4689 - auc: 0.8190 - val_loss: 0.4629 - val_auc: 0.8245\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4668 - auc: 0.8208 - val_loss: 0.4622 - val_auc: 0.8249\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4661 - auc: 0.8215 - val_loss: 0.4620 - val_auc: 0.8240\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4658 - auc: 0.8217 - val_loss: 0.4618 - val_auc: 0.8252\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4655 - auc: 0.8221 - val_loss: 0.4619 - val_auc: 0.8248\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4654 - auc: 0.8221 - val_loss: 0.4618 - val_auc: 0.8256\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4654 - auc: 0.8222 - val_loss: 0.4617 - val_auc: 0.8258\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4653 - auc: 0.8222 - val_loss: 0.4618 - val_auc: 0.8251\n",
      "Epoch 13/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4654 - auc: 0.8222 - val_loss: 0.4618 - val_auc: 0.8259\n",
      "Epoch 14/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4656 - auc: 0.8219\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4657 - auc: 0.8219 - val_loss: 0.4617 - val_auc: 0.8248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "280576/285001 [============================>.] - ETA: 0s - loss: 0.4654 - auc: 0.8221Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4653 - auc: 0.8223 - val_loss: 0.4618 - val_auc: 0.8261\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [5:07:18<3:47:03, 6811.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283884662973209\n",
      "0.826334745904025\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  24.2s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  24.5s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  24.5s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.6s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  24.2s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.7s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.7s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.7s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.8s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.7s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  24.4s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  24.5s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  24.4s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  24.5s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  24.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   6.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   6.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   6.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   6.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   6.2s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   9.0s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   9.4s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.9s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   9.1s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.9s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  32.4s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  33.0s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  33.3s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  38.7s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  33.1s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  10.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  10.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  10.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  10.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=  10.8s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   5.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   5.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   5.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   5.4s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   5.4s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  15.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  15.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  15.7s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  15.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  15.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  10.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  10.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  10.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  10.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=  10.4s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  23.0s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  22.9s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  23.4s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  23.4s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  23.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  20.8s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  20.3s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  20.2s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  20.5s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  19.9s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  26.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  24.7s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  24.4s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  24.6s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  24.5s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.4s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.4s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.5s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.4s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.5s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 18.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265253653627712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 58.2ms\tremaining: 58.1s\n",
      "1:\ttotal: 122ms\tremaining: 1m\n",
      "2:\ttotal: 192ms\tremaining: 1m 3s\n",
      "3:\ttotal: 265ms\tremaining: 1m 6s\n",
      "4:\ttotal: 331ms\tremaining: 1m 5s\n",
      "5:\ttotal: 395ms\tremaining: 1m 5s\n",
      "6:\ttotal: 446ms\tremaining: 1m 3s\n",
      "7:\ttotal: 512ms\tremaining: 1m 3s\n",
      "8:\ttotal: 565ms\tremaining: 1m 2s\n",
      "9:\ttotal: 621ms\tremaining: 1m 1s\n",
      "10:\ttotal: 673ms\tremaining: 1m\n",
      "11:\ttotal: 733ms\tremaining: 1m\n",
      "12:\ttotal: 789ms\tremaining: 59.9s\n",
      "13:\ttotal: 848ms\tremaining: 59.7s\n",
      "14:\ttotal: 900ms\tremaining: 59.1s\n",
      "15:\ttotal: 954ms\tremaining: 58.7s\n",
      "16:\ttotal: 1.01s\tremaining: 58.6s\n",
      "17:\ttotal: 1.08s\tremaining: 58.8s\n",
      "18:\ttotal: 1.14s\tremaining: 58.8s\n",
      "19:\ttotal: 1.2s\tremaining: 58.8s\n",
      "20:\ttotal: 1.26s\tremaining: 58.6s\n",
      "21:\ttotal: 1.31s\tremaining: 58.5s\n",
      "22:\ttotal: 1.37s\tremaining: 58s\n",
      "23:\ttotal: 1.43s\tremaining: 58s\n",
      "24:\ttotal: 1.48s\tremaining: 57.8s\n",
      "25:\ttotal: 1.54s\tremaining: 57.7s\n",
      "26:\ttotal: 1.6s\tremaining: 57.6s\n",
      "27:\ttotal: 1.66s\tremaining: 57.6s\n",
      "28:\ttotal: 1.71s\tremaining: 57.4s\n",
      "29:\ttotal: 1.78s\tremaining: 57.4s\n",
      "30:\ttotal: 1.83s\tremaining: 57.2s\n",
      "31:\ttotal: 1.89s\tremaining: 57.1s\n",
      "32:\ttotal: 1.95s\tremaining: 57s\n",
      "33:\ttotal: 2s\tremaining: 56.7s\n",
      "34:\ttotal: 2.05s\tremaining: 56.5s\n",
      "35:\ttotal: 2.11s\tremaining: 56.6s\n",
      "36:\ttotal: 2.17s\tremaining: 56.4s\n",
      "37:\ttotal: 2.22s\tremaining: 56.2s\n",
      "38:\ttotal: 2.28s\tremaining: 56.2s\n",
      "39:\ttotal: 2.35s\tremaining: 56.3s\n",
      "40:\ttotal: 2.4s\tremaining: 56.3s\n",
      "41:\ttotal: 2.46s\tremaining: 56.2s\n",
      "42:\ttotal: 2.52s\tremaining: 56.2s\n",
      "43:\ttotal: 2.59s\tremaining: 56.2s\n",
      "44:\ttotal: 2.64s\tremaining: 56s\n",
      "45:\ttotal: 2.69s\tremaining: 55.8s\n",
      "46:\ttotal: 2.74s\tremaining: 55.6s\n",
      "47:\ttotal: 2.79s\tremaining: 55.4s\n",
      "48:\ttotal: 2.85s\tremaining: 55.4s\n",
      "49:\ttotal: 2.91s\tremaining: 55.3s\n",
      "50:\ttotal: 2.97s\tremaining: 55.3s\n",
      "51:\ttotal: 3.03s\tremaining: 55.3s\n",
      "52:\ttotal: 3.1s\tremaining: 55.3s\n",
      "53:\ttotal: 3.15s\tremaining: 55.1s\n",
      "54:\ttotal: 3.21s\tremaining: 55.1s\n",
      "55:\ttotal: 3.27s\tremaining: 55.1s\n",
      "56:\ttotal: 3.33s\tremaining: 55.1s\n",
      "57:\ttotal: 3.4s\tremaining: 55.2s\n",
      "58:\ttotal: 3.47s\tremaining: 55.3s\n",
      "59:\ttotal: 3.52s\tremaining: 55.2s\n",
      "60:\ttotal: 3.58s\tremaining: 55.1s\n",
      "61:\ttotal: 3.63s\tremaining: 54.9s\n",
      "62:\ttotal: 3.69s\tremaining: 54.8s\n",
      "63:\ttotal: 3.75s\tremaining: 54.9s\n",
      "64:\ttotal: 3.81s\tremaining: 54.7s\n",
      "65:\ttotal: 3.87s\tremaining: 54.7s\n",
      "66:\ttotal: 3.92s\tremaining: 54.5s\n",
      "67:\ttotal: 3.98s\tremaining: 54.6s\n",
      "68:\ttotal: 4.04s\tremaining: 54.5s\n",
      "69:\ttotal: 4.1s\tremaining: 54.5s\n",
      "70:\ttotal: 4.15s\tremaining: 54.3s\n",
      "71:\ttotal: 4.21s\tremaining: 54.3s\n",
      "72:\ttotal: 4.26s\tremaining: 54.1s\n",
      "73:\ttotal: 4.31s\tremaining: 54s\n",
      "74:\ttotal: 4.37s\tremaining: 53.9s\n",
      "75:\ttotal: 4.44s\tremaining: 54s\n",
      "76:\ttotal: 4.5s\tremaining: 54s\n",
      "77:\ttotal: 4.56s\tremaining: 53.9s\n",
      "78:\ttotal: 4.61s\tremaining: 53.8s\n",
      "79:\ttotal: 4.67s\tremaining: 53.8s\n",
      "80:\ttotal: 4.73s\tremaining: 53.7s\n",
      "81:\ttotal: 4.79s\tremaining: 53.6s\n",
      "82:\ttotal: 4.84s\tremaining: 53.5s\n",
      "83:\ttotal: 4.91s\tremaining: 53.5s\n",
      "84:\ttotal: 4.97s\tremaining: 53.5s\n",
      "85:\ttotal: 5.02s\tremaining: 53.4s\n",
      "86:\ttotal: 5.07s\tremaining: 53.3s\n",
      "87:\ttotal: 5.13s\tremaining: 53.2s\n",
      "88:\ttotal: 5.19s\tremaining: 53.1s\n",
      "89:\ttotal: 5.24s\tremaining: 53s\n",
      "90:\ttotal: 5.29s\tremaining: 52.8s\n",
      "91:\ttotal: 5.36s\tremaining: 52.9s\n",
      "92:\ttotal: 5.42s\tremaining: 52.9s\n",
      "93:\ttotal: 5.49s\tremaining: 52.9s\n",
      "94:\ttotal: 5.54s\tremaining: 52.7s\n",
      "95:\ttotal: 5.59s\tremaining: 52.7s\n",
      "96:\ttotal: 5.64s\tremaining: 52.5s\n",
      "97:\ttotal: 5.71s\tremaining: 52.5s\n",
      "98:\ttotal: 5.76s\tremaining: 52.4s\n",
      "99:\ttotal: 5.82s\tremaining: 52.4s\n",
      "100:\ttotal: 5.88s\tremaining: 52.3s\n",
      "101:\ttotal: 5.92s\tremaining: 52.2s\n",
      "102:\ttotal: 5.99s\tremaining: 52.1s\n",
      "103:\ttotal: 6.05s\tremaining: 52.1s\n",
      "104:\ttotal: 6.11s\tremaining: 52.1s\n",
      "105:\ttotal: 6.16s\tremaining: 51.9s\n",
      "106:\ttotal: 6.21s\tremaining: 51.9s\n",
      "107:\ttotal: 6.27s\tremaining: 51.8s\n",
      "108:\ttotal: 6.33s\tremaining: 51.7s\n",
      "109:\ttotal: 6.39s\tremaining: 51.7s\n",
      "110:\ttotal: 6.45s\tremaining: 51.6s\n",
      "111:\ttotal: 6.51s\tremaining: 51.6s\n",
      "112:\ttotal: 6.57s\tremaining: 51.6s\n",
      "113:\ttotal: 6.62s\tremaining: 51.5s\n",
      "114:\ttotal: 6.68s\tremaining: 51.4s\n",
      "115:\ttotal: 6.74s\tremaining: 51.4s\n",
      "116:\ttotal: 6.79s\tremaining: 51.3s\n",
      "117:\ttotal: 6.84s\tremaining: 51.2s\n",
      "118:\ttotal: 6.9s\tremaining: 51.1s\n",
      "119:\ttotal: 6.96s\tremaining: 51s\n",
      "120:\ttotal: 7.02s\tremaining: 51s\n",
      "121:\ttotal: 7.07s\tremaining: 50.9s\n",
      "122:\ttotal: 7.14s\tremaining: 50.9s\n",
      "123:\ttotal: 7.2s\tremaining: 50.9s\n",
      "124:\ttotal: 7.25s\tremaining: 50.8s\n",
      "125:\ttotal: 7.3s\tremaining: 50.7s\n",
      "126:\ttotal: 7.36s\tremaining: 50.6s\n",
      "127:\ttotal: 7.43s\tremaining: 50.6s\n",
      "128:\ttotal: 7.48s\tremaining: 50.5s\n",
      "129:\ttotal: 7.54s\tremaining: 50.5s\n",
      "130:\ttotal: 7.6s\tremaining: 50.4s\n",
      "131:\ttotal: 7.67s\tremaining: 50.4s\n",
      "132:\ttotal: 7.72s\tremaining: 50.3s\n",
      "133:\ttotal: 7.78s\tremaining: 50.3s\n",
      "134:\ttotal: 7.83s\tremaining: 50.1s\n",
      "135:\ttotal: 7.89s\tremaining: 50.1s\n",
      "136:\ttotal: 7.94s\tremaining: 50s\n",
      "137:\ttotal: 8s\tremaining: 50s\n",
      "138:\ttotal: 8.05s\tremaining: 49.9s\n",
      "139:\ttotal: 8.11s\tremaining: 49.8s\n",
      "140:\ttotal: 8.17s\tremaining: 49.8s\n",
      "141:\ttotal: 8.22s\tremaining: 49.7s\n",
      "142:\ttotal: 8.28s\tremaining: 49.6s\n",
      "143:\ttotal: 8.34s\tremaining: 49.6s\n",
      "144:\ttotal: 8.39s\tremaining: 49.5s\n",
      "145:\ttotal: 8.45s\tremaining: 49.4s\n",
      "146:\ttotal: 8.5s\tremaining: 49.3s\n",
      "147:\ttotal: 8.56s\tremaining: 49.3s\n",
      "148:\ttotal: 8.61s\tremaining: 49.2s\n",
      "149:\ttotal: 8.66s\tremaining: 49.1s\n",
      "150:\ttotal: 8.72s\tremaining: 49s\n",
      "151:\ttotal: 8.78s\tremaining: 49s\n",
      "152:\ttotal: 8.83s\tremaining: 48.9s\n",
      "153:\ttotal: 8.89s\tremaining: 48.8s\n",
      "154:\ttotal: 8.94s\tremaining: 48.7s\n",
      "155:\ttotal: 9.01s\tremaining: 48.7s\n",
      "156:\ttotal: 9.06s\tremaining: 48.7s\n",
      "157:\ttotal: 9.13s\tremaining: 48.6s\n",
      "158:\ttotal: 9.18s\tremaining: 48.6s\n",
      "159:\ttotal: 9.25s\tremaining: 48.5s\n",
      "160:\ttotal: 9.3s\tremaining: 48.5s\n",
      "161:\ttotal: 9.35s\tremaining: 48.3s\n",
      "162:\ttotal: 9.4s\tremaining: 48.3s\n",
      "163:\ttotal: 9.46s\tremaining: 48.2s\n",
      "164:\ttotal: 9.52s\tremaining: 48.2s\n",
      "165:\ttotal: 9.57s\tremaining: 48.1s\n",
      "166:\ttotal: 9.62s\tremaining: 48s\n",
      "167:\ttotal: 9.69s\tremaining: 48s\n",
      "168:\ttotal: 9.76s\tremaining: 48s\n",
      "169:\ttotal: 9.81s\tremaining: 47.9s\n",
      "170:\ttotal: 9.86s\tremaining: 47.8s\n",
      "171:\ttotal: 9.92s\tremaining: 47.8s\n",
      "172:\ttotal: 9.97s\tremaining: 47.7s\n",
      "173:\ttotal: 10s\tremaining: 47.6s\n",
      "174:\ttotal: 10.1s\tremaining: 47.5s\n",
      "175:\ttotal: 10.2s\tremaining: 47.5s\n",
      "176:\ttotal: 10.2s\tremaining: 47.5s\n",
      "177:\ttotal: 10.3s\tremaining: 47.4s\n",
      "178:\ttotal: 10.3s\tremaining: 47.3s\n",
      "179:\ttotal: 10.4s\tremaining: 47.2s\n",
      "180:\ttotal: 10.4s\tremaining: 47.2s\n",
      "181:\ttotal: 10.5s\tremaining: 47.1s\n",
      "182:\ttotal: 10.5s\tremaining: 47s\n",
      "183:\ttotal: 10.6s\tremaining: 46.9s\n",
      "184:\ttotal: 10.6s\tremaining: 46.9s\n",
      "185:\ttotal: 10.7s\tremaining: 46.8s\n",
      "186:\ttotal: 10.8s\tremaining: 46.8s\n",
      "187:\ttotal: 10.8s\tremaining: 46.7s\n",
      "188:\ttotal: 10.9s\tremaining: 46.7s\n",
      "189:\ttotal: 10.9s\tremaining: 46.7s\n",
      "190:\ttotal: 11s\tremaining: 46.6s\n",
      "191:\ttotal: 11.1s\tremaining: 46.5s\n",
      "192:\ttotal: 11.1s\tremaining: 46.5s\n",
      "193:\ttotal: 11.2s\tremaining: 46.4s\n",
      "194:\ttotal: 11.2s\tremaining: 46.4s\n",
      "195:\ttotal: 11.3s\tremaining: 46.3s\n",
      "196:\ttotal: 11.4s\tremaining: 46.3s\n",
      "197:\ttotal: 11.4s\tremaining: 46.2s\n",
      "198:\ttotal: 11.5s\tremaining: 46.2s\n",
      "199:\ttotal: 11.5s\tremaining: 46.1s\n",
      "200:\ttotal: 11.6s\tremaining: 46.1s\n",
      "201:\ttotal: 11.6s\tremaining: 46s\n",
      "202:\ttotal: 11.7s\tremaining: 45.9s\n",
      "203:\ttotal: 11.8s\tremaining: 45.9s\n",
      "204:\ttotal: 11.8s\tremaining: 45.9s\n",
      "205:\ttotal: 11.9s\tremaining: 45.8s\n",
      "206:\ttotal: 11.9s\tremaining: 45.7s\n",
      "207:\ttotal: 12s\tremaining: 45.7s\n",
      "208:\ttotal: 12.1s\tremaining: 45.6s\n",
      "209:\ttotal: 12.1s\tremaining: 45.6s\n",
      "210:\ttotal: 12.2s\tremaining: 45.5s\n",
      "211:\ttotal: 12.2s\tremaining: 45.4s\n",
      "212:\ttotal: 12.3s\tremaining: 45.4s\n",
      "213:\ttotal: 12.3s\tremaining: 45.3s\n",
      "214:\ttotal: 12.4s\tremaining: 45.2s\n",
      "215:\ttotal: 12.5s\tremaining: 45.2s\n",
      "216:\ttotal: 12.5s\tremaining: 45.2s\n",
      "217:\ttotal: 12.6s\tremaining: 45.1s\n",
      "218:\ttotal: 12.6s\tremaining: 45s\n",
      "219:\ttotal: 12.7s\tremaining: 45s\n",
      "220:\ttotal: 12.7s\tremaining: 44.9s\n",
      "221:\ttotal: 12.8s\tremaining: 44.8s\n",
      "222:\ttotal: 12.8s\tremaining: 44.7s\n",
      "223:\ttotal: 12.9s\tremaining: 44.7s\n",
      "224:\ttotal: 13s\tremaining: 44.6s\n",
      "225:\ttotal: 13s\tremaining: 44.6s\n",
      "226:\ttotal: 13.1s\tremaining: 44.5s\n",
      "227:\ttotal: 13.1s\tremaining: 44.4s\n",
      "228:\ttotal: 13.2s\tremaining: 44.4s\n",
      "229:\ttotal: 13.2s\tremaining: 44.3s\n",
      "230:\ttotal: 13.3s\tremaining: 44.2s\n",
      "231:\ttotal: 13.3s\tremaining: 44.2s\n",
      "232:\ttotal: 13.4s\tremaining: 44.1s\n",
      "233:\ttotal: 13.4s\tremaining: 44s\n",
      "234:\ttotal: 13.5s\tremaining: 43.9s\n",
      "235:\ttotal: 13.5s\tremaining: 43.8s\n",
      "236:\ttotal: 13.6s\tremaining: 43.8s\n",
      "237:\ttotal: 13.7s\tremaining: 43.7s\n",
      "238:\ttotal: 13.7s\tremaining: 43.7s\n",
      "239:\ttotal: 13.8s\tremaining: 43.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240:\ttotal: 13.8s\tremaining: 43.5s\n",
      "241:\ttotal: 13.9s\tremaining: 43.5s\n",
      "242:\ttotal: 14s\tremaining: 43.5s\n",
      "243:\ttotal: 14s\tremaining: 43.4s\n",
      "244:\ttotal: 14.1s\tremaining: 43.4s\n",
      "245:\ttotal: 14.1s\tremaining: 43.3s\n",
      "246:\ttotal: 14.2s\tremaining: 43.2s\n",
      "247:\ttotal: 14.2s\tremaining: 43.2s\n",
      "248:\ttotal: 14.3s\tremaining: 43.1s\n",
      "249:\ttotal: 14.4s\tremaining: 43.1s\n",
      "250:\ttotal: 14.4s\tremaining: 43s\n",
      "251:\ttotal: 14.5s\tremaining: 43s\n",
      "252:\ttotal: 14.5s\tremaining: 42.9s\n",
      "253:\ttotal: 14.6s\tremaining: 42.9s\n",
      "254:\ttotal: 14.6s\tremaining: 42.8s\n",
      "255:\ttotal: 14.7s\tremaining: 42.7s\n",
      "256:\ttotal: 14.8s\tremaining: 42.7s\n",
      "257:\ttotal: 14.8s\tremaining: 42.6s\n",
      "258:\ttotal: 14.9s\tremaining: 42.5s\n",
      "259:\ttotal: 14.9s\tremaining: 42.5s\n",
      "260:\ttotal: 15s\tremaining: 42.4s\n",
      "261:\ttotal: 15s\tremaining: 42.4s\n",
      "262:\ttotal: 15.1s\tremaining: 42.3s\n",
      "263:\ttotal: 15.1s\tremaining: 42.2s\n",
      "264:\ttotal: 15.2s\tremaining: 42.1s\n",
      "265:\ttotal: 15.2s\tremaining: 42.1s\n",
      "266:\ttotal: 15.3s\tremaining: 42s\n",
      "267:\ttotal: 15.4s\tremaining: 41.9s\n",
      "268:\ttotal: 15.4s\tremaining: 41.9s\n",
      "269:\ttotal: 15.5s\tremaining: 41.8s\n",
      "270:\ttotal: 15.5s\tremaining: 41.8s\n",
      "271:\ttotal: 15.6s\tremaining: 41.7s\n",
      "272:\ttotal: 15.6s\tremaining: 41.7s\n",
      "273:\ttotal: 15.7s\tremaining: 41.6s\n",
      "274:\ttotal: 15.8s\tremaining: 41.5s\n",
      "275:\ttotal: 15.8s\tremaining: 41.5s\n",
      "276:\ttotal: 15.9s\tremaining: 41.4s\n",
      "277:\ttotal: 15.9s\tremaining: 41.4s\n",
      "278:\ttotal: 16s\tremaining: 41.3s\n",
      "279:\ttotal: 16s\tremaining: 41.2s\n",
      "280:\ttotal: 16.1s\tremaining: 41.2s\n",
      "281:\ttotal: 16.2s\tremaining: 41.2s\n",
      "282:\ttotal: 16.2s\tremaining: 41.1s\n",
      "283:\ttotal: 16.3s\tremaining: 41s\n",
      "284:\ttotal: 16.3s\tremaining: 41s\n",
      "285:\ttotal: 16.4s\tremaining: 40.9s\n",
      "286:\ttotal: 16.4s\tremaining: 40.9s\n",
      "287:\ttotal: 16.5s\tremaining: 40.8s\n",
      "288:\ttotal: 16.6s\tremaining: 40.7s\n",
      "289:\ttotal: 16.6s\tremaining: 40.7s\n",
      "290:\ttotal: 16.7s\tremaining: 40.6s\n",
      "291:\ttotal: 16.7s\tremaining: 40.5s\n",
      "292:\ttotal: 16.8s\tremaining: 40.5s\n",
      "293:\ttotal: 16.8s\tremaining: 40.4s\n",
      "294:\ttotal: 16.9s\tremaining: 40.4s\n",
      "295:\ttotal: 17s\tremaining: 40.3s\n",
      "296:\ttotal: 17s\tremaining: 40.3s\n",
      "297:\ttotal: 17.1s\tremaining: 40.2s\n",
      "298:\ttotal: 17.1s\tremaining: 40.2s\n",
      "299:\ttotal: 17.2s\tremaining: 40.1s\n",
      "300:\ttotal: 17.3s\tremaining: 40.1s\n",
      "301:\ttotal: 17.3s\tremaining: 40s\n",
      "302:\ttotal: 17.4s\tremaining: 39.9s\n",
      "303:\ttotal: 17.4s\tremaining: 39.9s\n",
      "304:\ttotal: 17.5s\tremaining: 39.8s\n",
      "305:\ttotal: 17.5s\tremaining: 39.7s\n",
      "306:\ttotal: 17.6s\tremaining: 39.7s\n",
      "307:\ttotal: 17.6s\tremaining: 39.6s\n",
      "308:\ttotal: 17.7s\tremaining: 39.5s\n",
      "309:\ttotal: 17.7s\tremaining: 39.5s\n",
      "310:\ttotal: 17.8s\tremaining: 39.4s\n",
      "311:\ttotal: 17.8s\tremaining: 39.3s\n",
      "312:\ttotal: 17.9s\tremaining: 39.3s\n",
      "313:\ttotal: 18s\tremaining: 39.2s\n",
      "314:\ttotal: 18s\tremaining: 39.2s\n",
      "315:\ttotal: 18.1s\tremaining: 39.1s\n",
      "316:\ttotal: 18.1s\tremaining: 39s\n",
      "317:\ttotal: 18.2s\tremaining: 39s\n",
      "318:\ttotal: 18.2s\tremaining: 38.9s\n",
      "319:\ttotal: 18.3s\tremaining: 38.8s\n",
      "320:\ttotal: 18.3s\tremaining: 38.8s\n",
      "321:\ttotal: 18.4s\tremaining: 38.7s\n",
      "322:\ttotal: 18.4s\tremaining: 38.7s\n",
      "323:\ttotal: 18.5s\tremaining: 38.6s\n",
      "324:\ttotal: 18.6s\tremaining: 38.6s\n",
      "325:\ttotal: 18.6s\tremaining: 38.5s\n",
      "326:\ttotal: 18.7s\tremaining: 38.4s\n",
      "327:\ttotal: 18.7s\tremaining: 38.4s\n",
      "328:\ttotal: 18.8s\tremaining: 38.3s\n",
      "329:\ttotal: 18.9s\tremaining: 38.3s\n",
      "330:\ttotal: 18.9s\tremaining: 38.2s\n",
      "331:\ttotal: 18.9s\tremaining: 38.1s\n",
      "332:\ttotal: 19s\tremaining: 38.1s\n",
      "333:\ttotal: 19.1s\tremaining: 38s\n",
      "334:\ttotal: 19.1s\tremaining: 38s\n",
      "335:\ttotal: 19.2s\tremaining: 37.9s\n",
      "336:\ttotal: 19.2s\tremaining: 37.9s\n",
      "337:\ttotal: 19.3s\tremaining: 37.8s\n",
      "338:\ttotal: 19.3s\tremaining: 37.7s\n",
      "339:\ttotal: 19.4s\tremaining: 37.7s\n",
      "340:\ttotal: 19.5s\tremaining: 37.6s\n",
      "341:\ttotal: 19.5s\tremaining: 37.5s\n",
      "342:\ttotal: 19.6s\tremaining: 37.5s\n",
      "343:\ttotal: 19.6s\tremaining: 37.4s\n",
      "344:\ttotal: 19.7s\tremaining: 37.4s\n",
      "345:\ttotal: 19.7s\tremaining: 37.3s\n",
      "346:\ttotal: 19.8s\tremaining: 37.2s\n",
      "347:\ttotal: 19.8s\tremaining: 37.2s\n",
      "348:\ttotal: 19.9s\tremaining: 37.1s\n",
      "349:\ttotal: 20s\tremaining: 37.1s\n",
      "350:\ttotal: 20s\tremaining: 37s\n",
      "351:\ttotal: 20.1s\tremaining: 36.9s\n",
      "352:\ttotal: 20.1s\tremaining: 36.9s\n",
      "353:\ttotal: 20.2s\tremaining: 36.8s\n",
      "354:\ttotal: 20.2s\tremaining: 36.8s\n",
      "355:\ttotal: 20.3s\tremaining: 36.7s\n",
      "356:\ttotal: 20.3s\tremaining: 36.6s\n",
      "357:\ttotal: 20.4s\tremaining: 36.6s\n",
      "358:\ttotal: 20.4s\tremaining: 36.5s\n",
      "359:\ttotal: 20.5s\tremaining: 36.4s\n",
      "360:\ttotal: 20.6s\tremaining: 36.4s\n",
      "361:\ttotal: 20.6s\tremaining: 36.3s\n",
      "362:\ttotal: 20.7s\tremaining: 36.3s\n",
      "363:\ttotal: 20.7s\tremaining: 36.2s\n",
      "364:\ttotal: 20.8s\tremaining: 36.2s\n",
      "365:\ttotal: 20.9s\tremaining: 36.1s\n",
      "366:\ttotal: 20.9s\tremaining: 36.1s\n",
      "367:\ttotal: 21s\tremaining: 36s\n",
      "368:\ttotal: 21s\tremaining: 36s\n",
      "369:\ttotal: 21.1s\tremaining: 35.9s\n",
      "370:\ttotal: 21.2s\tremaining: 35.9s\n",
      "371:\ttotal: 21.2s\tremaining: 35.8s\n",
      "372:\ttotal: 21.3s\tremaining: 35.8s\n",
      "373:\ttotal: 21.3s\tremaining: 35.7s\n",
      "374:\ttotal: 21.4s\tremaining: 35.6s\n",
      "375:\ttotal: 21.4s\tremaining: 35.6s\n",
      "376:\ttotal: 21.5s\tremaining: 35.5s\n",
      "377:\ttotal: 21.5s\tremaining: 35.4s\n",
      "378:\ttotal: 21.6s\tremaining: 35.4s\n",
      "379:\ttotal: 21.7s\tremaining: 35.4s\n",
      "380:\ttotal: 21.7s\tremaining: 35.3s\n",
      "381:\ttotal: 21.8s\tremaining: 35.3s\n",
      "382:\ttotal: 21.9s\tremaining: 35.2s\n",
      "383:\ttotal: 21.9s\tremaining: 35.1s\n",
      "384:\ttotal: 22s\tremaining: 35.1s\n",
      "385:\ttotal: 22s\tremaining: 35s\n",
      "386:\ttotal: 22.1s\tremaining: 35s\n",
      "387:\ttotal: 22.1s\tremaining: 34.9s\n",
      "388:\ttotal: 22.2s\tremaining: 34.9s\n",
      "389:\ttotal: 22.3s\tremaining: 34.8s\n",
      "390:\ttotal: 22.3s\tremaining: 34.8s\n",
      "391:\ttotal: 22.4s\tremaining: 34.7s\n",
      "392:\ttotal: 22.5s\tremaining: 34.7s\n",
      "393:\ttotal: 22.5s\tremaining: 34.6s\n",
      "394:\ttotal: 22.6s\tremaining: 34.6s\n",
      "395:\ttotal: 22.6s\tremaining: 34.5s\n",
      "396:\ttotal: 22.7s\tremaining: 34.5s\n",
      "397:\ttotal: 22.8s\tremaining: 34.4s\n",
      "398:\ttotal: 22.8s\tremaining: 34.4s\n",
      "399:\ttotal: 22.9s\tremaining: 34.3s\n",
      "400:\ttotal: 22.9s\tremaining: 34.2s\n",
      "401:\ttotal: 23s\tremaining: 34.2s\n",
      "402:\ttotal: 23s\tremaining: 34.1s\n",
      "403:\ttotal: 23.1s\tremaining: 34.1s\n",
      "404:\ttotal: 23.2s\tremaining: 34s\n",
      "405:\ttotal: 23.2s\tremaining: 34s\n",
      "406:\ttotal: 23.3s\tremaining: 33.9s\n",
      "407:\ttotal: 23.3s\tremaining: 33.9s\n",
      "408:\ttotal: 23.4s\tremaining: 33.8s\n",
      "409:\ttotal: 23.4s\tremaining: 33.7s\n",
      "410:\ttotal: 23.5s\tremaining: 33.6s\n",
      "411:\ttotal: 23.5s\tremaining: 33.6s\n",
      "412:\ttotal: 23.6s\tremaining: 33.5s\n",
      "413:\ttotal: 23.6s\tremaining: 33.5s\n",
      "414:\ttotal: 23.7s\tremaining: 33.4s\n",
      "415:\ttotal: 23.8s\tremaining: 33.4s\n",
      "416:\ttotal: 23.8s\tremaining: 33.3s\n",
      "417:\ttotal: 23.9s\tremaining: 33.2s\n",
      "418:\ttotal: 23.9s\tremaining: 33.2s\n",
      "419:\ttotal: 24s\tremaining: 33.1s\n",
      "420:\ttotal: 24s\tremaining: 33.1s\n",
      "421:\ttotal: 24.1s\tremaining: 33s\n",
      "422:\ttotal: 24.2s\tremaining: 33s\n",
      "423:\ttotal: 24.2s\tremaining: 32.9s\n",
      "424:\ttotal: 24.3s\tremaining: 32.8s\n",
      "425:\ttotal: 24.3s\tremaining: 32.8s\n",
      "426:\ttotal: 24.4s\tremaining: 32.7s\n",
      "427:\ttotal: 24.4s\tremaining: 32.7s\n",
      "428:\ttotal: 24.5s\tremaining: 32.6s\n",
      "429:\ttotal: 24.5s\tremaining: 32.5s\n",
      "430:\ttotal: 24.6s\tremaining: 32.5s\n",
      "431:\ttotal: 24.7s\tremaining: 32.4s\n",
      "432:\ttotal: 24.7s\tremaining: 32.4s\n",
      "433:\ttotal: 24.8s\tremaining: 32.3s\n",
      "434:\ttotal: 24.8s\tremaining: 32.3s\n",
      "435:\ttotal: 24.9s\tremaining: 32.2s\n",
      "436:\ttotal: 25s\tremaining: 32.2s\n",
      "437:\ttotal: 25s\tremaining: 32.1s\n",
      "438:\ttotal: 25.1s\tremaining: 32s\n",
      "439:\ttotal: 25.1s\tremaining: 32s\n",
      "440:\ttotal: 25.2s\tremaining: 31.9s\n",
      "441:\ttotal: 25.3s\tremaining: 31.9s\n",
      "442:\ttotal: 25.3s\tremaining: 31.8s\n",
      "443:\ttotal: 25.4s\tremaining: 31.8s\n",
      "444:\ttotal: 25.4s\tremaining: 31.7s\n",
      "445:\ttotal: 25.5s\tremaining: 31.7s\n",
      "446:\ttotal: 25.6s\tremaining: 31.6s\n",
      "447:\ttotal: 25.6s\tremaining: 31.5s\n",
      "448:\ttotal: 25.7s\tremaining: 31.5s\n",
      "449:\ttotal: 25.7s\tremaining: 31.4s\n",
      "450:\ttotal: 25.8s\tremaining: 31.4s\n",
      "451:\ttotal: 25.8s\tremaining: 31.3s\n",
      "452:\ttotal: 25.9s\tremaining: 31.3s\n",
      "453:\ttotal: 25.9s\tremaining: 31.2s\n",
      "454:\ttotal: 26s\tremaining: 31.2s\n",
      "455:\ttotal: 26.1s\tremaining: 31.1s\n",
      "456:\ttotal: 26.1s\tremaining: 31s\n",
      "457:\ttotal: 26.2s\tremaining: 31s\n",
      "458:\ttotal: 26.2s\tremaining: 30.9s\n",
      "459:\ttotal: 26.3s\tremaining: 30.9s\n",
      "460:\ttotal: 26.3s\tremaining: 30.8s\n",
      "461:\ttotal: 26.4s\tremaining: 30.7s\n",
      "462:\ttotal: 26.5s\tremaining: 30.7s\n",
      "463:\ttotal: 26.5s\tremaining: 30.6s\n",
      "464:\ttotal: 26.6s\tremaining: 30.6s\n",
      "465:\ttotal: 26.6s\tremaining: 30.5s\n",
      "466:\ttotal: 26.7s\tremaining: 30.4s\n",
      "467:\ttotal: 26.7s\tremaining: 30.4s\n",
      "468:\ttotal: 26.8s\tremaining: 30.3s\n",
      "469:\ttotal: 26.8s\tremaining: 30.3s\n",
      "470:\ttotal: 26.9s\tremaining: 30.2s\n",
      "471:\ttotal: 26.9s\tremaining: 30.1s\n",
      "472:\ttotal: 27s\tremaining: 30.1s\n",
      "473:\ttotal: 27.1s\tremaining: 30s\n",
      "474:\ttotal: 27.1s\tremaining: 30s\n",
      "475:\ttotal: 27.2s\tremaining: 29.9s\n",
      "476:\ttotal: 27.2s\tremaining: 29.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477:\ttotal: 27.3s\tremaining: 29.8s\n",
      "478:\ttotal: 27.4s\tremaining: 29.8s\n",
      "479:\ttotal: 27.4s\tremaining: 29.7s\n",
      "480:\ttotal: 27.5s\tremaining: 29.6s\n",
      "481:\ttotal: 27.5s\tremaining: 29.6s\n",
      "482:\ttotal: 27.6s\tremaining: 29.5s\n",
      "483:\ttotal: 27.6s\tremaining: 29.5s\n",
      "484:\ttotal: 27.7s\tremaining: 29.4s\n",
      "485:\ttotal: 27.8s\tremaining: 29.4s\n",
      "486:\ttotal: 27.8s\tremaining: 29.3s\n",
      "487:\ttotal: 27.9s\tremaining: 29.2s\n",
      "488:\ttotal: 27.9s\tremaining: 29.2s\n",
      "489:\ttotal: 28s\tremaining: 29.1s\n",
      "490:\ttotal: 28s\tremaining: 29s\n",
      "491:\ttotal: 28.1s\tremaining: 29s\n",
      "492:\ttotal: 28.1s\tremaining: 28.9s\n",
      "493:\ttotal: 28.2s\tremaining: 28.9s\n",
      "494:\ttotal: 28.2s\tremaining: 28.8s\n",
      "495:\ttotal: 28.3s\tremaining: 28.7s\n",
      "496:\ttotal: 28.3s\tremaining: 28.7s\n",
      "497:\ttotal: 28.4s\tremaining: 28.6s\n",
      "498:\ttotal: 28.5s\tremaining: 28.6s\n",
      "499:\ttotal: 28.5s\tremaining: 28.5s\n",
      "500:\ttotal: 28.6s\tremaining: 28.4s\n",
      "501:\ttotal: 28.6s\tremaining: 28.4s\n",
      "502:\ttotal: 28.7s\tremaining: 28.3s\n",
      "503:\ttotal: 28.7s\tremaining: 28.3s\n",
      "504:\ttotal: 28.8s\tremaining: 28.2s\n",
      "505:\ttotal: 28.8s\tremaining: 28.2s\n",
      "506:\ttotal: 28.9s\tremaining: 28.1s\n",
      "507:\ttotal: 29s\tremaining: 28s\n",
      "508:\ttotal: 29s\tremaining: 28s\n",
      "509:\ttotal: 29.1s\tremaining: 27.9s\n",
      "510:\ttotal: 29.1s\tremaining: 27.9s\n",
      "511:\ttotal: 29.2s\tremaining: 27.8s\n",
      "512:\ttotal: 29.2s\tremaining: 27.7s\n",
      "513:\ttotal: 29.3s\tremaining: 27.7s\n",
      "514:\ttotal: 29.3s\tremaining: 27.6s\n",
      "515:\ttotal: 29.4s\tremaining: 27.6s\n",
      "516:\ttotal: 29.5s\tremaining: 27.5s\n",
      "517:\ttotal: 29.5s\tremaining: 27.5s\n",
      "518:\ttotal: 29.6s\tremaining: 27.4s\n",
      "519:\ttotal: 29.6s\tremaining: 27.4s\n",
      "520:\ttotal: 29.7s\tremaining: 27.3s\n",
      "521:\ttotal: 29.7s\tremaining: 27.2s\n",
      "522:\ttotal: 29.8s\tremaining: 27.2s\n",
      "523:\ttotal: 29.8s\tremaining: 27.1s\n",
      "524:\ttotal: 29.9s\tremaining: 27s\n",
      "525:\ttotal: 29.9s\tremaining: 27s\n",
      "526:\ttotal: 30s\tremaining: 26.9s\n",
      "527:\ttotal: 30.1s\tremaining: 26.9s\n",
      "528:\ttotal: 30.1s\tremaining: 26.8s\n",
      "529:\ttotal: 30.2s\tremaining: 26.8s\n",
      "530:\ttotal: 30.2s\tremaining: 26.7s\n",
      "531:\ttotal: 30.3s\tremaining: 26.6s\n",
      "532:\ttotal: 30.3s\tremaining: 26.6s\n",
      "533:\ttotal: 30.4s\tremaining: 26.5s\n",
      "534:\ttotal: 30.4s\tremaining: 26.5s\n",
      "535:\ttotal: 30.5s\tremaining: 26.4s\n",
      "536:\ttotal: 30.6s\tremaining: 26.3s\n",
      "537:\ttotal: 30.6s\tremaining: 26.3s\n",
      "538:\ttotal: 30.7s\tremaining: 26.2s\n",
      "539:\ttotal: 30.7s\tremaining: 26.2s\n",
      "540:\ttotal: 30.8s\tremaining: 26.1s\n",
      "541:\ttotal: 30.9s\tremaining: 26.1s\n",
      "542:\ttotal: 30.9s\tremaining: 26s\n",
      "543:\ttotal: 31s\tremaining: 26s\n",
      "544:\ttotal: 31.1s\tremaining: 25.9s\n",
      "545:\ttotal: 31.1s\tremaining: 25.9s\n",
      "546:\ttotal: 31.2s\tremaining: 25.8s\n",
      "547:\ttotal: 31.2s\tremaining: 25.8s\n",
      "548:\ttotal: 31.3s\tremaining: 25.7s\n",
      "549:\ttotal: 31.4s\tremaining: 25.6s\n",
      "550:\ttotal: 31.4s\tremaining: 25.6s\n",
      "551:\ttotal: 31.5s\tremaining: 25.5s\n",
      "552:\ttotal: 31.5s\tremaining: 25.5s\n",
      "553:\ttotal: 31.6s\tremaining: 25.4s\n",
      "554:\ttotal: 31.6s\tremaining: 25.4s\n",
      "555:\ttotal: 31.7s\tremaining: 25.3s\n",
      "556:\ttotal: 31.7s\tremaining: 25.2s\n",
      "557:\ttotal: 31.8s\tremaining: 25.2s\n",
      "558:\ttotal: 31.9s\tremaining: 25.1s\n",
      "559:\ttotal: 31.9s\tremaining: 25.1s\n",
      "560:\ttotal: 32s\tremaining: 25s\n",
      "561:\ttotal: 32s\tremaining: 25s\n",
      "562:\ttotal: 32.1s\tremaining: 24.9s\n",
      "563:\ttotal: 32.2s\tremaining: 24.9s\n",
      "564:\ttotal: 32.2s\tremaining: 24.8s\n",
      "565:\ttotal: 32.3s\tremaining: 24.7s\n",
      "566:\ttotal: 32.3s\tremaining: 24.7s\n",
      "567:\ttotal: 32.4s\tremaining: 24.6s\n",
      "568:\ttotal: 32.4s\tremaining: 24.6s\n",
      "569:\ttotal: 32.5s\tremaining: 24.5s\n",
      "570:\ttotal: 32.6s\tremaining: 24.5s\n",
      "571:\ttotal: 32.6s\tremaining: 24.4s\n",
      "572:\ttotal: 32.7s\tremaining: 24.3s\n",
      "573:\ttotal: 32.7s\tremaining: 24.3s\n",
      "574:\ttotal: 32.8s\tremaining: 24.2s\n",
      "575:\ttotal: 32.8s\tremaining: 24.2s\n",
      "576:\ttotal: 32.9s\tremaining: 24.1s\n",
      "577:\ttotal: 32.9s\tremaining: 24.1s\n",
      "578:\ttotal: 33s\tremaining: 24s\n",
      "579:\ttotal: 33.1s\tremaining: 23.9s\n",
      "580:\ttotal: 33.1s\tremaining: 23.9s\n",
      "581:\ttotal: 33.2s\tremaining: 23.8s\n",
      "582:\ttotal: 33.2s\tremaining: 23.8s\n",
      "583:\ttotal: 33.3s\tremaining: 23.7s\n",
      "584:\ttotal: 33.3s\tremaining: 23.7s\n",
      "585:\ttotal: 33.4s\tremaining: 23.6s\n",
      "586:\ttotal: 33.5s\tremaining: 23.5s\n",
      "587:\ttotal: 33.5s\tremaining: 23.5s\n",
      "588:\ttotal: 33.6s\tremaining: 23.4s\n",
      "589:\ttotal: 33.7s\tremaining: 23.4s\n",
      "590:\ttotal: 33.7s\tremaining: 23.3s\n",
      "591:\ttotal: 33.8s\tremaining: 23.3s\n",
      "592:\ttotal: 33.8s\tremaining: 23.2s\n",
      "593:\ttotal: 33.9s\tremaining: 23.1s\n",
      "594:\ttotal: 33.9s\tremaining: 23.1s\n",
      "595:\ttotal: 34s\tremaining: 23s\n",
      "596:\ttotal: 34s\tremaining: 23s\n",
      "597:\ttotal: 34.1s\tremaining: 22.9s\n",
      "598:\ttotal: 34.1s\tremaining: 22.9s\n",
      "599:\ttotal: 34.2s\tremaining: 22.8s\n",
      "600:\ttotal: 34.3s\tremaining: 22.7s\n",
      "601:\ttotal: 34.3s\tremaining: 22.7s\n",
      "602:\ttotal: 34.4s\tremaining: 22.6s\n",
      "603:\ttotal: 34.4s\tremaining: 22.6s\n",
      "604:\ttotal: 34.5s\tremaining: 22.5s\n",
      "605:\ttotal: 34.5s\tremaining: 22.5s\n",
      "606:\ttotal: 34.6s\tremaining: 22.4s\n",
      "607:\ttotal: 34.7s\tremaining: 22.4s\n",
      "608:\ttotal: 34.7s\tremaining: 22.3s\n",
      "609:\ttotal: 34.8s\tremaining: 22.2s\n",
      "610:\ttotal: 34.9s\tremaining: 22.2s\n",
      "611:\ttotal: 34.9s\tremaining: 22.1s\n",
      "612:\ttotal: 35s\tremaining: 22.1s\n",
      "613:\ttotal: 35s\tremaining: 22s\n",
      "614:\ttotal: 35.1s\tremaining: 22s\n",
      "615:\ttotal: 35.1s\tremaining: 21.9s\n",
      "616:\ttotal: 35.2s\tremaining: 21.8s\n",
      "617:\ttotal: 35.2s\tremaining: 21.8s\n",
      "618:\ttotal: 35.3s\tremaining: 21.7s\n",
      "619:\ttotal: 35.4s\tremaining: 21.7s\n",
      "620:\ttotal: 35.4s\tremaining: 21.6s\n",
      "621:\ttotal: 35.5s\tremaining: 21.5s\n",
      "622:\ttotal: 35.5s\tremaining: 21.5s\n",
      "623:\ttotal: 35.6s\tremaining: 21.4s\n",
      "624:\ttotal: 35.6s\tremaining: 21.4s\n",
      "625:\ttotal: 35.7s\tremaining: 21.3s\n",
      "626:\ttotal: 35.8s\tremaining: 21.3s\n",
      "627:\ttotal: 35.8s\tremaining: 21.2s\n",
      "628:\ttotal: 35.9s\tremaining: 21.2s\n",
      "629:\ttotal: 35.9s\tremaining: 21.1s\n",
      "630:\ttotal: 36s\tremaining: 21s\n",
      "631:\ttotal: 36s\tremaining: 21s\n",
      "632:\ttotal: 36.1s\tremaining: 20.9s\n",
      "633:\ttotal: 36.2s\tremaining: 20.9s\n",
      "634:\ttotal: 36.2s\tremaining: 20.8s\n",
      "635:\ttotal: 36.3s\tremaining: 20.8s\n",
      "636:\ttotal: 36.3s\tremaining: 20.7s\n",
      "637:\ttotal: 36.4s\tremaining: 20.7s\n",
      "638:\ttotal: 36.5s\tremaining: 20.6s\n",
      "639:\ttotal: 36.5s\tremaining: 20.5s\n",
      "640:\ttotal: 36.6s\tremaining: 20.5s\n",
      "641:\ttotal: 36.6s\tremaining: 20.4s\n",
      "642:\ttotal: 36.7s\tremaining: 20.4s\n",
      "643:\ttotal: 36.8s\tremaining: 20.3s\n",
      "644:\ttotal: 36.8s\tremaining: 20.3s\n",
      "645:\ttotal: 36.8s\tremaining: 20.2s\n",
      "646:\ttotal: 36.9s\tremaining: 20.1s\n",
      "647:\ttotal: 37s\tremaining: 20.1s\n",
      "648:\ttotal: 37s\tremaining: 20s\n",
      "649:\ttotal: 37.1s\tremaining: 20s\n",
      "650:\ttotal: 37.1s\tremaining: 19.9s\n",
      "651:\ttotal: 37.2s\tremaining: 19.9s\n",
      "652:\ttotal: 37.3s\tremaining: 19.8s\n",
      "653:\ttotal: 37.3s\tremaining: 19.7s\n",
      "654:\ttotal: 37.4s\tremaining: 19.7s\n",
      "655:\ttotal: 37.4s\tremaining: 19.6s\n",
      "656:\ttotal: 37.5s\tremaining: 19.6s\n",
      "657:\ttotal: 37.5s\tremaining: 19.5s\n",
      "658:\ttotal: 37.6s\tremaining: 19.5s\n",
      "659:\ttotal: 37.7s\tremaining: 19.4s\n",
      "660:\ttotal: 37.7s\tremaining: 19.3s\n",
      "661:\ttotal: 37.8s\tremaining: 19.3s\n",
      "662:\ttotal: 37.8s\tremaining: 19.2s\n",
      "663:\ttotal: 37.9s\tremaining: 19.2s\n",
      "664:\ttotal: 37.9s\tremaining: 19.1s\n",
      "665:\ttotal: 38s\tremaining: 19.1s\n",
      "666:\ttotal: 38.1s\tremaining: 19s\n",
      "667:\ttotal: 38.1s\tremaining: 19s\n",
      "668:\ttotal: 38.2s\tremaining: 18.9s\n",
      "669:\ttotal: 38.2s\tremaining: 18.8s\n",
      "670:\ttotal: 38.3s\tremaining: 18.8s\n",
      "671:\ttotal: 38.4s\tremaining: 18.7s\n",
      "672:\ttotal: 38.4s\tremaining: 18.7s\n",
      "673:\ttotal: 38.5s\tremaining: 18.6s\n",
      "674:\ttotal: 38.5s\tremaining: 18.5s\n",
      "675:\ttotal: 38.6s\tremaining: 18.5s\n",
      "676:\ttotal: 38.6s\tremaining: 18.4s\n",
      "677:\ttotal: 38.7s\tremaining: 18.4s\n",
      "678:\ttotal: 38.8s\tremaining: 18.3s\n",
      "679:\ttotal: 38.8s\tremaining: 18.3s\n",
      "680:\ttotal: 38.9s\tremaining: 18.2s\n",
      "681:\ttotal: 38.9s\tremaining: 18.1s\n",
      "682:\ttotal: 39s\tremaining: 18.1s\n",
      "683:\ttotal: 39s\tremaining: 18s\n",
      "684:\ttotal: 39.1s\tremaining: 18s\n",
      "685:\ttotal: 39.1s\tremaining: 17.9s\n",
      "686:\ttotal: 39.2s\tremaining: 17.9s\n",
      "687:\ttotal: 39.3s\tremaining: 17.8s\n",
      "688:\ttotal: 39.3s\tremaining: 17.7s\n",
      "689:\ttotal: 39.4s\tremaining: 17.7s\n",
      "690:\ttotal: 39.4s\tremaining: 17.6s\n",
      "691:\ttotal: 39.5s\tremaining: 17.6s\n",
      "692:\ttotal: 39.5s\tremaining: 17.5s\n",
      "693:\ttotal: 39.6s\tremaining: 17.5s\n",
      "694:\ttotal: 39.7s\tremaining: 17.4s\n",
      "695:\ttotal: 39.7s\tremaining: 17.4s\n",
      "696:\ttotal: 39.8s\tremaining: 17.3s\n",
      "697:\ttotal: 39.8s\tremaining: 17.2s\n",
      "698:\ttotal: 39.9s\tremaining: 17.2s\n",
      "699:\ttotal: 40s\tremaining: 17.1s\n",
      "700:\ttotal: 40s\tremaining: 17.1s\n",
      "701:\ttotal: 40.1s\tremaining: 17s\n",
      "702:\ttotal: 40.1s\tremaining: 17s\n",
      "703:\ttotal: 40.2s\tremaining: 16.9s\n",
      "704:\ttotal: 40.2s\tremaining: 16.8s\n",
      "705:\ttotal: 40.3s\tremaining: 16.8s\n",
      "706:\ttotal: 40.3s\tremaining: 16.7s\n",
      "707:\ttotal: 40.4s\tremaining: 16.7s\n",
      "708:\ttotal: 40.5s\tremaining: 16.6s\n",
      "709:\ttotal: 40.5s\tremaining: 16.5s\n",
      "710:\ttotal: 40.6s\tremaining: 16.5s\n",
      "711:\ttotal: 40.6s\tremaining: 16.4s\n",
      "712:\ttotal: 40.7s\tremaining: 16.4s\n",
      "713:\ttotal: 40.7s\tremaining: 16.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714:\ttotal: 40.8s\tremaining: 16.3s\n",
      "715:\ttotal: 40.9s\tremaining: 16.2s\n",
      "716:\ttotal: 40.9s\tremaining: 16.1s\n",
      "717:\ttotal: 41s\tremaining: 16.1s\n",
      "718:\ttotal: 41s\tremaining: 16s\n",
      "719:\ttotal: 41.1s\tremaining: 16s\n",
      "720:\ttotal: 41.2s\tremaining: 15.9s\n",
      "721:\ttotal: 41.2s\tremaining: 15.9s\n",
      "722:\ttotal: 41.3s\tremaining: 15.8s\n",
      "723:\ttotal: 41.3s\tremaining: 15.8s\n",
      "724:\ttotal: 41.4s\tremaining: 15.7s\n",
      "725:\ttotal: 41.4s\tremaining: 15.6s\n",
      "726:\ttotal: 41.5s\tremaining: 15.6s\n",
      "727:\ttotal: 41.6s\tremaining: 15.5s\n",
      "728:\ttotal: 41.6s\tremaining: 15.5s\n",
      "729:\ttotal: 41.7s\tremaining: 15.4s\n",
      "730:\ttotal: 41.7s\tremaining: 15.3s\n",
      "731:\ttotal: 41.8s\tremaining: 15.3s\n",
      "732:\ttotal: 41.8s\tremaining: 15.2s\n",
      "733:\ttotal: 41.9s\tremaining: 15.2s\n",
      "734:\ttotal: 41.9s\tremaining: 15.1s\n",
      "735:\ttotal: 42s\tremaining: 15.1s\n",
      "736:\ttotal: 42.1s\tremaining: 15s\n",
      "737:\ttotal: 42.1s\tremaining: 15s\n",
      "738:\ttotal: 42.2s\tremaining: 14.9s\n",
      "739:\ttotal: 42.2s\tremaining: 14.8s\n",
      "740:\ttotal: 42.3s\tremaining: 14.8s\n",
      "741:\ttotal: 42.3s\tremaining: 14.7s\n",
      "742:\ttotal: 42.4s\tremaining: 14.7s\n",
      "743:\ttotal: 42.4s\tremaining: 14.6s\n",
      "744:\ttotal: 42.5s\tremaining: 14.5s\n",
      "745:\ttotal: 42.6s\tremaining: 14.5s\n",
      "746:\ttotal: 42.6s\tremaining: 14.4s\n",
      "747:\ttotal: 42.7s\tremaining: 14.4s\n",
      "748:\ttotal: 42.7s\tremaining: 14.3s\n",
      "749:\ttotal: 42.8s\tremaining: 14.3s\n",
      "750:\ttotal: 42.9s\tremaining: 14.2s\n",
      "751:\ttotal: 42.9s\tremaining: 14.2s\n",
      "752:\ttotal: 43s\tremaining: 14.1s\n",
      "753:\ttotal: 43s\tremaining: 14s\n",
      "754:\ttotal: 43.1s\tremaining: 14s\n",
      "755:\ttotal: 43.1s\tremaining: 13.9s\n",
      "756:\ttotal: 43.2s\tremaining: 13.9s\n",
      "757:\ttotal: 43.3s\tremaining: 13.8s\n",
      "758:\ttotal: 43.3s\tremaining: 13.8s\n",
      "759:\ttotal: 43.4s\tremaining: 13.7s\n",
      "760:\ttotal: 43.4s\tremaining: 13.6s\n",
      "761:\ttotal: 43.5s\tremaining: 13.6s\n",
      "762:\ttotal: 43.5s\tremaining: 13.5s\n",
      "763:\ttotal: 43.6s\tremaining: 13.5s\n",
      "764:\ttotal: 43.7s\tremaining: 13.4s\n",
      "765:\ttotal: 43.7s\tremaining: 13.4s\n",
      "766:\ttotal: 43.8s\tremaining: 13.3s\n",
      "767:\ttotal: 43.8s\tremaining: 13.2s\n",
      "768:\ttotal: 43.9s\tremaining: 13.2s\n",
      "769:\ttotal: 43.9s\tremaining: 13.1s\n",
      "770:\ttotal: 44s\tremaining: 13.1s\n",
      "771:\ttotal: 44.1s\tremaining: 13s\n",
      "772:\ttotal: 44.1s\tremaining: 13s\n",
      "773:\ttotal: 44.2s\tremaining: 12.9s\n",
      "774:\ttotal: 44.2s\tremaining: 12.8s\n",
      "775:\ttotal: 44.3s\tremaining: 12.8s\n",
      "776:\ttotal: 44.4s\tremaining: 12.7s\n",
      "777:\ttotal: 44.4s\tremaining: 12.7s\n",
      "778:\ttotal: 44.5s\tremaining: 12.6s\n",
      "779:\ttotal: 44.5s\tremaining: 12.6s\n",
      "780:\ttotal: 44.6s\tremaining: 12.5s\n",
      "781:\ttotal: 44.6s\tremaining: 12.4s\n",
      "782:\ttotal: 44.7s\tremaining: 12.4s\n",
      "783:\ttotal: 44.7s\tremaining: 12.3s\n",
      "784:\ttotal: 44.8s\tremaining: 12.3s\n",
      "785:\ttotal: 44.9s\tremaining: 12.2s\n",
      "786:\ttotal: 44.9s\tremaining: 12.2s\n",
      "787:\ttotal: 45s\tremaining: 12.1s\n",
      "788:\ttotal: 45s\tremaining: 12s\n",
      "789:\ttotal: 45.1s\tremaining: 12s\n",
      "790:\ttotal: 45.1s\tremaining: 11.9s\n",
      "791:\ttotal: 45.2s\tremaining: 11.9s\n",
      "792:\ttotal: 45.2s\tremaining: 11.8s\n",
      "793:\ttotal: 45.3s\tremaining: 11.7s\n",
      "794:\ttotal: 45.3s\tremaining: 11.7s\n",
      "795:\ttotal: 45.4s\tremaining: 11.6s\n",
      "796:\ttotal: 45.4s\tremaining: 11.6s\n",
      "797:\ttotal: 45.5s\tremaining: 11.5s\n",
      "798:\ttotal: 45.5s\tremaining: 11.5s\n",
      "799:\ttotal: 45.6s\tremaining: 11.4s\n",
      "800:\ttotal: 45.7s\tremaining: 11.3s\n",
      "801:\ttotal: 45.7s\tremaining: 11.3s\n",
      "802:\ttotal: 45.8s\tremaining: 11.2s\n",
      "803:\ttotal: 45.9s\tremaining: 11.2s\n",
      "804:\ttotal: 45.9s\tremaining: 11.1s\n",
      "805:\ttotal: 46s\tremaining: 11.1s\n",
      "806:\ttotal: 46s\tremaining: 11s\n",
      "807:\ttotal: 46.1s\tremaining: 10.9s\n",
      "808:\ttotal: 46.1s\tremaining: 10.9s\n",
      "809:\ttotal: 46.2s\tremaining: 10.8s\n",
      "810:\ttotal: 46.3s\tremaining: 10.8s\n",
      "811:\ttotal: 46.3s\tremaining: 10.7s\n",
      "812:\ttotal: 46.4s\tremaining: 10.7s\n",
      "813:\ttotal: 46.4s\tremaining: 10.6s\n",
      "814:\ttotal: 46.5s\tremaining: 10.5s\n",
      "815:\ttotal: 46.5s\tremaining: 10.5s\n",
      "816:\ttotal: 46.6s\tremaining: 10.4s\n",
      "817:\ttotal: 46.6s\tremaining: 10.4s\n",
      "818:\ttotal: 46.7s\tremaining: 10.3s\n",
      "819:\ttotal: 46.8s\tremaining: 10.3s\n",
      "820:\ttotal: 46.8s\tremaining: 10.2s\n",
      "821:\ttotal: 46.9s\tremaining: 10.2s\n",
      "822:\ttotal: 47s\tremaining: 10.1s\n",
      "823:\ttotal: 47s\tremaining: 10s\n",
      "824:\ttotal: 47.1s\tremaining: 9.99s\n",
      "825:\ttotal: 47.1s\tremaining: 9.93s\n",
      "826:\ttotal: 47.2s\tremaining: 9.87s\n",
      "827:\ttotal: 47.3s\tremaining: 9.82s\n",
      "828:\ttotal: 47.3s\tremaining: 9.76s\n",
      "829:\ttotal: 47.4s\tremaining: 9.7s\n",
      "830:\ttotal: 47.4s\tremaining: 9.64s\n",
      "831:\ttotal: 47.5s\tremaining: 9.58s\n",
      "832:\ttotal: 47.5s\tremaining: 9.53s\n",
      "833:\ttotal: 47.6s\tremaining: 9.47s\n",
      "834:\ttotal: 47.6s\tremaining: 9.41s\n",
      "835:\ttotal: 47.7s\tremaining: 9.36s\n",
      "836:\ttotal: 47.7s\tremaining: 9.3s\n",
      "837:\ttotal: 47.8s\tremaining: 9.24s\n",
      "838:\ttotal: 47.9s\tremaining: 9.18s\n",
      "839:\ttotal: 47.9s\tremaining: 9.13s\n",
      "840:\ttotal: 48s\tremaining: 9.07s\n",
      "841:\ttotal: 48s\tremaining: 9.01s\n",
      "842:\ttotal: 48.1s\tremaining: 8.95s\n",
      "843:\ttotal: 48.1s\tremaining: 8.89s\n",
      "844:\ttotal: 48.2s\tremaining: 8.84s\n",
      "845:\ttotal: 48.2s\tremaining: 8.78s\n",
      "846:\ttotal: 48.3s\tremaining: 8.72s\n",
      "847:\ttotal: 48.3s\tremaining: 8.67s\n",
      "848:\ttotal: 48.4s\tremaining: 8.61s\n",
      "849:\ttotal: 48.5s\tremaining: 8.55s\n",
      "850:\ttotal: 48.5s\tremaining: 8.49s\n",
      "851:\ttotal: 48.6s\tremaining: 8.44s\n",
      "852:\ttotal: 48.6s\tremaining: 8.38s\n",
      "853:\ttotal: 48.7s\tremaining: 8.32s\n",
      "854:\ttotal: 48.7s\tremaining: 8.27s\n",
      "855:\ttotal: 48.8s\tremaining: 8.21s\n",
      "856:\ttotal: 48.8s\tremaining: 8.15s\n",
      "857:\ttotal: 48.9s\tremaining: 8.09s\n",
      "858:\ttotal: 49s\tremaining: 8.04s\n",
      "859:\ttotal: 49s\tremaining: 7.98s\n",
      "860:\ttotal: 49.1s\tremaining: 7.92s\n",
      "861:\ttotal: 49.1s\tremaining: 7.87s\n",
      "862:\ttotal: 49.2s\tremaining: 7.81s\n",
      "863:\ttotal: 49.2s\tremaining: 7.75s\n",
      "864:\ttotal: 49.3s\tremaining: 7.69s\n",
      "865:\ttotal: 49.3s\tremaining: 7.63s\n",
      "866:\ttotal: 49.4s\tremaining: 7.58s\n",
      "867:\ttotal: 49.5s\tremaining: 7.52s\n",
      "868:\ttotal: 49.5s\tremaining: 7.46s\n",
      "869:\ttotal: 49.6s\tremaining: 7.41s\n",
      "870:\ttotal: 49.6s\tremaining: 7.35s\n",
      "871:\ttotal: 49.7s\tremaining: 7.29s\n",
      "872:\ttotal: 49.7s\tremaining: 7.24s\n",
      "873:\ttotal: 49.8s\tremaining: 7.18s\n",
      "874:\ttotal: 49.9s\tremaining: 7.12s\n",
      "875:\ttotal: 49.9s\tremaining: 7.07s\n",
      "876:\ttotal: 50s\tremaining: 7.01s\n",
      "877:\ttotal: 50s\tremaining: 6.95s\n",
      "878:\ttotal: 50.1s\tremaining: 6.9s\n",
      "879:\ttotal: 50.2s\tremaining: 6.84s\n",
      "880:\ttotal: 50.2s\tremaining: 6.78s\n",
      "881:\ttotal: 50.3s\tremaining: 6.72s\n",
      "882:\ttotal: 50.3s\tremaining: 6.67s\n",
      "883:\ttotal: 50.4s\tremaining: 6.61s\n",
      "884:\ttotal: 50.4s\tremaining: 6.55s\n",
      "885:\ttotal: 50.5s\tremaining: 6.5s\n",
      "886:\ttotal: 50.6s\tremaining: 6.44s\n",
      "887:\ttotal: 50.6s\tremaining: 6.39s\n",
      "888:\ttotal: 50.7s\tremaining: 6.33s\n",
      "889:\ttotal: 50.8s\tremaining: 6.27s\n",
      "890:\ttotal: 50.8s\tremaining: 6.22s\n",
      "891:\ttotal: 50.9s\tremaining: 6.16s\n",
      "892:\ttotal: 50.9s\tremaining: 6.1s\n",
      "893:\ttotal: 51s\tremaining: 6.05s\n",
      "894:\ttotal: 51.1s\tremaining: 5.99s\n",
      "895:\ttotal: 51.1s\tremaining: 5.93s\n",
      "896:\ttotal: 51.2s\tremaining: 5.88s\n",
      "897:\ttotal: 51.2s\tremaining: 5.82s\n",
      "898:\ttotal: 51.3s\tremaining: 5.76s\n",
      "899:\ttotal: 51.4s\tremaining: 5.71s\n",
      "900:\ttotal: 51.4s\tremaining: 5.65s\n",
      "901:\ttotal: 51.5s\tremaining: 5.59s\n",
      "902:\ttotal: 51.5s\tremaining: 5.53s\n",
      "903:\ttotal: 51.6s\tremaining: 5.48s\n",
      "904:\ttotal: 51.6s\tremaining: 5.42s\n",
      "905:\ttotal: 51.7s\tremaining: 5.36s\n",
      "906:\ttotal: 51.7s\tremaining: 5.3s\n",
      "907:\ttotal: 51.8s\tremaining: 5.25s\n",
      "908:\ttotal: 51.8s\tremaining: 5.19s\n",
      "909:\ttotal: 51.9s\tremaining: 5.13s\n",
      "910:\ttotal: 51.9s\tremaining: 5.07s\n",
      "911:\ttotal: 52s\tremaining: 5.02s\n",
      "912:\ttotal: 52.1s\tremaining: 4.96s\n",
      "913:\ttotal: 52.1s\tremaining: 4.9s\n",
      "914:\ttotal: 52.2s\tremaining: 4.85s\n",
      "915:\ttotal: 52.2s\tremaining: 4.79s\n",
      "916:\ttotal: 52.3s\tremaining: 4.73s\n",
      "917:\ttotal: 52.3s\tremaining: 4.67s\n",
      "918:\ttotal: 52.4s\tremaining: 4.62s\n",
      "919:\ttotal: 52.5s\tremaining: 4.56s\n",
      "920:\ttotal: 52.5s\tremaining: 4.5s\n",
      "921:\ttotal: 52.6s\tremaining: 4.45s\n",
      "922:\ttotal: 52.6s\tremaining: 4.39s\n",
      "923:\ttotal: 52.7s\tremaining: 4.33s\n",
      "924:\ttotal: 52.7s\tremaining: 4.28s\n",
      "925:\ttotal: 52.8s\tremaining: 4.22s\n",
      "926:\ttotal: 52.9s\tremaining: 4.16s\n",
      "927:\ttotal: 52.9s\tremaining: 4.11s\n",
      "928:\ttotal: 53s\tremaining: 4.05s\n",
      "929:\ttotal: 53s\tremaining: 3.99s\n",
      "930:\ttotal: 53.1s\tremaining: 3.93s\n",
      "931:\ttotal: 53.1s\tremaining: 3.88s\n",
      "932:\ttotal: 53.2s\tremaining: 3.82s\n",
      "933:\ttotal: 53.2s\tremaining: 3.76s\n",
      "934:\ttotal: 53.3s\tremaining: 3.71s\n",
      "935:\ttotal: 53.4s\tremaining: 3.65s\n",
      "936:\ttotal: 53.4s\tremaining: 3.59s\n",
      "937:\ttotal: 53.5s\tremaining: 3.54s\n",
      "938:\ttotal: 53.6s\tremaining: 3.48s\n",
      "939:\ttotal: 53.6s\tremaining: 3.42s\n",
      "940:\ttotal: 53.7s\tremaining: 3.36s\n",
      "941:\ttotal: 53.7s\tremaining: 3.31s\n",
      "942:\ttotal: 53.8s\tremaining: 3.25s\n",
      "943:\ttotal: 53.8s\tremaining: 3.19s\n",
      "944:\ttotal: 53.9s\tremaining: 3.14s\n",
      "945:\ttotal: 54s\tremaining: 3.08s\n",
      "946:\ttotal: 54s\tremaining: 3.02s\n",
      "947:\ttotal: 54.1s\tremaining: 2.97s\n",
      "948:\ttotal: 54.1s\tremaining: 2.91s\n",
      "949:\ttotal: 54.2s\tremaining: 2.85s\n",
      "950:\ttotal: 54.3s\tremaining: 2.79s\n",
      "951:\ttotal: 54.3s\tremaining: 2.74s\n",
      "952:\ttotal: 54.4s\tremaining: 2.68s\n",
      "953:\ttotal: 54.4s\tremaining: 2.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954:\ttotal: 54.5s\tremaining: 2.57s\n",
      "955:\ttotal: 54.5s\tremaining: 2.51s\n",
      "956:\ttotal: 54.6s\tremaining: 2.45s\n",
      "957:\ttotal: 54.7s\tremaining: 2.4s\n",
      "958:\ttotal: 54.7s\tremaining: 2.34s\n",
      "959:\ttotal: 54.8s\tremaining: 2.28s\n",
      "960:\ttotal: 54.8s\tremaining: 2.22s\n",
      "961:\ttotal: 54.9s\tremaining: 2.17s\n",
      "962:\ttotal: 54.9s\tremaining: 2.11s\n",
      "963:\ttotal: 55s\tremaining: 2.05s\n",
      "964:\ttotal: 55s\tremaining: 2s\n",
      "965:\ttotal: 55.1s\tremaining: 1.94s\n",
      "966:\ttotal: 55.2s\tremaining: 1.88s\n",
      "967:\ttotal: 55.2s\tremaining: 1.82s\n",
      "968:\ttotal: 55.3s\tremaining: 1.77s\n",
      "969:\ttotal: 55.3s\tremaining: 1.71s\n",
      "970:\ttotal: 55.4s\tremaining: 1.65s\n",
      "971:\ttotal: 55.4s\tremaining: 1.6s\n",
      "972:\ttotal: 55.5s\tremaining: 1.54s\n",
      "973:\ttotal: 55.5s\tremaining: 1.48s\n",
      "974:\ttotal: 55.6s\tremaining: 1.43s\n",
      "975:\ttotal: 55.6s\tremaining: 1.37s\n",
      "976:\ttotal: 55.7s\tremaining: 1.31s\n",
      "977:\ttotal: 55.7s\tremaining: 1.25s\n",
      "978:\ttotal: 55.8s\tremaining: 1.2s\n",
      "979:\ttotal: 55.8s\tremaining: 1.14s\n",
      "980:\ttotal: 55.9s\tremaining: 1.08s\n",
      "981:\ttotal: 56s\tremaining: 1.02s\n",
      "982:\ttotal: 56s\tremaining: 969ms\n",
      "983:\ttotal: 56.1s\tremaining: 912ms\n",
      "984:\ttotal: 56.1s\tremaining: 855ms\n",
      "985:\ttotal: 56.2s\tremaining: 798ms\n",
      "986:\ttotal: 56.2s\tremaining: 741ms\n",
      "987:\ttotal: 56.3s\tremaining: 684ms\n",
      "988:\ttotal: 56.3s\tremaining: 627ms\n",
      "989:\ttotal: 56.4s\tremaining: 570ms\n",
      "990:\ttotal: 56.4s\tremaining: 513ms\n",
      "991:\ttotal: 56.5s\tremaining: 456ms\n",
      "992:\ttotal: 56.6s\tremaining: 399ms\n",
      "993:\ttotal: 56.6s\tremaining: 342ms\n",
      "994:\ttotal: 56.7s\tremaining: 285ms\n",
      "995:\ttotal: 56.7s\tremaining: 228ms\n",
      "996:\ttotal: 56.8s\tremaining: 171ms\n",
      "997:\ttotal: 56.8s\tremaining: 114ms\n",
      "998:\ttotal: 56.9s\tremaining: 56.9ms\n",
      "999:\ttotal: 56.9s\tremaining: 0us\n",
      "0.8265605103704688\n",
      "0:\tlearn: 0.6780140\ttotal: 53.4ms\tremaining: 53.4s\n",
      "1:\tlearn: 0.6636927\ttotal: 111ms\tremaining: 55.5s\n",
      "2:\tlearn: 0.6502508\ttotal: 170ms\tremaining: 56.7s\n",
      "3:\tlearn: 0.6378219\ttotal: 231ms\tremaining: 57.5s\n",
      "4:\tlearn: 0.6264707\ttotal: 291ms\tremaining: 58s\n",
      "5:\tlearn: 0.6157302\ttotal: 346ms\tremaining: 57.4s\n",
      "6:\tlearn: 0.6058360\ttotal: 400ms\tremaining: 56.8s\n",
      "7:\tlearn: 0.5965310\ttotal: 450ms\tremaining: 55.8s\n",
      "8:\tlearn: 0.5877700\ttotal: 507ms\tremaining: 55.8s\n",
      "9:\tlearn: 0.5796432\ttotal: 570ms\tremaining: 56.5s\n",
      "10:\tlearn: 0.5722484\ttotal: 621ms\tremaining: 55.8s\n",
      "11:\tlearn: 0.5652518\ttotal: 677ms\tremaining: 55.7s\n",
      "12:\tlearn: 0.5588875\ttotal: 733ms\tremaining: 55.7s\n",
      "13:\tlearn: 0.5528327\ttotal: 792ms\tremaining: 55.8s\n",
      "14:\tlearn: 0.5472157\ttotal: 849ms\tremaining: 55.8s\n",
      "15:\tlearn: 0.5420569\ttotal: 916ms\tremaining: 56.4s\n",
      "16:\tlearn: 0.5373378\ttotal: 980ms\tremaining: 56.6s\n",
      "17:\tlearn: 0.5327924\ttotal: 1.03s\tremaining: 56.3s\n",
      "18:\tlearn: 0.5283339\ttotal: 1.09s\tremaining: 56.1s\n",
      "19:\tlearn: 0.5245373\ttotal: 1.14s\tremaining: 55.8s\n",
      "20:\tlearn: 0.5207678\ttotal: 1.2s\tremaining: 56s\n",
      "21:\tlearn: 0.5172504\ttotal: 1.27s\tremaining: 56.6s\n",
      "22:\tlearn: 0.5140041\ttotal: 1.33s\tremaining: 56.6s\n",
      "23:\tlearn: 0.5109670\ttotal: 1.39s\tremaining: 56.6s\n",
      "24:\tlearn: 0.5082421\ttotal: 1.46s\tremaining: 56.9s\n",
      "25:\tlearn: 0.5054644\ttotal: 1.51s\tremaining: 56.6s\n",
      "26:\tlearn: 0.5031089\ttotal: 1.57s\tremaining: 56.6s\n",
      "27:\tlearn: 0.5006940\ttotal: 1.63s\tremaining: 56.6s\n",
      "28:\tlearn: 0.4984480\ttotal: 1.69s\tremaining: 56.6s\n",
      "29:\tlearn: 0.4963749\ttotal: 1.76s\tremaining: 56.8s\n",
      "30:\tlearn: 0.4944880\ttotal: 1.82s\tremaining: 56.8s\n",
      "31:\tlearn: 0.4925580\ttotal: 1.87s\tremaining: 56.6s\n",
      "32:\tlearn: 0.4908226\ttotal: 1.93s\tremaining: 56.5s\n",
      "33:\tlearn: 0.4891149\ttotal: 1.99s\tremaining: 56.6s\n",
      "34:\tlearn: 0.4875597\ttotal: 2.04s\tremaining: 56.4s\n",
      "35:\tlearn: 0.4860696\ttotal: 2.1s\tremaining: 56.2s\n",
      "36:\tlearn: 0.4847784\ttotal: 2.16s\tremaining: 56.3s\n",
      "37:\tlearn: 0.4835161\ttotal: 2.22s\tremaining: 56.3s\n",
      "38:\tlearn: 0.4823418\ttotal: 2.29s\tremaining: 56.3s\n",
      "39:\tlearn: 0.4812369\ttotal: 2.35s\tremaining: 56.4s\n",
      "40:\tlearn: 0.4801758\ttotal: 2.4s\tremaining: 56.2s\n",
      "41:\tlearn: 0.4791328\ttotal: 2.46s\tremaining: 56s\n",
      "42:\tlearn: 0.4781340\ttotal: 2.51s\tremaining: 55.8s\n",
      "43:\tlearn: 0.4772089\ttotal: 2.56s\tremaining: 55.7s\n",
      "44:\tlearn: 0.4764181\ttotal: 2.62s\tremaining: 55.7s\n",
      "45:\tlearn: 0.4756214\ttotal: 2.68s\tremaining: 55.5s\n",
      "46:\tlearn: 0.4748648\ttotal: 2.73s\tremaining: 55.3s\n",
      "47:\tlearn: 0.4741766\ttotal: 2.79s\tremaining: 55.3s\n",
      "48:\tlearn: 0.4734615\ttotal: 2.86s\tremaining: 55.5s\n",
      "49:\tlearn: 0.4728175\ttotal: 2.92s\tremaining: 55.4s\n",
      "50:\tlearn: 0.4722308\ttotal: 2.97s\tremaining: 55.2s\n",
      "51:\tlearn: 0.4715803\ttotal: 3.03s\tremaining: 55.2s\n",
      "52:\tlearn: 0.4710407\ttotal: 3.09s\tremaining: 55.1s\n",
      "53:\tlearn: 0.4705685\ttotal: 3.15s\tremaining: 55.2s\n",
      "54:\tlearn: 0.4700774\ttotal: 3.21s\tremaining: 55.2s\n",
      "55:\tlearn: 0.4695851\ttotal: 3.26s\tremaining: 55s\n",
      "56:\tlearn: 0.4691223\ttotal: 3.31s\tremaining: 54.9s\n",
      "57:\tlearn: 0.4687350\ttotal: 3.37s\tremaining: 54.8s\n",
      "58:\tlearn: 0.4683021\ttotal: 3.42s\tremaining: 54.6s\n",
      "59:\tlearn: 0.4678949\ttotal: 3.48s\tremaining: 54.5s\n",
      "60:\tlearn: 0.4675440\ttotal: 3.53s\tremaining: 54.4s\n",
      "61:\tlearn: 0.4671756\ttotal: 3.59s\tremaining: 54.3s\n",
      "62:\tlearn: 0.4668622\ttotal: 3.64s\tremaining: 54.2s\n",
      "63:\tlearn: 0.4666012\ttotal: 3.69s\tremaining: 54s\n",
      "64:\tlearn: 0.4663156\ttotal: 3.75s\tremaining: 53.9s\n",
      "65:\tlearn: 0.4660611\ttotal: 3.81s\tremaining: 53.9s\n",
      "66:\tlearn: 0.4657923\ttotal: 3.87s\tremaining: 53.9s\n",
      "67:\tlearn: 0.4655060\ttotal: 3.92s\tremaining: 53.7s\n",
      "68:\tlearn: 0.4652639\ttotal: 3.98s\tremaining: 53.7s\n",
      "69:\tlearn: 0.4649996\ttotal: 4.03s\tremaining: 53.5s\n",
      "70:\tlearn: 0.4647956\ttotal: 4.08s\tremaining: 53.4s\n",
      "71:\tlearn: 0.4645832\ttotal: 4.13s\tremaining: 53.3s\n",
      "72:\tlearn: 0.4643896\ttotal: 4.19s\tremaining: 53.2s\n",
      "73:\tlearn: 0.4641951\ttotal: 4.25s\tremaining: 53.1s\n",
      "74:\tlearn: 0.4639958\ttotal: 4.3s\tremaining: 53.1s\n",
      "75:\tlearn: 0.4638262\ttotal: 4.36s\tremaining: 53.1s\n",
      "76:\tlearn: 0.4636753\ttotal: 4.42s\tremaining: 53s\n",
      "77:\tlearn: 0.4635164\ttotal: 4.48s\tremaining: 52.9s\n",
      "78:\tlearn: 0.4633624\ttotal: 4.54s\tremaining: 52.9s\n",
      "79:\tlearn: 0.4632342\ttotal: 4.59s\tremaining: 52.8s\n",
      "80:\tlearn: 0.4630866\ttotal: 4.65s\tremaining: 52.8s\n",
      "81:\tlearn: 0.4629159\ttotal: 4.7s\tremaining: 52.6s\n",
      "82:\tlearn: 0.4627883\ttotal: 4.76s\tremaining: 52.6s\n",
      "83:\tlearn: 0.4626798\ttotal: 4.82s\tremaining: 52.5s\n",
      "84:\tlearn: 0.4625354\ttotal: 4.88s\tremaining: 52.6s\n",
      "85:\tlearn: 0.4624392\ttotal: 4.95s\tremaining: 52.6s\n",
      "86:\tlearn: 0.4623386\ttotal: 5s\tremaining: 52.5s\n",
      "87:\tlearn: 0.4622504\ttotal: 5.06s\tremaining: 52.5s\n",
      "88:\tlearn: 0.4621399\ttotal: 5.13s\tremaining: 52.5s\n",
      "89:\tlearn: 0.4620407\ttotal: 5.19s\tremaining: 52.5s\n",
      "90:\tlearn: 0.4619560\ttotal: 5.24s\tremaining: 52.4s\n",
      "91:\tlearn: 0.4618645\ttotal: 5.29s\tremaining: 52.3s\n",
      "92:\tlearn: 0.4617638\ttotal: 5.36s\tremaining: 52.3s\n",
      "93:\tlearn: 0.4616794\ttotal: 5.42s\tremaining: 52.2s\n",
      "94:\tlearn: 0.4616076\ttotal: 5.46s\tremaining: 52.1s\n",
      "95:\tlearn: 0.4615291\ttotal: 5.52s\tremaining: 52s\n",
      "96:\tlearn: 0.4614614\ttotal: 5.58s\tremaining: 52s\n",
      "97:\tlearn: 0.4613872\ttotal: 5.63s\tremaining: 51.9s\n",
      "98:\tlearn: 0.4613435\ttotal: 5.7s\tremaining: 51.9s\n",
      "99:\tlearn: 0.4612790\ttotal: 5.76s\tremaining: 51.8s\n",
      "100:\tlearn: 0.4612083\ttotal: 5.83s\tremaining: 51.9s\n",
      "101:\tlearn: 0.4611498\ttotal: 5.88s\tremaining: 51.8s\n",
      "102:\tlearn: 0.4610877\ttotal: 5.95s\tremaining: 51.8s\n",
      "103:\tlearn: 0.4610292\ttotal: 6.01s\tremaining: 51.8s\n",
      "104:\tlearn: 0.4609826\ttotal: 6.07s\tremaining: 51.7s\n",
      "105:\tlearn: 0.4609214\ttotal: 6.12s\tremaining: 51.6s\n",
      "106:\tlearn: 0.4608666\ttotal: 6.17s\tremaining: 51.5s\n",
      "107:\tlearn: 0.4608102\ttotal: 6.23s\tremaining: 51.5s\n",
      "108:\tlearn: 0.4607442\ttotal: 6.29s\tremaining: 51.4s\n",
      "109:\tlearn: 0.4607021\ttotal: 6.34s\tremaining: 51.3s\n",
      "110:\tlearn: 0.4606546\ttotal: 6.4s\tremaining: 51.3s\n",
      "111:\tlearn: 0.4606063\ttotal: 6.45s\tremaining: 51.1s\n",
      "112:\tlearn: 0.4605531\ttotal: 6.52s\tremaining: 51.2s\n",
      "113:\tlearn: 0.4605059\ttotal: 6.58s\tremaining: 51.2s\n",
      "114:\tlearn: 0.4604674\ttotal: 6.64s\tremaining: 51.1s\n",
      "115:\tlearn: 0.4604254\ttotal: 6.69s\tremaining: 51s\n",
      "116:\tlearn: 0.4603850\ttotal: 6.75s\tremaining: 51s\n",
      "117:\tlearn: 0.4603481\ttotal: 6.8s\tremaining: 50.8s\n",
      "118:\tlearn: 0.4603203\ttotal: 6.86s\tremaining: 50.8s\n",
      "119:\tlearn: 0.4602784\ttotal: 6.91s\tremaining: 50.7s\n",
      "120:\tlearn: 0.4602329\ttotal: 6.97s\tremaining: 50.6s\n",
      "121:\tlearn: 0.4601859\ttotal: 7.02s\tremaining: 50.5s\n",
      "122:\tlearn: 0.4601516\ttotal: 7.08s\tremaining: 50.5s\n",
      "123:\tlearn: 0.4601093\ttotal: 7.13s\tremaining: 50.4s\n",
      "124:\tlearn: 0.4600801\ttotal: 7.19s\tremaining: 50.3s\n",
      "125:\tlearn: 0.4600395\ttotal: 7.25s\tremaining: 50.3s\n",
      "126:\tlearn: 0.4600119\ttotal: 7.31s\tremaining: 50.2s\n",
      "127:\tlearn: 0.4599846\ttotal: 7.36s\tremaining: 50.2s\n",
      "128:\tlearn: 0.4599582\ttotal: 7.42s\tremaining: 50.1s\n",
      "129:\tlearn: 0.4599273\ttotal: 7.49s\tremaining: 50.1s\n",
      "130:\tlearn: 0.4598947\ttotal: 7.54s\tremaining: 50s\n",
      "131:\tlearn: 0.4598654\ttotal: 7.59s\tremaining: 49.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132:\tlearn: 0.4598465\ttotal: 7.64s\tremaining: 49.8s\n",
      "133:\tlearn: 0.4598246\ttotal: 7.7s\tremaining: 49.8s\n",
      "134:\tlearn: 0.4597972\ttotal: 7.75s\tremaining: 49.7s\n",
      "135:\tlearn: 0.4597606\ttotal: 7.8s\tremaining: 49.6s\n",
      "136:\tlearn: 0.4597360\ttotal: 7.86s\tremaining: 49.5s\n",
      "137:\tlearn: 0.4597106\ttotal: 7.92s\tremaining: 49.5s\n",
      "138:\tlearn: 0.4596893\ttotal: 7.97s\tremaining: 49.4s\n",
      "139:\tlearn: 0.4596749\ttotal: 8.02s\tremaining: 49.3s\n",
      "140:\tlearn: 0.4596558\ttotal: 8.08s\tremaining: 49.2s\n",
      "141:\tlearn: 0.4596220\ttotal: 8.13s\tremaining: 49.1s\n",
      "142:\tlearn: 0.4596045\ttotal: 8.18s\tremaining: 49s\n",
      "143:\tlearn: 0.4595879\ttotal: 8.23s\tremaining: 48.9s\n",
      "144:\tlearn: 0.4595560\ttotal: 8.28s\tremaining: 48.8s\n",
      "145:\tlearn: 0.4595355\ttotal: 8.35s\tremaining: 48.8s\n",
      "146:\tlearn: 0.4595154\ttotal: 8.4s\tremaining: 48.7s\n",
      "147:\tlearn: 0.4594998\ttotal: 8.45s\tremaining: 48.7s\n",
      "148:\tlearn: 0.4594743\ttotal: 8.51s\tremaining: 48.6s\n",
      "149:\tlearn: 0.4594508\ttotal: 8.57s\tremaining: 48.5s\n",
      "150:\tlearn: 0.4594283\ttotal: 8.62s\tremaining: 48.4s\n",
      "151:\tlearn: 0.4593955\ttotal: 8.68s\tremaining: 48.4s\n",
      "152:\tlearn: 0.4593621\ttotal: 8.73s\tremaining: 48.3s\n",
      "153:\tlearn: 0.4593358\ttotal: 8.78s\tremaining: 48.3s\n",
      "154:\tlearn: 0.4593115\ttotal: 8.84s\tremaining: 48.2s\n",
      "155:\tlearn: 0.4592944\ttotal: 8.89s\tremaining: 48.1s\n",
      "156:\tlearn: 0.4592779\ttotal: 8.96s\tremaining: 48.1s\n",
      "157:\tlearn: 0.4592623\ttotal: 9.01s\tremaining: 48s\n",
      "158:\tlearn: 0.4592443\ttotal: 9.06s\tremaining: 47.9s\n",
      "159:\tlearn: 0.4592288\ttotal: 9.12s\tremaining: 47.9s\n",
      "160:\tlearn: 0.4592000\ttotal: 9.18s\tremaining: 47.8s\n",
      "161:\tlearn: 0.4591739\ttotal: 9.24s\tremaining: 47.8s\n",
      "162:\tlearn: 0.4591624\ttotal: 9.3s\tremaining: 47.8s\n",
      "163:\tlearn: 0.4591455\ttotal: 9.36s\tremaining: 47.7s\n",
      "164:\tlearn: 0.4591290\ttotal: 9.42s\tremaining: 47.7s\n",
      "165:\tlearn: 0.4591110\ttotal: 9.48s\tremaining: 47.6s\n",
      "166:\tlearn: 0.4591001\ttotal: 9.53s\tremaining: 47.5s\n",
      "167:\tlearn: 0.4590834\ttotal: 9.59s\tremaining: 47.5s\n",
      "168:\tlearn: 0.4590724\ttotal: 9.65s\tremaining: 47.4s\n",
      "169:\tlearn: 0.4590586\ttotal: 9.71s\tremaining: 47.4s\n",
      "170:\tlearn: 0.4590440\ttotal: 9.76s\tremaining: 47.3s\n",
      "171:\tlearn: 0.4590315\ttotal: 9.82s\tremaining: 47.3s\n",
      "172:\tlearn: 0.4590150\ttotal: 9.88s\tremaining: 47.2s\n",
      "173:\tlearn: 0.4590027\ttotal: 9.93s\tremaining: 47.1s\n",
      "174:\tlearn: 0.4589768\ttotal: 9.99s\tremaining: 47.1s\n",
      "175:\tlearn: 0.4589610\ttotal: 10s\tremaining: 47s\n",
      "176:\tlearn: 0.4589494\ttotal: 10.1s\tremaining: 47s\n",
      "177:\tlearn: 0.4589331\ttotal: 10.2s\tremaining: 46.9s\n",
      "178:\tlearn: 0.4589212\ttotal: 10.2s\tremaining: 46.8s\n",
      "179:\tlearn: 0.4589073\ttotal: 10.3s\tremaining: 46.7s\n",
      "180:\tlearn: 0.4588940\ttotal: 10.3s\tremaining: 46.7s\n",
      "181:\tlearn: 0.4588716\ttotal: 10.4s\tremaining: 46.6s\n",
      "182:\tlearn: 0.4588557\ttotal: 10.4s\tremaining: 46.6s\n",
      "183:\tlearn: 0.4588434\ttotal: 10.5s\tremaining: 46.7s\n",
      "184:\tlearn: 0.4588264\ttotal: 10.6s\tremaining: 46.7s\n",
      "185:\tlearn: 0.4588114\ttotal: 10.7s\tremaining: 46.7s\n",
      "186:\tlearn: 0.4587988\ttotal: 10.7s\tremaining: 46.7s\n",
      "187:\tlearn: 0.4587808\ttotal: 10.8s\tremaining: 46.7s\n",
      "188:\tlearn: 0.4587653\ttotal: 10.9s\tremaining: 46.7s\n",
      "189:\tlearn: 0.4587541\ttotal: 11s\tremaining: 46.7s\n",
      "190:\tlearn: 0.4587437\ttotal: 11s\tremaining: 46.7s\n",
      "191:\tlearn: 0.4587321\ttotal: 11.1s\tremaining: 46.7s\n",
      "192:\tlearn: 0.4587210\ttotal: 11.2s\tremaining: 46.7s\n",
      "193:\tlearn: 0.4587009\ttotal: 11.2s\tremaining: 46.7s\n",
      "194:\tlearn: 0.4586850\ttotal: 11.3s\tremaining: 46.7s\n",
      "195:\tlearn: 0.4586704\ttotal: 11.4s\tremaining: 46.6s\n",
      "196:\tlearn: 0.4586576\ttotal: 11.4s\tremaining: 46.5s\n",
      "197:\tlearn: 0.4586487\ttotal: 11.5s\tremaining: 46.5s\n",
      "198:\tlearn: 0.4586385\ttotal: 11.5s\tremaining: 46.4s\n",
      "199:\tlearn: 0.4586280\ttotal: 11.6s\tremaining: 46.4s\n",
      "200:\tlearn: 0.4586173\ttotal: 11.7s\tremaining: 46.4s\n",
      "201:\tlearn: 0.4586052\ttotal: 11.7s\tremaining: 46.3s\n",
      "202:\tlearn: 0.4585915\ttotal: 11.8s\tremaining: 46.2s\n",
      "203:\tlearn: 0.4585792\ttotal: 11.8s\tremaining: 46.2s\n",
      "204:\tlearn: 0.4585630\ttotal: 11.9s\tremaining: 46.1s\n",
      "205:\tlearn: 0.4585536\ttotal: 12s\tremaining: 46.1s\n",
      "206:\tlearn: 0.4585414\ttotal: 12s\tremaining: 46s\n",
      "207:\tlearn: 0.4585328\ttotal: 12.1s\tremaining: 46s\n",
      "208:\tlearn: 0.4585200\ttotal: 12.1s\tremaining: 45.9s\n",
      "209:\tlearn: 0.4585026\ttotal: 12.2s\tremaining: 45.8s\n",
      "210:\tlearn: 0.4584913\ttotal: 12.2s\tremaining: 45.7s\n",
      "211:\tlearn: 0.4584821\ttotal: 12.3s\tremaining: 45.7s\n",
      "212:\tlearn: 0.4584717\ttotal: 12.3s\tremaining: 45.6s\n",
      "213:\tlearn: 0.4584606\ttotal: 12.4s\tremaining: 45.5s\n",
      "214:\tlearn: 0.4584531\ttotal: 12.5s\tremaining: 45.5s\n",
      "215:\tlearn: 0.4584422\ttotal: 12.5s\tremaining: 45.4s\n",
      "216:\tlearn: 0.4584365\ttotal: 12.6s\tremaining: 45.3s\n",
      "217:\tlearn: 0.4584245\ttotal: 12.6s\tremaining: 45.3s\n",
      "218:\tlearn: 0.4584087\ttotal: 12.7s\tremaining: 45.2s\n",
      "219:\tlearn: 0.4583974\ttotal: 12.7s\tremaining: 45.1s\n",
      "220:\tlearn: 0.4583909\ttotal: 12.8s\tremaining: 45.1s\n",
      "221:\tlearn: 0.4583814\ttotal: 12.8s\tremaining: 45s\n",
      "222:\tlearn: 0.4583701\ttotal: 12.9s\tremaining: 44.9s\n",
      "223:\tlearn: 0.4583602\ttotal: 12.9s\tremaining: 44.9s\n",
      "224:\tlearn: 0.4583518\ttotal: 13s\tremaining: 44.8s\n",
      "225:\tlearn: 0.4583439\ttotal: 13.1s\tremaining: 44.8s\n",
      "226:\tlearn: 0.4583361\ttotal: 13.1s\tremaining: 44.7s\n",
      "227:\tlearn: 0.4583237\ttotal: 13.2s\tremaining: 44.6s\n",
      "228:\tlearn: 0.4583111\ttotal: 13.2s\tremaining: 44.6s\n",
      "229:\tlearn: 0.4583033\ttotal: 13.3s\tremaining: 44.5s\n",
      "230:\tlearn: 0.4582887\ttotal: 13.3s\tremaining: 44.4s\n",
      "231:\tlearn: 0.4582787\ttotal: 13.4s\tremaining: 44.4s\n",
      "232:\tlearn: 0.4582691\ttotal: 13.5s\tremaining: 44.3s\n",
      "233:\tlearn: 0.4582603\ttotal: 13.5s\tremaining: 44.3s\n",
      "234:\tlearn: 0.4582478\ttotal: 13.6s\tremaining: 44.2s\n",
      "235:\tlearn: 0.4582394\ttotal: 13.6s\tremaining: 44.1s\n",
      "236:\tlearn: 0.4582314\ttotal: 13.7s\tremaining: 44s\n",
      "237:\tlearn: 0.4582207\ttotal: 13.7s\tremaining: 44s\n",
      "238:\tlearn: 0.4582128\ttotal: 13.8s\tremaining: 43.9s\n",
      "239:\tlearn: 0.4582037\ttotal: 13.8s\tremaining: 43.8s\n",
      "240:\tlearn: 0.4581931\ttotal: 13.9s\tremaining: 43.8s\n",
      "241:\tlearn: 0.4581834\ttotal: 14s\tremaining: 43.7s\n",
      "242:\tlearn: 0.4581740\ttotal: 14s\tremaining: 43.6s\n",
      "243:\tlearn: 0.4581642\ttotal: 14.1s\tremaining: 43.6s\n",
      "244:\tlearn: 0.4581561\ttotal: 14.1s\tremaining: 43.5s\n",
      "245:\tlearn: 0.4581471\ttotal: 14.2s\tremaining: 43.5s\n",
      "246:\tlearn: 0.4581386\ttotal: 14.2s\tremaining: 43.4s\n",
      "247:\tlearn: 0.4581302\ttotal: 14.3s\tremaining: 43.3s\n",
      "248:\tlearn: 0.4581227\ttotal: 14.3s\tremaining: 43.3s\n",
      "249:\tlearn: 0.4581163\ttotal: 14.4s\tremaining: 43.2s\n",
      "250:\tlearn: 0.4581068\ttotal: 14.4s\tremaining: 43.1s\n",
      "251:\tlearn: 0.4580966\ttotal: 14.5s\tremaining: 43.1s\n",
      "252:\tlearn: 0.4580879\ttotal: 14.6s\tremaining: 43.1s\n",
      "253:\tlearn: 0.4580795\ttotal: 14.6s\tremaining: 43s\n",
      "254:\tlearn: 0.4580723\ttotal: 14.7s\tremaining: 43s\n",
      "255:\tlearn: 0.4580627\ttotal: 14.8s\tremaining: 43s\n",
      "256:\tlearn: 0.4580544\ttotal: 14.9s\tremaining: 42.9s\n",
      "257:\tlearn: 0.4580467\ttotal: 14.9s\tremaining: 42.9s\n",
      "258:\tlearn: 0.4580390\ttotal: 15s\tremaining: 42.8s\n",
      "259:\tlearn: 0.4580346\ttotal: 15s\tremaining: 42.8s\n",
      "260:\tlearn: 0.4580262\ttotal: 15.1s\tremaining: 42.8s\n",
      "261:\tlearn: 0.4580172\ttotal: 15.2s\tremaining: 42.8s\n",
      "262:\tlearn: 0.4580064\ttotal: 15.3s\tremaining: 42.8s\n",
      "263:\tlearn: 0.4579977\ttotal: 15.3s\tremaining: 42.8s\n",
      "264:\tlearn: 0.4579910\ttotal: 15.4s\tremaining: 42.7s\n",
      "265:\tlearn: 0.4579858\ttotal: 15.5s\tremaining: 42.7s\n",
      "266:\tlearn: 0.4579750\ttotal: 15.5s\tremaining: 42.7s\n",
      "267:\tlearn: 0.4579639\ttotal: 15.6s\tremaining: 42.6s\n",
      "268:\tlearn: 0.4579555\ttotal: 15.7s\tremaining: 42.5s\n",
      "269:\tlearn: 0.4579432\ttotal: 15.7s\tremaining: 42.5s\n",
      "270:\tlearn: 0.4579307\ttotal: 15.8s\tremaining: 42.4s\n",
      "271:\tlearn: 0.4579246\ttotal: 15.8s\tremaining: 42.4s\n",
      "272:\tlearn: 0.4579168\ttotal: 15.9s\tremaining: 42.3s\n",
      "273:\tlearn: 0.4579112\ttotal: 15.9s\tremaining: 42.2s\n",
      "274:\tlearn: 0.4579043\ttotal: 16s\tremaining: 42.1s\n",
      "275:\tlearn: 0.4578979\ttotal: 16s\tremaining: 42.1s\n",
      "276:\tlearn: 0.4578896\ttotal: 16.1s\tremaining: 42s\n",
      "277:\tlearn: 0.4578817\ttotal: 16.1s\tremaining: 41.9s\n",
      "278:\tlearn: 0.4578749\ttotal: 16.2s\tremaining: 41.9s\n",
      "279:\tlearn: 0.4578660\ttotal: 16.3s\tremaining: 41.8s\n",
      "280:\tlearn: 0.4578594\ttotal: 16.3s\tremaining: 41.8s\n",
      "281:\tlearn: 0.4578506\ttotal: 16.4s\tremaining: 41.7s\n",
      "282:\tlearn: 0.4578445\ttotal: 16.4s\tremaining: 41.6s\n",
      "283:\tlearn: 0.4578374\ttotal: 16.5s\tremaining: 41.6s\n",
      "284:\tlearn: 0.4578299\ttotal: 16.6s\tremaining: 41.5s\n",
      "285:\tlearn: 0.4578237\ttotal: 16.6s\tremaining: 41.5s\n",
      "286:\tlearn: 0.4578152\ttotal: 16.7s\tremaining: 41.4s\n",
      "287:\tlearn: 0.4578086\ttotal: 16.7s\tremaining: 41.4s\n",
      "288:\tlearn: 0.4577998\ttotal: 16.8s\tremaining: 41.3s\n",
      "289:\tlearn: 0.4577856\ttotal: 16.8s\tremaining: 41.2s\n",
      "290:\tlearn: 0.4577738\ttotal: 16.9s\tremaining: 41.1s\n",
      "291:\tlearn: 0.4577609\ttotal: 17s\tremaining: 41.1s\n",
      "292:\tlearn: 0.4577539\ttotal: 17s\tremaining: 41s\n",
      "293:\tlearn: 0.4577453\ttotal: 17.1s\tremaining: 41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294:\tlearn: 0.4577398\ttotal: 17.1s\tremaining: 40.9s\n",
      "295:\tlearn: 0.4577333\ttotal: 17.2s\tremaining: 40.9s\n",
      "296:\tlearn: 0.4577286\ttotal: 17.2s\tremaining: 40.8s\n",
      "297:\tlearn: 0.4577227\ttotal: 17.3s\tremaining: 40.8s\n",
      "298:\tlearn: 0.4577160\ttotal: 17.4s\tremaining: 40.7s\n",
      "299:\tlearn: 0.4577076\ttotal: 17.4s\tremaining: 40.6s\n",
      "300:\tlearn: 0.4577023\ttotal: 17.5s\tremaining: 40.6s\n",
      "301:\tlearn: 0.4576935\ttotal: 17.5s\tremaining: 40.5s\n",
      "302:\tlearn: 0.4576866\ttotal: 17.6s\tremaining: 40.4s\n",
      "303:\tlearn: 0.4576770\ttotal: 17.6s\tremaining: 40.4s\n",
      "304:\tlearn: 0.4576712\ttotal: 17.7s\tremaining: 40.3s\n",
      "305:\tlearn: 0.4576656\ttotal: 17.7s\tremaining: 40.2s\n",
      "306:\tlearn: 0.4576591\ttotal: 17.8s\tremaining: 40.2s\n",
      "307:\tlearn: 0.4576513\ttotal: 17.9s\tremaining: 40.1s\n",
      "308:\tlearn: 0.4576446\ttotal: 17.9s\tremaining: 40s\n",
      "309:\tlearn: 0.4576363\ttotal: 18s\tremaining: 40s\n",
      "310:\tlearn: 0.4576308\ttotal: 18s\tremaining: 39.9s\n",
      "311:\tlearn: 0.4576240\ttotal: 18.1s\tremaining: 39.9s\n",
      "312:\tlearn: 0.4576138\ttotal: 18.1s\tremaining: 39.8s\n",
      "313:\tlearn: 0.4576074\ttotal: 18.2s\tremaining: 39.7s\n",
      "314:\tlearn: 0.4575985\ttotal: 18.2s\tremaining: 39.7s\n",
      "315:\tlearn: 0.4575924\ttotal: 18.3s\tremaining: 39.6s\n",
      "316:\tlearn: 0.4575848\ttotal: 18.3s\tremaining: 39.5s\n",
      "317:\tlearn: 0.4575793\ttotal: 18.4s\tremaining: 39.4s\n",
      "318:\tlearn: 0.4575715\ttotal: 18.4s\tremaining: 39.4s\n",
      "319:\tlearn: 0.4575639\ttotal: 18.5s\tremaining: 39.3s\n",
      "320:\tlearn: 0.4575576\ttotal: 18.6s\tremaining: 39.3s\n",
      "321:\tlearn: 0.4575498\ttotal: 18.6s\tremaining: 39.2s\n",
      "322:\tlearn: 0.4575443\ttotal: 18.7s\tremaining: 39.2s\n",
      "323:\tlearn: 0.4575383\ttotal: 18.7s\tremaining: 39.1s\n",
      "324:\tlearn: 0.4575292\ttotal: 18.8s\tremaining: 39.1s\n",
      "325:\tlearn: 0.4575236\ttotal: 18.9s\tremaining: 39s\n",
      "326:\tlearn: 0.4575163\ttotal: 18.9s\tremaining: 38.9s\n",
      "327:\tlearn: 0.4575109\ttotal: 19s\tremaining: 38.9s\n",
      "328:\tlearn: 0.4575017\ttotal: 19s\tremaining: 38.8s\n",
      "329:\tlearn: 0.4574970\ttotal: 19.1s\tremaining: 38.7s\n",
      "330:\tlearn: 0.4574856\ttotal: 19.1s\tremaining: 38.7s\n",
      "331:\tlearn: 0.4574778\ttotal: 19.2s\tremaining: 38.6s\n",
      "332:\tlearn: 0.4574696\ttotal: 19.3s\tremaining: 38.6s\n",
      "333:\tlearn: 0.4574631\ttotal: 19.3s\tremaining: 38.5s\n",
      "334:\tlearn: 0.4574572\ttotal: 19.4s\tremaining: 38.4s\n",
      "335:\tlearn: 0.4574518\ttotal: 19.4s\tremaining: 38.4s\n",
      "336:\tlearn: 0.4574447\ttotal: 19.5s\tremaining: 38.3s\n",
      "337:\tlearn: 0.4574393\ttotal: 19.5s\tremaining: 38.2s\n",
      "338:\tlearn: 0.4574321\ttotal: 19.6s\tremaining: 38.2s\n",
      "339:\tlearn: 0.4574271\ttotal: 19.6s\tremaining: 38.1s\n",
      "340:\tlearn: 0.4574208\ttotal: 19.7s\tremaining: 38.1s\n",
      "341:\tlearn: 0.4574142\ttotal: 19.8s\tremaining: 38s\n",
      "342:\tlearn: 0.4574085\ttotal: 19.8s\tremaining: 38s\n",
      "343:\tlearn: 0.4574034\ttotal: 19.9s\tremaining: 37.9s\n",
      "344:\tlearn: 0.4573941\ttotal: 19.9s\tremaining: 37.8s\n",
      "345:\tlearn: 0.4573873\ttotal: 20s\tremaining: 37.8s\n",
      "346:\tlearn: 0.4573801\ttotal: 20s\tremaining: 37.7s\n",
      "347:\tlearn: 0.4573735\ttotal: 20.1s\tremaining: 37.6s\n",
      "348:\tlearn: 0.4573662\ttotal: 20.1s\tremaining: 37.6s\n",
      "349:\tlearn: 0.4573604\ttotal: 20.2s\tremaining: 37.5s\n",
      "350:\tlearn: 0.4573552\ttotal: 20.3s\tremaining: 37.5s\n",
      "351:\tlearn: 0.4573478\ttotal: 20.3s\tremaining: 37.4s\n",
      "352:\tlearn: 0.4573437\ttotal: 20.4s\tremaining: 37.3s\n",
      "353:\tlearn: 0.4573345\ttotal: 20.4s\tremaining: 37.3s\n",
      "354:\tlearn: 0.4573286\ttotal: 20.5s\tremaining: 37.3s\n",
      "355:\tlearn: 0.4573232\ttotal: 20.6s\tremaining: 37.2s\n",
      "356:\tlearn: 0.4573143\ttotal: 20.6s\tremaining: 37.2s\n",
      "357:\tlearn: 0.4573080\ttotal: 20.7s\tremaining: 37.1s\n",
      "358:\tlearn: 0.4573045\ttotal: 20.8s\tremaining: 37.1s\n",
      "359:\tlearn: 0.4573002\ttotal: 20.8s\tremaining: 37s\n",
      "360:\tlearn: 0.4572913\ttotal: 20.9s\tremaining: 36.9s\n",
      "361:\tlearn: 0.4572830\ttotal: 20.9s\tremaining: 36.9s\n",
      "362:\tlearn: 0.4572765\ttotal: 21s\tremaining: 36.8s\n",
      "363:\tlearn: 0.4572708\ttotal: 21s\tremaining: 36.8s\n",
      "364:\tlearn: 0.4572651\ttotal: 21.1s\tremaining: 36.7s\n",
      "365:\tlearn: 0.4572573\ttotal: 21.1s\tremaining: 36.6s\n",
      "366:\tlearn: 0.4572522\ttotal: 21.2s\tremaining: 36.6s\n",
      "367:\tlearn: 0.4572441\ttotal: 21.3s\tremaining: 36.5s\n",
      "368:\tlearn: 0.4572389\ttotal: 21.3s\tremaining: 36.4s\n",
      "369:\tlearn: 0.4572332\ttotal: 21.4s\tremaining: 36.4s\n",
      "370:\tlearn: 0.4572235\ttotal: 21.4s\tremaining: 36.3s\n",
      "371:\tlearn: 0.4572161\ttotal: 21.5s\tremaining: 36.2s\n",
      "372:\tlearn: 0.4572065\ttotal: 21.5s\tremaining: 36.2s\n",
      "373:\tlearn: 0.4572019\ttotal: 21.6s\tremaining: 36.1s\n",
      "374:\tlearn: 0.4571959\ttotal: 21.6s\tremaining: 36.1s\n",
      "375:\tlearn: 0.4571904\ttotal: 21.7s\tremaining: 36s\n",
      "376:\tlearn: 0.4571826\ttotal: 21.8s\tremaining: 36s\n",
      "377:\tlearn: 0.4571764\ttotal: 21.8s\tremaining: 35.9s\n",
      "378:\tlearn: 0.4571707\ttotal: 21.9s\tremaining: 35.8s\n",
      "379:\tlearn: 0.4571650\ttotal: 21.9s\tremaining: 35.8s\n",
      "380:\tlearn: 0.4571599\ttotal: 22s\tremaining: 35.7s\n",
      "381:\tlearn: 0.4571544\ttotal: 22s\tremaining: 35.6s\n",
      "382:\tlearn: 0.4571478\ttotal: 22.1s\tremaining: 35.6s\n",
      "383:\tlearn: 0.4571403\ttotal: 22.2s\tremaining: 35.5s\n",
      "384:\tlearn: 0.4571320\ttotal: 22.2s\tremaining: 35.5s\n",
      "385:\tlearn: 0.4571273\ttotal: 22.3s\tremaining: 35.4s\n",
      "386:\tlearn: 0.4571209\ttotal: 22.3s\tremaining: 35.4s\n",
      "387:\tlearn: 0.4571163\ttotal: 22.4s\tremaining: 35.3s\n",
      "388:\tlearn: 0.4571128\ttotal: 22.4s\tremaining: 35.2s\n",
      "389:\tlearn: 0.4571084\ttotal: 22.5s\tremaining: 35.2s\n",
      "390:\tlearn: 0.4571034\ttotal: 22.5s\tremaining: 35.1s\n",
      "391:\tlearn: 0.4570974\ttotal: 22.6s\tremaining: 35s\n",
      "392:\tlearn: 0.4570923\ttotal: 22.7s\tremaining: 35s\n",
      "393:\tlearn: 0.4570857\ttotal: 22.7s\tremaining: 34.9s\n",
      "394:\tlearn: 0.4570785\ttotal: 22.8s\tremaining: 34.9s\n",
      "395:\tlearn: 0.4570691\ttotal: 22.8s\tremaining: 34.8s\n",
      "396:\tlearn: 0.4570626\ttotal: 22.9s\tremaining: 34.7s\n",
      "397:\tlearn: 0.4570543\ttotal: 22.9s\tremaining: 34.7s\n",
      "398:\tlearn: 0.4570475\ttotal: 23s\tremaining: 34.6s\n",
      "399:\tlearn: 0.4570423\ttotal: 23s\tremaining: 34.6s\n",
      "400:\tlearn: 0.4570350\ttotal: 23.1s\tremaining: 34.5s\n",
      "401:\tlearn: 0.4570291\ttotal: 23.2s\tremaining: 34.5s\n",
      "402:\tlearn: 0.4570215\ttotal: 23.2s\tremaining: 34.4s\n",
      "403:\tlearn: 0.4570155\ttotal: 23.3s\tremaining: 34.3s\n",
      "404:\tlearn: 0.4570089\ttotal: 23.3s\tremaining: 34.3s\n",
      "405:\tlearn: 0.4570004\ttotal: 23.4s\tremaining: 34.2s\n",
      "406:\tlearn: 0.4569941\ttotal: 23.4s\tremaining: 34.2s\n",
      "407:\tlearn: 0.4569864\ttotal: 23.5s\tremaining: 34.1s\n",
      "408:\tlearn: 0.4569811\ttotal: 23.6s\tremaining: 34.1s\n",
      "409:\tlearn: 0.4569755\ttotal: 23.6s\tremaining: 34s\n",
      "410:\tlearn: 0.4569691\ttotal: 23.7s\tremaining: 33.9s\n",
      "411:\tlearn: 0.4569623\ttotal: 23.7s\tremaining: 33.9s\n",
      "412:\tlearn: 0.4569554\ttotal: 23.8s\tremaining: 33.8s\n",
      "413:\tlearn: 0.4569513\ttotal: 23.9s\tremaining: 33.8s\n",
      "414:\tlearn: 0.4569455\ttotal: 23.9s\tremaining: 33.7s\n",
      "415:\tlearn: 0.4569377\ttotal: 24s\tremaining: 33.7s\n",
      "416:\tlearn: 0.4569325\ttotal: 24s\tremaining: 33.6s\n",
      "417:\tlearn: 0.4569256\ttotal: 24.1s\tremaining: 33.5s\n",
      "418:\tlearn: 0.4569207\ttotal: 24.2s\tremaining: 33.5s\n",
      "419:\tlearn: 0.4569150\ttotal: 24.2s\tremaining: 33.5s\n",
      "420:\tlearn: 0.4569093\ttotal: 24.3s\tremaining: 33.4s\n",
      "421:\tlearn: 0.4569035\ttotal: 24.3s\tremaining: 33.3s\n",
      "422:\tlearn: 0.4568989\ttotal: 24.4s\tremaining: 33.3s\n",
      "423:\tlearn: 0.4568913\ttotal: 24.5s\tremaining: 33.2s\n",
      "424:\tlearn: 0.4568860\ttotal: 24.5s\tremaining: 33.2s\n",
      "425:\tlearn: 0.4568792\ttotal: 24.6s\tremaining: 33.1s\n",
      "426:\tlearn: 0.4568712\ttotal: 24.6s\tremaining: 33s\n",
      "427:\tlearn: 0.4568654\ttotal: 24.7s\tremaining: 33s\n",
      "428:\tlearn: 0.4568583\ttotal: 24.7s\tremaining: 32.9s\n",
      "429:\tlearn: 0.4568536\ttotal: 24.8s\tremaining: 32.9s\n",
      "430:\tlearn: 0.4568490\ttotal: 24.9s\tremaining: 32.8s\n",
      "431:\tlearn: 0.4568439\ttotal: 24.9s\tremaining: 32.8s\n",
      "432:\tlearn: 0.4568372\ttotal: 25s\tremaining: 32.7s\n",
      "433:\tlearn: 0.4568310\ttotal: 25s\tremaining: 32.6s\n",
      "434:\tlearn: 0.4568212\ttotal: 25.1s\tremaining: 32.6s\n",
      "435:\tlearn: 0.4568166\ttotal: 25.2s\tremaining: 32.5s\n",
      "436:\tlearn: 0.4568090\ttotal: 25.2s\tremaining: 32.5s\n",
      "437:\tlearn: 0.4568044\ttotal: 25.3s\tremaining: 32.4s\n",
      "438:\tlearn: 0.4567978\ttotal: 25.3s\tremaining: 32.4s\n",
      "439:\tlearn: 0.4567911\ttotal: 25.4s\tremaining: 32.3s\n",
      "440:\tlearn: 0.4567819\ttotal: 25.5s\tremaining: 32.3s\n",
      "441:\tlearn: 0.4567735\ttotal: 25.5s\tremaining: 32.2s\n",
      "442:\tlearn: 0.4567662\ttotal: 25.6s\tremaining: 32.1s\n",
      "443:\tlearn: 0.4567589\ttotal: 25.6s\tremaining: 32.1s\n",
      "444:\tlearn: 0.4567536\ttotal: 25.7s\tremaining: 32s\n",
      "445:\tlearn: 0.4567490\ttotal: 25.7s\tremaining: 32s\n",
      "446:\tlearn: 0.4567423\ttotal: 25.8s\tremaining: 31.9s\n",
      "447:\tlearn: 0.4567345\ttotal: 25.9s\tremaining: 31.9s\n",
      "448:\tlearn: 0.4567263\ttotal: 25.9s\tremaining: 31.8s\n",
      "449:\tlearn: 0.4567223\ttotal: 26s\tremaining: 31.8s\n",
      "450:\tlearn: 0.4567164\ttotal: 26.1s\tremaining: 31.7s\n",
      "451:\tlearn: 0.4567109\ttotal: 26.1s\tremaining: 31.7s\n",
      "452:\tlearn: 0.4567035\ttotal: 26.2s\tremaining: 31.6s\n",
      "453:\tlearn: 0.4566996\ttotal: 26.2s\tremaining: 31.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454:\tlearn: 0.4566912\ttotal: 26.3s\tremaining: 31.5s\n",
      "455:\tlearn: 0.4566841\ttotal: 26.4s\tremaining: 31.4s\n",
      "456:\tlearn: 0.4566785\ttotal: 26.4s\tremaining: 31.4s\n",
      "457:\tlearn: 0.4566713\ttotal: 26.5s\tremaining: 31.3s\n",
      "458:\tlearn: 0.4566647\ttotal: 26.5s\tremaining: 31.2s\n",
      "459:\tlearn: 0.4566563\ttotal: 26.6s\tremaining: 31.2s\n",
      "460:\tlearn: 0.4566496\ttotal: 26.6s\tremaining: 31.1s\n",
      "461:\tlearn: 0.4566400\ttotal: 26.7s\tremaining: 31.1s\n",
      "462:\tlearn: 0.4566343\ttotal: 26.7s\tremaining: 31s\n",
      "463:\tlearn: 0.4566286\ttotal: 26.8s\tremaining: 31s\n",
      "464:\tlearn: 0.4566210\ttotal: 26.9s\tremaining: 30.9s\n",
      "465:\tlearn: 0.4566147\ttotal: 26.9s\tremaining: 30.8s\n",
      "466:\tlearn: 0.4566097\ttotal: 27s\tremaining: 30.8s\n",
      "467:\tlearn: 0.4566037\ttotal: 27s\tremaining: 30.7s\n",
      "468:\tlearn: 0.4565970\ttotal: 27.1s\tremaining: 30.7s\n",
      "469:\tlearn: 0.4565914\ttotal: 27.1s\tremaining: 30.6s\n",
      "470:\tlearn: 0.4565864\ttotal: 27.2s\tremaining: 30.6s\n",
      "471:\tlearn: 0.4565803\ttotal: 27.3s\tremaining: 30.5s\n",
      "472:\tlearn: 0.4565744\ttotal: 27.3s\tremaining: 30.4s\n",
      "473:\tlearn: 0.4565694\ttotal: 27.4s\tremaining: 30.4s\n",
      "474:\tlearn: 0.4565642\ttotal: 27.4s\tremaining: 30.3s\n",
      "475:\tlearn: 0.4565586\ttotal: 27.5s\tremaining: 30.3s\n",
      "476:\tlearn: 0.4565523\ttotal: 27.5s\tremaining: 30.2s\n",
      "477:\tlearn: 0.4565452\ttotal: 27.6s\tremaining: 30.1s\n",
      "478:\tlearn: 0.4565374\ttotal: 27.7s\tremaining: 30.1s\n",
      "479:\tlearn: 0.4565293\ttotal: 27.7s\tremaining: 30s\n",
      "480:\tlearn: 0.4565245\ttotal: 27.8s\tremaining: 30s\n",
      "481:\tlearn: 0.4565206\ttotal: 27.8s\tremaining: 29.9s\n",
      "482:\tlearn: 0.4565146\ttotal: 27.9s\tremaining: 29.9s\n",
      "483:\tlearn: 0.4565093\ttotal: 28s\tremaining: 29.8s\n",
      "484:\tlearn: 0.4565040\ttotal: 28s\tremaining: 29.7s\n",
      "485:\tlearn: 0.4564968\ttotal: 28.1s\tremaining: 29.7s\n",
      "486:\tlearn: 0.4564884\ttotal: 28.1s\tremaining: 29.6s\n",
      "487:\tlearn: 0.4564825\ttotal: 28.2s\tremaining: 29.6s\n",
      "488:\tlearn: 0.4564753\ttotal: 28.2s\tremaining: 29.5s\n",
      "489:\tlearn: 0.4564696\ttotal: 28.3s\tremaining: 29.4s\n",
      "490:\tlearn: 0.4564635\ttotal: 28.3s\tremaining: 29.4s\n",
      "491:\tlearn: 0.4564574\ttotal: 28.4s\tremaining: 29.3s\n",
      "492:\tlearn: 0.4564516\ttotal: 28.4s\tremaining: 29.3s\n",
      "493:\tlearn: 0.4564461\ttotal: 28.5s\tremaining: 29.2s\n",
      "494:\tlearn: 0.4564411\ttotal: 28.6s\tremaining: 29.1s\n",
      "495:\tlearn: 0.4564344\ttotal: 28.6s\tremaining: 29.1s\n",
      "496:\tlearn: 0.4564293\ttotal: 28.7s\tremaining: 29s\n",
      "497:\tlearn: 0.4564243\ttotal: 28.7s\tremaining: 28.9s\n",
      "498:\tlearn: 0.4564179\ttotal: 28.8s\tremaining: 28.9s\n",
      "499:\tlearn: 0.4564117\ttotal: 28.8s\tremaining: 28.8s\n",
      "500:\tlearn: 0.4564071\ttotal: 28.9s\tremaining: 28.8s\n",
      "501:\tlearn: 0.4564009\ttotal: 28.9s\tremaining: 28.7s\n",
      "502:\tlearn: 0.4563943\ttotal: 29s\tremaining: 28.7s\n",
      "503:\tlearn: 0.4563884\ttotal: 29.1s\tremaining: 28.6s\n",
      "504:\tlearn: 0.4563827\ttotal: 29.1s\tremaining: 28.5s\n",
      "505:\tlearn: 0.4563768\ttotal: 29.2s\tremaining: 28.5s\n",
      "506:\tlearn: 0.4563726\ttotal: 29.2s\tremaining: 28.4s\n",
      "507:\tlearn: 0.4563656\ttotal: 29.3s\tremaining: 28.4s\n",
      "508:\tlearn: 0.4563595\ttotal: 29.3s\tremaining: 28.3s\n",
      "509:\tlearn: 0.4563549\ttotal: 29.4s\tremaining: 28.2s\n",
      "510:\tlearn: 0.4563480\ttotal: 29.5s\tremaining: 28.2s\n",
      "511:\tlearn: 0.4563411\ttotal: 29.5s\tremaining: 28.1s\n",
      "512:\tlearn: 0.4563370\ttotal: 29.6s\tremaining: 28.1s\n",
      "513:\tlearn: 0.4563281\ttotal: 29.6s\tremaining: 28s\n",
      "514:\tlearn: 0.4563228\ttotal: 29.7s\tremaining: 28s\n",
      "515:\tlearn: 0.4563166\ttotal: 29.8s\tremaining: 27.9s\n",
      "516:\tlearn: 0.4563098\ttotal: 29.8s\tremaining: 27.9s\n",
      "517:\tlearn: 0.4563038\ttotal: 29.9s\tremaining: 27.8s\n",
      "518:\tlearn: 0.4562962\ttotal: 30s\tremaining: 27.8s\n",
      "519:\tlearn: 0.4562902\ttotal: 30s\tremaining: 27.7s\n",
      "520:\tlearn: 0.4562848\ttotal: 30.1s\tremaining: 27.7s\n",
      "521:\tlearn: 0.4562786\ttotal: 30.2s\tremaining: 27.6s\n",
      "522:\tlearn: 0.4562729\ttotal: 30.2s\tremaining: 27.6s\n",
      "523:\tlearn: 0.4562668\ttotal: 30.3s\tremaining: 27.5s\n",
      "524:\tlearn: 0.4562621\ttotal: 30.4s\tremaining: 27.5s\n",
      "525:\tlearn: 0.4562571\ttotal: 30.4s\tremaining: 27.4s\n",
      "526:\tlearn: 0.4562499\ttotal: 30.5s\tremaining: 27.4s\n",
      "527:\tlearn: 0.4562435\ttotal: 30.6s\tremaining: 27.3s\n",
      "528:\tlearn: 0.4562383\ttotal: 30.6s\tremaining: 27.3s\n",
      "529:\tlearn: 0.4562328\ttotal: 30.7s\tremaining: 27.2s\n",
      "530:\tlearn: 0.4562265\ttotal: 30.8s\tremaining: 27.2s\n",
      "531:\tlearn: 0.4562232\ttotal: 30.9s\tremaining: 27.1s\n",
      "532:\tlearn: 0.4562166\ttotal: 30.9s\tremaining: 27.1s\n",
      "533:\tlearn: 0.4562120\ttotal: 31s\tremaining: 27s\n",
      "534:\tlearn: 0.4562069\ttotal: 31.1s\tremaining: 27s\n",
      "535:\tlearn: 0.4562032\ttotal: 31.1s\tremaining: 26.9s\n",
      "536:\tlearn: 0.4561986\ttotal: 31.2s\tremaining: 26.9s\n",
      "537:\tlearn: 0.4561923\ttotal: 31.3s\tremaining: 26.8s\n",
      "538:\tlearn: 0.4561868\ttotal: 31.3s\tremaining: 26.8s\n",
      "539:\tlearn: 0.4561825\ttotal: 31.4s\tremaining: 26.7s\n",
      "540:\tlearn: 0.4561756\ttotal: 31.4s\tremaining: 26.7s\n",
      "541:\tlearn: 0.4561686\ttotal: 31.5s\tremaining: 26.6s\n",
      "542:\tlearn: 0.4561629\ttotal: 31.5s\tremaining: 26.5s\n",
      "543:\tlearn: 0.4561559\ttotal: 31.6s\tremaining: 26.5s\n",
      "544:\tlearn: 0.4561513\ttotal: 31.7s\tremaining: 26.4s\n",
      "545:\tlearn: 0.4561457\ttotal: 31.7s\tremaining: 26.4s\n",
      "546:\tlearn: 0.4561394\ttotal: 31.8s\tremaining: 26.3s\n",
      "547:\tlearn: 0.4561326\ttotal: 31.8s\tremaining: 26.3s\n",
      "548:\tlearn: 0.4561276\ttotal: 31.9s\tremaining: 26.2s\n",
      "549:\tlearn: 0.4561219\ttotal: 31.9s\tremaining: 26.1s\n",
      "550:\tlearn: 0.4561155\ttotal: 32s\tremaining: 26.1s\n",
      "551:\tlearn: 0.4561093\ttotal: 32.1s\tremaining: 26s\n",
      "552:\tlearn: 0.4561053\ttotal: 32.1s\tremaining: 26s\n",
      "553:\tlearn: 0.4560976\ttotal: 32.2s\tremaining: 25.9s\n",
      "554:\tlearn: 0.4560918\ttotal: 32.2s\tremaining: 25.8s\n",
      "555:\tlearn: 0.4560858\ttotal: 32.3s\tremaining: 25.8s\n",
      "556:\tlearn: 0.4560782\ttotal: 32.3s\tremaining: 25.7s\n",
      "557:\tlearn: 0.4560720\ttotal: 32.4s\tremaining: 25.7s\n",
      "558:\tlearn: 0.4560675\ttotal: 32.5s\tremaining: 25.6s\n",
      "559:\tlearn: 0.4560619\ttotal: 32.5s\tremaining: 25.5s\n",
      "560:\tlearn: 0.4560537\ttotal: 32.6s\tremaining: 25.5s\n",
      "561:\tlearn: 0.4560468\ttotal: 32.6s\tremaining: 25.4s\n",
      "562:\tlearn: 0.4560417\ttotal: 32.7s\tremaining: 25.4s\n",
      "563:\tlearn: 0.4560370\ttotal: 32.8s\tremaining: 25.3s\n",
      "564:\tlearn: 0.4560323\ttotal: 32.8s\tremaining: 25.3s\n",
      "565:\tlearn: 0.4560282\ttotal: 32.9s\tremaining: 25.2s\n",
      "566:\tlearn: 0.4560229\ttotal: 33s\tremaining: 25.2s\n",
      "567:\tlearn: 0.4560161\ttotal: 33s\tremaining: 25.1s\n",
      "568:\tlearn: 0.4560098\ttotal: 33.1s\tremaining: 25.1s\n",
      "569:\tlearn: 0.4560036\ttotal: 33.1s\tremaining: 25s\n",
      "570:\tlearn: 0.4559994\ttotal: 33.2s\tremaining: 24.9s\n",
      "571:\tlearn: 0.4559937\ttotal: 33.3s\tremaining: 24.9s\n",
      "572:\tlearn: 0.4559857\ttotal: 33.3s\tremaining: 24.8s\n",
      "573:\tlearn: 0.4559787\ttotal: 33.4s\tremaining: 24.8s\n",
      "574:\tlearn: 0.4559747\ttotal: 33.4s\tremaining: 24.7s\n",
      "575:\tlearn: 0.4559706\ttotal: 33.5s\tremaining: 24.7s\n",
      "576:\tlearn: 0.4559659\ttotal: 33.5s\tremaining: 24.6s\n",
      "577:\tlearn: 0.4559621\ttotal: 33.6s\tremaining: 24.5s\n",
      "578:\tlearn: 0.4559562\ttotal: 33.7s\tremaining: 24.5s\n",
      "579:\tlearn: 0.4559515\ttotal: 33.7s\tremaining: 24.4s\n",
      "580:\tlearn: 0.4559465\ttotal: 33.8s\tremaining: 24.4s\n",
      "581:\tlearn: 0.4559418\ttotal: 33.8s\tremaining: 24.3s\n",
      "582:\tlearn: 0.4559363\ttotal: 33.9s\tremaining: 24.2s\n",
      "583:\tlearn: 0.4559332\ttotal: 34s\tremaining: 24.2s\n",
      "584:\tlearn: 0.4559276\ttotal: 34s\tremaining: 24.1s\n",
      "585:\tlearn: 0.4559226\ttotal: 34.1s\tremaining: 24.1s\n",
      "586:\tlearn: 0.4559183\ttotal: 34.1s\tremaining: 24s\n",
      "587:\tlearn: 0.4559121\ttotal: 34.2s\tremaining: 23.9s\n",
      "588:\tlearn: 0.4559058\ttotal: 34.2s\tremaining: 23.9s\n",
      "589:\tlearn: 0.4558968\ttotal: 34.3s\tremaining: 23.8s\n",
      "590:\tlearn: 0.4558923\ttotal: 34.4s\tremaining: 23.8s\n",
      "591:\tlearn: 0.4558854\ttotal: 34.4s\tremaining: 23.7s\n",
      "592:\tlearn: 0.4558781\ttotal: 34.5s\tremaining: 23.7s\n",
      "593:\tlearn: 0.4558750\ttotal: 34.5s\tremaining: 23.6s\n",
      "594:\tlearn: 0.4558697\ttotal: 34.6s\tremaining: 23.5s\n",
      "595:\tlearn: 0.4558663\ttotal: 34.6s\tremaining: 23.5s\n",
      "596:\tlearn: 0.4558612\ttotal: 34.7s\tremaining: 23.4s\n",
      "597:\tlearn: 0.4558537\ttotal: 34.7s\tremaining: 23.3s\n",
      "598:\tlearn: 0.4558484\ttotal: 34.8s\tremaining: 23.3s\n",
      "599:\tlearn: 0.4558442\ttotal: 34.8s\tremaining: 23.2s\n",
      "600:\tlearn: 0.4558373\ttotal: 34.9s\tremaining: 23.2s\n",
      "601:\tlearn: 0.4558319\ttotal: 35s\tremaining: 23.1s\n",
      "602:\tlearn: 0.4558274\ttotal: 35s\tremaining: 23s\n",
      "603:\tlearn: 0.4558208\ttotal: 35.1s\tremaining: 23s\n",
      "604:\tlearn: 0.4558147\ttotal: 35.1s\tremaining: 22.9s\n",
      "605:\tlearn: 0.4558109\ttotal: 35.2s\tremaining: 22.9s\n",
      "606:\tlearn: 0.4558038\ttotal: 35.2s\tremaining: 22.8s\n",
      "607:\tlearn: 0.4557989\ttotal: 35.3s\tremaining: 22.8s\n",
      "608:\tlearn: 0.4557944\ttotal: 35.4s\tremaining: 22.7s\n",
      "609:\tlearn: 0.4557888\ttotal: 35.4s\tremaining: 22.7s\n",
      "610:\tlearn: 0.4557836\ttotal: 35.5s\tremaining: 22.6s\n",
      "611:\tlearn: 0.4557800\ttotal: 35.5s\tremaining: 22.5s\n",
      "612:\tlearn: 0.4557745\ttotal: 35.6s\tremaining: 22.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613:\tlearn: 0.4557649\ttotal: 35.7s\tremaining: 22.4s\n",
      "614:\tlearn: 0.4557575\ttotal: 35.7s\tremaining: 22.4s\n",
      "615:\tlearn: 0.4557513\ttotal: 35.8s\tremaining: 22.3s\n",
      "616:\tlearn: 0.4557446\ttotal: 35.8s\tremaining: 22.2s\n",
      "617:\tlearn: 0.4557364\ttotal: 35.9s\tremaining: 22.2s\n",
      "618:\tlearn: 0.4557301\ttotal: 36s\tremaining: 22.1s\n",
      "619:\tlearn: 0.4557234\ttotal: 36s\tremaining: 22.1s\n",
      "620:\tlearn: 0.4557189\ttotal: 36.1s\tremaining: 22s\n",
      "621:\tlearn: 0.4557131\ttotal: 36.1s\tremaining: 22s\n",
      "622:\tlearn: 0.4557084\ttotal: 36.2s\tremaining: 21.9s\n",
      "623:\tlearn: 0.4557017\ttotal: 36.3s\tremaining: 21.9s\n",
      "624:\tlearn: 0.4556957\ttotal: 36.3s\tremaining: 21.8s\n",
      "625:\tlearn: 0.4556900\ttotal: 36.4s\tremaining: 21.7s\n",
      "626:\tlearn: 0.4556843\ttotal: 36.4s\tremaining: 21.7s\n",
      "627:\tlearn: 0.4556774\ttotal: 36.5s\tremaining: 21.6s\n",
      "628:\tlearn: 0.4556731\ttotal: 36.5s\tremaining: 21.6s\n",
      "629:\tlearn: 0.4556671\ttotal: 36.6s\tremaining: 21.5s\n",
      "630:\tlearn: 0.4556614\ttotal: 36.7s\tremaining: 21.4s\n",
      "631:\tlearn: 0.4556579\ttotal: 36.7s\tremaining: 21.4s\n",
      "632:\tlearn: 0.4556512\ttotal: 36.8s\tremaining: 21.3s\n",
      "633:\tlearn: 0.4556480\ttotal: 36.8s\tremaining: 21.3s\n",
      "634:\tlearn: 0.4556421\ttotal: 36.9s\tremaining: 21.2s\n",
      "635:\tlearn: 0.4556373\ttotal: 37s\tremaining: 21.2s\n",
      "636:\tlearn: 0.4556339\ttotal: 37s\tremaining: 21.1s\n",
      "637:\tlearn: 0.4556283\ttotal: 37.1s\tremaining: 21s\n",
      "638:\tlearn: 0.4556240\ttotal: 37.1s\tremaining: 21s\n",
      "639:\tlearn: 0.4556193\ttotal: 37.2s\tremaining: 20.9s\n",
      "640:\tlearn: 0.4556122\ttotal: 37.2s\tremaining: 20.9s\n",
      "641:\tlearn: 0.4556037\ttotal: 37.3s\tremaining: 20.8s\n",
      "642:\tlearn: 0.4555982\ttotal: 37.4s\tremaining: 20.7s\n",
      "643:\tlearn: 0.4555928\ttotal: 37.4s\tremaining: 20.7s\n",
      "644:\tlearn: 0.4555866\ttotal: 37.5s\tremaining: 20.6s\n",
      "645:\tlearn: 0.4555828\ttotal: 37.5s\tremaining: 20.6s\n",
      "646:\tlearn: 0.4555763\ttotal: 37.6s\tremaining: 20.5s\n",
      "647:\tlearn: 0.4555691\ttotal: 37.6s\tremaining: 20.4s\n",
      "648:\tlearn: 0.4555637\ttotal: 37.7s\tremaining: 20.4s\n",
      "649:\tlearn: 0.4555580\ttotal: 37.7s\tremaining: 20.3s\n",
      "650:\tlearn: 0.4555527\ttotal: 37.8s\tremaining: 20.3s\n",
      "651:\tlearn: 0.4555476\ttotal: 37.8s\tremaining: 20.2s\n",
      "652:\tlearn: 0.4555405\ttotal: 37.9s\tremaining: 20.1s\n",
      "653:\tlearn: 0.4555349\ttotal: 38s\tremaining: 20.1s\n",
      "654:\tlearn: 0.4555283\ttotal: 38s\tremaining: 20s\n",
      "655:\tlearn: 0.4555218\ttotal: 38.1s\tremaining: 20s\n",
      "656:\tlearn: 0.4555164\ttotal: 38.1s\tremaining: 19.9s\n",
      "657:\tlearn: 0.4555112\ttotal: 38.2s\tremaining: 19.9s\n",
      "658:\tlearn: 0.4555059\ttotal: 38.3s\tremaining: 19.8s\n",
      "659:\tlearn: 0.4555008\ttotal: 38.3s\tremaining: 19.7s\n",
      "660:\tlearn: 0.4554956\ttotal: 38.4s\tremaining: 19.7s\n",
      "661:\tlearn: 0.4554892\ttotal: 38.4s\tremaining: 19.6s\n",
      "662:\tlearn: 0.4554844\ttotal: 38.5s\tremaining: 19.6s\n",
      "663:\tlearn: 0.4554784\ttotal: 38.5s\tremaining: 19.5s\n",
      "664:\tlearn: 0.4554725\ttotal: 38.6s\tremaining: 19.4s\n",
      "665:\tlearn: 0.4554676\ttotal: 38.6s\tremaining: 19.4s\n",
      "666:\tlearn: 0.4554618\ttotal: 38.7s\tremaining: 19.3s\n",
      "667:\tlearn: 0.4554579\ttotal: 38.8s\tremaining: 19.3s\n",
      "668:\tlearn: 0.4554527\ttotal: 38.8s\tremaining: 19.2s\n",
      "669:\tlearn: 0.4554483\ttotal: 38.9s\tremaining: 19.2s\n",
      "670:\tlearn: 0.4554448\ttotal: 38.9s\tremaining: 19.1s\n",
      "671:\tlearn: 0.4554396\ttotal: 39s\tremaining: 19s\n",
      "672:\tlearn: 0.4554348\ttotal: 39s\tremaining: 19s\n",
      "673:\tlearn: 0.4554296\ttotal: 39.1s\tremaining: 18.9s\n",
      "674:\tlearn: 0.4554238\ttotal: 39.1s\tremaining: 18.8s\n",
      "675:\tlearn: 0.4554191\ttotal: 39.2s\tremaining: 18.8s\n",
      "676:\tlearn: 0.4554148\ttotal: 39.3s\tremaining: 18.7s\n",
      "677:\tlearn: 0.4554090\ttotal: 39.3s\tremaining: 18.7s\n",
      "678:\tlearn: 0.4554016\ttotal: 39.4s\tremaining: 18.6s\n",
      "679:\tlearn: 0.4553954\ttotal: 39.4s\tremaining: 18.6s\n",
      "680:\tlearn: 0.4553916\ttotal: 39.5s\tremaining: 18.5s\n",
      "681:\tlearn: 0.4553861\ttotal: 39.5s\tremaining: 18.4s\n",
      "682:\tlearn: 0.4553816\ttotal: 39.6s\tremaining: 18.4s\n",
      "683:\tlearn: 0.4553754\ttotal: 39.7s\tremaining: 18.3s\n",
      "684:\tlearn: 0.4553698\ttotal: 39.7s\tremaining: 18.3s\n",
      "685:\tlearn: 0.4553656\ttotal: 39.8s\tremaining: 18.2s\n",
      "686:\tlearn: 0.4553597\ttotal: 39.8s\tremaining: 18.2s\n",
      "687:\tlearn: 0.4553528\ttotal: 39.9s\tremaining: 18.1s\n",
      "688:\tlearn: 0.4553482\ttotal: 40s\tremaining: 18s\n",
      "689:\tlearn: 0.4553414\ttotal: 40s\tremaining: 18s\n",
      "690:\tlearn: 0.4553355\ttotal: 40.1s\tremaining: 17.9s\n",
      "691:\tlearn: 0.4553296\ttotal: 40.2s\tremaining: 17.9s\n",
      "692:\tlearn: 0.4553244\ttotal: 40.2s\tremaining: 17.8s\n",
      "693:\tlearn: 0.4553190\ttotal: 40.3s\tremaining: 17.8s\n",
      "694:\tlearn: 0.4553112\ttotal: 40.3s\tremaining: 17.7s\n",
      "695:\tlearn: 0.4553051\ttotal: 40.4s\tremaining: 17.6s\n",
      "696:\tlearn: 0.4553001\ttotal: 40.4s\tremaining: 17.6s\n",
      "697:\tlearn: 0.4552941\ttotal: 40.5s\tremaining: 17.5s\n",
      "698:\tlearn: 0.4552900\ttotal: 40.6s\tremaining: 17.5s\n",
      "699:\tlearn: 0.4552846\ttotal: 40.6s\tremaining: 17.4s\n",
      "700:\tlearn: 0.4552812\ttotal: 40.7s\tremaining: 17.4s\n",
      "701:\tlearn: 0.4552756\ttotal: 40.7s\tremaining: 17.3s\n",
      "702:\tlearn: 0.4552707\ttotal: 40.8s\tremaining: 17.2s\n",
      "703:\tlearn: 0.4552643\ttotal: 40.8s\tremaining: 17.2s\n",
      "704:\tlearn: 0.4552602\ttotal: 40.9s\tremaining: 17.1s\n",
      "705:\tlearn: 0.4552550\ttotal: 40.9s\tremaining: 17s\n",
      "706:\tlearn: 0.4552516\ttotal: 41s\tremaining: 17s\n",
      "707:\tlearn: 0.4552459\ttotal: 41.1s\tremaining: 16.9s\n",
      "708:\tlearn: 0.4552420\ttotal: 41.1s\tremaining: 16.9s\n",
      "709:\tlearn: 0.4552376\ttotal: 41.2s\tremaining: 16.8s\n",
      "710:\tlearn: 0.4552330\ttotal: 41.2s\tremaining: 16.8s\n",
      "711:\tlearn: 0.4552263\ttotal: 41.3s\tremaining: 16.7s\n",
      "712:\tlearn: 0.4552211\ttotal: 41.3s\tremaining: 16.6s\n",
      "713:\tlearn: 0.4552153\ttotal: 41.4s\tremaining: 16.6s\n",
      "714:\tlearn: 0.4552107\ttotal: 41.5s\tremaining: 16.5s\n",
      "715:\tlearn: 0.4552042\ttotal: 41.5s\tremaining: 16.5s\n",
      "716:\tlearn: 0.4551966\ttotal: 41.6s\tremaining: 16.4s\n",
      "717:\tlearn: 0.4551908\ttotal: 41.6s\tremaining: 16.3s\n",
      "718:\tlearn: 0.4551821\ttotal: 41.7s\tremaining: 16.3s\n",
      "719:\tlearn: 0.4551758\ttotal: 41.8s\tremaining: 16.2s\n",
      "720:\tlearn: 0.4551714\ttotal: 41.8s\tremaining: 16.2s\n",
      "721:\tlearn: 0.4551664\ttotal: 41.9s\tremaining: 16.1s\n",
      "722:\tlearn: 0.4551624\ttotal: 41.9s\tremaining: 16.1s\n",
      "723:\tlearn: 0.4551578\ttotal: 42s\tremaining: 16s\n",
      "724:\tlearn: 0.4551527\ttotal: 42s\tremaining: 15.9s\n",
      "725:\tlearn: 0.4551478\ttotal: 42.1s\tremaining: 15.9s\n",
      "726:\tlearn: 0.4551415\ttotal: 42.1s\tremaining: 15.8s\n",
      "727:\tlearn: 0.4551347\ttotal: 42.2s\tremaining: 15.8s\n",
      "728:\tlearn: 0.4551303\ttotal: 42.2s\tremaining: 15.7s\n",
      "729:\tlearn: 0.4551268\ttotal: 42.3s\tremaining: 15.6s\n",
      "730:\tlearn: 0.4551194\ttotal: 42.4s\tremaining: 15.6s\n",
      "731:\tlearn: 0.4551146\ttotal: 42.4s\tremaining: 15.5s\n",
      "732:\tlearn: 0.4551092\ttotal: 42.5s\tremaining: 15.5s\n",
      "733:\tlearn: 0.4551028\ttotal: 42.5s\tremaining: 15.4s\n",
      "734:\tlearn: 0.4550978\ttotal: 42.6s\tremaining: 15.4s\n",
      "735:\tlearn: 0.4550920\ttotal: 42.7s\tremaining: 15.3s\n",
      "736:\tlearn: 0.4550866\ttotal: 42.7s\tremaining: 15.2s\n",
      "737:\tlearn: 0.4550834\ttotal: 42.8s\tremaining: 15.2s\n",
      "738:\tlearn: 0.4550788\ttotal: 42.8s\tremaining: 15.1s\n",
      "739:\tlearn: 0.4550731\ttotal: 42.9s\tremaining: 15.1s\n",
      "740:\tlearn: 0.4550670\ttotal: 42.9s\tremaining: 15s\n",
      "741:\tlearn: 0.4550621\ttotal: 43s\tremaining: 14.9s\n",
      "742:\tlearn: 0.4550573\ttotal: 43s\tremaining: 14.9s\n",
      "743:\tlearn: 0.4550521\ttotal: 43.1s\tremaining: 14.8s\n",
      "744:\tlearn: 0.4550465\ttotal: 43.1s\tremaining: 14.8s\n",
      "745:\tlearn: 0.4550393\ttotal: 43.2s\tremaining: 14.7s\n",
      "746:\tlearn: 0.4550344\ttotal: 43.3s\tremaining: 14.7s\n",
      "747:\tlearn: 0.4550281\ttotal: 43.3s\tremaining: 14.6s\n",
      "748:\tlearn: 0.4550246\ttotal: 43.4s\tremaining: 14.5s\n",
      "749:\tlearn: 0.4550185\ttotal: 43.5s\tremaining: 14.5s\n",
      "750:\tlearn: 0.4550130\ttotal: 43.5s\tremaining: 14.4s\n",
      "751:\tlearn: 0.4550081\ttotal: 43.6s\tremaining: 14.4s\n",
      "752:\tlearn: 0.4550023\ttotal: 43.6s\tremaining: 14.3s\n",
      "753:\tlearn: 0.4549969\ttotal: 43.7s\tremaining: 14.3s\n",
      "754:\tlearn: 0.4549933\ttotal: 43.7s\tremaining: 14.2s\n",
      "755:\tlearn: 0.4549881\ttotal: 43.8s\tremaining: 14.1s\n",
      "756:\tlearn: 0.4549826\ttotal: 43.9s\tremaining: 14.1s\n",
      "757:\tlearn: 0.4549783\ttotal: 43.9s\tremaining: 14s\n",
      "758:\tlearn: 0.4549726\ttotal: 44s\tremaining: 14s\n",
      "759:\tlearn: 0.4549697\ttotal: 44s\tremaining: 13.9s\n",
      "760:\tlearn: 0.4549662\ttotal: 44.1s\tremaining: 13.8s\n",
      "761:\tlearn: 0.4549601\ttotal: 44.1s\tremaining: 13.8s\n",
      "762:\tlearn: 0.4549553\ttotal: 44.2s\tremaining: 13.7s\n",
      "763:\tlearn: 0.4549485\ttotal: 44.2s\tremaining: 13.7s\n",
      "764:\tlearn: 0.4549429\ttotal: 44.3s\tremaining: 13.6s\n",
      "765:\tlearn: 0.4549389\ttotal: 44.4s\tremaining: 13.6s\n",
      "766:\tlearn: 0.4549337\ttotal: 44.4s\tremaining: 13.5s\n",
      "767:\tlearn: 0.4549271\ttotal: 44.5s\tremaining: 13.4s\n",
      "768:\tlearn: 0.4549214\ttotal: 44.5s\tremaining: 13.4s\n",
      "769:\tlearn: 0.4549143\ttotal: 44.6s\tremaining: 13.3s\n",
      "770:\tlearn: 0.4549083\ttotal: 44.6s\tremaining: 13.3s\n",
      "771:\tlearn: 0.4549035\ttotal: 44.7s\tremaining: 13.2s\n",
      "772:\tlearn: 0.4548989\ttotal: 44.8s\tremaining: 13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773:\tlearn: 0.4548949\ttotal: 44.8s\tremaining: 13.1s\n",
      "774:\tlearn: 0.4548884\ttotal: 44.9s\tremaining: 13s\n",
      "775:\tlearn: 0.4548815\ttotal: 44.9s\tremaining: 13s\n",
      "776:\tlearn: 0.4548758\ttotal: 45s\tremaining: 12.9s\n",
      "777:\tlearn: 0.4548702\ttotal: 45.1s\tremaining: 12.9s\n",
      "778:\tlearn: 0.4548645\ttotal: 45.1s\tremaining: 12.8s\n",
      "779:\tlearn: 0.4548608\ttotal: 45.2s\tremaining: 12.7s\n",
      "780:\tlearn: 0.4548568\ttotal: 45.2s\tremaining: 12.7s\n",
      "781:\tlearn: 0.4548512\ttotal: 45.3s\tremaining: 12.6s\n",
      "782:\tlearn: 0.4548481\ttotal: 45.3s\tremaining: 12.6s\n",
      "783:\tlearn: 0.4548432\ttotal: 45.4s\tremaining: 12.5s\n",
      "784:\tlearn: 0.4548365\ttotal: 45.4s\tremaining: 12.4s\n",
      "785:\tlearn: 0.4548326\ttotal: 45.5s\tremaining: 12.4s\n",
      "786:\tlearn: 0.4548263\ttotal: 45.5s\tremaining: 12.3s\n",
      "787:\tlearn: 0.4548204\ttotal: 45.6s\tremaining: 12.3s\n",
      "788:\tlearn: 0.4548137\ttotal: 45.7s\tremaining: 12.2s\n",
      "789:\tlearn: 0.4548079\ttotal: 45.7s\tremaining: 12.2s\n",
      "790:\tlearn: 0.4548020\ttotal: 45.8s\tremaining: 12.1s\n",
      "791:\tlearn: 0.4547960\ttotal: 45.8s\tremaining: 12s\n",
      "792:\tlearn: 0.4547886\ttotal: 45.9s\tremaining: 12s\n",
      "793:\tlearn: 0.4547837\ttotal: 46s\tremaining: 11.9s\n",
      "794:\tlearn: 0.4547783\ttotal: 46s\tremaining: 11.9s\n",
      "795:\tlearn: 0.4547726\ttotal: 46.1s\tremaining: 11.8s\n",
      "796:\tlearn: 0.4547686\ttotal: 46.1s\tremaining: 11.7s\n",
      "797:\tlearn: 0.4547641\ttotal: 46.2s\tremaining: 11.7s\n",
      "798:\tlearn: 0.4547569\ttotal: 46.2s\tremaining: 11.6s\n",
      "799:\tlearn: 0.4547520\ttotal: 46.3s\tremaining: 11.6s\n",
      "800:\tlearn: 0.4547451\ttotal: 46.4s\tremaining: 11.5s\n",
      "801:\tlearn: 0.4547400\ttotal: 46.4s\tremaining: 11.5s\n",
      "802:\tlearn: 0.4547359\ttotal: 46.5s\tremaining: 11.4s\n",
      "803:\tlearn: 0.4547326\ttotal: 46.5s\tremaining: 11.3s\n",
      "804:\tlearn: 0.4547263\ttotal: 46.6s\tremaining: 11.3s\n",
      "805:\tlearn: 0.4547223\ttotal: 46.6s\tremaining: 11.2s\n",
      "806:\tlearn: 0.4547174\ttotal: 46.7s\tremaining: 11.2s\n",
      "807:\tlearn: 0.4547123\ttotal: 46.7s\tremaining: 11.1s\n",
      "808:\tlearn: 0.4547074\ttotal: 46.8s\tremaining: 11s\n",
      "809:\tlearn: 0.4547023\ttotal: 46.9s\tremaining: 11s\n",
      "810:\tlearn: 0.4546986\ttotal: 46.9s\tremaining: 10.9s\n",
      "811:\tlearn: 0.4546943\ttotal: 47s\tremaining: 10.9s\n",
      "812:\tlearn: 0.4546914\ttotal: 47s\tremaining: 10.8s\n",
      "813:\tlearn: 0.4546848\ttotal: 47.1s\tremaining: 10.8s\n",
      "814:\tlearn: 0.4546803\ttotal: 47.1s\tremaining: 10.7s\n",
      "815:\tlearn: 0.4546756\ttotal: 47.2s\tremaining: 10.6s\n",
      "816:\tlearn: 0.4546697\ttotal: 47.2s\tremaining: 10.6s\n",
      "817:\tlearn: 0.4546636\ttotal: 47.3s\tremaining: 10.5s\n",
      "818:\tlearn: 0.4546585\ttotal: 47.3s\tremaining: 10.5s\n",
      "819:\tlearn: 0.4546545\ttotal: 47.4s\tremaining: 10.4s\n",
      "820:\tlearn: 0.4546502\ttotal: 47.4s\tremaining: 10.3s\n",
      "821:\tlearn: 0.4546458\ttotal: 47.5s\tremaining: 10.3s\n",
      "822:\tlearn: 0.4546409\ttotal: 47.6s\tremaining: 10.2s\n",
      "823:\tlearn: 0.4546354\ttotal: 47.6s\tremaining: 10.2s\n",
      "824:\tlearn: 0.4546312\ttotal: 47.7s\tremaining: 10.1s\n",
      "825:\tlearn: 0.4546263\ttotal: 47.7s\tremaining: 10.1s\n",
      "826:\tlearn: 0.4546213\ttotal: 47.8s\tremaining: 10s\n",
      "827:\tlearn: 0.4546174\ttotal: 47.8s\tremaining: 9.94s\n",
      "828:\tlearn: 0.4546121\ttotal: 47.9s\tremaining: 9.88s\n",
      "829:\tlearn: 0.4546083\ttotal: 48s\tremaining: 9.82s\n",
      "830:\tlearn: 0.4546043\ttotal: 48s\tremaining: 9.76s\n",
      "831:\tlearn: 0.4546000\ttotal: 48.1s\tremaining: 9.71s\n",
      "832:\tlearn: 0.4545949\ttotal: 48.1s\tremaining: 9.65s\n",
      "833:\tlearn: 0.4545909\ttotal: 48.2s\tremaining: 9.59s\n",
      "834:\tlearn: 0.4545870\ttotal: 48.2s\tremaining: 9.53s\n",
      "835:\tlearn: 0.4545833\ttotal: 48.3s\tremaining: 9.47s\n",
      "836:\tlearn: 0.4545773\ttotal: 48.3s\tremaining: 9.41s\n",
      "837:\tlearn: 0.4545711\ttotal: 48.4s\tremaining: 9.35s\n",
      "838:\tlearn: 0.4545633\ttotal: 48.5s\tremaining: 9.3s\n",
      "839:\tlearn: 0.4545588\ttotal: 48.5s\tremaining: 9.24s\n",
      "840:\tlearn: 0.4545546\ttotal: 48.6s\tremaining: 9.18s\n",
      "841:\tlearn: 0.4545495\ttotal: 48.6s\tremaining: 9.13s\n",
      "842:\tlearn: 0.4545447\ttotal: 48.7s\tremaining: 9.07s\n",
      "843:\tlearn: 0.4545391\ttotal: 48.8s\tremaining: 9.01s\n",
      "844:\tlearn: 0.4545343\ttotal: 48.8s\tremaining: 8.95s\n",
      "845:\tlearn: 0.4545271\ttotal: 48.9s\tremaining: 8.9s\n",
      "846:\tlearn: 0.4545209\ttotal: 48.9s\tremaining: 8.84s\n",
      "847:\tlearn: 0.4545171\ttotal: 49s\tremaining: 8.78s\n",
      "848:\tlearn: 0.4545141\ttotal: 49s\tremaining: 8.72s\n",
      "849:\tlearn: 0.4545106\ttotal: 49.1s\tremaining: 8.66s\n",
      "850:\tlearn: 0.4545058\ttotal: 49.1s\tremaining: 8.61s\n",
      "851:\tlearn: 0.4545017\ttotal: 49.2s\tremaining: 8.55s\n",
      "852:\tlearn: 0.4544977\ttotal: 49.3s\tremaining: 8.49s\n",
      "853:\tlearn: 0.4544899\ttotal: 49.3s\tremaining: 8.43s\n",
      "854:\tlearn: 0.4544844\ttotal: 49.4s\tremaining: 8.38s\n",
      "855:\tlearn: 0.4544778\ttotal: 49.4s\tremaining: 8.32s\n",
      "856:\tlearn: 0.4544722\ttotal: 49.5s\tremaining: 8.26s\n",
      "857:\tlearn: 0.4544687\ttotal: 49.5s\tremaining: 8.2s\n",
      "858:\tlearn: 0.4544638\ttotal: 49.6s\tremaining: 8.14s\n",
      "859:\tlearn: 0.4544589\ttotal: 49.7s\tremaining: 8.08s\n",
      "860:\tlearn: 0.4544550\ttotal: 49.7s\tremaining: 8.03s\n",
      "861:\tlearn: 0.4544513\ttotal: 49.8s\tremaining: 7.97s\n",
      "862:\tlearn: 0.4544465\ttotal: 49.8s\tremaining: 7.91s\n",
      "863:\tlearn: 0.4544395\ttotal: 49.9s\tremaining: 7.85s\n",
      "864:\tlearn: 0.4544316\ttotal: 49.9s\tremaining: 7.79s\n",
      "865:\tlearn: 0.4544272\ttotal: 50s\tremaining: 7.74s\n",
      "866:\tlearn: 0.4544229\ttotal: 50.1s\tremaining: 7.68s\n",
      "867:\tlearn: 0.4544185\ttotal: 50.1s\tremaining: 7.62s\n",
      "868:\tlearn: 0.4544144\ttotal: 50.2s\tremaining: 7.56s\n",
      "869:\tlearn: 0.4544100\ttotal: 50.2s\tremaining: 7.51s\n",
      "870:\tlearn: 0.4544055\ttotal: 50.3s\tremaining: 7.45s\n",
      "871:\tlearn: 0.4543995\ttotal: 50.4s\tremaining: 7.39s\n",
      "872:\tlearn: 0.4543975\ttotal: 50.4s\tremaining: 7.33s\n",
      "873:\tlearn: 0.4543910\ttotal: 50.5s\tremaining: 7.28s\n",
      "874:\tlearn: 0.4543859\ttotal: 50.5s\tremaining: 7.22s\n",
      "875:\tlearn: 0.4543787\ttotal: 50.6s\tremaining: 7.16s\n",
      "876:\tlearn: 0.4543734\ttotal: 50.6s\tremaining: 7.1s\n",
      "877:\tlearn: 0.4543680\ttotal: 50.7s\tremaining: 7.04s\n",
      "878:\tlearn: 0.4543579\ttotal: 50.7s\tremaining: 6.99s\n",
      "879:\tlearn: 0.4543510\ttotal: 50.8s\tremaining: 6.93s\n",
      "880:\tlearn: 0.4543475\ttotal: 50.8s\tremaining: 6.87s\n",
      "881:\tlearn: 0.4543410\ttotal: 50.9s\tremaining: 6.81s\n",
      "882:\tlearn: 0.4543360\ttotal: 51s\tremaining: 6.75s\n",
      "883:\tlearn: 0.4543316\ttotal: 51s\tremaining: 6.7s\n",
      "884:\tlearn: 0.4543263\ttotal: 51.1s\tremaining: 6.64s\n",
      "885:\tlearn: 0.4543200\ttotal: 51.1s\tremaining: 6.58s\n",
      "886:\tlearn: 0.4543151\ttotal: 51.2s\tremaining: 6.52s\n",
      "887:\tlearn: 0.4543100\ttotal: 51.2s\tremaining: 6.46s\n",
      "888:\tlearn: 0.4543052\ttotal: 51.3s\tremaining: 6.4s\n",
      "889:\tlearn: 0.4542981\ttotal: 51.4s\tremaining: 6.35s\n",
      "890:\tlearn: 0.4542921\ttotal: 51.4s\tremaining: 6.29s\n",
      "891:\tlearn: 0.4542866\ttotal: 51.5s\tremaining: 6.23s\n",
      "892:\tlearn: 0.4542818\ttotal: 51.5s\tremaining: 6.17s\n",
      "893:\tlearn: 0.4542774\ttotal: 51.6s\tremaining: 6.11s\n",
      "894:\tlearn: 0.4542693\ttotal: 51.6s\tremaining: 6.06s\n",
      "895:\tlearn: 0.4542652\ttotal: 51.7s\tremaining: 6s\n",
      "896:\tlearn: 0.4542606\ttotal: 51.7s\tremaining: 5.94s\n",
      "897:\tlearn: 0.4542549\ttotal: 51.8s\tremaining: 5.88s\n",
      "898:\tlearn: 0.4542498\ttotal: 51.9s\tremaining: 5.83s\n",
      "899:\tlearn: 0.4542464\ttotal: 51.9s\tremaining: 5.77s\n",
      "900:\tlearn: 0.4542427\ttotal: 52s\tremaining: 5.71s\n",
      "901:\tlearn: 0.4542376\ttotal: 52s\tremaining: 5.65s\n",
      "902:\tlearn: 0.4542321\ttotal: 52.1s\tremaining: 5.59s\n",
      "903:\tlearn: 0.4542289\ttotal: 52.1s\tremaining: 5.54s\n",
      "904:\tlearn: 0.4542224\ttotal: 52.2s\tremaining: 5.48s\n",
      "905:\tlearn: 0.4542189\ttotal: 52.3s\tremaining: 5.42s\n",
      "906:\tlearn: 0.4542137\ttotal: 52.3s\tremaining: 5.36s\n",
      "907:\tlearn: 0.4542105\ttotal: 52.4s\tremaining: 5.3s\n",
      "908:\tlearn: 0.4542047\ttotal: 52.4s\tremaining: 5.25s\n",
      "909:\tlearn: 0.4541981\ttotal: 52.5s\tremaining: 5.19s\n",
      "910:\tlearn: 0.4541945\ttotal: 52.5s\tremaining: 5.13s\n",
      "911:\tlearn: 0.4541887\ttotal: 52.6s\tremaining: 5.08s\n",
      "912:\tlearn: 0.4541827\ttotal: 52.6s\tremaining: 5.02s\n",
      "913:\tlearn: 0.4541786\ttotal: 52.7s\tremaining: 4.96s\n",
      "914:\tlearn: 0.4541741\ttotal: 52.8s\tremaining: 4.9s\n",
      "915:\tlearn: 0.4541703\ttotal: 52.8s\tremaining: 4.84s\n",
      "916:\tlearn: 0.4541655\ttotal: 52.9s\tremaining: 4.79s\n",
      "917:\tlearn: 0.4541615\ttotal: 52.9s\tremaining: 4.73s\n",
      "918:\tlearn: 0.4541564\ttotal: 53s\tremaining: 4.67s\n",
      "919:\tlearn: 0.4541511\ttotal: 53s\tremaining: 4.61s\n",
      "920:\tlearn: 0.4541442\ttotal: 53.1s\tremaining: 4.55s\n",
      "921:\tlearn: 0.4541400\ttotal: 53.2s\tremaining: 4.5s\n",
      "922:\tlearn: 0.4541354\ttotal: 53.2s\tremaining: 4.44s\n",
      "923:\tlearn: 0.4541319\ttotal: 53.3s\tremaining: 4.38s\n",
      "924:\tlearn: 0.4541269\ttotal: 53.3s\tremaining: 4.32s\n",
      "925:\tlearn: 0.4541224\ttotal: 53.4s\tremaining: 4.27s\n",
      "926:\tlearn: 0.4541183\ttotal: 53.4s\tremaining: 4.21s\n",
      "927:\tlearn: 0.4541136\ttotal: 53.5s\tremaining: 4.15s\n",
      "928:\tlearn: 0.4541088\ttotal: 53.6s\tremaining: 4.09s\n",
      "929:\tlearn: 0.4541044\ttotal: 53.6s\tremaining: 4.04s\n",
      "930:\tlearn: 0.4540999\ttotal: 53.7s\tremaining: 3.98s\n",
      "931:\tlearn: 0.4540935\ttotal: 53.7s\tremaining: 3.92s\n",
      "932:\tlearn: 0.4540893\ttotal: 53.8s\tremaining: 3.86s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933:\tlearn: 0.4540839\ttotal: 53.8s\tremaining: 3.8s\n",
      "934:\tlearn: 0.4540790\ttotal: 53.9s\tremaining: 3.75s\n",
      "935:\tlearn: 0.4540734\ttotal: 53.9s\tremaining: 3.69s\n",
      "936:\tlearn: 0.4540685\ttotal: 54s\tremaining: 3.63s\n",
      "937:\tlearn: 0.4540636\ttotal: 54s\tremaining: 3.57s\n",
      "938:\tlearn: 0.4540611\ttotal: 54.1s\tremaining: 3.51s\n",
      "939:\tlearn: 0.4540550\ttotal: 54.1s\tremaining: 3.46s\n",
      "940:\tlearn: 0.4540502\ttotal: 54.2s\tremaining: 3.4s\n",
      "941:\tlearn: 0.4540461\ttotal: 54.3s\tremaining: 3.34s\n",
      "942:\tlearn: 0.4540405\ttotal: 54.3s\tremaining: 3.28s\n",
      "943:\tlearn: 0.4540366\ttotal: 54.4s\tremaining: 3.23s\n",
      "944:\tlearn: 0.4540301\ttotal: 54.4s\tremaining: 3.17s\n",
      "945:\tlearn: 0.4540250\ttotal: 54.5s\tremaining: 3.11s\n",
      "946:\tlearn: 0.4540172\ttotal: 54.5s\tremaining: 3.05s\n",
      "947:\tlearn: 0.4540101\ttotal: 54.6s\tremaining: 3s\n",
      "948:\tlearn: 0.4540037\ttotal: 54.7s\tremaining: 2.94s\n",
      "949:\tlearn: 0.4539982\ttotal: 54.7s\tremaining: 2.88s\n",
      "950:\tlearn: 0.4539929\ttotal: 54.8s\tremaining: 2.82s\n",
      "951:\tlearn: 0.4539858\ttotal: 54.8s\tremaining: 2.76s\n",
      "952:\tlearn: 0.4539810\ttotal: 54.9s\tremaining: 2.71s\n",
      "953:\tlearn: 0.4539727\ttotal: 54.9s\tremaining: 2.65s\n",
      "954:\tlearn: 0.4539670\ttotal: 55s\tremaining: 2.59s\n",
      "955:\tlearn: 0.4539640\ttotal: 55s\tremaining: 2.53s\n",
      "956:\tlearn: 0.4539564\ttotal: 55.1s\tremaining: 2.48s\n",
      "957:\tlearn: 0.4539522\ttotal: 55.1s\tremaining: 2.42s\n",
      "958:\tlearn: 0.4539464\ttotal: 55.2s\tremaining: 2.36s\n",
      "959:\tlearn: 0.4539410\ttotal: 55.3s\tremaining: 2.3s\n",
      "960:\tlearn: 0.4539363\ttotal: 55.3s\tremaining: 2.24s\n",
      "961:\tlearn: 0.4539312\ttotal: 55.4s\tremaining: 2.19s\n",
      "962:\tlearn: 0.4539270\ttotal: 55.4s\tremaining: 2.13s\n",
      "963:\tlearn: 0.4539221\ttotal: 55.5s\tremaining: 2.07s\n",
      "964:\tlearn: 0.4539161\ttotal: 55.5s\tremaining: 2.01s\n",
      "965:\tlearn: 0.4539130\ttotal: 55.6s\tremaining: 1.96s\n",
      "966:\tlearn: 0.4539077\ttotal: 55.7s\tremaining: 1.9s\n",
      "967:\tlearn: 0.4539030\ttotal: 55.7s\tremaining: 1.84s\n",
      "968:\tlearn: 0.4538980\ttotal: 55.8s\tremaining: 1.78s\n",
      "969:\tlearn: 0.4538948\ttotal: 55.8s\tremaining: 1.73s\n",
      "970:\tlearn: 0.4538898\ttotal: 55.9s\tremaining: 1.67s\n",
      "971:\tlearn: 0.4538860\ttotal: 55.9s\tremaining: 1.61s\n",
      "972:\tlearn: 0.4538798\ttotal: 56s\tremaining: 1.55s\n",
      "973:\tlearn: 0.4538747\ttotal: 56.1s\tremaining: 1.5s\n",
      "974:\tlearn: 0.4538693\ttotal: 56.1s\tremaining: 1.44s\n",
      "975:\tlearn: 0.4538642\ttotal: 56.2s\tremaining: 1.38s\n",
      "976:\tlearn: 0.4538603\ttotal: 56.2s\tremaining: 1.32s\n",
      "977:\tlearn: 0.4538534\ttotal: 56.3s\tremaining: 1.27s\n",
      "978:\tlearn: 0.4538500\ttotal: 56.4s\tremaining: 1.21s\n",
      "979:\tlearn: 0.4538443\ttotal: 56.4s\tremaining: 1.15s\n",
      "980:\tlearn: 0.4538399\ttotal: 56.5s\tremaining: 1.09s\n",
      "981:\tlearn: 0.4538348\ttotal: 56.5s\tremaining: 1.04s\n",
      "982:\tlearn: 0.4538311\ttotal: 56.6s\tremaining: 979ms\n",
      "983:\tlearn: 0.4538256\ttotal: 56.6s\tremaining: 921ms\n",
      "984:\tlearn: 0.4538206\ttotal: 56.7s\tremaining: 864ms\n",
      "985:\tlearn: 0.4538168\ttotal: 56.8s\tremaining: 806ms\n",
      "986:\tlearn: 0.4538107\ttotal: 56.8s\tremaining: 748ms\n",
      "987:\tlearn: 0.4538054\ttotal: 56.9s\tremaining: 691ms\n",
      "988:\tlearn: 0.4538003\ttotal: 56.9s\tremaining: 633ms\n",
      "989:\tlearn: 0.4537973\ttotal: 57s\tremaining: 576ms\n",
      "990:\tlearn: 0.4537921\ttotal: 57s\tremaining: 518ms\n",
      "991:\tlearn: 0.4537872\ttotal: 57.1s\tremaining: 460ms\n",
      "992:\tlearn: 0.4537818\ttotal: 57.1s\tremaining: 403ms\n",
      "993:\tlearn: 0.4537751\ttotal: 57.2s\tremaining: 345ms\n",
      "994:\tlearn: 0.4537708\ttotal: 57.3s\tremaining: 288ms\n",
      "995:\tlearn: 0.4537675\ttotal: 57.3s\tremaining: 230ms\n",
      "996:\tlearn: 0.4537618\ttotal: 57.4s\tremaining: 173ms\n",
      "997:\tlearn: 0.4537586\ttotal: 57.4s\tremaining: 115ms\n",
      "998:\tlearn: 0.4537540\ttotal: 57.5s\tremaining: 57.6ms\n",
      "999:\tlearn: 0.4537497\ttotal: 57.6s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265107123630833\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6181 - auc: 0.7297 - val_loss: 0.5140 - val_auc: 0.7803\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5171 - auc: 0.7769 - val_loss: 0.4924 - val_auc: 0.7984\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4927 - auc: 0.7966 - val_loss: 0.4842 - val_auc: 0.8066\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4831 - auc: 0.8055 - val_loss: 0.4801 - val_auc: 0.8111\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4785 - auc: 0.8098 - val_loss: 0.4777 - val_auc: 0.8130\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4764 - auc: 0.8121 - val_loss: 0.4763 - val_auc: 0.8136\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4750 - auc: 0.8135 - val_loss: 0.4756 - val_auc: 0.8160\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4754 - val_auc: 0.8153\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4737 - auc: 0.8148 - val_loss: 0.4753 - val_auc: 0.8150\n",
      "Epoch 10/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4740 - auc: 0.8145\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4739 - auc: 0.8147 - val_loss: 0.4752 - val_auc: 0.8153\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8151 - val_loss: 0.4752 - val_auc: 0.8152\n",
      "Epoch 12/100\n",
      "283648/284999 [============================>.] - ETA: 0s - loss: 0.4737 - auc: 0.8150Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4737 - auc: 0.8150 - val_loss: 0.4752 - val_auc: 0.8152\n",
      "Epoch 00012: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6966 - auc: 0.6725 - val_loss: 0.5431 - val_auc: 0.7536\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5505 - auc: 0.7516 - val_loss: 0.5058 - val_auc: 0.7849\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5111 - auc: 0.7797 - val_loss: 0.4901 - val_auc: 0.8000\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4930 - auc: 0.7960 - val_loss: 0.4826 - val_auc: 0.8076\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4843 - auc: 0.8043 - val_loss: 0.4788 - val_auc: 0.8116\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4798 - auc: 0.8089 - val_loss: 0.4764 - val_auc: 0.8137\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4775 - auc: 0.8111 - val_loss: 0.4751 - val_auc: 0.8161\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4759 - auc: 0.8127 - val_loss: 0.4742 - val_auc: 0.8161\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4751 - auc: 0.8135 - val_loss: 0.4735 - val_auc: 0.8170\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8140 - val_loss: 0.4735 - val_auc: 0.8162\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4732 - auc: 0.8154 - val_loss: 0.4732 - val_auc: 0.8175\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8149 - val_loss: 0.4731 - val_auc: 0.8168\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4733 - auc: 0.8155 - val_loss: 0.4732 - val_auc: 0.8163\n",
      "Epoch 14/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4727 - auc: 0.8158\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4727 - auc: 0.8160 - val_loss: 0.4732 - val_auc: 0.8172\n",
      "Epoch 15/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4731 - auc: 0.8156 - val_loss: 0.4732 - val_auc: 0.8170\n",
      "Epoch 16/100\n",
      "283648/284999 [============================>.] - ETA: 0s - loss: 0.4726 - auc: 0.8160Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4728 - auc: 0.8157 - val_loss: 0.4732 - val_auc: 0.8173\n",
      "Epoch 00016: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5761 - auc: 0.7512 - val_loss: 0.4927 - val_auc: 0.8053\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5017 - auc: 0.7915 - val_loss: 0.4726 - val_auc: 0.8173\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4859 - auc: 0.8033 - val_loss: 0.4674 - val_auc: 0.8221\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4798 - auc: 0.8087 - val_loss: 0.4650 - val_auc: 0.8247\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4774 - auc: 0.8112 - val_loss: 0.4637 - val_auc: 0.8258\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4759 - auc: 0.8126 - val_loss: 0.4625 - val_auc: 0.8275\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4749 - auc: 0.8136 - val_loss: 0.4617 - val_auc: 0.8270\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4748 - auc: 0.8138 - val_loss: 0.4613 - val_auc: 0.8276\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4746 - auc: 0.8141 - val_loss: 0.4610 - val_auc: 0.8282\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4609 - val_auc: 0.8291\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8147 - val_loss: 0.4609 - val_auc: 0.8284\n",
      "Epoch 12/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4734 - auc: 0.8153 - val_loss: 0.4607 - val_auc: 0.8293\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8151 - val_loss: 0.4609 - val_auc: 0.8290\n",
      "Epoch 14/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8150 - val_loss: 0.4611 - val_auc: 0.8284\n",
      "Epoch 15/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4736 - auc: 0.8152Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8151 - val_loss: 0.4614 - val_auc: 0.8282\n",
      "Epoch 00015: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6211 - auc: 0.7236 - val_loss: 0.5036 - val_auc: 0.7906\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5151 - auc: 0.7794 - val_loss: 0.4792 - val_auc: 0.8103\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4921 - auc: 0.7974 - val_loss: 0.4703 - val_auc: 0.8206\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4828 - auc: 0.8057 - val_loss: 0.4660 - val_auc: 0.8245\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4782 - auc: 0.8104 - val_loss: 0.4634 - val_auc: 0.8268\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4765 - auc: 0.8121 - val_loss: 0.4622 - val_auc: 0.8279\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4753 - auc: 0.8131 - val_loss: 0.4614 - val_auc: 0.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4749 - auc: 0.8136 - val_loss: 0.4612 - val_auc: 0.8286\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4745 - auc: 0.8142 - val_loss: 0.4610 - val_auc: 0.8290\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4745 - auc: 0.8139 - val_loss: 0.4606 - val_auc: 0.8287\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4736 - auc: 0.8150 - val_loss: 0.4607 - val_auc: 0.8289\n",
      "Epoch 12/100\n",
      "276480/284999 [============================>.] - ETA: 0s - loss: 0.4738 - auc: 0.8147\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4608 - val_auc: 0.8288\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8144 - val_loss: 0.4609 - val_auc: 0.8292\n",
      "Epoch 14/100\n",
      "278528/284999 [============================>.] - ETA: 0s - loss: 0.4735 - auc: 0.8152Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.4737 - auc: 0.8151 - val_loss: 0.4609 - val_auc: 0.8282\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5670 - auc: 0.7876 - val_loss: 0.4878 - val_auc: 0.8122\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4907 - auc: 0.8034 - val_loss: 0.4710 - val_auc: 0.8197\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4792 - auc: 0.8100 - val_loss: 0.4670 - val_auc: 0.8239\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4759 - auc: 0.8128 - val_loss: 0.4656 - val_auc: 0.8244\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4747 - auc: 0.8138 - val_loss: 0.4650 - val_auc: 0.8258\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4742 - auc: 0.8144 - val_loss: 0.4646 - val_auc: 0.8249\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8147 - val_loss: 0.4645 - val_auc: 0.8254\n",
      "Epoch 8/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4737 - auc: 0.8149\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4737 - auc: 0.8149 - val_loss: 0.4646 - val_auc: 0.8254\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4647 - val_auc: 0.8250\n",
      "Epoch 10/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4737 - auc: 0.8148Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4736 - auc: 0.8149 - val_loss: 0.4648 - val_auc: 0.8255\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6050 - auc: 0.7315 - val_loss: 0.4996 - val_auc: 0.7940\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5111 - auc: 0.7823 - val_loss: 0.4797 - val_auc: 0.8106\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4908 - auc: 0.7983 - val_loss: 0.4726 - val_auc: 0.8187\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4823 - auc: 0.8063 - val_loss: 0.4693 - val_auc: 0.8218\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4780 - auc: 0.8105 - val_loss: 0.4676 - val_auc: 0.8235\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4760 - auc: 0.8125 - val_loss: 0.4666 - val_auc: 0.8243\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4751 - auc: 0.8135 - val_loss: 0.4662 - val_auc: 0.8239\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8144 - val_loss: 0.4660 - val_auc: 0.8244\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4744 - auc: 0.8143 - val_loss: 0.4658 - val_auc: 0.8246\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8144 - val_loss: 0.4660 - val_auc: 0.8236\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8145 - val_loss: 0.4658 - val_auc: 0.8243\n",
      "Epoch 12/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4742 - auc: 0.8145\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4741 - auc: 0.8144 - val_loss: 0.4659 - val_auc: 0.8242\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4736 - auc: 0.8150 - val_loss: 0.4658 - val_auc: 0.8247\n",
      "Epoch 14/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4735 - auc: 0.8151Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8150 - val_loss: 0.4658 - val_auc: 0.8240\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6157 - auc: 0.7343 - val_loss: 0.5058 - val_auc: 0.7906\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5111 - auc: 0.7834 - val_loss: 0.4807 - val_auc: 0.8106\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4870 - auc: 0.8025 - val_loss: 0.4728 - val_auc: 0.8180\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4794 - auc: 0.8093 - val_loss: 0.4696 - val_auc: 0.8207\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4757 - auc: 0.8129 - val_loss: 0.4681 - val_auc: 0.8216\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4751 - auc: 0.8135 - val_loss: 0.4677 - val_auc: 0.8226\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4744 - auc: 0.8143 - val_loss: 0.4676 - val_auc: 0.8228\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8150 - val_loss: 0.4675 - val_auc: 0.8227\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8149 - val_loss: 0.4673 - val_auc: 0.8224\n",
      "Epoch 10/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4733 - auc: 0.8152\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8148 - val_loss: 0.4676 - val_auc: 0.8223\n",
      "Epoch 11/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4733 - auc: 0.8153Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8151 - val_loss: 0.4675 - val_auc: 0.8217\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6868 - auc: 0.6234 - val_loss: 0.5291 - val_auc: 0.7641\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5411 - auc: 0.7545 - val_loss: 0.4926 - val_auc: 0.7991\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5042 - auc: 0.7859 - val_loss: 0.4794 - val_auc: 0.8113\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4894 - auc: 0.7997 - val_loss: 0.4735 - val_auc: 0.8172\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4822 - auc: 0.8063 - val_loss: 0.4701 - val_auc: 0.8207\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4788 - auc: 0.8097 - val_loss: 0.4683 - val_auc: 0.8219\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4763 - auc: 0.8122 - val_loss: 0.4672 - val_auc: 0.8232\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4753 - auc: 0.8132 - val_loss: 0.4666 - val_auc: 0.8234\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4749 - auc: 0.8138 - val_loss: 0.4664 - val_auc: 0.8242\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8143 - val_loss: 0.4664 - val_auc: 0.8241\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8147 - val_loss: 0.4661 - val_auc: 0.8241\n",
      "Epoch 12/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4737 - auc: 0.8149\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4736 - auc: 0.8150 - val_loss: 0.4663 - val_auc: 0.8237\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4733 - auc: 0.8155 - val_loss: 0.4663 - val_auc: 0.8241\n",
      "Epoch 14/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4733 - auc: 0.8152Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4733 - auc: 0.8153 - val_loss: 0.4664 - val_auc: 0.8241\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6198 - auc: 0.7130 - val_loss: 0.4987 - val_auc: 0.7969\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5145 - auc: 0.7797 - val_loss: 0.4720 - val_auc: 0.8186\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4916 - auc: 0.7981 - val_loss: 0.4640 - val_auc: 0.8265\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4839 - auc: 0.8048 - val_loss: 0.4610 - val_auc: 0.8301\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4795 - auc: 0.8090 - val_loss: 0.4587 - val_auc: 0.8329\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4769 - auc: 0.8117 - val_loss: 0.4574 - val_auc: 0.8336\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4760 - auc: 0.8126 - val_loss: 0.4564 - val_auc: 0.8332\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8141 - val_loss: 0.4560 - val_auc: 0.8337\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8140 - val_loss: 0.4563 - val_auc: 0.8342\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8147 - val_loss: 0.4555 - val_auc: 0.8339\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8144 - val_loss: 0.4559 - val_auc: 0.8341\n",
      "Epoch 12/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4738 - auc: 0.8149\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8150 - val_loss: 0.4558 - val_auc: 0.8343\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4557 - val_auc: 0.8334\n",
      "Epoch 14/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4738 - auc: 0.8149Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8150 - val_loss: 0.4559 - val_auc: 0.8341\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6930 - auc: 0.6727 - val_loss: 0.5296 - val_auc: 0.7648\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5548 - auc: 0.7484 - val_loss: 0.4957 - val_auc: 0.7944\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5148 - auc: 0.7762 - val_loss: 0.4809 - val_auc: 0.8101\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4957 - auc: 0.7929 - val_loss: 0.4732 - val_auc: 0.8176\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4856 - auc: 0.8030 - val_loss: 0.4684 - val_auc: 0.8226\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4808 - auc: 0.8077 - val_loss: 0.4652 - val_auc: 0.8258\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4772 - auc: 0.8114 - val_loss: 0.4636 - val_auc: 0.8269\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4754 - auc: 0.8130 - val_loss: 0.4630 - val_auc: 0.8275\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4748 - auc: 0.8138 - val_loss: 0.4623 - val_auc: 0.8276\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4744 - auc: 0.8142 - val_loss: 0.4625 - val_auc: 0.8276\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8150 - val_loss: 0.4619 - val_auc: 0.8279\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8147 - val_loss: 0.4623 - val_auc: 0.8280\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8152 - val_loss: 0.4623 - val_auc: 0.8285\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8145 - val_loss: 0.4620 - val_auc: 0.8272\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8149 - val_loss: 0.4621 - val_auc: 0.8278\n",
      "Epoch 16/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4736 - auc: 0.8152Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8153 - val_loss: 0.4622 - val_auc: 0.8274\n",
      "Epoch 00016: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5915 - auc: 0.7371 - val_loss: 0.4898 - val_auc: 0.8065\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5040 - auc: 0.7894 - val_loss: 0.4705 - val_auc: 0.8214\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4858 - auc: 0.8035 - val_loss: 0.4640 - val_auc: 0.8274\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4790 - auc: 0.8097 - val_loss: 0.4613 - val_auc: 0.8299\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4763 - auc: 0.8123 - val_loss: 0.4606 - val_auc: 0.8295\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4751 - auc: 0.8135 - val_loss: 0.4603 - val_auc: 0.8303\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4747 - auc: 0.8137 - val_loss: 0.4603 - val_auc: 0.8303\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8142 - val_loss: 0.4604 - val_auc: 0.8296\n",
      "Epoch 9/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4747 - auc: 0.8139Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4747 - auc: 0.8138 - val_loss: 0.4603 - val_auc: 0.8300\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6058 - auc: 0.7370 - val_loss: 0.4892 - val_auc: 0.8038\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5095 - auc: 0.7848 - val_loss: 0.4692 - val_auc: 0.8194\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4899 - auc: 0.7996 - val_loss: 0.4642 - val_auc: 0.8253\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4821 - auc: 0.8066 - val_loss: 0.4614 - val_auc: 0.8272\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4785 - auc: 0.8100 - val_loss: 0.4600 - val_auc: 0.8293\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4760 - auc: 0.8124 - val_loss: 0.4589 - val_auc: 0.8304\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4755 - auc: 0.8129 - val_loss: 0.4589 - val_auc: 0.8312\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4747 - auc: 0.8138 - val_loss: 0.4584 - val_auc: 0.8309\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4750 - auc: 0.8135 - val_loss: 0.4583 - val_auc: 0.8314\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4739 - auc: 0.8145 - val_loss: 0.4577 - val_auc: 0.8313\n",
      "Epoch 11/100\n",
      "278528/285000 [============================>.] - ETA: 0s - loss: 0.4745 - auc: 0.8139Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4744 - auc: 0.8141 - val_loss: 0.4581 - val_auc: 0.8311\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.7137 - auc: 0.5843 - val_loss: 0.5307 - val_auc: 0.7614\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5416 - auc: 0.7553 - val_loss: 0.4913 - val_auc: 0.7994\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5089 - auc: 0.7827 - val_loss: 0.4770 - val_auc: 0.8141\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4934 - auc: 0.7961 - val_loss: 0.4697 - val_auc: 0.8216\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4853 - auc: 0.8035 - val_loss: 0.4659 - val_auc: 0.8248\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4803 - auc: 0.8082 - val_loss: 0.4637 - val_auc: 0.8272\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4779 - auc: 0.8108 - val_loss: 0.4623 - val_auc: 0.8293\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4774 - auc: 0.8111 - val_loss: 0.4614 - val_auc: 0.8288\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4758 - auc: 0.8129 - val_loss: 0.4606 - val_auc: 0.8304\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4751 - auc: 0.8134 - val_loss: 0.4602 - val_auc: 0.8303\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8143 - val_loss: 0.4599 - val_auc: 0.8308\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8143 - val_loss: 0.4599 - val_auc: 0.8300\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8146 - val_loss: 0.4598 - val_auc: 0.8301\n",
      "Epoch 14/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4736 - auc: 0.8150Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4736 - auc: 0.8151 - val_loss: 0.4597 - val_auc: 0.8307\n",
      "Epoch 00014: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6056 - auc: 0.7254 - val_loss: 0.5075 - val_auc: 0.7873\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5075 - auc: 0.7856 - val_loss: 0.4844 - val_auc: 0.8071\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4860 - auc: 0.8032 - val_loss: 0.4780 - val_auc: 0.8128\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4790 - auc: 0.8098 - val_loss: 0.4754 - val_auc: 0.8154\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4758 - auc: 0.8128 - val_loss: 0.4743 - val_auc: 0.8177\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4747 - auc: 0.8138 - val_loss: 0.4739 - val_auc: 0.8168\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4740 - auc: 0.8145 - val_loss: 0.4738 - val_auc: 0.8168\n",
      "Epoch 8/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4739 - auc: 0.8148\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8148 - val_loss: 0.4737 - val_auc: 0.8164\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8146 - val_loss: 0.4738 - val_auc: 0.8174\n",
      "Epoch 10/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4735 - auc: 0.8152Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8150 - val_loss: 0.4738 - val_auc: 0.8173\n",
      "Epoch 00010: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.7145 - auc: 0.6205 - val_loss: 0.5320 - val_auc: 0.7604\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5537 - auc: 0.7485 - val_loss: 0.4943 - val_auc: 0.7962\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5144 - auc: 0.7777 - val_loss: 0.4798 - val_auc: 0.8107\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4964 - auc: 0.7930 - val_loss: 0.4714 - val_auc: 0.8187\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4869 - auc: 0.8019 - val_loss: 0.4666 - val_auc: 0.8234\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4820 - auc: 0.8066 - val_loss: 0.4639 - val_auc: 0.8267\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4786 - auc: 0.8100 - val_loss: 0.4621 - val_auc: 0.8276\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4767 - auc: 0.8117 - val_loss: 0.4610 - val_auc: 0.8296\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4756 - auc: 0.8131 - val_loss: 0.4601 - val_auc: 0.8300\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4747 - auc: 0.8139 - val_loss: 0.4597 - val_auc: 0.8303\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8145 - val_loss: 0.4598 - val_auc: 0.8300\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8141 - val_loss: 0.4598 - val_auc: 0.8303\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4594 - val_auc: 0.8310\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8147 - val_loss: 0.4596 - val_auc: 0.8302\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8148 - val_loss: 0.4595 - val_auc: 0.8304\n",
      "Epoch 16/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4737 - auc: 0.8151\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4736 - auc: 0.8153 - val_loss: 0.4592 - val_auc: 0.8307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4733 - auc: 0.8152 - val_loss: 0.4595 - val_auc: 0.8310\n",
      "Epoch 18/100\n",
      "281600/285000 [============================>.] - ETA: 0s - loss: 0.4739 - auc: 0.8150Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4738 - auc: 0.8149 - val_loss: 0.4596 - val_auc: 0.8306\n",
      "Epoch 00018: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5699 - auc: 0.7623 - val_loss: 0.4843 - val_auc: 0.8140\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4933 - auc: 0.7996 - val_loss: 0.4677 - val_auc: 0.8218\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4806 - auc: 0.8082 - val_loss: 0.4643 - val_auc: 0.8256\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4763 - auc: 0.8124 - val_loss: 0.4626 - val_auc: 0.8275\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4752 - auc: 0.8133 - val_loss: 0.4618 - val_auc: 0.8282\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8143 - val_loss: 0.4616 - val_auc: 0.8281\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4748 - auc: 0.8136 - val_loss: 0.4615 - val_auc: 0.8287\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8143 - val_loss: 0.4616 - val_auc: 0.8287\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8145 - val_loss: 0.4616 - val_auc: 0.8285\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8146 - val_loss: 0.4615 - val_auc: 0.8290\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4613 - val_auc: 0.8291\n",
      "Epoch 12/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4743 - auc: 0.8145Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8146 - val_loss: 0.4612 - val_auc: 0.8283\n",
      "Epoch 00012: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5877 - auc: 0.7432 - val_loss: 0.4896 - val_auc: 0.8060\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.5056 - auc: 0.7875 - val_loss: 0.4695 - val_auc: 0.8214\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8005 - val_loss: 0.4627 - val_auc: 0.8270\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4816 - auc: 0.8071 - val_loss: 0.4602 - val_auc: 0.8305\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4789 - auc: 0.8097 - val_loss: 0.4586 - val_auc: 0.8316\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4767 - auc: 0.8119 - val_loss: 0.4573 - val_auc: 0.8323\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4754 - auc: 0.8132 - val_loss: 0.4565 - val_auc: 0.8339\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4750 - auc: 0.8137 - val_loss: 0.4553 - val_auc: 0.8344\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4746 - auc: 0.8140 - val_loss: 0.4553 - val_auc: 0.8343\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8143 - val_loss: 0.4554 - val_auc: 0.8352\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8141 - val_loss: 0.4553 - val_auc: 0.8342\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4740 - auc: 0.8147 - val_loss: 0.4552 - val_auc: 0.8347\n",
      "Epoch 13/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4744 - auc: 0.8142\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4744 - auc: 0.8141 - val_loss: 0.4553 - val_auc: 0.8340\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4549 - val_auc: 0.8345\n",
      "Epoch 15/100\n",
      "276480/285001 [============================>.] - ETA: 0s - loss: 0.4738 - auc: 0.8147Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4551 - val_auc: 0.8347\n",
      "Epoch 00015: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6344 - auc: 0.7124 - val_loss: 0.5163 - val_auc: 0.7767\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5266 - auc: 0.7681 - val_loss: 0.4885 - val_auc: 0.8020\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4982 - auc: 0.7912 - val_loss: 0.4780 - val_auc: 0.8126\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4865 - auc: 0.8021 - val_loss: 0.4730 - val_auc: 0.8183\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4810 - auc: 0.8076 - val_loss: 0.4703 - val_auc: 0.8201\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4784 - auc: 0.8100 - val_loss: 0.4685 - val_auc: 0.8227\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4765 - auc: 0.8121 - val_loss: 0.4671 - val_auc: 0.8233\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4750 - auc: 0.8136 - val_loss: 0.4664 - val_auc: 0.8238\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4744 - auc: 0.8143 - val_loss: 0.4660 - val_auc: 0.8243\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4742 - auc: 0.8146 - val_loss: 0.4659 - val_auc: 0.8249\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8145 - val_loss: 0.4659 - val_auc: 0.8246\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8150 - val_loss: 0.4656 - val_auc: 0.8248\n",
      "Epoch 13/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4735 - auc: 0.8152\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4734 - auc: 0.8152 - val_loss: 0.4656 - val_auc: 0.8247\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8151 - val_loss: 0.4656 - val_auc: 0.8248\n",
      "Epoch 15/100\n",
      "276480/285001 [============================>.] - ETA: 0s - loss: 0.4733 - auc: 0.8154Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4733 - auc: 0.8154 - val_loss: 0.4656 - val_auc: 0.8245\n",
      "Epoch 00015: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.7708 - auc: 0.5592 - val_loss: 0.5502 - val_auc: 0.7389\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5785 - auc: 0.7281 - val_loss: 0.5065 - val_auc: 0.7835\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5300 - auc: 0.7644 - val_loss: 0.4873 - val_auc: 0.8026\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5046 - auc: 0.7851 - val_loss: 0.4767 - val_auc: 0.8142\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4915 - auc: 0.7973 - val_loss: 0.4706 - val_auc: 0.8206\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4840 - auc: 0.8048 - val_loss: 0.4668 - val_auc: 0.8248\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4799 - auc: 0.8087 - val_loss: 0.4645 - val_auc: 0.8256\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4775 - auc: 0.8111 - val_loss: 0.4633 - val_auc: 0.8265\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4759 - auc: 0.8127 - val_loss: 0.4626 - val_auc: 0.8272\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4754 - auc: 0.8132 - val_loss: 0.4622 - val_auc: 0.8274\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4745 - auc: 0.8142 - val_loss: 0.4620 - val_auc: 0.8277\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4747 - auc: 0.8139 - val_loss: 0.4620 - val_auc: 0.8275\n",
      "Epoch 13/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4743 - auc: 0.8145 - val_loss: 0.4619 - val_auc: 0.8280\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4739 - auc: 0.8149 - val_loss: 0.4618 - val_auc: 0.8281\n",
      "Epoch 15/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4734 - auc: 0.8154 - val_loss: 0.4619 - val_auc: 0.8272\n",
      "Epoch 16/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4735 - auc: 0.8153Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4735 - auc: 0.8154 - val_loss: 0.4619 - val_auc: 0.8272\n",
      "Epoch 00016: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6734 - auc: 0.6512 - val_loss: 0.5181 - val_auc: 0.7755\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5380 - auc: 0.7602 - val_loss: 0.4889 - val_auc: 0.8025\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5054 - auc: 0.7856 - val_loss: 0.4783 - val_auc: 0.8129\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4899 - auc: 0.7992 - val_loss: 0.4733 - val_auc: 0.8170\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4825 - auc: 0.8062 - val_loss: 0.4708 - val_auc: 0.8197\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4789 - auc: 0.8097 - val_loss: 0.4696 - val_auc: 0.8197\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4767 - auc: 0.8117 - val_loss: 0.4691 - val_auc: 0.8215\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4754 - auc: 0.8132 - val_loss: 0.4686 - val_auc: 0.8213\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4749 - auc: 0.8137 - val_loss: 0.4686 - val_auc: 0.8215\n",
      "Epoch 10/100\n",
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4738 - auc: 0.8149\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4737 - auc: 0.8150 - val_loss: 0.4684 - val_auc: 0.8209\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4685 - val_auc: 0.8221\n",
      "Epoch 12/100\n",
      "276480/285001 [============================>.] - ETA: 0s - loss: 0.4734 - auc: 0.8151Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4737 - auc: 0.8149 - val_loss: 0.4686 - val_auc: 0.8220\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [5:51:31<1:32:44, 5564.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8259485147534571\n",
      "0.8202278605475976\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.3s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.0s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=10, max_depth=3, gamma=5, colsample_bytree=1.0, total=  23.9s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.6s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.6s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.7s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.6s\n",
      "[CV] subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=50, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=1.0, total=   1.6s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  22.2s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  23.0s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  22.3s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  22.5s\n",
      "[CV] subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=500, min_child_weight=5, max_depth=5, gamma=0.5, colsample_bytree=0.8, total=  22.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   5.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   5.9s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   5.7s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   5.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=3, gamma=2, colsample_bytree=0.6, total=   5.7s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.2s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.4s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.3s\n",
      "[CV] subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=1.0, n_estimators=300, min_child_weight=5, max_depth=3, gamma=1.5, colsample_bytree=1.0, total=   8.5s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  30.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  30.5s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  30.1s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  30.4s\n",
      "[CV] subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.8, n_estimators=800, min_child_weight=1, max_depth=4, gamma=0.5, colsample_bytree=1.0, total=  30.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=   9.8s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=   9.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=   9.6s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=   9.5s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=5, max_depth=5, gamma=2, colsample_bytree=1.0, total=   9.7s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   4.7s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   4.6s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   4.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   4.5s\n",
      "[CV] subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6 \n",
      "[CV]  subsample=1.0, n_estimators=100, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, total=   4.8s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  14.6s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  14.2s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  14.2s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  14.1s\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=1, max_depth=5, gamma=1.5, colsample_bytree=1.0, total=  14.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=   9.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=   9.3s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=   9.2s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=   9.4s\n",
      "[CV] subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.6, n_estimators=200, min_child_weight=10, max_depth=5, gamma=1.5, colsample_bytree=0.8, total=   9.5s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  21.4s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  20.7s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  20.9s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  20.1s\n",
      "[CV] subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=800, min_child_weight=10, max_depth=3, gamma=2, colsample_bytree=0.8, total=  20.4s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  17.5s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  17.4s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  17.6s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  17.3s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=5, max_depth=4, gamma=2, colsample_bytree=0.6, total=  17.8s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  22.1s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  21.5s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  21.2s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  21.4s\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=10, max_depth=5, gamma=2, colsample_bytree=0.6, total=  21.8s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   2.9s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   3.0s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   2.9s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   2.8s\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=3, gamma=0.5, colsample_bytree=0.6, total=   2.8s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   7.3s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   7.2s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   7.2s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   7.3s\n",
      "[CV] subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8 \n",
      "[CV]  subsample=1.0, n_estimators=200, min_child_weight=10, max_depth=4, gamma=1, colsample_bytree=0.8, total=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820661163426179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 34.8ms\tremaining: 3.45s\n",
      "1:\ttotal: 65ms\tremaining: 3.18s\n",
      "2:\ttotal: 94.5ms\tremaining: 3.05s\n",
      "3:\ttotal: 124ms\tremaining: 2.98s\n",
      "4:\ttotal: 155ms\tremaining: 2.94s\n",
      "5:\ttotal: 187ms\tremaining: 2.92s\n",
      "6:\ttotal: 219ms\tremaining: 2.91s\n",
      "7:\ttotal: 252ms\tremaining: 2.9s\n",
      "8:\ttotal: 285ms\tremaining: 2.88s\n",
      "9:\ttotal: 315ms\tremaining: 2.84s\n",
      "10:\ttotal: 348ms\tremaining: 2.81s\n",
      "11:\ttotal: 380ms\tremaining: 2.79s\n",
      "12:\ttotal: 412ms\tremaining: 2.76s\n",
      "13:\ttotal: 444ms\tremaining: 2.73s\n",
      "14:\ttotal: 477ms\tremaining: 2.7s\n",
      "15:\ttotal: 510ms\tremaining: 2.68s\n",
      "16:\ttotal: 543ms\tremaining: 2.65s\n",
      "17:\ttotal: 574ms\tremaining: 2.62s\n",
      "18:\ttotal: 606ms\tremaining: 2.58s\n",
      "19:\ttotal: 637ms\tremaining: 2.55s\n",
      "20:\ttotal: 667ms\tremaining: 2.51s\n",
      "21:\ttotal: 700ms\tremaining: 2.48s\n",
      "22:\ttotal: 732ms\tremaining: 2.45s\n",
      "23:\ttotal: 764ms\tremaining: 2.42s\n",
      "24:\ttotal: 793ms\tremaining: 2.38s\n",
      "25:\ttotal: 824ms\tremaining: 2.35s\n",
      "26:\ttotal: 855ms\tremaining: 2.31s\n",
      "27:\ttotal: 887ms\tremaining: 2.28s\n",
      "28:\ttotal: 920ms\tremaining: 2.25s\n",
      "29:\ttotal: 953ms\tremaining: 2.22s\n",
      "30:\ttotal: 984ms\tremaining: 2.19s\n",
      "31:\ttotal: 1.01s\tremaining: 2.16s\n",
      "32:\ttotal: 1.04s\tremaining: 2.12s\n",
      "33:\ttotal: 1.07s\tremaining: 2.08s\n",
      "34:\ttotal: 1.1s\tremaining: 2.05s\n",
      "35:\ttotal: 1.13s\tremaining: 2.01s\n",
      "36:\ttotal: 1.17s\tremaining: 1.98s\n",
      "37:\ttotal: 1.2s\tremaining: 1.95s\n",
      "38:\ttotal: 1.23s\tremaining: 1.92s\n",
      "39:\ttotal: 1.26s\tremaining: 1.89s\n",
      "40:\ttotal: 1.29s\tremaining: 1.86s\n",
      "41:\ttotal: 1.32s\tremaining: 1.83s\n",
      "42:\ttotal: 1.35s\tremaining: 1.79s\n",
      "43:\ttotal: 1.38s\tremaining: 1.76s\n",
      "44:\ttotal: 1.42s\tremaining: 1.73s\n",
      "45:\ttotal: 1.45s\tremaining: 1.7s\n",
      "46:\ttotal: 1.48s\tremaining: 1.67s\n",
      "47:\ttotal: 1.51s\tremaining: 1.63s\n",
      "48:\ttotal: 1.54s\tremaining: 1.6s\n",
      "49:\ttotal: 1.57s\tremaining: 1.57s\n",
      "50:\ttotal: 1.6s\tremaining: 1.54s\n",
      "51:\ttotal: 1.64s\tremaining: 1.51s\n",
      "52:\ttotal: 1.67s\tremaining: 1.48s\n",
      "53:\ttotal: 1.7s\tremaining: 1.45s\n",
      "54:\ttotal: 1.73s\tremaining: 1.42s\n",
      "55:\ttotal: 1.77s\tremaining: 1.39s\n",
      "56:\ttotal: 1.8s\tremaining: 1.36s\n",
      "57:\ttotal: 1.83s\tremaining: 1.33s\n",
      "58:\ttotal: 1.86s\tremaining: 1.29s\n",
      "59:\ttotal: 1.89s\tremaining: 1.26s\n",
      "60:\ttotal: 1.93s\tremaining: 1.23s\n",
      "61:\ttotal: 1.96s\tremaining: 1.2s\n",
      "62:\ttotal: 1.99s\tremaining: 1.17s\n",
      "63:\ttotal: 2.02s\tremaining: 1.14s\n",
      "64:\ttotal: 2.05s\tremaining: 1.1s\n",
      "65:\ttotal: 2.08s\tremaining: 1.07s\n",
      "66:\ttotal: 2.11s\tremaining: 1.04s\n",
      "67:\ttotal: 2.14s\tremaining: 1.01s\n",
      "68:\ttotal: 2.17s\tremaining: 975ms\n",
      "69:\ttotal: 2.21s\tremaining: 946ms\n",
      "70:\ttotal: 2.24s\tremaining: 915ms\n",
      "71:\ttotal: 2.27s\tremaining: 884ms\n",
      "72:\ttotal: 2.3s\tremaining: 851ms\n",
      "73:\ttotal: 2.33s\tremaining: 819ms\n",
      "74:\ttotal: 2.36s\tremaining: 787ms\n",
      "75:\ttotal: 2.39s\tremaining: 755ms\n",
      "76:\ttotal: 2.42s\tremaining: 724ms\n",
      "77:\ttotal: 2.46s\tremaining: 692ms\n",
      "78:\ttotal: 2.49s\tremaining: 661ms\n",
      "79:\ttotal: 2.52s\tremaining: 629ms\n",
      "80:\ttotal: 2.55s\tremaining: 597ms\n",
      "81:\ttotal: 2.58s\tremaining: 566ms\n",
      "82:\ttotal: 2.61s\tremaining: 534ms\n",
      "83:\ttotal: 2.65s\tremaining: 504ms\n",
      "84:\ttotal: 2.68s\tremaining: 473ms\n",
      "85:\ttotal: 2.71s\tremaining: 441ms\n",
      "86:\ttotal: 2.74s\tremaining: 409ms\n",
      "87:\ttotal: 2.77s\tremaining: 378ms\n",
      "88:\ttotal: 2.8s\tremaining: 346ms\n",
      "89:\ttotal: 2.83s\tremaining: 315ms\n",
      "90:\ttotal: 2.86s\tremaining: 283ms\n",
      "91:\ttotal: 2.9s\tremaining: 252ms\n",
      "92:\ttotal: 2.93s\tremaining: 220ms\n",
      "93:\ttotal: 2.96s\tremaining: 189ms\n",
      "94:\ttotal: 2.99s\tremaining: 157ms\n",
      "95:\ttotal: 3.02s\tremaining: 126ms\n",
      "96:\ttotal: 3.05s\tremaining: 94.4ms\n",
      "97:\ttotal: 3.09s\tremaining: 63ms\n",
      "98:\ttotal: 3.12s\tremaining: 31.5ms\n",
      "99:\ttotal: 3.15s\tremaining: 0us\n",
      "0.8208134093196682\n",
      "0:\tlearn: 0.6572458\ttotal: 36.9ms\tremaining: 3.65s\n",
      "1:\tlearn: 0.6278258\ttotal: 72.1ms\tremaining: 3.53s\n",
      "2:\tlearn: 0.6034696\ttotal: 107ms\tremaining: 3.46s\n",
      "3:\tlearn: 0.5831176\ttotal: 142ms\tremaining: 3.4s\n",
      "4:\tlearn: 0.5660882\ttotal: 177ms\tremaining: 3.36s\n",
      "5:\tlearn: 0.5517333\ttotal: 212ms\tremaining: 3.32s\n",
      "6:\tlearn: 0.5393842\ttotal: 248ms\tremaining: 3.29s\n",
      "7:\tlearn: 0.5289101\ttotal: 284ms\tremaining: 3.27s\n",
      "8:\tlearn: 0.5199575\ttotal: 319ms\tremaining: 3.22s\n",
      "9:\tlearn: 0.5124404\ttotal: 353ms\tremaining: 3.17s\n",
      "10:\tlearn: 0.5059252\ttotal: 387ms\tremaining: 3.13s\n",
      "11:\tlearn: 0.5002793\ttotal: 418ms\tremaining: 3.07s\n",
      "12:\tlearn: 0.4956094\ttotal: 454ms\tremaining: 3.04s\n",
      "13:\tlearn: 0.4915532\ttotal: 490ms\tremaining: 3.01s\n",
      "14:\tlearn: 0.4879409\ttotal: 522ms\tremaining: 2.96s\n",
      "15:\tlearn: 0.4848483\ttotal: 552ms\tremaining: 2.9s\n",
      "16:\tlearn: 0.4821772\ttotal: 586ms\tremaining: 2.86s\n",
      "17:\tlearn: 0.4800447\ttotal: 618ms\tremaining: 2.81s\n",
      "18:\tlearn: 0.4781632\ttotal: 647ms\tremaining: 2.76s\n",
      "19:\tlearn: 0.4764114\ttotal: 683ms\tremaining: 2.73s\n",
      "20:\tlearn: 0.4749058\ttotal: 715ms\tremaining: 2.69s\n",
      "21:\tlearn: 0.4735783\ttotal: 746ms\tremaining: 2.64s\n",
      "22:\tlearn: 0.4724610\ttotal: 777ms\tremaining: 2.6s\n",
      "23:\tlearn: 0.4714645\ttotal: 808ms\tremaining: 2.56s\n",
      "24:\tlearn: 0.4706279\ttotal: 838ms\tremaining: 2.52s\n",
      "25:\tlearn: 0.4699069\ttotal: 871ms\tremaining: 2.48s\n",
      "26:\tlearn: 0.4692459\ttotal: 906ms\tremaining: 2.45s\n",
      "27:\tlearn: 0.4687037\ttotal: 937ms\tremaining: 2.41s\n",
      "28:\tlearn: 0.4682851\ttotal: 970ms\tremaining: 2.37s\n",
      "29:\tlearn: 0.4678499\ttotal: 1s\tremaining: 2.34s\n",
      "30:\tlearn: 0.4675375\ttotal: 1.03s\tremaining: 2.3s\n",
      "31:\tlearn: 0.4671821\ttotal: 1.07s\tremaining: 2.27s\n",
      "32:\tlearn: 0.4668730\ttotal: 1.1s\tremaining: 2.23s\n",
      "33:\tlearn: 0.4666279\ttotal: 1.13s\tremaining: 2.19s\n",
      "34:\tlearn: 0.4663948\ttotal: 1.16s\tremaining: 2.15s\n",
      "35:\tlearn: 0.4662126\ttotal: 1.19s\tremaining: 2.12s\n",
      "36:\tlearn: 0.4660039\ttotal: 1.22s\tremaining: 2.08s\n",
      "37:\tlearn: 0.4658104\ttotal: 1.25s\tremaining: 2.04s\n",
      "38:\tlearn: 0.4656721\ttotal: 1.28s\tremaining: 2.01s\n",
      "39:\tlearn: 0.4655270\ttotal: 1.32s\tremaining: 1.98s\n",
      "40:\tlearn: 0.4653980\ttotal: 1.36s\tremaining: 1.95s\n",
      "41:\tlearn: 0.4652567\ttotal: 1.39s\tremaining: 1.92s\n",
      "42:\tlearn: 0.4651548\ttotal: 1.42s\tremaining: 1.88s\n",
      "43:\tlearn: 0.4650575\ttotal: 1.45s\tremaining: 1.84s\n",
      "44:\tlearn: 0.4649617\ttotal: 1.48s\tremaining: 1.81s\n",
      "45:\tlearn: 0.4648975\ttotal: 1.51s\tremaining: 1.77s\n",
      "46:\tlearn: 0.4648323\ttotal: 1.54s\tremaining: 1.74s\n",
      "47:\tlearn: 0.4647545\ttotal: 1.57s\tremaining: 1.7s\n",
      "48:\tlearn: 0.4646711\ttotal: 1.6s\tremaining: 1.67s\n",
      "49:\tlearn: 0.4645992\ttotal: 1.63s\tremaining: 1.63s\n",
      "50:\tlearn: 0.4645438\ttotal: 1.67s\tremaining: 1.6s\n",
      "51:\tlearn: 0.4644825\ttotal: 1.69s\tremaining: 1.56s\n",
      "52:\tlearn: 0.4644345\ttotal: 1.72s\tremaining: 1.53s\n",
      "53:\tlearn: 0.4643719\ttotal: 1.75s\tremaining: 1.5s\n",
      "54:\tlearn: 0.4643219\ttotal: 1.79s\tremaining: 1.46s\n",
      "55:\tlearn: 0.4642696\ttotal: 1.82s\tremaining: 1.43s\n",
      "56:\tlearn: 0.4642279\ttotal: 1.85s\tremaining: 1.4s\n",
      "57:\tlearn: 0.4641900\ttotal: 1.88s\tremaining: 1.36s\n",
      "58:\tlearn: 0.4641534\ttotal: 1.91s\tremaining: 1.33s\n",
      "59:\tlearn: 0.4641274\ttotal: 1.94s\tremaining: 1.29s\n",
      "60:\tlearn: 0.4640865\ttotal: 1.97s\tremaining: 1.26s\n",
      "61:\tlearn: 0.4640500\ttotal: 2s\tremaining: 1.23s\n",
      "62:\tlearn: 0.4639938\ttotal: 2.04s\tremaining: 1.2s\n",
      "63:\tlearn: 0.4639643\ttotal: 2.07s\tremaining: 1.17s\n",
      "64:\tlearn: 0.4639345\ttotal: 2.1s\tremaining: 1.13s\n",
      "65:\tlearn: 0.4639062\ttotal: 2.13s\tremaining: 1.1s\n",
      "66:\tlearn: 0.4638810\ttotal: 2.16s\tremaining: 1.06s\n",
      "67:\tlearn: 0.4638557\ttotal: 2.19s\tremaining: 1.03s\n",
      "68:\tlearn: 0.4638262\ttotal: 2.22s\tremaining: 998ms\n",
      "69:\tlearn: 0.4638024\ttotal: 2.25s\tremaining: 966ms\n",
      "70:\tlearn: 0.4637772\ttotal: 2.29s\tremaining: 934ms\n",
      "71:\tlearn: 0.4637515\ttotal: 2.32s\tremaining: 902ms\n",
      "72:\tlearn: 0.4637239\ttotal: 2.35s\tremaining: 869ms\n",
      "73:\tlearn: 0.4636933\ttotal: 2.38s\tremaining: 837ms\n",
      "74:\tlearn: 0.4636661\ttotal: 2.41s\tremaining: 804ms\n",
      "75:\tlearn: 0.4636399\ttotal: 2.44s\tremaining: 772ms\n",
      "76:\tlearn: 0.4636081\ttotal: 2.48s\tremaining: 740ms\n",
      "77:\tlearn: 0.4635826\ttotal: 2.51s\tremaining: 707ms\n",
      "78:\tlearn: 0.4635600\ttotal: 2.54s\tremaining: 675ms\n",
      "79:\tlearn: 0.4635407\ttotal: 2.57s\tremaining: 642ms\n",
      "80:\tlearn: 0.4635087\ttotal: 2.6s\tremaining: 610ms\n",
      "81:\tlearn: 0.4634857\ttotal: 2.63s\tremaining: 577ms\n",
      "82:\tlearn: 0.4634626\ttotal: 2.67s\tremaining: 546ms\n",
      "83:\tlearn: 0.4634294\ttotal: 2.7s\tremaining: 515ms\n",
      "84:\tlearn: 0.4634077\ttotal: 2.73s\tremaining: 482ms\n",
      "85:\tlearn: 0.4633863\ttotal: 2.76s\tremaining: 450ms\n",
      "86:\tlearn: 0.4633652\ttotal: 2.79s\tremaining: 418ms\n",
      "87:\tlearn: 0.4633217\ttotal: 2.83s\tremaining: 385ms\n",
      "88:\tlearn: 0.4632996\ttotal: 2.86s\tremaining: 353ms\n",
      "89:\tlearn: 0.4632733\ttotal: 2.9s\tremaining: 322ms\n",
      "90:\tlearn: 0.4632450\ttotal: 2.92s\tremaining: 289ms\n",
      "91:\tlearn: 0.4632156\ttotal: 2.96s\tremaining: 257ms\n",
      "92:\tlearn: 0.4632007\ttotal: 2.99s\tremaining: 225ms\n",
      "93:\tlearn: 0.4631766\ttotal: 3.02s\tremaining: 193ms\n",
      "94:\tlearn: 0.4631601\ttotal: 3.05s\tremaining: 160ms\n",
      "95:\tlearn: 0.4631476\ttotal: 3.08s\tremaining: 128ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96:\tlearn: 0.4631196\ttotal: 3.11s\tremaining: 96.3ms\n",
      "97:\tlearn: 0.4630901\ttotal: 3.15s\tremaining: 64.2ms\n",
      "98:\tlearn: 0.4630623\ttotal: 3.18s\tremaining: 32.1ms\n",
      "99:\tlearn: 0.4630440\ttotal: 3.21s\tremaining: 0us\n",
      "0.820648902575744\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5833 - auc: 0.7405 - val_loss: 0.5154 - val_auc: 0.7906\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5127 - auc: 0.7817 - val_loss: 0.4925 - val_auc: 0.8021\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4967 - auc: 0.7920 - val_loss: 0.4880 - val_auc: 0.8065\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4923 - auc: 0.7959 - val_loss: 0.4860 - val_auc: 0.8068\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4902 - auc: 0.7979 - val_loss: 0.4850 - val_auc: 0.8082\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.7992 - val_loss: 0.4847 - val_auc: 0.8084\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4885 - auc: 0.7997 - val_loss: 0.4847 - val_auc: 0.8087\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4878 - auc: 0.8006 - val_loss: 0.4846 - val_auc: 0.8080\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4874 - auc: 0.8010 - val_loss: 0.4845 - val_auc: 0.8078\n",
      "Epoch 10/100\n",
      "277504/284999 [============================>.] - ETA: 0s - loss: 0.4878 - auc: 0.8003Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4880 - auc: 0.8002 - val_loss: 0.4847 - val_auc: 0.8082\n",
      "Epoch 00010: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5869 - auc: 0.7741 - val_loss: 0.5078 - val_auc: 0.7989\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5062 - auc: 0.7908 - val_loss: 0.4861 - val_auc: 0.8079\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4916 - auc: 0.7972 - val_loss: 0.4829 - val_auc: 0.8089\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7990 - val_loss: 0.4828 - val_auc: 0.8102\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.7993 - val_loss: 0.4827 - val_auc: 0.8098\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8003 - val_loss: 0.4826 - val_auc: 0.8105\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8000 - val_loss: 0.4826 - val_auc: 0.8099\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8005 - val_loss: 0.4826 - val_auc: 0.8097\n",
      "Epoch 9/100\n",
      "276480/284999 [============================>.] - ETA: 0s - loss: 0.4878 - auc: 0.8005Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4877 - auc: 0.8005 - val_loss: 0.4828 - val_auc: 0.8101\n",
      "Epoch 00009: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6368 - auc: 0.6723 - val_loss: 0.5187 - val_auc: 0.7785\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5427 - auc: 0.7476 - val_loss: 0.4911 - val_auc: 0.8002\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5170 - auc: 0.7704 - val_loss: 0.4816 - val_auc: 0.8114\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.5057 - auc: 0.7819 - val_loss: 0.4770 - val_auc: 0.8171\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4992 - auc: 0.7885 - val_loss: 0.4738 - val_auc: 0.8199\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4955 - auc: 0.7926 - val_loss: 0.4724 - val_auc: 0.8225\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4941 - auc: 0.7937 - val_loss: 0.4712 - val_auc: 0.8228\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4914 - auc: 0.7966 - val_loss: 0.4700 - val_auc: 0.8238\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4899 - auc: 0.7984 - val_loss: 0.4688 - val_auc: 0.8253\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.7996 - val_loss: 0.4690 - val_auc: 0.8245\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.7997 - val_loss: 0.4685 - val_auc: 0.8246\n",
      "Epoch 12/100\n",
      "281600/284999 [============================>.] - ETA: 0s - loss: 0.4883 - auc: 0.8001\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4884 - auc: 0.8000 - val_loss: 0.4684 - val_auc: 0.8245\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.7998 - val_loss: 0.4686 - val_auc: 0.8243\n",
      "Epoch 14/100\n",
      "282624/284999 [============================>.] - ETA: 0s - loss: 0.4887 - auc: 0.8000Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4889 - auc: 0.7999 - val_loss: 0.4689 - val_auc: 0.8241\n",
      "Epoch 00014: early stopping\n",
      "Train on 284999 samples, validate on 15001 samples\n",
      "Epoch 1/100\n",
      "284999/284999 [==============================] - 2s 7us/sample - loss: 0.6375 - auc: 0.7059 - val_loss: 0.5153 - val_auc: 0.7804\n",
      "Epoch 2/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5445 - auc: 0.7514 - val_loss: 0.4923 - val_auc: 0.7988\n",
      "Epoch 3/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5201 - auc: 0.7687 - val_loss: 0.4838 - val_auc: 0.8074\n",
      "Epoch 4/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5086 - auc: 0.7793 - val_loss: 0.4797 - val_auc: 0.8126\n",
      "Epoch 5/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5026 - auc: 0.7850 - val_loss: 0.4773 - val_auc: 0.8163\n",
      "Epoch 6/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.5000 - auc: 0.7877 - val_loss: 0.4760 - val_auc: 0.8171\n",
      "Epoch 7/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4985 - auc: 0.7894 - val_loss: 0.4754 - val_auc: 0.8189\n",
      "Epoch 8/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4974 - auc: 0.7905 - val_loss: 0.4752 - val_auc: 0.8191\n",
      "Epoch 9/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4964 - auc: 0.7917 - val_loss: 0.4748 - val_auc: 0.8205\n",
      "Epoch 10/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4961 - auc: 0.7922 - val_loss: 0.4745 - val_auc: 0.8195\n",
      "Epoch 11/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4960 - auc: 0.7925 - val_loss: 0.4744 - val_auc: 0.8199\n",
      "Epoch 12/100\n",
      "277504/284999 [============================>.] - ETA: 0s - loss: 0.4950 - auc: 0.7932\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4952 - auc: 0.7930 - val_loss: 0.4742 - val_auc: 0.8205\n",
      "Epoch 13/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4952 - auc: 0.7933 - val_loss: 0.4737 - val_auc: 0.8214\n",
      "Epoch 14/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4945 - auc: 0.7940 - val_loss: 0.4735 - val_auc: 0.8219\n",
      "Epoch 15/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4929 - auc: 0.7956 - val_loss: 0.4721 - val_auc: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4915 - auc: 0.7968 - val_loss: 0.4708 - val_auc: 0.8244\n",
      "Epoch 17/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4897 - auc: 0.7988 - val_loss: 0.4698 - val_auc: 0.8221\n",
      "Epoch 18/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7995 - val_loss: 0.4692 - val_auc: 0.8242\n",
      "Epoch 19/100\n",
      "275456/284999 [===========================>..] - ETA: 0s - loss: 0.4882 - auc: 0.8004\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8006 - val_loss: 0.4687 - val_auc: 0.8245\n",
      "Epoch 20/100\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8005 - val_loss: 0.4688 - val_auc: 0.8246\n",
      "Epoch 21/100\n",
      "280576/284999 [============================>.] - ETA: 0s - loss: 0.4878 - auc: 0.8007Restoring model weights from the end of the best epoch.\n",
      "284999/284999 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8005 - val_loss: 0.4688 - val_auc: 0.8242\n",
      "Epoch 00021: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6378 - auc: 0.6988 - val_loss: 0.5224 - val_auc: 0.7727\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5394 - auc: 0.7521 - val_loss: 0.4931 - val_auc: 0.7985\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5130 - auc: 0.7747 - val_loss: 0.4846 - val_auc: 0.8086\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5035 - auc: 0.7840 - val_loss: 0.4815 - val_auc: 0.8125\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5000 - auc: 0.7875 - val_loss: 0.4795 - val_auc: 0.8137\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4977 - auc: 0.7901 - val_loss: 0.4791 - val_auc: 0.8156\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4955 - auc: 0.7925 - val_loss: 0.4779 - val_auc: 0.8166\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4928 - auc: 0.7953 - val_loss: 0.4764 - val_auc: 0.8174\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4912 - auc: 0.7967 - val_loss: 0.4752 - val_auc: 0.8183\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4897 - auc: 0.7987 - val_loss: 0.4746 - val_auc: 0.8192\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8002 - val_loss: 0.4741 - val_auc: 0.8192\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8003 - val_loss: 0.4743 - val_auc: 0.8183\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4883 - auc: 0.8001 - val_loss: 0.4743 - val_auc: 0.8194\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4878 - auc: 0.8007 - val_loss: 0.4746 - val_auc: 0.8188\n",
      "Epoch 15/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4876 - auc: 0.8011Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4877 - auc: 0.8010 - val_loss: 0.4743 - val_auc: 0.8187\n",
      "Epoch 00015: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5853 - auc: 0.7345 - val_loss: 0.5171 - val_auc: 0.7903\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5171 - auc: 0.7799 - val_loss: 0.4904 - val_auc: 0.8067\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4981 - auc: 0.7913 - val_loss: 0.4806 - val_auc: 0.8137\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4909 - auc: 0.7974 - val_loss: 0.4770 - val_auc: 0.8163\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4895 - auc: 0.7987 - val_loss: 0.4761 - val_auc: 0.8173\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4896 - auc: 0.7985 - val_loss: 0.4758 - val_auc: 0.8179\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4889 - auc: 0.7994 - val_loss: 0.4759 - val_auc: 0.8170\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8001 - val_loss: 0.4755 - val_auc: 0.8173\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4877 - auc: 0.8008 - val_loss: 0.4757 - val_auc: 0.8182\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8004 - val_loss: 0.4758 - val_auc: 0.8185\n",
      "Epoch 11/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4870 - auc: 0.8015Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4870 - auc: 0.8016 - val_loss: 0.4758 - val_auc: 0.8176\n",
      "Epoch 00011: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.9900 - auc: 0.2975 - val_loss: 0.7094 - val_auc: 0.3672\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.6440 - auc: 0.5777 - val_loss: 0.5542 - val_auc: 0.7177\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5623 - auc: 0.7136 - val_loss: 0.5183 - val_auc: 0.7662\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5363 - auc: 0.7475 - val_loss: 0.5058 - val_auc: 0.7821\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5238 - auc: 0.7606 - val_loss: 0.4991 - val_auc: 0.7899\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5151 - auc: 0.7703 - val_loss: 0.4953 - val_auc: 0.7964\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5102 - auc: 0.7756 - val_loss: 0.4922 - val_auc: 0.8025\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5058 - auc: 0.7816 - val_loss: 0.4897 - val_auc: 0.8068\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5024 - auc: 0.7858 - val_loss: 0.4872 - val_auc: 0.8089\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4997 - auc: 0.7883 - val_loss: 0.4846 - val_auc: 0.8103\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4959 - auc: 0.7922 - val_loss: 0.4821 - val_auc: 0.8129\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4928 - auc: 0.7953 - val_loss: 0.4798 - val_auc: 0.8151\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4906 - auc: 0.7981 - val_loss: 0.4780 - val_auc: 0.8155\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4885 - auc: 0.8001 - val_loss: 0.4775 - val_auc: 0.8166\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8003 - val_loss: 0.4770 - val_auc: 0.8151\n",
      "Epoch 16/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4885 - auc: 0.8005 - val_loss: 0.4769 - val_auc: 0.8157\n",
      "Epoch 17/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4879 - auc: 0.8011\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8011 - val_loss: 0.4768 - val_auc: 0.8163\n",
      "Epoch 18/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4878 - auc: 0.8010 - val_loss: 0.4770 - val_auc: 0.8158\n",
      "Epoch 19/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4875 - auc: 0.8013Restoring model weights from the end of the best epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4878 - auc: 0.8012 - val_loss: 0.4769 - val_auc: 0.8161\n",
      "Epoch 00019: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6163 - auc: 0.6654 - val_loss: 0.5142 - val_auc: 0.7927\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5180 - auc: 0.7747 - val_loss: 0.4869 - val_auc: 0.8059\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5033 - auc: 0.7851 - val_loss: 0.4819 - val_auc: 0.8097\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4978 - auc: 0.7903 - val_loss: 0.4797 - val_auc: 0.8140\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4940 - auc: 0.7943 - val_loss: 0.4775 - val_auc: 0.8159\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4924 - auc: 0.7959 - val_loss: 0.4764 - val_auc: 0.8168\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4901 - auc: 0.7980 - val_loss: 0.4755 - val_auc: 0.8173\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7992 - val_loss: 0.4750 - val_auc: 0.8187\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.7997 - val_loss: 0.4747 - val_auc: 0.8182\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4883 - auc: 0.8001 - val_loss: 0.4748 - val_auc: 0.8194\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.7998 - val_loss: 0.4745 - val_auc: 0.8186\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4895 - auc: 0.7990 - val_loss: 0.4748 - val_auc: 0.8182\n",
      "Epoch 13/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4879 - auc: 0.8006Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8005 - val_loss: 0.4746 - val_auc: 0.8185\n",
      "Epoch 00013: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5559 - auc: 0.7808 - val_loss: 0.4833 - val_auc: 0.8248\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4989 - auc: 0.7953 - val_loss: 0.4678 - val_auc: 0.8270\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4908 - auc: 0.7975 - val_loss: 0.4661 - val_auc: 0.8274\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4897 - auc: 0.7982 - val_loss: 0.4660 - val_auc: 0.8272\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4896 - auc: 0.7983 - val_loss: 0.4662 - val_auc: 0.8271\n",
      "Epoch 6/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4897 - auc: 0.7986\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4897 - auc: 0.7985 - val_loss: 0.4663 - val_auc: 0.8272\n",
      "Epoch 7/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4894 - auc: 0.7986Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4895 - auc: 0.7985 - val_loss: 0.4663 - val_auc: 0.8278\n",
      "Epoch 00007: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6368 - auc: 0.6587 - val_loss: 0.5259 - val_auc: 0.7722\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5414 - auc: 0.7508 - val_loss: 0.4974 - val_auc: 0.7956\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5164 - auc: 0.7716 - val_loss: 0.4877 - val_auc: 0.8038\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5053 - auc: 0.7824 - val_loss: 0.4836 - val_auc: 0.8093\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5007 - auc: 0.7869 - val_loss: 0.4813 - val_auc: 0.8131\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4974 - auc: 0.7906 - val_loss: 0.4795 - val_auc: 0.8152\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4951 - auc: 0.7931 - val_loss: 0.4782 - val_auc: 0.8166\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4932 - auc: 0.7947 - val_loss: 0.4766 - val_auc: 0.8170\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4918 - auc: 0.7964 - val_loss: 0.4752 - val_auc: 0.8189\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4898 - auc: 0.7985 - val_loss: 0.4742 - val_auc: 0.8191\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7993 - val_loss: 0.4733 - val_auc: 0.8210\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4884 - auc: 0.8000 - val_loss: 0.4731 - val_auc: 0.8200\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4880 - auc: 0.8005 - val_loss: 0.4726 - val_auc: 0.8206\n",
      "Epoch 14/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4876 - auc: 0.8010\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4880 - auc: 0.8007 - val_loss: 0.4729 - val_auc: 0.8198\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4875 - auc: 0.8012 - val_loss: 0.4728 - val_auc: 0.8208\n",
      "Epoch 16/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4881 - auc: 0.8007Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4880 - auc: 0.8008 - val_loss: 0.4727 - val_auc: 0.8192\n",
      "Epoch 00016: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.5773 - auc: 0.7698 - val_loss: 0.4890 - val_auc: 0.8135\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5052 - auc: 0.7883 - val_loss: 0.4726 - val_auc: 0.8222\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4932 - auc: 0.7949 - val_loss: 0.4694 - val_auc: 0.8239\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4904 - auc: 0.7976 - val_loss: 0.4685 - val_auc: 0.8256\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4895 - auc: 0.7985 - val_loss: 0.4685 - val_auc: 0.8254\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4892 - auc: 0.7990 - val_loss: 0.4687 - val_auc: 0.8250\n",
      "Epoch 7/100\n",
      "284672/285000 [============================>.] - ETA: 0s - loss: 0.4888 - auc: 0.7993\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.4888 - auc: 0.7993 - val_loss: 0.4685 - val_auc: 0.8251\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4883 - auc: 0.8000 - val_loss: 0.4686 - val_auc: 0.8252\n",
      "Epoch 9/100\n",
      "282624/285000 [============================>.] - ETA: 0s - loss: 0.4885 - auc: 0.7997Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4884 - auc: 0.7998 - val_loss: 0.4686 - val_auc: 0.8250\n",
      "Epoch 00009: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6901 - auc: 0.6249 - val_loss: 0.5520 - val_auc: 0.7357\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5716 - auc: 0.7188 - val_loss: 0.5150 - val_auc: 0.7690\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5352 - auc: 0.7502 - val_loss: 0.5005 - val_auc: 0.7883\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5185 - auc: 0.7673 - val_loss: 0.4913 - val_auc: 0.8021\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5088 - auc: 0.7778 - val_loss: 0.4848 - val_auc: 0.8098\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5018 - auc: 0.7857 - val_loss: 0.4799 - val_auc: 0.8160\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4970 - auc: 0.7908 - val_loss: 0.4764 - val_auc: 0.8179\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4938 - auc: 0.7941 - val_loss: 0.4742 - val_auc: 0.8201\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4916 - auc: 0.7966 - val_loss: 0.4723 - val_auc: 0.8211\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4902 - auc: 0.7981 - val_loss: 0.4713 - val_auc: 0.8221\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.8000 - val_loss: 0.4706 - val_auc: 0.8232\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7997 - val_loss: 0.4704 - val_auc: 0.8230\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8006 - val_loss: 0.4700 - val_auc: 0.8230\n",
      "Epoch 14/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4883 - auc: 0.8004\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4884 - auc: 0.8003 - val_loss: 0.4700 - val_auc: 0.8231\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8007 - val_loss: 0.4700 - val_auc: 0.8229\n",
      "Epoch 16/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4882 - auc: 0.8007Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8010 - val_loss: 0.4700 - val_auc: 0.8231\n",
      "Epoch 00016: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.6602 - auc: 0.6478 - val_loss: 0.5245 - val_auc: 0.7708\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5519 - auc: 0.7396 - val_loss: 0.4928 - val_auc: 0.7999\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5201 - auc: 0.7675 - val_loss: 0.4808 - val_auc: 0.8130\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5071 - auc: 0.7804 - val_loss: 0.4759 - val_auc: 0.8182\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5010 - auc: 0.7864 - val_loss: 0.4738 - val_auc: 0.8212\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4978 - auc: 0.7900 - val_loss: 0.4727 - val_auc: 0.8216\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4965 - auc: 0.7911 - val_loss: 0.4723 - val_auc: 0.8232\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4948 - auc: 0.7931 - val_loss: 0.4713 - val_auc: 0.8237\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4940 - auc: 0.7940 - val_loss: 0.4708 - val_auc: 0.8256\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4927 - auc: 0.7955 - val_loss: 0.4702 - val_auc: 0.8260\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4910 - auc: 0.7972 - val_loss: 0.4697 - val_auc: 0.8256\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4904 - auc: 0.7980 - val_loss: 0.4685 - val_auc: 0.8260\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4894 - auc: 0.7990 - val_loss: 0.4682 - val_auc: 0.8267\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4888 - auc: 0.7998 - val_loss: 0.4680 - val_auc: 0.8263\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4889 - auc: 0.7996 - val_loss: 0.4681 - val_auc: 0.8265\n",
      "Epoch 16/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.8000 - val_loss: 0.4676 - val_auc: 0.8269\n",
      "Epoch 17/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4884 - auc: 0.8004 - val_loss: 0.4677 - val_auc: 0.8269\n",
      "Epoch 18/100\n",
      "279552/285000 [============================>.] - ETA: 0s - loss: 0.4877 - auc: 0.8012Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4877 - auc: 0.8009 - val_loss: 0.4680 - val_auc: 0.8267\n",
      "Epoch 00018: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.7130 - auc: 0.5714 - val_loss: 0.5600 - val_auc: 0.7230\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5766 - auc: 0.7081 - val_loss: 0.5204 - val_auc: 0.7650\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5362 - auc: 0.7481 - val_loss: 0.5042 - val_auc: 0.7852\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5162 - auc: 0.7698 - val_loss: 0.4960 - val_auc: 0.7966\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5055 - auc: 0.7817 - val_loss: 0.4914 - val_auc: 0.8027\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4994 - auc: 0.7884 - val_loss: 0.4880 - val_auc: 0.8054\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4942 - auc: 0.7939 - val_loss: 0.4856 - val_auc: 0.8084\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4908 - auc: 0.7975 - val_loss: 0.4841 - val_auc: 0.8094\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4899 - auc: 0.7983 - val_loss: 0.4834 - val_auc: 0.8093\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4883 - auc: 0.8001 - val_loss: 0.4832 - val_auc: 0.8100\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4876 - auc: 0.8008 - val_loss: 0.4830 - val_auc: 0.8104\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8009 - val_loss: 0.4831 - val_auc: 0.8107\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4874 - auc: 0.8014 - val_loss: 0.4833 - val_auc: 0.8095\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4876 - auc: 0.8012 - val_loss: 0.4830 - val_auc: 0.8103\n",
      "Epoch 15/100\n",
      "277504/285000 [============================>.] - ETA: 0s - loss: 0.4870 - auc: 0.8019\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4871 - auc: 0.8019 - val_loss: 0.4832 - val_auc: 0.8097\n",
      "Epoch 16/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4870 - auc: 0.8019 - val_loss: 0.4829 - val_auc: 0.8103\n",
      "Epoch 17/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8008Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4876 - auc: 0.8012 - val_loss: 0.4830 - val_auc: 0.8097\n",
      "Epoch 00017: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 7us/sample - loss: 0.9034 - auc: 0.4179 - val_loss: 0.6519 - val_auc: 0.6108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.6538 - auc: 0.6155 - val_loss: 0.5494 - val_auc: 0.7183\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5708 - auc: 0.7063 - val_loss: 0.5134 - val_auc: 0.7728\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5383 - auc: 0.7441 - val_loss: 0.4991 - val_auc: 0.7931\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5212 - auc: 0.7637 - val_loss: 0.4908 - val_auc: 0.8041\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5112 - auc: 0.7751 - val_loss: 0.4864 - val_auc: 0.8095\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5053 - auc: 0.7817 - val_loss: 0.4835 - val_auc: 0.8118\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5009 - auc: 0.7865 - val_loss: 0.4815 - val_auc: 0.8146\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4986 - auc: 0.7894 - val_loss: 0.4794 - val_auc: 0.8159\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4963 - auc: 0.7920 - val_loss: 0.4777 - val_auc: 0.8175\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4939 - auc: 0.7945 - val_loss: 0.4763 - val_auc: 0.8188\n",
      "Epoch 12/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4920 - auc: 0.7965 - val_loss: 0.4750 - val_auc: 0.8186\n",
      "Epoch 13/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4904 - auc: 0.7983 - val_loss: 0.4734 - val_auc: 0.8202\n",
      "Epoch 14/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4900 - auc: 0.7987 - val_loss: 0.4724 - val_auc: 0.8214\n",
      "Epoch 15/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8000 - val_loss: 0.4717 - val_auc: 0.8221\n",
      "Epoch 16/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7999 - val_loss: 0.4717 - val_auc: 0.8210\n",
      "Epoch 17/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.8004 - val_loss: 0.4719 - val_auc: 0.8209\n",
      "Epoch 18/100\n",
      "280576/285000 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8011\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4880 - auc: 0.8009 - val_loss: 0.4716 - val_auc: 0.8209\n",
      "Epoch 19/100\n",
      "283648/285000 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8009Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8008 - val_loss: 0.4715 - val_auc: 0.8221\n",
      "Epoch 00019: early stopping\n",
      "Train on 285000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.7222 - auc: 0.5464 - val_loss: 0.5678 - val_auc: 0.7012\n",
      "Epoch 2/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5742 - auc: 0.7040 - val_loss: 0.5168 - val_auc: 0.7675\n",
      "Epoch 3/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5336 - auc: 0.7489 - val_loss: 0.4981 - val_auc: 0.8021\n",
      "Epoch 4/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5144 - auc: 0.7733 - val_loss: 0.4859 - val_auc: 0.8135\n",
      "Epoch 5/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.5013 - auc: 0.7861 - val_loss: 0.4779 - val_auc: 0.8198\n",
      "Epoch 6/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4937 - auc: 0.7943 - val_loss: 0.4733 - val_auc: 0.8218\n",
      "Epoch 7/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4910 - auc: 0.7971 - val_loss: 0.4717 - val_auc: 0.8229\n",
      "Epoch 8/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4902 - auc: 0.7982 - val_loss: 0.4715 - val_auc: 0.8232\n",
      "Epoch 9/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4892 - auc: 0.7993 - val_loss: 0.4712 - val_auc: 0.8228\n",
      "Epoch 10/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7996 - val_loss: 0.4707 - val_auc: 0.8233\n",
      "Epoch 11/100\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4886 - auc: 0.8001 - val_loss: 0.4708 - val_auc: 0.8234\n",
      "Epoch 12/100\n",
      "276480/285000 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8006Restoring model weights from the end of the best epoch.\n",
      "285000/285000 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8007 - val_loss: 0.4710 - val_auc: 0.8229\n",
      "Epoch 00012: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 1.3891 - auc: 0.2088 - val_loss: 1.0228 - val_auc: 0.1802\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.8661 - auc: 0.2323 - val_loss: 0.7319 - val_auc: 0.2272\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.6628 - auc: 0.4303 - val_loss: 0.5935 - val_auc: 0.6555\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5780 - auc: 0.6695 - val_loss: 0.5337 - val_auc: 0.7622\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5436 - auc: 0.7337 - val_loss: 0.5070 - val_auc: 0.7995\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5255 - auc: 0.7589 - val_loss: 0.4918 - val_auc: 0.8126\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5143 - auc: 0.7720 - val_loss: 0.4825 - val_auc: 0.8185\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5067 - auc: 0.7806 - val_loss: 0.4770 - val_auc: 0.8225\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5031 - auc: 0.7847 - val_loss: 0.4738 - val_auc: 0.8238\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5002 - auc: 0.7877 - val_loss: 0.4719 - val_auc: 0.8258\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4982 - auc: 0.7904 - val_loss: 0.4709 - val_auc: 0.8273\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4968 - auc: 0.7919 - val_loss: 0.4695 - val_auc: 0.8271\n",
      "Epoch 13/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4953 - auc: 0.7934 - val_loss: 0.4687 - val_auc: 0.8282\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4942 - auc: 0.7945 - val_loss: 0.4678 - val_auc: 0.8283\n",
      "Epoch 15/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4926 - auc: 0.7962 - val_loss: 0.4664 - val_auc: 0.8294\n",
      "Epoch 16/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4913 - auc: 0.7975 - val_loss: 0.4653 - val_auc: 0.8303\n",
      "Epoch 17/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4903 - auc: 0.7988 - val_loss: 0.4646 - val_auc: 0.8298\n",
      "Epoch 18/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4891 - auc: 0.8001 - val_loss: 0.4642 - val_auc: 0.8310\n",
      "Epoch 19/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8002 - val_loss: 0.4642 - val_auc: 0.8306\n",
      "Epoch 20/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4891 - auc: 0.8001 - val_loss: 0.4640 - val_auc: 0.8300\n",
      "Epoch 21/100\n",
      "278528/285001 [============================>.] - ETA: 0s - loss: 0.4881 - auc: 0.8010\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8011 - val_loss: 0.4638 - val_auc: 0.8309\n",
      "Epoch 22/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4885 - auc: 0.8003 - val_loss: 0.4639 - val_auc: 0.8299\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283648/285001 [============================>.] - ETA: 0s - loss: 0.4881 - auc: 0.8012Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8011 - val_loss: 0.4639 - val_auc: 0.8305\n",
      "Epoch 00023: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.9118 - auc: 0.4160 - val_loss: 0.6445 - val_auc: 0.6025\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.6578 - auc: 0.6221 - val_loss: 0.5580 - val_auc: 0.7155\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5896 - auc: 0.6918 - val_loss: 0.5295 - val_auc: 0.7483\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5555 - auc: 0.7248 - val_loss: 0.5142 - val_auc: 0.7710\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5358 - auc: 0.7456 - val_loss: 0.5041 - val_auc: 0.7857\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5221 - auc: 0.7621 - val_loss: 0.4971 - val_auc: 0.7966\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5129 - auc: 0.7731 - val_loss: 0.4922 - val_auc: 0.8026\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5077 - auc: 0.7790 - val_loss: 0.4886 - val_auc: 0.8067\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5025 - auc: 0.7849 - val_loss: 0.4855 - val_auc: 0.8090\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4991 - auc: 0.7887 - val_loss: 0.4831 - val_auc: 0.8120\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4967 - auc: 0.7914 - val_loss: 0.4814 - val_auc: 0.8129\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4946 - auc: 0.7938 - val_loss: 0.4796 - val_auc: 0.8147\n",
      "Epoch 13/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4929 - auc: 0.7955 - val_loss: 0.4783 - val_auc: 0.8155\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4910 - auc: 0.7977 - val_loss: 0.4768 - val_auc: 0.8170\n",
      "Epoch 15/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4891 - auc: 0.7997 - val_loss: 0.4759 - val_auc: 0.8174\n",
      "Epoch 16/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8001 - val_loss: 0.4752 - val_auc: 0.8175\n",
      "Epoch 17/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4874 - auc: 0.8016 - val_loss: 0.4754 - val_auc: 0.8176\n",
      "Epoch 18/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4876 - auc: 0.8016 - val_loss: 0.4748 - val_auc: 0.8179\n",
      "Epoch 19/100\n",
      "282624/285001 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8010Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.4880 - auc: 0.8011 - val_loss: 0.4753 - val_auc: 0.8166\n",
      "Epoch 00019: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.7935 - auc: 0.4130 - val_loss: 0.5931 - val_auc: 0.6698\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5781 - auc: 0.6886 - val_loss: 0.5164 - val_auc: 0.7707\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5371 - auc: 0.7450 - val_loss: 0.4965 - val_auc: 0.7971\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5163 - auc: 0.7691 - val_loss: 0.4856 - val_auc: 0.8091\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5050 - auc: 0.7815 - val_loss: 0.4794 - val_auc: 0.8139\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4977 - auc: 0.7896 - val_loss: 0.4768 - val_auc: 0.8181\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4958 - auc: 0.7921 - val_loss: 0.4757 - val_auc: 0.8187\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4935 - auc: 0.7946 - val_loss: 0.4753 - val_auc: 0.8189\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4927 - auc: 0.7955 - val_loss: 0.4749 - val_auc: 0.8191\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4910 - auc: 0.7974 - val_loss: 0.4743 - val_auc: 0.8201\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4903 - auc: 0.7983 - val_loss: 0.4737 - val_auc: 0.8193\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7997 - val_loss: 0.4736 - val_auc: 0.8195\n",
      "Epoch 13/100\n",
      "279552/285001 [============================>.] - ETA: 0s - loss: 0.4888 - auc: 0.7999\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4887 - auc: 0.8001 - val_loss: 0.4736 - val_auc: 0.8198\n",
      "Epoch 14/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4881 - auc: 0.8005 - val_loss: 0.4736 - val_auc: 0.8199\n",
      "Epoch 15/100\n",
      "282624/285001 [============================>.] - ETA: 0s - loss: 0.4883 - auc: 0.8006Restoring model weights from the end of the best epoch.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4883 - auc: 0.8002 - val_loss: 0.4736 - val_auc: 0.8201\n",
      "Epoch 00015: early stopping\n",
      "Train on 285001 samples, validate on 14999 samples\n",
      "Epoch 1/100\n",
      "285001/285001 [==============================] - 2s 7us/sample - loss: 0.6111 - auc: 0.7263 - val_loss: 0.5151 - val_auc: 0.7816\n",
      "Epoch 2/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5258 - auc: 0.7657 - val_loss: 0.4936 - val_auc: 0.7971\n",
      "Epoch 3/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5084 - auc: 0.7789 - val_loss: 0.4876 - val_auc: 0.8030\n",
      "Epoch 4/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.5012 - auc: 0.7862 - val_loss: 0.4849 - val_auc: 0.8077\n",
      "Epoch 5/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4970 - auc: 0.7910 - val_loss: 0.4823 - val_auc: 0.8108\n",
      "Epoch 6/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4941 - auc: 0.7938 - val_loss: 0.4804 - val_auc: 0.8125\n",
      "Epoch 7/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4917 - auc: 0.7965 - val_loss: 0.4784 - val_auc: 0.8153\n",
      "Epoch 8/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4895 - auc: 0.7985 - val_loss: 0.4774 - val_auc: 0.8161\n",
      "Epoch 9/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4890 - auc: 0.7991 - val_loss: 0.4770 - val_auc: 0.8161\n",
      "Epoch 10/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8002 - val_loss: 0.4767 - val_auc: 0.8161\n",
      "Epoch 11/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4882 - auc: 0.8004 - val_loss: 0.4767 - val_auc: 0.8168\n",
      "Epoch 12/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4879 - auc: 0.8006 - val_loss: 0.4769 - val_auc: 0.8162\n",
      "Epoch 13/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4874 - auc: 0.8012 - val_loss: 0.4768 - val_auc: 0.8159\n",
      "Epoch 14/100\n",
      "284672/285001 [============================>.] - ETA: 0s - loss: 0.4877 - auc: 0.8010\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4877 - auc: 0.8009 - val_loss: 0.4768 - val_auc: 0.8161\n",
      "Epoch 15/100\n",
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4878 - auc: 0.8009 - val_loss: 0.4768 - val_auc: 0.8161\n",
      "Epoch 16/100\n",
      "276480/285001 [============================>.] - ETA: 0s - loss: 0.4877 - auc: 0.8011Restoring model weights from the end of the best epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285001/285001 [==============================] - 2s 6us/sample - loss: 0.4875 - auc: 0.8014 - val_loss: 0.4767 - val_auc: 0.8163\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [6:30:34<00:00, 4597.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819757478486921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "cvs = []\n",
    "model_fs = [get_tuned_lr,get_tuned_xgb,get_tuned_cat,get_tuned_lgbm]\n",
    "embs_dims = [100,50,20,10,5]\n",
    "for emb_dim in tqdm(embs_dims):\n",
    "    train = pd.DataFrame(np.load('embs/tanh_train_emb'+str(emb_dim)+'.npy'))\n",
    "    test = pd.DataFrame(np.load('embs/tanh_test_emb'+str(emb_dim)+'.npy'))\n",
    "    for f in model_fs:\n",
    "        model, cv = f(train,target)\n",
    "        cvs.append(cv)\n",
    "        model.fit(train,target)\n",
    "        preds.append(model.predict_proba(test))\n",
    "                     \n",
    "    oof_preds = np.zeros((len(train)))\n",
    "    test_preds = np.zeros((len(test)))\n",
    "    temp_cvs = []          \n",
    "    skf = StratifiedKFold(n_splits=20)\n",
    "    for train_index, test_index in skf.split(train, target):\n",
    "   \n",
    "        model = get_nn(emb_dim)\n",
    "\n",
    "        es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n",
    "                                     verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "\n",
    "        rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                          patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "        X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model = get_nn(emb_dim)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n",
    "        \n",
    "        es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n",
    "                                     verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "\n",
    "        rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                          patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "        model.fit(X_train,y_train,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  verbose=1,\n",
    "                  batch_size=1024,\n",
    "                  callbacks=[es, rlr],\n",
    "                  epochs=100\n",
    "                 )\n",
    "        valid_fold_preds = model.predict(X_test)\n",
    "        test_fold_preds = model.predict(test)\n",
    "        oof_preds[test_index] = valid_fold_preds.ravel()\n",
    "        test_preds += test_fold_preds.ravel()\n",
    "        temp_cvs.append(metrics.roc_auc_score(y_test, valid_fold_preds))\n",
    "        \n",
    "        K.clear_session()\n",
    "    preds.append(np.array(test_preds)/20)\n",
    "    cvs.append(sum(temp_cvs)/len(temp_cvs))\n",
    "    print(cvs[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cvs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = []\n",
    "#for i in range(30):\n",
    "#    if not i in [s * 5-1 for s in range(10)]:\n",
    "#        temp.append(preds[i])\n",
    "#preds2 = temp.copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3048989 , 0.639223  , 0.07293235, ..., 0.35365551, 0.66508035,\n",
       "       0.16567642])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_cvs = [i - 0.5 for i in cvs]\n",
    "weights = [i/sum(adj_cvs) for i in adj_cvs]\n",
    "final_pred = np.zeros((200000,))\n",
    "for pred in range(len(preds)):\n",
    "    if preds[pred].shape == (200000,2):\n",
    "        final_pred += weights[pred] * preds[pred][:,1]\n",
    "    else:\n",
    "        final_pred += weights[pred] * preds[pred]\n",
    "        \n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030103151632998766"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 0\n",
    "for x,y in zip(final_pred, pd.read_csv('emb_lr_nn_xgb_cat_lgbm2.csv').target):\n",
    "    temp += abs(x-y)/len(final_pred)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [08:00<32:02, 480.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-24845df7e00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpreds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtemps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "temps = []\n",
    "for i in  tqdm(range(5)):\n",
    "    for s in range(5):\n",
    "        temp = 0\n",
    "        for m in range(len(preds2[i])):\n",
    "            temp += abs(preds2[i]-preds2[i])/len(preds2[i])\n",
    "        temps.append(temp)\n",
    "plt.plot(temps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1170128372484102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt = pd.read_csv('emb_lr_nn_xgb_cat_lgbm.csv')\n",
    "avg = 0\n",
    "for x,y in zip(final_pred,alt.target):\n",
    "    avg += abs(x-y)/len(final_pred)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91d64f49e8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50), final_pred[:50],'ro')\n",
    "plt.plot(range(50), alt.target[:50],'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('input/sample_submission.csv')\n",
    "sub['target'] = final_pred\n",
    "sub.to_csv('emb_lr_nn_xgb_cat_lgbm3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.229977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.load('embs/train_emb5.npy').reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
