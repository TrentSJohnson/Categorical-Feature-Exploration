{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...  2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...  f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...  ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...  8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...  b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#Load the data and make new df\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n",
    "enc_train = train[['bin_0','bin_1','bin_2']]\n",
    "enc_test = test[['bin_0','bin_1','bin_2']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Getting a Sense of the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[i] for i in test.bin_3])\n",
    "\n",
    "enc = encoder.transform([[i] for i in train.bin_3]).toarray()\n",
    "enc_train['bin_3'] = enc[:,0]\n",
    "\n",
    "enc = encoder.transform([[i] for i in test.bin_3]).toarray()\n",
    "enc_test['bin_3'] = enc[:,0]\n",
    "\n",
    "encoder.fit([[i] for i in test.bin_4])\n",
    "enc = encoder.transform([[i] for i in train.bin_4]).toarray()\n",
    "enc_train['bin_4'] = enc[:,0]\n",
    "\n",
    "enc = encoder.transform([[i] for i in test.bin_4]).toarray()\n",
    "enc_test['bin_4'] = enc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_corr(x,y):\n",
    "    corr = [] \n",
    "    for a, b in zip(x,y):\n",
    "        if a == b:\n",
    "            corr.append(1)\n",
    "        if a > b:\n",
    "            corr.append(0)\n",
    "        if b > a:\n",
    "            corr.append(2)\n",
    "    plt.hist(corr,bins=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_corr(test.bin_0,test.bin_1)\n",
    "binary_corr(test.bin_1,test.bin_2)\n",
    "binary_corr(test.bin_2,test.bin_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oboe        92293\n",
       "Piano       84517\n",
       "Bassoon     68448\n",
       "Theremin    54742\n",
       "Name: nom_4, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nom_0 analysis\n",
    "train.nom_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>x0_Blue</th>\n",
       "      <th>x0_Green</th>\n",
       "      <th>x0_Circle</th>\n",
       "      <th>x0_Polygon</th>\n",
       "      <th>x0_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Hamster</th>\n",
       "      <th>x0_Lion</th>\n",
       "      <th>x0_Canada</th>\n",
       "      <th>x0_China</th>\n",
       "      <th>x0_Costa Rica</th>\n",
       "      <th>x0_Finland</th>\n",
       "      <th>x0_India</th>\n",
       "      <th>x0_Bassoon</th>\n",
       "      <th>x0_Oboe</th>\n",
       "      <th>x0_Piano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  x0_Blue  x0_Green  x0_Circle  \\\n",
       "0      0      0      1    0.0    0.0      1.0       0.0        0.0   \n",
       "1      0      0      0    0.0    1.0      0.0       0.0        0.0   \n",
       "2      1      0      1    1.0    0.0      1.0       0.0        0.0   \n",
       "3      0      0      1    0.0    0.0      0.0       0.0        0.0   \n",
       "4      0      1      1    1.0    1.0      0.0       0.0        0.0   \n",
       "\n",
       "   x0_Polygon  x0_Square  ...  x0_Hamster  x0_Lion  x0_Canada  x0_China  \\\n",
       "0         0.0        0.0  ...         0.0      0.0        0.0       0.0   \n",
       "1         0.0        1.0  ...         0.0      1.0        1.0       0.0   \n",
       "2         0.0        1.0  ...         0.0      0.0        0.0       1.0   \n",
       "3         0.0        0.0  ...         0.0      0.0        0.0       1.0   \n",
       "4         0.0        0.0  ...         0.0      0.0        0.0       1.0   \n",
       "\n",
       "   x0_Costa Rica  x0_Finland  x0_India  x0_Bassoon  x0_Oboe  x0_Piano  \n",
       "0            0.0         1.0       0.0         0.0      0.0       1.0  \n",
       "1            0.0         0.0       0.0         0.0      0.0       1.0  \n",
       "2            0.0         0.0       0.0         0.0      0.0       1.0  \n",
       "3            0.0         0.0       0.0         0.0      0.0       1.0  \n",
       "4            0.0         0.0       0.0         0.0      0.0       1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the one hot encoded weights to the enc_train\n",
    "\n",
    "#get cols and fit to test\n",
    "hot_cols = ['nom_0','nom_1','nom_2','nom_3', 'nom_4']\n",
    "\n",
    "#transform and add to train\n",
    "for col in hot_cols:\n",
    "    test_col = [[i] for i in test[col]]\n",
    "    train_col = [[i] for i in train[col]]\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(test_col)\n",
    "\n",
    "    nom = encoder.transform(train_col).toarray()\n",
    "    for i in range(len(encoder.get_feature_names())-1):\n",
    "        enc_train[encoder.get_feature_names()[i]] = nom[:,i]\n",
    "    enc_train.head()\n",
    "\n",
    "    #transfrom and add to test\n",
    "    nom = encoder.transform(test_col).toarray()\n",
    "    for i in range(len(encoder.get_feature_names())-1):\n",
    "        enc_test[encoder.get_feature_names()[i]] = nom[:,i]\n",
    "    encoder = None\n",
    "enc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "522\n",
      "1220\n",
      "11981\n"
     ]
    }
   ],
   "source": [
    "#nom 5 analysis\n",
    "noms = ['nom_5','nom_6','nom_7','nom_9']\n",
    "for nom in noms:\n",
    "    print(len(train[nom].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do some analyisis on nom_5\n",
    "temp = []\n",
    "for i in train['nom_7']:\n",
    "    temp.append(int(i,16))\n",
    "\n",
    "plt.hist(temp,bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up large noms to be clustered\n",
    "noms = ['nom_5','nom_6','nom_7','nom_9']\n",
    "testhexnom =[[int(test[nom][i],16) for nom in noms] for i in range(len(test.nom_5))]\n",
    "hexnom = [[int(train[nom][i],16) for nom in noms] for i in range(len(train.nom_5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [1:55:37<00:00, 144.32s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find best cluster count\n",
    "from sklearn.cluster import KMeans\n",
    "scores = []\n",
    "for i in tqdm(range(100)):\n",
    "    km = KMeans(i+2,n_jobs=10)\n",
    "    km.fit(testhexnom)\n",
    "    temp.append(km.score(testhexnom))\n",
    "    km = None\n",
    "plt.plot(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly.express'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-47a797dbcc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly.express'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning:\n",
      "\n",
      "The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>x0_Blue</th>\n",
       "      <th>x0_Green</th>\n",
       "      <th>x0_Circle</th>\n",
       "      <th>x0_Polygon</th>\n",
       "      <th>x0_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x0_T</th>\n",
       "      <th>x0_U</th>\n",
       "      <th>x0_V</th>\n",
       "      <th>x0_W</th>\n",
       "      <th>x0_X</th>\n",
       "      <th>x0_Y</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  x0_Blue  x0_Green  x0_Circle  \\\n",
       "0      0      0      0      0      0        0         1          0   \n",
       "1      0      1      0      0      0        0         1          0   \n",
       "2      0      0      0      1      0        1         0          0   \n",
       "3      0      1      0      1      0        0         0          0   \n",
       "4      0      0      0      1      1        0         0          0   \n",
       "\n",
       "   x0_Polygon  x0_Square  ...  x0_S  x0_T  x0_U  x0_V  x0_W  x0_X  x0_Y  \\\n",
       "0           0          0  ...     0     0     0     0     0     0     0   \n",
       "1           0          0  ...     0     0     0     0     0     0     0   \n",
       "2           0          0  ...     0     0     0     0     0     0     0   \n",
       "3           0          0  ...     0     0     0     0     0     0     0   \n",
       "4           0          0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   ord_5  day  month  \n",
       "0    161    2      2  \n",
       "1     22    7      8  \n",
       "2     24    7      2  \n",
       "3     23    2      1  \n",
       "4      4    7      8  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode noms in train\n",
    "encoder = OneHotEncoder()\n",
    "#fit everything for test data\n",
    "km = KMeans(20,n_jobs=10)\n",
    "km.fit(testhexnom)\n",
    "encoder.fit([[i] for i in km.predict(testhexnom)])\n",
    "\n",
    "#encode the test data\n",
    "pred = km.predict(hexnom)\n",
    "enc = encoder.transform([[i] for i in pred]).toarray()\n",
    "for i in range(len(encoder.get_feature_names())-1):\n",
    "    enc_train[encoder.get_feature_names()[i]] = enc[:,i]\n",
    "enc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>x0_Blue</th>\n",
       "      <th>x0_Green</th>\n",
       "      <th>x0_Circle</th>\n",
       "      <th>x0_Polygon</th>\n",
       "      <th>x0_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x0_T</th>\n",
       "      <th>x0_U</th>\n",
       "      <th>x0_V</th>\n",
       "      <th>x0_W</th>\n",
       "      <th>x0_X</th>\n",
       "      <th>x0_Y</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  x0_Blue  x0_Green  x0_Circle  \\\n",
       "0      0      0      1      0      0        1         0          0   \n",
       "1      0      0      0      0      1        0         0          0   \n",
       "2      1      0      1      1      0        1         0          0   \n",
       "3      0      0      1      0      0        0         0          0   \n",
       "4      0      1      1      1      1        0         0          0   \n",
       "\n",
       "   x0_Polygon  x0_Square  ...  x0_S  x0_T  x0_U  x0_V  x0_W  x0_X  x0_Y  \\\n",
       "0           0          0  ...     0     0     0     0     0     0     0   \n",
       "1           0          1  ...     0     0     0     0     0     0     0   \n",
       "2           0          1  ...     0     0     0     0     0     0     0   \n",
       "3           0          0  ...     0     0     0     0     0     0     0   \n",
       "4           0          0  ...     0     0     0     0     1     0     0   \n",
       "\n",
       "   ord_5  day  month  \n",
       "0     40    5     11  \n",
       "1     98    7      5  \n",
       "2     16    1     12  \n",
       "3     50    2      3  \n",
       "4    130    4     11  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode noms in test\n",
    "\n",
    "pred = km.predict(testhexnom)\n",
    "enc = encoder.transform([[i] for i in pred]).toarray()\n",
    "for i in range(len(encoder.get_feature_names())-1):\n",
    "    enc_test[encoder.get_feature_names()[i]] = enc[:,i]\n",
    "enc_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ord Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord_0 3\n",
      "ord_1 5\n",
      "ord_2 6\n",
      "ord_3 15\n",
      "ord_4 26\n",
      "ord_5 192\n"
     ]
    }
   ],
   "source": [
    "##see distribution of ords\n",
    "ords = ['ord_0','ord_1','ord_2','ord_3','ord_4','ord_5']\n",
    "for ordt in ords:\n",
    "    print(ordt,len(test[ordt].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning:\n",
      "\n",
      "The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>x0_Blue</th>\n",
       "      <th>x0_Green</th>\n",
       "      <th>x0_Circle</th>\n",
       "      <th>x0_Polygon</th>\n",
       "      <th>x0_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x0_T</th>\n",
       "      <th>x0_U</th>\n",
       "      <th>x0_V</th>\n",
       "      <th>x0_W</th>\n",
       "      <th>x0_X</th>\n",
       "      <th>x0_Y</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  x0_Blue  x0_Green  x0_Circle  \\\n",
       "0      0      0      1      0      0        1         0          0   \n",
       "1      0      0      0      0      1        0         0          0   \n",
       "2      1      0      1      1      0        1         0          0   \n",
       "3      0      0      1      0      0        0         0          0   \n",
       "4      0      1      1      1      1        0         0          0   \n",
       "\n",
       "   x0_Polygon  x0_Square  ...  x0_S  x0_T  x0_U  x0_V  x0_W  x0_X  x0_Y  \\\n",
       "0           0          0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1           0          1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2           0          1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3           0          0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4           0          0  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "\n",
       "   ord_5  day  month  \n",
       "0     40    5     11  \n",
       "1     98    7      5  \n",
       "2     16    1     12  \n",
       "3     50    2      3  \n",
       "4    130    4     11  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add one hot ords excpet too big one\n",
    "hot_cols = ords[:len(ords)-1]\n",
    "\n",
    "for col in hot_cols:\n",
    "    test_col = [[i] for i in test[col]]\n",
    "    train_col = [[i] for i in train[col]]\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(test_col)\n",
    "    encs = encoder.transform(train_col).toarray()\n",
    "\n",
    "    \n",
    "    for i in range(len(encoder.get_feature_names())-1):\n",
    "        enc_train[encoder.get_feature_names()[i]] = encs[:,i]\n",
    "\n",
    "    encs = encoder.transform(test_col).toarray()\n",
    "\n",
    "    for i in range(len(encoder.get_feature_names())-1):\n",
    "        enc_test[encoder.get_feature_names()[i]] = encs[:,i]\n",
    "    \n",
    "enc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(train.ord_5.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add last ord normally\n",
    "enc_test[ords[-1]] = [inds.index(i) for i in test.ord_5]\n",
    "enc_train[ords[-1]] = [inds.index(i) for i in train.ord_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add day month\n",
    "enc_train['day']= train.day\n",
    "enc_train['month']= train.month\n",
    "enc_test['day']= test.day\n",
    "enc_test['month']= test.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>x0_Blue</th>\n",
       "      <th>x0_Green</th>\n",
       "      <th>x0_Circle</th>\n",
       "      <th>x0_Polygon</th>\n",
       "      <th>x0_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x0_T</th>\n",
       "      <th>x0_U</th>\n",
       "      <th>x0_V</th>\n",
       "      <th>x0_W</th>\n",
       "      <th>x0_X</th>\n",
       "      <th>x0_Y</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  x0_Blue  x0_Green  x0_Circle  \\\n",
       "0      0      0      1      0      0        1         0          0   \n",
       "1      0      0      0      0      1        0         0          0   \n",
       "2      1      0      1      1      0        1         0          0   \n",
       "3      0      0      1      0      0        0         0          0   \n",
       "4      0      1      1      1      1        0         0          0   \n",
       "\n",
       "   x0_Polygon  x0_Square  ...  x0_S  x0_T  x0_U  x0_V  x0_W  x0_X  x0_Y  \\\n",
       "0           0          0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1           0          1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2           0          1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3           0          0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4           0          0  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "\n",
       "   ord_5  day  month  \n",
       "0     40    5     11  \n",
       "1     98    7      5  \n",
       "2     16    1     12  \n",
       "3     50    2      3  \n",
       "4    130    4     11  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = enc_train.astype('int64')\n",
    "enc_test = enc_test.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-62e62fbe936a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36m_non_cv_scores_importances\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_non_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mscore_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mbase_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_score_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36m_get_score_importances\u001b[0;34m(self, score_func, X, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_score_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         return get_score_importances(score_func, X, y, n_iter=self.n_iter,\n\u001b[0;32m--> 231\u001b[0;31m                                      random_state=self.rng_)\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/permutation_importance.py\u001b[0m in \u001b[0;36mget_score_importances\u001b[0;34m(score_func, X, y, n_iter, columns_to_shuffle, random_state)\u001b[0m\n\u001b[1;32m     89\u001b[0m         scores_shuffled = _get_scores_shufled(\n\u001b[1;32m     90\u001b[0m             \u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_shuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m         \u001b[0mscores_decreases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores_shuffled\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/permutation_importance.py\u001b[0m in \u001b[0;36m_get_scores_shufled\u001b[0;34m(score_func, X, y, columns_to_shuffle, random_state)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         random_state=None):\n\u001b[1;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/permutation_importance.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         random_state=None):\n\u001b[1;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mpd_scorer\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbase_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         result = self.predict_proba(X, raw_score, num_iteration,\n\u001b[0;32m--> 753\u001b[0;31m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \"\"\"\n\u001b[1;32m    799\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 800\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 607\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    276\u001b[0m                    \"Did not expect the data types in fields \")\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#et feature importances\n",
    "from lightgbm import LGBMClassifier\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "lg = LGBMClassifier(n_jobs=10)\n",
    "lg.fit(enc_train, train.target)\n",
    "\n",
    "perm = PermutationImportance(lg).fit(enc_train, train.target)\n",
    "eli5.explain_weights(perm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "def get_tuned_xgb(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'n_estimators' : [50, 100, 200, 300, 500, 800, 1000]\n",
    "        }\n",
    "    \n",
    "    xgb = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1003)\n",
    "    random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=8, cv=skf.split(x,y), verbose=2, random_state=1003 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return XGBClassifier(**random_search.best_params_)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "def get_tuned_lgbm(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "    \n",
    "    lg = LGBMClassifier(objective='binary')\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1002)\n",
    "    random_search = RandomizedSearchCV(lg, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=8, cv=skf.split(x,y), verbose=1, random_state=1002 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return LGBMClassifier(**random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "def get_tuned_cat(x,y): \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "          'iterations':[2,50,100,500,1000],\n",
    "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "          'l2_leaf_reg':[3,1,5,10,100],\n",
    "          'border_count':[32,5,10,20,50,100,200],\n",
    "          'thread_count':[4],\n",
    "              'loss_function': ['Logloss', 'CrossEntropy']}\n",
    "    \n",
    "    cat = CatBoostClassifier(eval_metric = 'AUC')\n",
    "\n",
    "    folds = 5\n",
    "    param_comb = 15\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "    random_search = RandomizedSearchCV(cat, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=8, cv=skf.split(x,y), verbose=0, random_state=1001 )\n",
    "\n",
    "    random_search.fit(x,y)\n",
    "    print(random_search.best_score_)\n",
    "    return CatBoostClassifier(**random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 49.8ms\tremaining: 24.9s\n",
      "1:\ttotal: 97.6ms\tremaining: 24.3s\n",
      "2:\ttotal: 149ms\tremaining: 24.7s\n",
      "3:\ttotal: 191ms\tremaining: 23.7s\n",
      "4:\ttotal: 243ms\tremaining: 24.1s\n",
      "5:\ttotal: 300ms\tremaining: 24.7s\n",
      "6:\ttotal: 351ms\tremaining: 24.7s\n",
      "7:\ttotal: 392ms\tremaining: 24.1s\n",
      "8:\ttotal: 435ms\tremaining: 23.7s\n",
      "9:\ttotal: 485ms\tremaining: 23.8s\n",
      "10:\ttotal: 540ms\tremaining: 24s\n",
      "11:\ttotal: 593ms\tremaining: 24.1s\n",
      "12:\ttotal: 640ms\tremaining: 24s\n",
      "13:\ttotal: 689ms\tremaining: 23.9s\n",
      "14:\ttotal: 740ms\tremaining: 23.9s\n",
      "15:\ttotal: 790ms\tremaining: 23.9s\n",
      "16:\ttotal: 848ms\tremaining: 24.1s\n",
      "17:\ttotal: 909ms\tremaining: 24.3s\n",
      "18:\ttotal: 956ms\tremaining: 24.2s\n",
      "19:\ttotal: 1.01s\tremaining: 24.2s\n",
      "20:\ttotal: 1.05s\tremaining: 24s\n",
      "21:\ttotal: 1.1s\tremaining: 23.9s\n",
      "22:\ttotal: 1.15s\tremaining: 23.7s\n",
      "23:\ttotal: 1.19s\tremaining: 23.6s\n",
      "24:\ttotal: 1.25s\tremaining: 23.7s\n",
      "25:\ttotal: 1.29s\tremaining: 23.6s\n",
      "26:\ttotal: 1.34s\tremaining: 23.5s\n",
      "27:\ttotal: 1.39s\tremaining: 23.4s\n",
      "28:\ttotal: 1.43s\tremaining: 23.1s\n",
      "29:\ttotal: 1.47s\tremaining: 23s\n",
      "30:\ttotal: 1.51s\tremaining: 22.9s\n",
      "31:\ttotal: 1.56s\tremaining: 22.8s\n",
      "32:\ttotal: 1.6s\tremaining: 22.7s\n",
      "33:\ttotal: 1.65s\tremaining: 22.7s\n",
      "34:\ttotal: 1.71s\tremaining: 22.7s\n",
      "35:\ttotal: 1.76s\tremaining: 22.7s\n",
      "36:\ttotal: 1.8s\tremaining: 22.5s\n",
      "37:\ttotal: 1.85s\tremaining: 22.5s\n",
      "38:\ttotal: 1.89s\tremaining: 22.4s\n",
      "39:\ttotal: 1.95s\tremaining: 22.4s\n",
      "40:\ttotal: 2s\tremaining: 22.4s\n",
      "41:\ttotal: 2.05s\tremaining: 22.4s\n",
      "42:\ttotal: 2.1s\tremaining: 22.3s\n",
      "43:\ttotal: 2.15s\tremaining: 22.3s\n",
      "44:\ttotal: 2.2s\tremaining: 22.3s\n",
      "45:\ttotal: 2.25s\tremaining: 22.2s\n",
      "46:\ttotal: 2.29s\tremaining: 22.1s\n",
      "47:\ttotal: 2.34s\tremaining: 22s\n",
      "48:\ttotal: 2.39s\tremaining: 22s\n",
      "49:\ttotal: 2.44s\tremaining: 22s\n",
      "50:\ttotal: 2.49s\tremaining: 21.9s\n",
      "51:\ttotal: 2.53s\tremaining: 21.8s\n",
      "52:\ttotal: 2.58s\tremaining: 21.7s\n",
      "53:\ttotal: 2.63s\tremaining: 21.7s\n",
      "54:\ttotal: 2.68s\tremaining: 21.7s\n",
      "55:\ttotal: 2.73s\tremaining: 21.6s\n",
      "56:\ttotal: 2.78s\tremaining: 21.6s\n",
      "57:\ttotal: 2.83s\tremaining: 21.6s\n",
      "58:\ttotal: 2.88s\tremaining: 21.5s\n",
      "59:\ttotal: 2.93s\tremaining: 21.5s\n",
      "60:\ttotal: 2.98s\tremaining: 21.4s\n",
      "61:\ttotal: 3.02s\tremaining: 21.3s\n",
      "62:\ttotal: 3.07s\tremaining: 21.3s\n",
      "63:\ttotal: 3.12s\tremaining: 21.2s\n",
      "64:\ttotal: 3.16s\tremaining: 21.2s\n",
      "65:\ttotal: 3.21s\tremaining: 21.1s\n",
      "66:\ttotal: 3.26s\tremaining: 21.1s\n",
      "67:\ttotal: 3.31s\tremaining: 21s\n",
      "68:\ttotal: 3.35s\tremaining: 21s\n",
      "69:\ttotal: 3.41s\tremaining: 20.9s\n",
      "70:\ttotal: 3.46s\tremaining: 20.9s\n",
      "71:\ttotal: 3.52s\tremaining: 20.9s\n",
      "72:\ttotal: 3.57s\tremaining: 20.9s\n",
      "73:\ttotal: 3.63s\tremaining: 20.9s\n",
      "74:\ttotal: 3.68s\tremaining: 20.9s\n",
      "75:\ttotal: 3.72s\tremaining: 20.8s\n",
      "76:\ttotal: 3.77s\tremaining: 20.7s\n",
      "77:\ttotal: 3.81s\tremaining: 20.6s\n",
      "78:\ttotal: 3.87s\tremaining: 20.6s\n",
      "79:\ttotal: 3.92s\tremaining: 20.6s\n",
      "80:\ttotal: 3.97s\tremaining: 20.5s\n",
      "81:\ttotal: 4.02s\tremaining: 20.5s\n",
      "82:\ttotal: 4.07s\tremaining: 20.5s\n",
      "83:\ttotal: 4.13s\tremaining: 20.5s\n",
      "84:\ttotal: 4.17s\tremaining: 20.4s\n",
      "85:\ttotal: 4.21s\tremaining: 20.3s\n",
      "86:\ttotal: 4.26s\tremaining: 20.2s\n",
      "87:\ttotal: 4.3s\tremaining: 20.1s\n",
      "88:\ttotal: 4.35s\tremaining: 20.1s\n",
      "89:\ttotal: 4.4s\tremaining: 20s\n",
      "90:\ttotal: 4.45s\tremaining: 20s\n",
      "91:\ttotal: 4.49s\tremaining: 19.9s\n",
      "92:\ttotal: 4.53s\tremaining: 19.8s\n",
      "93:\ttotal: 4.59s\tremaining: 19.8s\n",
      "94:\ttotal: 4.63s\tremaining: 19.7s\n",
      "95:\ttotal: 4.68s\tremaining: 19.7s\n",
      "96:\ttotal: 4.73s\tremaining: 19.6s\n",
      "97:\ttotal: 4.78s\tremaining: 19.6s\n",
      "98:\ttotal: 4.83s\tremaining: 19.5s\n",
      "99:\ttotal: 4.87s\tremaining: 19.5s\n",
      "100:\ttotal: 4.92s\tremaining: 19.4s\n",
      "101:\ttotal: 4.96s\tremaining: 19.4s\n",
      "102:\ttotal: 5s\tremaining: 19.3s\n",
      "103:\ttotal: 5.05s\tremaining: 19.2s\n",
      "104:\ttotal: 5.1s\tremaining: 19.2s\n",
      "105:\ttotal: 5.14s\tremaining: 19.1s\n",
      "106:\ttotal: 5.2s\tremaining: 19.1s\n",
      "107:\ttotal: 5.24s\tremaining: 19s\n",
      "108:\ttotal: 5.29s\tremaining: 19s\n",
      "109:\ttotal: 5.34s\tremaining: 18.9s\n",
      "110:\ttotal: 5.39s\tremaining: 18.9s\n",
      "111:\ttotal: 5.44s\tremaining: 18.9s\n",
      "112:\ttotal: 5.49s\tremaining: 18.8s\n",
      "113:\ttotal: 5.54s\tremaining: 18.8s\n",
      "114:\ttotal: 5.59s\tremaining: 18.7s\n",
      "115:\ttotal: 5.64s\tremaining: 18.7s\n",
      "116:\ttotal: 5.68s\tremaining: 18.6s\n",
      "117:\ttotal: 5.74s\tremaining: 18.6s\n",
      "118:\ttotal: 5.78s\tremaining: 18.5s\n",
      "119:\ttotal: 5.83s\tremaining: 18.5s\n",
      "120:\ttotal: 5.88s\tremaining: 18.4s\n",
      "121:\ttotal: 5.93s\tremaining: 18.4s\n",
      "122:\ttotal: 5.97s\tremaining: 18.3s\n",
      "123:\ttotal: 6.02s\tremaining: 18.3s\n",
      "124:\ttotal: 6.08s\tremaining: 18.2s\n",
      "125:\ttotal: 6.12s\tremaining: 18.2s\n",
      "126:\ttotal: 6.17s\tremaining: 18.1s\n",
      "127:\ttotal: 6.21s\tremaining: 18.1s\n",
      "128:\ttotal: 6.27s\tremaining: 18s\n",
      "129:\ttotal: 6.32s\tremaining: 18s\n",
      "130:\ttotal: 6.37s\tremaining: 17.9s\n",
      "131:\ttotal: 6.41s\tremaining: 17.9s\n",
      "132:\ttotal: 6.46s\tremaining: 17.8s\n",
      "133:\ttotal: 6.51s\tremaining: 17.8s\n",
      "134:\ttotal: 6.55s\tremaining: 17.7s\n",
      "135:\ttotal: 6.61s\tremaining: 17.7s\n",
      "136:\ttotal: 6.66s\tremaining: 17.6s\n",
      "137:\ttotal: 6.7s\tremaining: 17.6s\n",
      "138:\ttotal: 6.75s\tremaining: 17.5s\n",
      "139:\ttotal: 6.79s\tremaining: 17.5s\n",
      "140:\ttotal: 6.83s\tremaining: 17.4s\n",
      "141:\ttotal: 6.88s\tremaining: 17.3s\n",
      "142:\ttotal: 6.92s\tremaining: 17.3s\n",
      "143:\ttotal: 6.97s\tremaining: 17.2s\n",
      "144:\ttotal: 7.03s\tremaining: 17.2s\n",
      "145:\ttotal: 7.08s\tremaining: 17.2s\n",
      "146:\ttotal: 7.12s\tremaining: 17.1s\n",
      "147:\ttotal: 7.17s\tremaining: 17.1s\n",
      "148:\ttotal: 7.22s\tremaining: 17s\n",
      "149:\ttotal: 7.26s\tremaining: 17s\n",
      "150:\ttotal: 7.31s\tremaining: 16.9s\n",
      "151:\ttotal: 7.36s\tremaining: 16.8s\n",
      "152:\ttotal: 7.41s\tremaining: 16.8s\n",
      "153:\ttotal: 7.47s\tremaining: 16.8s\n",
      "154:\ttotal: 7.52s\tremaining: 16.7s\n",
      "155:\ttotal: 7.56s\tremaining: 16.7s\n",
      "156:\ttotal: 7.61s\tremaining: 16.6s\n",
      "157:\ttotal: 7.65s\tremaining: 16.6s\n",
      "158:\ttotal: 7.7s\tremaining: 16.5s\n",
      "159:\ttotal: 7.75s\tremaining: 16.5s\n",
      "160:\ttotal: 7.79s\tremaining: 16.4s\n",
      "161:\ttotal: 7.84s\tremaining: 16.4s\n",
      "162:\ttotal: 7.88s\tremaining: 16.3s\n",
      "163:\ttotal: 7.92s\tremaining: 16.2s\n",
      "164:\ttotal: 7.97s\tremaining: 16.2s\n",
      "165:\ttotal: 8.02s\tremaining: 16.1s\n",
      "166:\ttotal: 8.07s\tremaining: 16.1s\n",
      "167:\ttotal: 8.11s\tremaining: 16s\n",
      "168:\ttotal: 8.16s\tremaining: 16s\n",
      "169:\ttotal: 8.21s\tremaining: 15.9s\n",
      "170:\ttotal: 8.26s\tremaining: 15.9s\n",
      "171:\ttotal: 8.3s\tremaining: 15.8s\n",
      "172:\ttotal: 8.35s\tremaining: 15.8s\n",
      "173:\ttotal: 8.41s\tremaining: 15.8s\n",
      "174:\ttotal: 8.47s\tremaining: 15.7s\n",
      "175:\ttotal: 8.52s\tremaining: 15.7s\n",
      "176:\ttotal: 8.56s\tremaining: 15.6s\n",
      "177:\ttotal: 8.61s\tremaining: 15.6s\n",
      "178:\ttotal: 8.66s\tremaining: 15.5s\n",
      "179:\ttotal: 8.71s\tremaining: 15.5s\n",
      "180:\ttotal: 8.76s\tremaining: 15.4s\n",
      "181:\ttotal: 8.8s\tremaining: 15.4s\n",
      "182:\ttotal: 8.85s\tremaining: 15.3s\n",
      "183:\ttotal: 8.9s\tremaining: 15.3s\n",
      "184:\ttotal: 8.96s\tremaining: 15.2s\n",
      "185:\ttotal: 9.01s\tremaining: 15.2s\n",
      "186:\ttotal: 9.05s\tremaining: 15.1s\n",
      "187:\ttotal: 9.1s\tremaining: 15.1s\n",
      "188:\ttotal: 9.15s\tremaining: 15.1s\n",
      "189:\ttotal: 9.2s\tremaining: 15s\n",
      "190:\ttotal: 9.25s\tremaining: 15s\n",
      "191:\ttotal: 9.3s\tremaining: 14.9s\n",
      "192:\ttotal: 9.35s\tremaining: 14.9s\n",
      "193:\ttotal: 9.4s\tremaining: 14.8s\n",
      "194:\ttotal: 9.44s\tremaining: 14.8s\n",
      "195:\ttotal: 9.49s\tremaining: 14.7s\n",
      "196:\ttotal: 9.54s\tremaining: 14.7s\n",
      "197:\ttotal: 9.59s\tremaining: 14.6s\n",
      "198:\ttotal: 9.64s\tremaining: 14.6s\n",
      "199:\ttotal: 9.68s\tremaining: 14.5s\n",
      "200:\ttotal: 9.73s\tremaining: 14.5s\n",
      "201:\ttotal: 9.78s\tremaining: 14.4s\n",
      "202:\ttotal: 9.84s\tremaining: 14.4s\n",
      "203:\ttotal: 9.88s\tremaining: 14.3s\n",
      "204:\ttotal: 9.93s\tremaining: 14.3s\n",
      "205:\ttotal: 9.98s\tremaining: 14.2s\n",
      "206:\ttotal: 10s\tremaining: 14.2s\n",
      "207:\ttotal: 10.1s\tremaining: 14.2s\n",
      "208:\ttotal: 10.1s\tremaining: 14.1s\n",
      "209:\ttotal: 10.2s\tremaining: 14.1s\n",
      "210:\ttotal: 10.2s\tremaining: 14s\n",
      "211:\ttotal: 10.3s\tremaining: 14s\n",
      "212:\ttotal: 10.3s\tremaining: 13.9s\n",
      "213:\ttotal: 10.4s\tremaining: 13.9s\n",
      "214:\ttotal: 10.4s\tremaining: 13.8s\n",
      "215:\ttotal: 10.5s\tremaining: 13.8s\n",
      "216:\ttotal: 10.5s\tremaining: 13.7s\n",
      "217:\ttotal: 10.6s\tremaining: 13.7s\n",
      "218:\ttotal: 10.6s\tremaining: 13.6s\n",
      "219:\ttotal: 10.7s\tremaining: 13.6s\n",
      "220:\ttotal: 10.7s\tremaining: 13.5s\n",
      "221:\ttotal: 10.8s\tremaining: 13.5s\n",
      "222:\ttotal: 10.8s\tremaining: 13.4s\n",
      "223:\ttotal: 10.9s\tremaining: 13.4s\n",
      "224:\ttotal: 10.9s\tremaining: 13.4s\n",
      "225:\ttotal: 11s\tremaining: 13.3s\n",
      "226:\ttotal: 11s\tremaining: 13.3s\n",
      "227:\ttotal: 11.1s\tremaining: 13.2s\n",
      "228:\ttotal: 11.1s\tremaining: 13.2s\n",
      "229:\ttotal: 11.2s\tremaining: 13.1s\n",
      "230:\ttotal: 11.2s\tremaining: 13s\n",
      "231:\ttotal: 11.2s\tremaining: 13s\n",
      "232:\ttotal: 11.3s\tremaining: 12.9s\n",
      "233:\ttotal: 11.3s\tremaining: 12.9s\n",
      "234:\ttotal: 11.4s\tremaining: 12.8s\n",
      "235:\ttotal: 11.4s\tremaining: 12.8s\n",
      "236:\ttotal: 11.5s\tremaining: 12.8s\n",
      "237:\ttotal: 11.5s\tremaining: 12.7s\n",
      "238:\ttotal: 11.6s\tremaining: 12.7s\n",
      "239:\ttotal: 11.6s\tremaining: 12.6s\n",
      "240:\ttotal: 11.7s\tremaining: 12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241:\ttotal: 11.7s\tremaining: 12.5s\n",
      "242:\ttotal: 11.8s\tremaining: 12.4s\n",
      "243:\ttotal: 11.8s\tremaining: 12.4s\n",
      "244:\ttotal: 11.9s\tremaining: 12.3s\n",
      "245:\ttotal: 11.9s\tremaining: 12.3s\n",
      "246:\ttotal: 12s\tremaining: 12.2s\n",
      "247:\ttotal: 12s\tremaining: 12.2s\n",
      "248:\ttotal: 12.1s\tremaining: 12.2s\n",
      "249:\ttotal: 12.1s\tremaining: 12.1s\n",
      "250:\ttotal: 12.1s\tremaining: 12.1s\n",
      "251:\ttotal: 12.2s\tremaining: 12s\n",
      "252:\ttotal: 12.3s\tremaining: 12s\n",
      "253:\ttotal: 12.3s\tremaining: 11.9s\n",
      "254:\ttotal: 12.4s\tremaining: 11.9s\n",
      "255:\ttotal: 12.4s\tremaining: 11.8s\n",
      "256:\ttotal: 12.5s\tremaining: 11.8s\n",
      "257:\ttotal: 12.5s\tremaining: 11.7s\n",
      "258:\ttotal: 12.6s\tremaining: 11.7s\n",
      "259:\ttotal: 12.6s\tremaining: 11.6s\n",
      "260:\ttotal: 12.6s\tremaining: 11.6s\n",
      "261:\ttotal: 12.7s\tremaining: 11.5s\n",
      "262:\ttotal: 12.7s\tremaining: 11.5s\n",
      "263:\ttotal: 12.8s\tremaining: 11.4s\n",
      "264:\ttotal: 12.8s\tremaining: 11.4s\n",
      "265:\ttotal: 12.9s\tremaining: 11.3s\n",
      "266:\ttotal: 12.9s\tremaining: 11.3s\n",
      "267:\ttotal: 13s\tremaining: 11.2s\n",
      "268:\ttotal: 13s\tremaining: 11.2s\n",
      "269:\ttotal: 13.1s\tremaining: 11.2s\n",
      "270:\ttotal: 13.1s\tremaining: 11.1s\n",
      "271:\ttotal: 13.2s\tremaining: 11.1s\n",
      "272:\ttotal: 13.2s\tremaining: 11s\n",
      "273:\ttotal: 13.3s\tremaining: 11s\n",
      "274:\ttotal: 13.3s\tremaining: 10.9s\n",
      "275:\ttotal: 13.4s\tremaining: 10.9s\n",
      "276:\ttotal: 13.4s\tremaining: 10.8s\n",
      "277:\ttotal: 13.5s\tremaining: 10.8s\n",
      "278:\ttotal: 13.5s\tremaining: 10.7s\n",
      "279:\ttotal: 13.6s\tremaining: 10.7s\n",
      "280:\ttotal: 13.6s\tremaining: 10.6s\n",
      "281:\ttotal: 13.7s\tremaining: 10.6s\n",
      "282:\ttotal: 13.7s\tremaining: 10.5s\n",
      "283:\ttotal: 13.8s\tremaining: 10.5s\n",
      "284:\ttotal: 13.8s\tremaining: 10.4s\n",
      "285:\ttotal: 13.9s\tremaining: 10.4s\n",
      "286:\ttotal: 13.9s\tremaining: 10.3s\n",
      "287:\ttotal: 13.9s\tremaining: 10.3s\n",
      "288:\ttotal: 14s\tremaining: 10.2s\n",
      "289:\ttotal: 14s\tremaining: 10.2s\n",
      "290:\ttotal: 14.1s\tremaining: 10.1s\n",
      "291:\ttotal: 14.1s\tremaining: 10.1s\n",
      "292:\ttotal: 14.2s\tremaining: 10s\n",
      "293:\ttotal: 14.2s\tremaining: 9.97s\n",
      "294:\ttotal: 14.3s\tremaining: 9.93s\n",
      "295:\ttotal: 14.3s\tremaining: 9.87s\n",
      "296:\ttotal: 14.4s\tremaining: 9.83s\n",
      "297:\ttotal: 14.4s\tremaining: 9.78s\n",
      "298:\ttotal: 14.5s\tremaining: 9.72s\n",
      "299:\ttotal: 14.5s\tremaining: 9.67s\n",
      "300:\ttotal: 14.6s\tremaining: 9.63s\n",
      "301:\ttotal: 14.6s\tremaining: 9.58s\n",
      "302:\ttotal: 14.7s\tremaining: 9.53s\n",
      "303:\ttotal: 14.7s\tremaining: 9.48s\n",
      "304:\ttotal: 14.8s\tremaining: 9.43s\n",
      "305:\ttotal: 14.8s\tremaining: 9.38s\n",
      "306:\ttotal: 14.8s\tremaining: 9.33s\n",
      "307:\ttotal: 14.9s\tremaining: 9.29s\n",
      "308:\ttotal: 14.9s\tremaining: 9.24s\n",
      "309:\ttotal: 15s\tremaining: 9.19s\n",
      "310:\ttotal: 15s\tremaining: 9.14s\n",
      "311:\ttotal: 15.1s\tremaining: 9.09s\n",
      "312:\ttotal: 15.1s\tremaining: 9.03s\n",
      "313:\ttotal: 15.2s\tremaining: 8.98s\n",
      "314:\ttotal: 15.2s\tremaining: 8.93s\n",
      "315:\ttotal: 15.3s\tremaining: 8.89s\n",
      "316:\ttotal: 15.3s\tremaining: 8.84s\n",
      "317:\ttotal: 15.3s\tremaining: 8.79s\n",
      "318:\ttotal: 15.4s\tremaining: 8.74s\n",
      "319:\ttotal: 15.4s\tremaining: 8.69s\n",
      "320:\ttotal: 15.5s\tremaining: 8.64s\n",
      "321:\ttotal: 15.5s\tremaining: 8.59s\n",
      "322:\ttotal: 15.6s\tremaining: 8.54s\n",
      "323:\ttotal: 15.6s\tremaining: 8.49s\n",
      "324:\ttotal: 15.7s\tremaining: 8.45s\n",
      "325:\ttotal: 15.7s\tremaining: 8.4s\n",
      "326:\ttotal: 15.8s\tremaining: 8.35s\n",
      "327:\ttotal: 15.8s\tremaining: 8.3s\n",
      "328:\ttotal: 15.9s\tremaining: 8.25s\n",
      "329:\ttotal: 15.9s\tremaining: 8.2s\n",
      "330:\ttotal: 16s\tremaining: 8.15s\n",
      "331:\ttotal: 16s\tremaining: 8.11s\n",
      "332:\ttotal: 16.1s\tremaining: 8.05s\n",
      "333:\ttotal: 16.1s\tremaining: 8s\n",
      "334:\ttotal: 16.2s\tremaining: 7.96s\n",
      "335:\ttotal: 16.2s\tremaining: 7.91s\n",
      "336:\ttotal: 16.3s\tremaining: 7.87s\n",
      "337:\ttotal: 16.3s\tremaining: 7.82s\n",
      "338:\ttotal: 16.4s\tremaining: 7.77s\n",
      "339:\ttotal: 16.4s\tremaining: 7.72s\n",
      "340:\ttotal: 16.5s\tremaining: 7.67s\n",
      "341:\ttotal: 16.5s\tremaining: 7.63s\n",
      "342:\ttotal: 16.6s\tremaining: 7.58s\n",
      "343:\ttotal: 16.6s\tremaining: 7.53s\n",
      "344:\ttotal: 16.7s\tremaining: 7.48s\n",
      "345:\ttotal: 16.7s\tremaining: 7.43s\n",
      "346:\ttotal: 16.7s\tremaining: 7.38s\n",
      "347:\ttotal: 16.8s\tremaining: 7.34s\n",
      "348:\ttotal: 16.8s\tremaining: 7.29s\n",
      "349:\ttotal: 16.9s\tremaining: 7.24s\n",
      "350:\ttotal: 16.9s\tremaining: 7.19s\n",
      "351:\ttotal: 17s\tremaining: 7.14s\n",
      "352:\ttotal: 17s\tremaining: 7.09s\n",
      "353:\ttotal: 17.1s\tremaining: 7.04s\n",
      "354:\ttotal: 17.1s\tremaining: 7s\n",
      "355:\ttotal: 17.2s\tremaining: 6.95s\n",
      "356:\ttotal: 17.2s\tremaining: 6.9s\n",
      "357:\ttotal: 17.3s\tremaining: 6.85s\n",
      "358:\ttotal: 17.3s\tremaining: 6.8s\n",
      "359:\ttotal: 17.4s\tremaining: 6.76s\n",
      "360:\ttotal: 17.4s\tremaining: 6.71s\n",
      "361:\ttotal: 17.5s\tremaining: 6.66s\n",
      "362:\ttotal: 17.5s\tremaining: 6.61s\n",
      "363:\ttotal: 17.5s\tremaining: 6.55s\n",
      "364:\ttotal: 17.6s\tremaining: 6.5s\n",
      "365:\ttotal: 17.6s\tremaining: 6.46s\n",
      "366:\ttotal: 17.7s\tremaining: 6.41s\n",
      "367:\ttotal: 17.7s\tremaining: 6.36s\n",
      "368:\ttotal: 17.8s\tremaining: 6.31s\n",
      "369:\ttotal: 17.8s\tremaining: 6.26s\n",
      "370:\ttotal: 17.9s\tremaining: 6.21s\n",
      "371:\ttotal: 17.9s\tremaining: 6.17s\n",
      "372:\ttotal: 18s\tremaining: 6.12s\n",
      "373:\ttotal: 18s\tremaining: 6.07s\n",
      "374:\ttotal: 18.1s\tremaining: 6.03s\n",
      "375:\ttotal: 18.1s\tremaining: 5.98s\n",
      "376:\ttotal: 18.2s\tremaining: 5.93s\n",
      "377:\ttotal: 18.2s\tremaining: 5.88s\n",
      "378:\ttotal: 18.3s\tremaining: 5.83s\n",
      "379:\ttotal: 18.3s\tremaining: 5.79s\n",
      "380:\ttotal: 18.4s\tremaining: 5.74s\n",
      "381:\ttotal: 18.4s\tremaining: 5.69s\n",
      "382:\ttotal: 18.5s\tremaining: 5.64s\n",
      "383:\ttotal: 18.5s\tremaining: 5.6s\n",
      "384:\ttotal: 18.6s\tremaining: 5.55s\n",
      "385:\ttotal: 18.6s\tremaining: 5.5s\n",
      "386:\ttotal: 18.7s\tremaining: 5.45s\n",
      "387:\ttotal: 18.7s\tremaining: 5.41s\n",
      "388:\ttotal: 18.8s\tremaining: 5.36s\n",
      "389:\ttotal: 18.8s\tremaining: 5.31s\n",
      "390:\ttotal: 18.9s\tremaining: 5.26s\n",
      "391:\ttotal: 18.9s\tremaining: 5.22s\n",
      "392:\ttotal: 19s\tremaining: 5.17s\n",
      "393:\ttotal: 19s\tremaining: 5.12s\n",
      "394:\ttotal: 19.1s\tremaining: 5.07s\n",
      "395:\ttotal: 19.1s\tremaining: 5.02s\n",
      "396:\ttotal: 19.2s\tremaining: 4.98s\n",
      "397:\ttotal: 19.2s\tremaining: 4.93s\n",
      "398:\ttotal: 19.3s\tremaining: 4.88s\n",
      "399:\ttotal: 19.3s\tremaining: 4.83s\n",
      "400:\ttotal: 19.4s\tremaining: 4.78s\n",
      "401:\ttotal: 19.4s\tremaining: 4.73s\n",
      "402:\ttotal: 19.4s\tremaining: 4.68s\n",
      "403:\ttotal: 19.5s\tremaining: 4.63s\n",
      "404:\ttotal: 19.5s\tremaining: 4.58s\n",
      "405:\ttotal: 19.6s\tremaining: 4.54s\n",
      "406:\ttotal: 19.7s\tremaining: 4.49s\n",
      "407:\ttotal: 19.7s\tremaining: 4.44s\n",
      "408:\ttotal: 19.7s\tremaining: 4.39s\n",
      "409:\ttotal: 19.8s\tremaining: 4.34s\n",
      "410:\ttotal: 19.8s\tremaining: 4.3s\n",
      "411:\ttotal: 19.9s\tremaining: 4.25s\n",
      "412:\ttotal: 19.9s\tremaining: 4.2s\n",
      "413:\ttotal: 20s\tremaining: 4.15s\n",
      "414:\ttotal: 20s\tremaining: 4.1s\n",
      "415:\ttotal: 20.1s\tremaining: 4.05s\n",
      "416:\ttotal: 20.1s\tremaining: 4.01s\n",
      "417:\ttotal: 20.2s\tremaining: 3.96s\n",
      "418:\ttotal: 20.2s\tremaining: 3.91s\n",
      "419:\ttotal: 20.3s\tremaining: 3.86s\n",
      "420:\ttotal: 20.3s\tremaining: 3.81s\n",
      "421:\ttotal: 20.4s\tremaining: 3.77s\n",
      "422:\ttotal: 20.4s\tremaining: 3.72s\n",
      "423:\ttotal: 20.5s\tremaining: 3.67s\n",
      "424:\ttotal: 20.5s\tremaining: 3.62s\n",
      "425:\ttotal: 20.6s\tremaining: 3.57s\n",
      "426:\ttotal: 20.6s\tremaining: 3.52s\n",
      "427:\ttotal: 20.7s\tremaining: 3.48s\n",
      "428:\ttotal: 20.7s\tremaining: 3.43s\n",
      "429:\ttotal: 20.8s\tremaining: 3.38s\n",
      "430:\ttotal: 20.8s\tremaining: 3.33s\n",
      "431:\ttotal: 20.9s\tremaining: 3.28s\n",
      "432:\ttotal: 20.9s\tremaining: 3.23s\n",
      "433:\ttotal: 21s\tremaining: 3.19s\n",
      "434:\ttotal: 21s\tremaining: 3.14s\n",
      "435:\ttotal: 21s\tremaining: 3.09s\n",
      "436:\ttotal: 21.1s\tremaining: 3.04s\n",
      "437:\ttotal: 21.1s\tremaining: 2.99s\n",
      "438:\ttotal: 21.2s\tremaining: 2.94s\n",
      "439:\ttotal: 21.2s\tremaining: 2.89s\n",
      "440:\ttotal: 21.3s\tremaining: 2.85s\n",
      "441:\ttotal: 21.3s\tremaining: 2.8s\n",
      "442:\ttotal: 21.4s\tremaining: 2.75s\n",
      "443:\ttotal: 21.4s\tremaining: 2.7s\n",
      "444:\ttotal: 21.5s\tremaining: 2.65s\n",
      "445:\ttotal: 21.5s\tremaining: 2.6s\n",
      "446:\ttotal: 21.6s\tremaining: 2.56s\n",
      "447:\ttotal: 21.6s\tremaining: 2.51s\n",
      "448:\ttotal: 21.7s\tremaining: 2.46s\n",
      "449:\ttotal: 21.7s\tremaining: 2.41s\n",
      "450:\ttotal: 21.8s\tremaining: 2.36s\n",
      "451:\ttotal: 21.8s\tremaining: 2.31s\n",
      "452:\ttotal: 21.9s\tremaining: 2.27s\n",
      "453:\ttotal: 21.9s\tremaining: 2.22s\n",
      "454:\ttotal: 21.9s\tremaining: 2.17s\n",
      "455:\ttotal: 22s\tremaining: 2.12s\n",
      "456:\ttotal: 22s\tremaining: 2.07s\n",
      "457:\ttotal: 22.1s\tremaining: 2.02s\n",
      "458:\ttotal: 22.1s\tremaining: 1.98s\n",
      "459:\ttotal: 22.2s\tremaining: 1.93s\n",
      "460:\ttotal: 22.2s\tremaining: 1.88s\n",
      "461:\ttotal: 22.3s\tremaining: 1.83s\n",
      "462:\ttotal: 22.3s\tremaining: 1.78s\n",
      "463:\ttotal: 22.4s\tremaining: 1.74s\n",
      "464:\ttotal: 22.4s\tremaining: 1.69s\n",
      "465:\ttotal: 22.5s\tremaining: 1.64s\n",
      "466:\ttotal: 22.5s\tremaining: 1.59s\n",
      "467:\ttotal: 22.6s\tremaining: 1.54s\n",
      "468:\ttotal: 22.6s\tremaining: 1.49s\n",
      "469:\ttotal: 22.6s\tremaining: 1.45s\n",
      "470:\ttotal: 22.7s\tremaining: 1.4s\n",
      "471:\ttotal: 22.7s\tremaining: 1.35s\n",
      "472:\ttotal: 22.8s\tremaining: 1.3s\n",
      "473:\ttotal: 22.8s\tremaining: 1.25s\n",
      "474:\ttotal: 22.9s\tremaining: 1.2s\n",
      "475:\ttotal: 22.9s\tremaining: 1.16s\n",
      "476:\ttotal: 23s\tremaining: 1.11s\n",
      "477:\ttotal: 23s\tremaining: 1.06s\n",
      "478:\ttotal: 23.1s\tremaining: 1.01s\n",
      "479:\ttotal: 23.1s\tremaining: 963ms\n",
      "480:\ttotal: 23.2s\tremaining: 915ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481:\ttotal: 23.2s\tremaining: 866ms\n",
      "482:\ttotal: 23.2s\tremaining: 818ms\n",
      "483:\ttotal: 23.3s\tremaining: 770ms\n",
      "484:\ttotal: 23.3s\tremaining: 722ms\n",
      "485:\ttotal: 23.4s\tremaining: 673ms\n",
      "486:\ttotal: 23.4s\tremaining: 625ms\n",
      "487:\ttotal: 23.5s\tremaining: 577ms\n",
      "488:\ttotal: 23.5s\tremaining: 529ms\n",
      "489:\ttotal: 23.6s\tremaining: 481ms\n",
      "490:\ttotal: 23.6s\tremaining: 433ms\n",
      "491:\ttotal: 23.7s\tremaining: 385ms\n",
      "492:\ttotal: 23.7s\tremaining: 337ms\n",
      "493:\ttotal: 23.8s\tremaining: 289ms\n",
      "494:\ttotal: 23.8s\tremaining: 240ms\n",
      "495:\ttotal: 23.9s\tremaining: 192ms\n",
      "496:\ttotal: 23.9s\tremaining: 144ms\n",
      "497:\ttotal: 23.9s\tremaining: 96.1ms\n",
      "498:\ttotal: 24s\tremaining: 48ms\n",
      "499:\ttotal: 24s\tremaining: 0us\n",
      "0.7517116671033757\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=8)]: Done  75 out of  75 | elapsed:   58.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7478176981306396\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done  75 out of  75 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7338403979977742\n"
     ]
    }
   ],
   "source": [
    "tcat = get_tuned_cat(enc_train,train.target)\n",
    "tlg = get_tuned_lgbm(enc_train,train.target)\n",
    "txgb = get_tuned_xgb(enc_train,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done  75 out of  75 | elapsed: 49.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7579177183315073\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "estimators=[('xgb', txgb), ('lg', tlg), ('cat', tcat)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6565699\ttotal: 53.2ms\tremaining: 26.6s\n",
      "1:\tlearn: 0.6331423\ttotal: 102ms\tremaining: 25.4s\n",
      "2:\tlearn: 0.6174176\ttotal: 144ms\tremaining: 23.8s\n",
      "3:\tlearn: 0.6072923\ttotal: 192ms\tremaining: 23.9s\n",
      "4:\tlearn: 0.5995001\ttotal: 242ms\tremaining: 24s\n",
      "5:\tlearn: 0.5942852\ttotal: 290ms\tremaining: 23.9s\n",
      "6:\tlearn: 0.5901022\ttotal: 345ms\tremaining: 24.3s\n",
      "7:\tlearn: 0.5868917\ttotal: 400ms\tremaining: 24.6s\n",
      "8:\tlearn: 0.5846418\ttotal: 450ms\tremaining: 24.5s\n",
      "9:\tlearn: 0.5827079\ttotal: 501ms\tremaining: 24.6s\n",
      "10:\tlearn: 0.5807745\ttotal: 552ms\tremaining: 24.5s\n",
      "11:\tlearn: 0.5790417\ttotal: 601ms\tremaining: 24.5s\n",
      "12:\tlearn: 0.5775885\ttotal: 640ms\tremaining: 24s\n",
      "13:\tlearn: 0.5760781\ttotal: 685ms\tremaining: 23.8s\n",
      "14:\tlearn: 0.5748536\ttotal: 736ms\tremaining: 23.8s\n",
      "15:\tlearn: 0.5738083\ttotal: 777ms\tremaining: 23.5s\n",
      "16:\tlearn: 0.5728008\ttotal: 826ms\tremaining: 23.5s\n",
      "17:\tlearn: 0.5718352\ttotal: 867ms\tremaining: 23.2s\n",
      "18:\tlearn: 0.5709090\ttotal: 911ms\tremaining: 23.1s\n",
      "19:\tlearn: 0.5700254\ttotal: 959ms\tremaining: 23s\n",
      "20:\tlearn: 0.5691252\ttotal: 1.01s\tremaining: 23s\n",
      "21:\tlearn: 0.5681414\ttotal: 1.05s\tremaining: 22.9s\n",
      "22:\tlearn: 0.5673765\ttotal: 1.1s\tremaining: 22.9s\n",
      "23:\tlearn: 0.5665808\ttotal: 1.15s\tremaining: 22.8s\n",
      "24:\tlearn: 0.5658224\ttotal: 1.2s\tremaining: 22.9s\n",
      "25:\tlearn: 0.5651374\ttotal: 1.25s\tremaining: 22.8s\n",
      "26:\tlearn: 0.5645338\ttotal: 1.3s\tremaining: 22.7s\n",
      "27:\tlearn: 0.5638445\ttotal: 1.34s\tremaining: 22.5s\n",
      "28:\tlearn: 0.5632846\ttotal: 1.38s\tremaining: 22.5s\n",
      "29:\tlearn: 0.5626005\ttotal: 1.43s\tremaining: 22.4s\n",
      "30:\tlearn: 0.5619538\ttotal: 1.47s\tremaining: 22.3s\n",
      "31:\tlearn: 0.5614892\ttotal: 1.52s\tremaining: 22.3s\n",
      "32:\tlearn: 0.5609118\ttotal: 1.57s\tremaining: 22.2s\n",
      "33:\tlearn: 0.5604037\ttotal: 1.61s\tremaining: 22.1s\n",
      "34:\tlearn: 0.5599105\ttotal: 1.66s\tremaining: 22.1s\n",
      "35:\tlearn: 0.5593975\ttotal: 1.71s\tremaining: 22.1s\n",
      "36:\tlearn: 0.5589582\ttotal: 1.75s\tremaining: 22s\n",
      "37:\tlearn: 0.5584557\ttotal: 1.8s\tremaining: 21.9s\n",
      "38:\tlearn: 0.5579616\ttotal: 1.84s\tremaining: 21.8s\n",
      "39:\tlearn: 0.5576000\ttotal: 1.89s\tremaining: 21.8s\n",
      "40:\tlearn: 0.5571785\ttotal: 1.94s\tremaining: 21.7s\n",
      "41:\tlearn: 0.5568233\ttotal: 1.98s\tremaining: 21.6s\n",
      "42:\tlearn: 0.5563974\ttotal: 2.02s\tremaining: 21.5s\n",
      "43:\tlearn: 0.5559678\ttotal: 2.06s\tremaining: 21.4s\n",
      "44:\tlearn: 0.5555165\ttotal: 2.11s\tremaining: 21.3s\n",
      "45:\tlearn: 0.5550561\ttotal: 2.16s\tremaining: 21.3s\n",
      "46:\tlearn: 0.5546744\ttotal: 2.21s\tremaining: 21.3s\n",
      "47:\tlearn: 0.5543088\ttotal: 2.26s\tremaining: 21.3s\n",
      "48:\tlearn: 0.5539290\ttotal: 2.3s\tremaining: 21.2s\n",
      "49:\tlearn: 0.5535894\ttotal: 2.35s\tremaining: 21.2s\n",
      "50:\tlearn: 0.5531955\ttotal: 2.4s\tremaining: 21.1s\n",
      "51:\tlearn: 0.5528797\ttotal: 2.45s\tremaining: 21.1s\n",
      "52:\tlearn: 0.5524989\ttotal: 2.49s\tremaining: 21s\n",
      "53:\tlearn: 0.5521259\ttotal: 2.54s\tremaining: 21s\n",
      "54:\tlearn: 0.5517285\ttotal: 2.6s\tremaining: 21s\n",
      "55:\tlearn: 0.5513750\ttotal: 2.65s\tremaining: 21s\n",
      "56:\tlearn: 0.5510953\ttotal: 2.69s\tremaining: 20.9s\n",
      "57:\tlearn: 0.5508067\ttotal: 2.74s\tremaining: 20.9s\n",
      "58:\tlearn: 0.5505903\ttotal: 2.79s\tremaining: 20.8s\n",
      "59:\tlearn: 0.5503087\ttotal: 2.84s\tremaining: 20.8s\n",
      "60:\tlearn: 0.5499961\ttotal: 2.88s\tremaining: 20.8s\n",
      "61:\tlearn: 0.5496020\ttotal: 2.92s\tremaining: 20.7s\n",
      "62:\tlearn: 0.5493373\ttotal: 2.98s\tremaining: 20.7s\n",
      "63:\tlearn: 0.5490958\ttotal: 3.02s\tremaining: 20.6s\n",
      "64:\tlearn: 0.5487962\ttotal: 3.08s\tremaining: 20.6s\n",
      "65:\tlearn: 0.5485793\ttotal: 3.13s\tremaining: 20.6s\n",
      "66:\tlearn: 0.5483488\ttotal: 3.17s\tremaining: 20.5s\n",
      "67:\tlearn: 0.5480984\ttotal: 3.21s\tremaining: 20.4s\n",
      "68:\tlearn: 0.5478420\ttotal: 3.25s\tremaining: 20.3s\n",
      "69:\tlearn: 0.5476075\ttotal: 3.3s\tremaining: 20.3s\n",
      "70:\tlearn: 0.5473393\ttotal: 3.35s\tremaining: 20.3s\n",
      "71:\tlearn: 0.5471070\ttotal: 3.4s\tremaining: 20.2s\n",
      "72:\tlearn: 0.5468176\ttotal: 3.44s\tremaining: 20.1s\n",
      "73:\tlearn: 0.5465766\ttotal: 3.48s\tremaining: 20.1s\n",
      "74:\tlearn: 0.5463915\ttotal: 3.53s\tremaining: 20s\n",
      "75:\tlearn: 0.5461767\ttotal: 3.58s\tremaining: 20s\n",
      "76:\tlearn: 0.5460014\ttotal: 3.63s\tremaining: 19.9s\n",
      "77:\tlearn: 0.5458368\ttotal: 3.67s\tremaining: 19.9s\n",
      "78:\tlearn: 0.5456324\ttotal: 3.72s\tremaining: 19.8s\n",
      "79:\tlearn: 0.5454248\ttotal: 3.77s\tremaining: 19.8s\n",
      "80:\tlearn: 0.5452691\ttotal: 3.81s\tremaining: 19.7s\n",
      "81:\tlearn: 0.5450852\ttotal: 3.85s\tremaining: 19.6s\n",
      "82:\tlearn: 0.5448940\ttotal: 3.9s\tremaining: 19.6s\n",
      "83:\tlearn: 0.5447102\ttotal: 3.95s\tremaining: 19.5s\n",
      "84:\tlearn: 0.5445460\ttotal: 3.99s\tremaining: 19.5s\n",
      "85:\tlearn: 0.5443705\ttotal: 4.05s\tremaining: 19.5s\n",
      "86:\tlearn: 0.5442375\ttotal: 4.09s\tremaining: 19.4s\n",
      "87:\tlearn: 0.5440778\ttotal: 4.14s\tremaining: 19.4s\n",
      "88:\tlearn: 0.5438051\ttotal: 4.18s\tremaining: 19.3s\n",
      "89:\tlearn: 0.5436466\ttotal: 4.24s\tremaining: 19.3s\n",
      "90:\tlearn: 0.5434916\ttotal: 4.28s\tremaining: 19.2s\n",
      "91:\tlearn: 0.5433358\ttotal: 4.33s\tremaining: 19.2s\n",
      "92:\tlearn: 0.5432035\ttotal: 4.38s\tremaining: 19.2s\n",
      "93:\tlearn: 0.5430917\ttotal: 4.42s\tremaining: 19.1s\n",
      "94:\tlearn: 0.5429598\ttotal: 4.48s\tremaining: 19.1s\n",
      "95:\tlearn: 0.5427808\ttotal: 4.53s\tremaining: 19.1s\n",
      "96:\tlearn: 0.5426358\ttotal: 4.57s\tremaining: 19s\n",
      "97:\tlearn: 0.5424920\ttotal: 4.62s\tremaining: 18.9s\n",
      "98:\tlearn: 0.5423661\ttotal: 4.66s\tremaining: 18.9s\n",
      "99:\tlearn: 0.5422461\ttotal: 4.71s\tremaining: 18.8s\n",
      "100:\tlearn: 0.5420906\ttotal: 4.75s\tremaining: 18.8s\n",
      "101:\tlearn: 0.5419817\ttotal: 4.8s\tremaining: 18.7s\n",
      "102:\tlearn: 0.5418544\ttotal: 4.85s\tremaining: 18.7s\n",
      "103:\tlearn: 0.5416220\ttotal: 4.9s\tremaining: 18.6s\n",
      "104:\tlearn: 0.5413696\ttotal: 4.95s\tremaining: 18.6s\n",
      "105:\tlearn: 0.5412554\ttotal: 5s\tremaining: 18.6s\n",
      "106:\tlearn: 0.5411466\ttotal: 5.05s\tremaining: 18.5s\n",
      "107:\tlearn: 0.5410245\ttotal: 5.09s\tremaining: 18.5s\n",
      "108:\tlearn: 0.5408994\ttotal: 5.13s\tremaining: 18.4s\n",
      "109:\tlearn: 0.5407516\ttotal: 5.19s\tremaining: 18.4s\n",
      "110:\tlearn: 0.5406450\ttotal: 5.24s\tremaining: 18.4s\n",
      "111:\tlearn: 0.5405581\ttotal: 5.29s\tremaining: 18.3s\n",
      "112:\tlearn: 0.5404202\ttotal: 5.33s\tremaining: 18.3s\n",
      "113:\tlearn: 0.5403303\ttotal: 5.38s\tremaining: 18.2s\n",
      "114:\tlearn: 0.5402323\ttotal: 5.44s\tremaining: 18.2s\n",
      "115:\tlearn: 0.5401264\ttotal: 5.49s\tremaining: 18.2s\n",
      "116:\tlearn: 0.5400262\ttotal: 5.53s\tremaining: 18.1s\n",
      "117:\tlearn: 0.5399421\ttotal: 5.58s\tremaining: 18.1s\n",
      "118:\tlearn: 0.5398133\ttotal: 5.63s\tremaining: 18s\n",
      "119:\tlearn: 0.5397386\ttotal: 5.68s\tremaining: 18s\n",
      "120:\tlearn: 0.5395390\ttotal: 5.74s\tremaining: 18s\n",
      "121:\tlearn: 0.5394577\ttotal: 5.79s\tremaining: 17.9s\n",
      "122:\tlearn: 0.5393521\ttotal: 5.83s\tremaining: 17.9s\n",
      "123:\tlearn: 0.5392333\ttotal: 5.88s\tremaining: 17.8s\n",
      "124:\tlearn: 0.5391509\ttotal: 5.93s\tremaining: 17.8s\n",
      "125:\tlearn: 0.5390568\ttotal: 5.98s\tremaining: 17.7s\n",
      "126:\tlearn: 0.5389790\ttotal: 6.02s\tremaining: 17.7s\n",
      "127:\tlearn: 0.5388042\ttotal: 6.06s\tremaining: 17.6s\n",
      "128:\tlearn: 0.5387224\ttotal: 6.11s\tremaining: 17.6s\n",
      "129:\tlearn: 0.5386452\ttotal: 6.16s\tremaining: 17.5s\n",
      "130:\tlearn: 0.5385736\ttotal: 6.2s\tremaining: 17.5s\n",
      "131:\tlearn: 0.5384801\ttotal: 6.24s\tremaining: 17.4s\n",
      "132:\tlearn: 0.5384122\ttotal: 6.29s\tremaining: 17.3s\n",
      "133:\tlearn: 0.5383269\ttotal: 6.33s\tremaining: 17.3s\n",
      "134:\tlearn: 0.5382098\ttotal: 6.38s\tremaining: 17.3s\n",
      "135:\tlearn: 0.5381454\ttotal: 6.43s\tremaining: 17.2s\n",
      "136:\tlearn: 0.5380040\ttotal: 6.48s\tremaining: 17.2s\n",
      "137:\tlearn: 0.5379307\ttotal: 6.52s\tremaining: 17.1s\n",
      "138:\tlearn: 0.5377939\ttotal: 6.57s\tremaining: 17.1s\n",
      "139:\tlearn: 0.5377268\ttotal: 6.62s\tremaining: 17s\n",
      "140:\tlearn: 0.5376396\ttotal: 6.66s\tremaining: 17s\n",
      "141:\tlearn: 0.5375811\ttotal: 6.7s\tremaining: 16.9s\n",
      "142:\tlearn: 0.5375088\ttotal: 6.74s\tremaining: 16.8s\n",
      "143:\tlearn: 0.5374162\ttotal: 6.8s\tremaining: 16.8s\n",
      "144:\tlearn: 0.5373628\ttotal: 6.84s\tremaining: 16.8s\n",
      "145:\tlearn: 0.5372937\ttotal: 6.89s\tremaining: 16.7s\n",
      "146:\tlearn: 0.5372180\ttotal: 6.94s\tremaining: 16.7s\n",
      "147:\tlearn: 0.5371541\ttotal: 6.99s\tremaining: 16.6s\n",
      "148:\tlearn: 0.5370997\ttotal: 7.04s\tremaining: 16.6s\n",
      "149:\tlearn: 0.5370521\ttotal: 7.09s\tremaining: 16.5s\n",
      "150:\tlearn: 0.5370108\ttotal: 7.14s\tremaining: 16.5s\n",
      "151:\tlearn: 0.5369476\ttotal: 7.18s\tremaining: 16.4s\n",
      "152:\tlearn: 0.5369005\ttotal: 7.22s\tremaining: 16.4s\n",
      "153:\tlearn: 0.5368509\ttotal: 7.26s\tremaining: 16.3s\n",
      "154:\tlearn: 0.5367975\ttotal: 7.31s\tremaining: 16.3s\n",
      "155:\tlearn: 0.5367460\ttotal: 7.36s\tremaining: 16.2s\n",
      "156:\tlearn: 0.5367099\ttotal: 7.41s\tremaining: 16.2s\n",
      "157:\tlearn: 0.5366009\ttotal: 7.45s\tremaining: 16.1s\n",
      "158:\tlearn: 0.5365425\ttotal: 7.5s\tremaining: 16.1s\n",
      "159:\tlearn: 0.5364896\ttotal: 7.55s\tremaining: 16s\n",
      "160:\tlearn: 0.5364145\ttotal: 7.59s\tremaining: 16s\n",
      "161:\tlearn: 0.5363663\ttotal: 7.63s\tremaining: 15.9s\n",
      "162:\tlearn: 0.5363155\ttotal: 7.67s\tremaining: 15.9s\n",
      "163:\tlearn: 0.5359682\ttotal: 7.71s\tremaining: 15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.5358699\ttotal: 7.76s\tremaining: 15.8s\n",
      "165:\tlearn: 0.5357976\ttotal: 7.81s\tremaining: 15.7s\n",
      "166:\tlearn: 0.5357403\ttotal: 7.85s\tremaining: 15.7s\n",
      "167:\tlearn: 0.5356941\ttotal: 7.89s\tremaining: 15.6s\n",
      "168:\tlearn: 0.5356609\ttotal: 7.94s\tremaining: 15.6s\n",
      "169:\tlearn: 0.5354064\ttotal: 8s\tremaining: 15.5s\n",
      "170:\tlearn: 0.5351810\ttotal: 8.05s\tremaining: 15.5s\n",
      "171:\tlearn: 0.5351284\ttotal: 8.09s\tremaining: 15.4s\n",
      "172:\tlearn: 0.5350490\ttotal: 8.13s\tremaining: 15.4s\n",
      "173:\tlearn: 0.5349974\ttotal: 8.18s\tremaining: 15.3s\n",
      "174:\tlearn: 0.5349257\ttotal: 8.22s\tremaining: 15.3s\n",
      "175:\tlearn: 0.5348652\ttotal: 8.27s\tremaining: 15.2s\n",
      "176:\tlearn: 0.5348139\ttotal: 8.32s\tremaining: 15.2s\n",
      "177:\tlearn: 0.5347681\ttotal: 8.36s\tremaining: 15.1s\n",
      "178:\tlearn: 0.5347091\ttotal: 8.41s\tremaining: 15.1s\n",
      "179:\tlearn: 0.5346604\ttotal: 8.46s\tremaining: 15s\n",
      "180:\tlearn: 0.5346207\ttotal: 8.51s\tremaining: 15s\n",
      "181:\tlearn: 0.5345801\ttotal: 8.56s\tremaining: 15s\n",
      "182:\tlearn: 0.5345266\ttotal: 8.6s\tremaining: 14.9s\n",
      "183:\tlearn: 0.5344778\ttotal: 8.65s\tremaining: 14.9s\n",
      "184:\tlearn: 0.5344450\ttotal: 8.7s\tremaining: 14.8s\n",
      "185:\tlearn: 0.5344050\ttotal: 8.76s\tremaining: 14.8s\n",
      "186:\tlearn: 0.5343170\ttotal: 8.81s\tremaining: 14.7s\n",
      "187:\tlearn: 0.5342810\ttotal: 8.86s\tremaining: 14.7s\n",
      "188:\tlearn: 0.5342142\ttotal: 8.91s\tremaining: 14.7s\n",
      "189:\tlearn: 0.5341736\ttotal: 8.96s\tremaining: 14.6s\n",
      "190:\tlearn: 0.5341375\ttotal: 9s\tremaining: 14.6s\n",
      "191:\tlearn: 0.5340945\ttotal: 9.05s\tremaining: 14.5s\n",
      "192:\tlearn: 0.5339130\ttotal: 9.1s\tremaining: 14.5s\n",
      "193:\tlearn: 0.5338675\ttotal: 9.15s\tremaining: 14.4s\n",
      "194:\tlearn: 0.5338298\ttotal: 9.2s\tremaining: 14.4s\n",
      "195:\tlearn: 0.5337921\ttotal: 9.24s\tremaining: 14.3s\n",
      "196:\tlearn: 0.5337527\ttotal: 9.28s\tremaining: 14.3s\n",
      "197:\tlearn: 0.5337231\ttotal: 9.32s\tremaining: 14.2s\n",
      "198:\tlearn: 0.5336951\ttotal: 9.37s\tremaining: 14.2s\n",
      "199:\tlearn: 0.5336650\ttotal: 9.42s\tremaining: 14.1s\n",
      "200:\tlearn: 0.5336287\ttotal: 9.46s\tremaining: 14.1s\n",
      "201:\tlearn: 0.5335838\ttotal: 9.5s\tremaining: 14s\n",
      "202:\tlearn: 0.5335591\ttotal: 9.55s\tremaining: 14s\n",
      "203:\tlearn: 0.5335259\ttotal: 9.6s\tremaining: 13.9s\n",
      "204:\tlearn: 0.5333954\ttotal: 9.65s\tremaining: 13.9s\n",
      "205:\tlearn: 0.5333610\ttotal: 9.69s\tremaining: 13.8s\n",
      "206:\tlearn: 0.5332157\ttotal: 9.74s\tremaining: 13.8s\n",
      "207:\tlearn: 0.5331817\ttotal: 9.79s\tremaining: 13.7s\n",
      "208:\tlearn: 0.5331439\ttotal: 9.84s\tremaining: 13.7s\n",
      "209:\tlearn: 0.5330866\ttotal: 9.89s\tremaining: 13.7s\n",
      "210:\tlearn: 0.5328649\ttotal: 9.93s\tremaining: 13.6s\n",
      "211:\tlearn: 0.5328024\ttotal: 9.97s\tremaining: 13.5s\n",
      "212:\tlearn: 0.5327825\ttotal: 10s\tremaining: 13.5s\n",
      "213:\tlearn: 0.5326833\ttotal: 10.1s\tremaining: 13.4s\n",
      "214:\tlearn: 0.5326550\ttotal: 10.1s\tremaining: 13.4s\n",
      "215:\tlearn: 0.5326315\ttotal: 10.1s\tremaining: 13.3s\n",
      "216:\tlearn: 0.5325978\ttotal: 10.2s\tremaining: 13.3s\n",
      "217:\tlearn: 0.5325715\ttotal: 10.2s\tremaining: 13.2s\n",
      "218:\tlearn: 0.5325463\ttotal: 10.3s\tremaining: 13.2s\n",
      "219:\tlearn: 0.5325135\ttotal: 10.3s\tremaining: 13.2s\n",
      "220:\tlearn: 0.5324861\ttotal: 10.4s\tremaining: 13.1s\n",
      "221:\tlearn: 0.5324545\ttotal: 10.5s\tremaining: 13.1s\n",
      "222:\tlearn: 0.5324205\ttotal: 10.5s\tremaining: 13s\n",
      "223:\tlearn: 0.5323964\ttotal: 10.5s\tremaining: 13s\n",
      "224:\tlearn: 0.5323744\ttotal: 10.6s\tremaining: 12.9s\n",
      "225:\tlearn: 0.5323501\ttotal: 10.6s\tremaining: 12.9s\n",
      "226:\tlearn: 0.5323268\ttotal: 10.7s\tremaining: 12.9s\n",
      "227:\tlearn: 0.5322959\ttotal: 10.7s\tremaining: 12.8s\n",
      "228:\tlearn: 0.5322718\ttotal: 10.8s\tremaining: 12.8s\n",
      "229:\tlearn: 0.5322468\ttotal: 10.8s\tremaining: 12.7s\n",
      "230:\tlearn: 0.5322233\ttotal: 10.9s\tremaining: 12.7s\n",
      "231:\tlearn: 0.5321975\ttotal: 10.9s\tremaining: 12.6s\n",
      "232:\tlearn: 0.5321650\ttotal: 11s\tremaining: 12.6s\n",
      "233:\tlearn: 0.5321382\ttotal: 11s\tremaining: 12.5s\n",
      "234:\tlearn: 0.5321161\ttotal: 11s\tremaining: 12.5s\n",
      "235:\tlearn: 0.5320969\ttotal: 11.1s\tremaining: 12.4s\n",
      "236:\tlearn: 0.5320723\ttotal: 11.1s\tremaining: 12.4s\n",
      "237:\tlearn: 0.5320477\ttotal: 11.2s\tremaining: 12.3s\n",
      "238:\tlearn: 0.5319821\ttotal: 11.2s\tremaining: 12.3s\n",
      "239:\tlearn: 0.5319532\ttotal: 11.3s\tremaining: 12.2s\n",
      "240:\tlearn: 0.5319269\ttotal: 11.3s\tremaining: 12.2s\n",
      "241:\tlearn: 0.5318929\ttotal: 11.4s\tremaining: 12.1s\n",
      "242:\tlearn: 0.5318738\ttotal: 11.4s\tremaining: 12.1s\n",
      "243:\tlearn: 0.5318485\ttotal: 11.5s\tremaining: 12s\n",
      "244:\tlearn: 0.5318269\ttotal: 11.5s\tremaining: 12s\n",
      "245:\tlearn: 0.5318083\ttotal: 11.6s\tremaining: 11.9s\n",
      "246:\tlearn: 0.5317889\ttotal: 11.6s\tremaining: 11.9s\n",
      "247:\tlearn: 0.5317727\ttotal: 11.7s\tremaining: 11.9s\n",
      "248:\tlearn: 0.5317511\ttotal: 11.7s\tremaining: 11.8s\n",
      "249:\tlearn: 0.5317352\ttotal: 11.8s\tremaining: 11.8s\n",
      "250:\tlearn: 0.5315636\ttotal: 11.8s\tremaining: 11.7s\n",
      "251:\tlearn: 0.5313578\ttotal: 11.9s\tremaining: 11.7s\n",
      "252:\tlearn: 0.5312502\ttotal: 11.9s\tremaining: 11.6s\n",
      "253:\tlearn: 0.5312145\ttotal: 12s\tremaining: 11.6s\n",
      "254:\tlearn: 0.5311961\ttotal: 12s\tremaining: 11.5s\n",
      "255:\tlearn: 0.5311695\ttotal: 12s\tremaining: 11.5s\n",
      "256:\tlearn: 0.5311481\ttotal: 12.1s\tremaining: 11.4s\n",
      "257:\tlearn: 0.5311288\ttotal: 12.1s\tremaining: 11.4s\n",
      "258:\tlearn: 0.5311147\ttotal: 12.2s\tremaining: 11.3s\n",
      "259:\tlearn: 0.5310943\ttotal: 12.2s\tremaining: 11.3s\n",
      "260:\tlearn: 0.5310744\ttotal: 12.3s\tremaining: 11.2s\n",
      "261:\tlearn: 0.5309806\ttotal: 12.3s\tremaining: 11.2s\n",
      "262:\tlearn: 0.5309649\ttotal: 12.4s\tremaining: 11.2s\n",
      "263:\tlearn: 0.5309298\ttotal: 12.4s\tremaining: 11.1s\n",
      "264:\tlearn: 0.5309165\ttotal: 12.5s\tremaining: 11.1s\n",
      "265:\tlearn: 0.5309008\ttotal: 12.5s\tremaining: 11s\n",
      "266:\tlearn: 0.5308790\ttotal: 12.6s\tremaining: 11s\n",
      "267:\tlearn: 0.5308608\ttotal: 12.6s\tremaining: 10.9s\n",
      "268:\tlearn: 0.5307069\ttotal: 12.7s\tremaining: 10.9s\n",
      "269:\tlearn: 0.5306834\ttotal: 12.7s\tremaining: 10.8s\n",
      "270:\tlearn: 0.5306601\ttotal: 12.8s\tremaining: 10.8s\n",
      "271:\tlearn: 0.5306152\ttotal: 12.8s\tremaining: 10.7s\n",
      "272:\tlearn: 0.5304772\ttotal: 12.9s\tremaining: 10.7s\n",
      "273:\tlearn: 0.5302510\ttotal: 12.9s\tremaining: 10.6s\n",
      "274:\tlearn: 0.5302307\ttotal: 13s\tremaining: 10.6s\n",
      "275:\tlearn: 0.5301816\ttotal: 13s\tremaining: 10.6s\n",
      "276:\tlearn: 0.5301622\ttotal: 13.1s\tremaining: 10.5s\n",
      "277:\tlearn: 0.5301446\ttotal: 13.1s\tremaining: 10.5s\n",
      "278:\tlearn: 0.5301256\ttotal: 13.1s\tremaining: 10.4s\n",
      "279:\tlearn: 0.5301073\ttotal: 13.2s\tremaining: 10.4s\n",
      "280:\tlearn: 0.5300893\ttotal: 13.2s\tremaining: 10.3s\n",
      "281:\tlearn: 0.5300767\ttotal: 13.3s\tremaining: 10.3s\n",
      "282:\tlearn: 0.5300599\ttotal: 13.3s\tremaining: 10.2s\n",
      "283:\tlearn: 0.5300339\ttotal: 13.4s\tremaining: 10.2s\n",
      "284:\tlearn: 0.5300197\ttotal: 13.4s\tremaining: 10.1s\n",
      "285:\tlearn: 0.5299979\ttotal: 13.5s\tremaining: 10.1s\n",
      "286:\tlearn: 0.5299765\ttotal: 13.5s\tremaining: 10s\n",
      "287:\tlearn: 0.5299637\ttotal: 13.5s\tremaining: 9.97s\n",
      "288:\tlearn: 0.5298857\ttotal: 13.6s\tremaining: 9.93s\n",
      "289:\tlearn: 0.5298654\ttotal: 13.6s\tremaining: 9.88s\n",
      "290:\tlearn: 0.5298517\ttotal: 13.7s\tremaining: 9.83s\n",
      "291:\tlearn: 0.5298409\ttotal: 13.7s\tremaining: 9.78s\n",
      "292:\tlearn: 0.5297924\ttotal: 13.8s\tremaining: 9.73s\n",
      "293:\tlearn: 0.5297706\ttotal: 13.8s\tremaining: 9.7s\n",
      "294:\tlearn: 0.5297555\ttotal: 13.9s\tremaining: 9.65s\n",
      "295:\tlearn: 0.5297308\ttotal: 13.9s\tremaining: 9.6s\n",
      "296:\tlearn: 0.5297044\ttotal: 14s\tremaining: 9.55s\n",
      "297:\tlearn: 0.5295773\ttotal: 14s\tremaining: 9.51s\n",
      "298:\tlearn: 0.5295597\ttotal: 14.1s\tremaining: 9.46s\n",
      "299:\tlearn: 0.5294471\ttotal: 14.1s\tremaining: 9.41s\n",
      "300:\tlearn: 0.5294326\ttotal: 14.2s\tremaining: 9.37s\n",
      "301:\tlearn: 0.5294158\ttotal: 14.2s\tremaining: 9.32s\n",
      "302:\tlearn: 0.5294000\ttotal: 14.3s\tremaining: 9.28s\n",
      "303:\tlearn: 0.5292410\ttotal: 14.3s\tremaining: 9.23s\n",
      "304:\tlearn: 0.5292256\ttotal: 14.4s\tremaining: 9.18s\n",
      "305:\tlearn: 0.5292152\ttotal: 14.4s\tremaining: 9.14s\n",
      "306:\tlearn: 0.5292002\ttotal: 14.5s\tremaining: 9.09s\n",
      "307:\tlearn: 0.5291796\ttotal: 14.5s\tremaining: 9.04s\n",
      "308:\tlearn: 0.5290847\ttotal: 14.6s\tremaining: 9s\n",
      "309:\tlearn: 0.5290499\ttotal: 14.6s\tremaining: 8.95s\n",
      "310:\tlearn: 0.5290300\ttotal: 14.7s\tremaining: 8.9s\n",
      "311:\tlearn: 0.5290168\ttotal: 14.7s\tremaining: 8.85s\n",
      "312:\tlearn: 0.5290033\ttotal: 14.7s\tremaining: 8.81s\n",
      "313:\tlearn: 0.5289196\ttotal: 14.8s\tremaining: 8.76s\n",
      "314:\tlearn: 0.5289027\ttotal: 14.8s\tremaining: 8.71s\n",
      "315:\tlearn: 0.5288451\ttotal: 14.9s\tremaining: 8.66s\n",
      "316:\tlearn: 0.5288305\ttotal: 14.9s\tremaining: 8.62s\n",
      "317:\tlearn: 0.5288111\ttotal: 15s\tremaining: 8.56s\n",
      "318:\tlearn: 0.5287614\ttotal: 15s\tremaining: 8.52s\n",
      "319:\tlearn: 0.5287441\ttotal: 15.1s\tremaining: 8.48s\n",
      "320:\tlearn: 0.5287284\ttotal: 15.1s\tremaining: 8.43s\n",
      "321:\tlearn: 0.5287102\ttotal: 15.2s\tremaining: 8.38s\n",
      "322:\tlearn: 0.5286972\ttotal: 15.2s\tremaining: 8.33s\n",
      "323:\tlearn: 0.5286850\ttotal: 15.2s\tremaining: 8.28s\n",
      "324:\tlearn: 0.5286746\ttotal: 15.3s\tremaining: 8.23s\n",
      "325:\tlearn: 0.5286618\ttotal: 15.3s\tremaining: 8.19s\n",
      "326:\tlearn: 0.5286357\ttotal: 15.4s\tremaining: 8.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327:\tlearn: 0.5286199\ttotal: 15.4s\tremaining: 8.09s\n",
      "328:\tlearn: 0.5285976\ttotal: 15.5s\tremaining: 8.04s\n",
      "329:\tlearn: 0.5285867\ttotal: 15.5s\tremaining: 7.99s\n",
      "330:\tlearn: 0.5285760\ttotal: 15.6s\tremaining: 7.94s\n",
      "331:\tlearn: 0.5285694\ttotal: 15.6s\tremaining: 7.9s\n",
      "332:\tlearn: 0.5285575\ttotal: 15.6s\tremaining: 7.85s\n",
      "333:\tlearn: 0.5285478\ttotal: 15.7s\tremaining: 7.8s\n",
      "334:\tlearn: 0.5284134\ttotal: 15.7s\tremaining: 7.75s\n",
      "335:\tlearn: 0.5284023\ttotal: 15.8s\tremaining: 7.7s\n",
      "336:\tlearn: 0.5283923\ttotal: 15.8s\tremaining: 7.65s\n",
      "337:\tlearn: 0.5283836\ttotal: 15.9s\tremaining: 7.61s\n",
      "338:\tlearn: 0.5283711\ttotal: 15.9s\tremaining: 7.56s\n",
      "339:\tlearn: 0.5283582\ttotal: 16s\tremaining: 7.51s\n",
      "340:\tlearn: 0.5283447\ttotal: 16s\tremaining: 7.46s\n",
      "341:\tlearn: 0.5283355\ttotal: 16s\tremaining: 7.41s\n",
      "342:\tlearn: 0.5283230\ttotal: 16.1s\tremaining: 7.37s\n",
      "343:\tlearn: 0.5282516\ttotal: 16.1s\tremaining: 7.32s\n",
      "344:\tlearn: 0.5282373\ttotal: 16.2s\tremaining: 7.27s\n",
      "345:\tlearn: 0.5282251\ttotal: 16.2s\tremaining: 7.23s\n",
      "346:\tlearn: 0.5282167\ttotal: 16.3s\tremaining: 7.18s\n",
      "347:\tlearn: 0.5282036\ttotal: 16.3s\tremaining: 7.13s\n",
      "348:\tlearn: 0.5281659\ttotal: 16.4s\tremaining: 7.09s\n",
      "349:\tlearn: 0.5281523\ttotal: 16.4s\tremaining: 7.04s\n",
      "350:\tlearn: 0.5280040\ttotal: 16.5s\tremaining: 7s\n",
      "351:\tlearn: 0.5279938\ttotal: 16.5s\tremaining: 6.95s\n",
      "352:\tlearn: 0.5279825\ttotal: 16.6s\tremaining: 6.91s\n",
      "353:\tlearn: 0.5279686\ttotal: 16.6s\tremaining: 6.86s\n",
      "354:\tlearn: 0.5279547\ttotal: 16.7s\tremaining: 6.81s\n",
      "355:\tlearn: 0.5279444\ttotal: 16.7s\tremaining: 6.76s\n",
      "356:\tlearn: 0.5279075\ttotal: 16.8s\tremaining: 6.71s\n",
      "357:\tlearn: 0.5278822\ttotal: 16.8s\tremaining: 6.67s\n",
      "358:\tlearn: 0.5278685\ttotal: 16.9s\tremaining: 6.62s\n",
      "359:\tlearn: 0.5278436\ttotal: 16.9s\tremaining: 6.58s\n",
      "360:\tlearn: 0.5278303\ttotal: 17s\tremaining: 6.53s\n",
      "361:\tlearn: 0.5278204\ttotal: 17s\tremaining: 6.48s\n",
      "362:\tlearn: 0.5278079\ttotal: 17.1s\tremaining: 6.44s\n",
      "363:\tlearn: 0.5278006\ttotal: 17.1s\tremaining: 6.39s\n",
      "364:\tlearn: 0.5277911\ttotal: 17.2s\tremaining: 6.34s\n",
      "365:\tlearn: 0.5277654\ttotal: 17.2s\tremaining: 6.3s\n",
      "366:\tlearn: 0.5277552\ttotal: 17.2s\tremaining: 6.25s\n",
      "367:\tlearn: 0.5276523\ttotal: 17.3s\tremaining: 6.2s\n",
      "368:\tlearn: 0.5276425\ttotal: 17.3s\tremaining: 6.15s\n",
      "369:\tlearn: 0.5276312\ttotal: 17.4s\tremaining: 6.11s\n",
      "370:\tlearn: 0.5276168\ttotal: 17.4s\tremaining: 6.06s\n",
      "371:\tlearn: 0.5276069\ttotal: 17.5s\tremaining: 6.02s\n",
      "372:\tlearn: 0.5275967\ttotal: 17.5s\tremaining: 5.97s\n",
      "373:\tlearn: 0.5275527\ttotal: 17.6s\tremaining: 5.92s\n",
      "374:\tlearn: 0.5275385\ttotal: 17.6s\tremaining: 5.88s\n",
      "375:\tlearn: 0.5275246\ttotal: 17.7s\tremaining: 5.83s\n",
      "376:\tlearn: 0.5275194\ttotal: 17.7s\tremaining: 5.78s\n",
      "377:\tlearn: 0.5275061\ttotal: 17.8s\tremaining: 5.74s\n",
      "378:\tlearn: 0.5274204\ttotal: 17.8s\tremaining: 5.69s\n",
      "379:\tlearn: 0.5274068\ttotal: 17.9s\tremaining: 5.64s\n",
      "380:\tlearn: 0.5273947\ttotal: 17.9s\tremaining: 5.59s\n",
      "381:\tlearn: 0.5273831\ttotal: 18s\tremaining: 5.54s\n",
      "382:\tlearn: 0.5273694\ttotal: 18s\tremaining: 5.5s\n",
      "383:\tlearn: 0.5273023\ttotal: 18.1s\tremaining: 5.45s\n",
      "384:\tlearn: 0.5272912\ttotal: 18.1s\tremaining: 5.41s\n",
      "385:\tlearn: 0.5272790\ttotal: 18.2s\tremaining: 5.36s\n",
      "386:\tlearn: 0.5272666\ttotal: 18.2s\tremaining: 5.31s\n",
      "387:\tlearn: 0.5272477\ttotal: 18.2s\tremaining: 5.27s\n",
      "388:\tlearn: 0.5272363\ttotal: 18.3s\tremaining: 5.22s\n",
      "389:\tlearn: 0.5272004\ttotal: 18.3s\tremaining: 5.17s\n",
      "390:\tlearn: 0.5271943\ttotal: 18.4s\tremaining: 5.12s\n",
      "391:\tlearn: 0.5271850\ttotal: 18.4s\tremaining: 5.08s\n",
      "392:\tlearn: 0.5271713\ttotal: 18.5s\tremaining: 5.03s\n",
      "393:\tlearn: 0.5271615\ttotal: 18.5s\tremaining: 4.99s\n",
      "394:\tlearn: 0.5271471\ttotal: 18.6s\tremaining: 4.94s\n",
      "395:\tlearn: 0.5271305\ttotal: 18.6s\tremaining: 4.89s\n",
      "396:\tlearn: 0.5271219\ttotal: 18.7s\tremaining: 4.85s\n",
      "397:\tlearn: 0.5271147\ttotal: 18.7s\tremaining: 4.8s\n",
      "398:\tlearn: 0.5271048\ttotal: 18.8s\tremaining: 4.75s\n",
      "399:\tlearn: 0.5270890\ttotal: 18.8s\tremaining: 4.71s\n",
      "400:\tlearn: 0.5270795\ttotal: 18.9s\tremaining: 4.66s\n",
      "401:\tlearn: 0.5270394\ttotal: 18.9s\tremaining: 4.62s\n",
      "402:\tlearn: 0.5270307\ttotal: 19s\tremaining: 4.57s\n",
      "403:\tlearn: 0.5268411\ttotal: 19s\tremaining: 4.53s\n",
      "404:\tlearn: 0.5268300\ttotal: 19.1s\tremaining: 4.48s\n",
      "405:\tlearn: 0.5268253\ttotal: 19.1s\tremaining: 4.43s\n",
      "406:\tlearn: 0.5268184\ttotal: 19.2s\tremaining: 4.39s\n",
      "407:\tlearn: 0.5267483\ttotal: 19.2s\tremaining: 4.34s\n",
      "408:\tlearn: 0.5267389\ttotal: 19.3s\tremaining: 4.29s\n",
      "409:\tlearn: 0.5267325\ttotal: 19.3s\tremaining: 4.24s\n",
      "410:\tlearn: 0.5267175\ttotal: 19.4s\tremaining: 4.2s\n",
      "411:\tlearn: 0.5267051\ttotal: 19.4s\tremaining: 4.15s\n",
      "412:\tlearn: 0.5266996\ttotal: 19.5s\tremaining: 4.1s\n",
      "413:\tlearn: 0.5266852\ttotal: 19.5s\tremaining: 4.05s\n",
      "414:\tlearn: 0.5266760\ttotal: 19.6s\tremaining: 4.01s\n",
      "415:\tlearn: 0.5266663\ttotal: 19.6s\tremaining: 3.96s\n",
      "416:\tlearn: 0.5266509\ttotal: 19.6s\tremaining: 3.91s\n",
      "417:\tlearn: 0.5266401\ttotal: 19.7s\tremaining: 3.86s\n",
      "418:\tlearn: 0.5266316\ttotal: 19.7s\tremaining: 3.81s\n",
      "419:\tlearn: 0.5265729\ttotal: 19.8s\tremaining: 3.77s\n",
      "420:\tlearn: 0.5265565\ttotal: 19.8s\tremaining: 3.72s\n",
      "421:\tlearn: 0.5265474\ttotal: 19.9s\tremaining: 3.67s\n",
      "422:\tlearn: 0.5265353\ttotal: 19.9s\tremaining: 3.63s\n",
      "423:\tlearn: 0.5265115\ttotal: 20s\tremaining: 3.58s\n",
      "424:\tlearn: 0.5265016\ttotal: 20s\tremaining: 3.53s\n",
      "425:\tlearn: 0.5264952\ttotal: 20.1s\tremaining: 3.48s\n",
      "426:\tlearn: 0.5264476\ttotal: 20.1s\tremaining: 3.44s\n",
      "427:\tlearn: 0.5264359\ttotal: 20.2s\tremaining: 3.39s\n",
      "428:\tlearn: 0.5264074\ttotal: 20.2s\tremaining: 3.35s\n",
      "429:\tlearn: 0.5263991\ttotal: 20.3s\tremaining: 3.3s\n",
      "430:\tlearn: 0.5263894\ttotal: 20.3s\tremaining: 3.25s\n",
      "431:\tlearn: 0.5263822\ttotal: 20.4s\tremaining: 3.2s\n",
      "432:\tlearn: 0.5263735\ttotal: 20.4s\tremaining: 3.16s\n",
      "433:\tlearn: 0.5263647\ttotal: 20.5s\tremaining: 3.11s\n",
      "434:\tlearn: 0.5263539\ttotal: 20.5s\tremaining: 3.06s\n",
      "435:\tlearn: 0.5263489\ttotal: 20.6s\tremaining: 3.02s\n",
      "436:\tlearn: 0.5262533\ttotal: 20.6s\tremaining: 2.97s\n",
      "437:\tlearn: 0.5262383\ttotal: 20.6s\tremaining: 2.92s\n",
      "438:\tlearn: 0.5262320\ttotal: 20.7s\tremaining: 2.88s\n",
      "439:\tlearn: 0.5261684\ttotal: 20.7s\tremaining: 2.83s\n",
      "440:\tlearn: 0.5261615\ttotal: 20.8s\tremaining: 2.78s\n",
      "441:\tlearn: 0.5261041\ttotal: 20.8s\tremaining: 2.73s\n",
      "442:\tlearn: 0.5260964\ttotal: 20.9s\tremaining: 2.69s\n",
      "443:\tlearn: 0.5260861\ttotal: 20.9s\tremaining: 2.64s\n",
      "444:\tlearn: 0.5259995\ttotal: 21s\tremaining: 2.59s\n",
      "445:\tlearn: 0.5259825\ttotal: 21s\tremaining: 2.55s\n",
      "446:\tlearn: 0.5258104\ttotal: 21.1s\tremaining: 2.5s\n",
      "447:\tlearn: 0.5258021\ttotal: 21.1s\tremaining: 2.45s\n",
      "448:\tlearn: 0.5257944\ttotal: 21.2s\tremaining: 2.4s\n",
      "449:\tlearn: 0.5257867\ttotal: 21.2s\tremaining: 2.36s\n",
      "450:\tlearn: 0.5257762\ttotal: 21.3s\tremaining: 2.31s\n",
      "451:\tlearn: 0.5257627\ttotal: 21.3s\tremaining: 2.26s\n",
      "452:\tlearn: 0.5257511\ttotal: 21.3s\tremaining: 2.21s\n",
      "453:\tlearn: 0.5257403\ttotal: 21.4s\tremaining: 2.17s\n",
      "454:\tlearn: 0.5257313\ttotal: 21.4s\tremaining: 2.12s\n",
      "455:\tlearn: 0.5257228\ttotal: 21.5s\tremaining: 2.07s\n",
      "456:\tlearn: 0.5256847\ttotal: 21.5s\tremaining: 2.02s\n",
      "457:\tlearn: 0.5256746\ttotal: 21.6s\tremaining: 1.98s\n",
      "458:\tlearn: 0.5256684\ttotal: 21.6s\tremaining: 1.93s\n",
      "459:\tlearn: 0.5256580\ttotal: 21.7s\tremaining: 1.88s\n",
      "460:\tlearn: 0.5256505\ttotal: 21.7s\tremaining: 1.84s\n",
      "461:\tlearn: 0.5256463\ttotal: 21.8s\tremaining: 1.79s\n",
      "462:\tlearn: 0.5256393\ttotal: 21.8s\tremaining: 1.74s\n",
      "463:\tlearn: 0.5256257\ttotal: 21.8s\tremaining: 1.7s\n",
      "464:\tlearn: 0.5256195\ttotal: 21.9s\tremaining: 1.65s\n",
      "465:\tlearn: 0.5255862\ttotal: 21.9s\tremaining: 1.6s\n",
      "466:\tlearn: 0.5255799\ttotal: 22s\tremaining: 1.55s\n",
      "467:\tlearn: 0.5255725\ttotal: 22s\tremaining: 1.51s\n",
      "468:\tlearn: 0.5255660\ttotal: 22.1s\tremaining: 1.46s\n",
      "469:\tlearn: 0.5255494\ttotal: 22.1s\tremaining: 1.41s\n",
      "470:\tlearn: 0.5254365\ttotal: 22.2s\tremaining: 1.36s\n",
      "471:\tlearn: 0.5254240\ttotal: 22.2s\tremaining: 1.32s\n",
      "472:\tlearn: 0.5254087\ttotal: 22.3s\tremaining: 1.27s\n",
      "473:\tlearn: 0.5254035\ttotal: 22.3s\tremaining: 1.22s\n",
      "474:\tlearn: 0.5253964\ttotal: 22.4s\tremaining: 1.18s\n",
      "475:\tlearn: 0.5253084\ttotal: 22.4s\tremaining: 1.13s\n",
      "476:\tlearn: 0.5252997\ttotal: 22.5s\tremaining: 1.08s\n",
      "477:\tlearn: 0.5252940\ttotal: 22.5s\tremaining: 1.04s\n",
      "478:\tlearn: 0.5252859\ttotal: 22.6s\tremaining: 989ms\n",
      "479:\tlearn: 0.5252775\ttotal: 22.6s\tremaining: 942ms\n",
      "480:\tlearn: 0.5252664\ttotal: 22.7s\tremaining: 895ms\n",
      "481:\tlearn: 0.5252589\ttotal: 22.7s\tremaining: 848ms\n",
      "482:\tlearn: 0.5252506\ttotal: 22.8s\tremaining: 801ms\n",
      "483:\tlearn: 0.5252442\ttotal: 22.8s\tremaining: 754ms\n",
      "484:\tlearn: 0.5252362\ttotal: 22.8s\tremaining: 707ms\n",
      "485:\tlearn: 0.5251964\ttotal: 22.9s\tremaining: 660ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486:\tlearn: 0.5251917\ttotal: 22.9s\tremaining: 613ms\n",
      "487:\tlearn: 0.5251866\ttotal: 23s\tremaining: 565ms\n",
      "488:\tlearn: 0.5251775\ttotal: 23s\tremaining: 518ms\n",
      "489:\tlearn: 0.5251654\ttotal: 23.1s\tremaining: 471ms\n",
      "490:\tlearn: 0.5251470\ttotal: 23.1s\tremaining: 424ms\n",
      "491:\tlearn: 0.5251407\ttotal: 23.2s\tremaining: 377ms\n",
      "492:\tlearn: 0.5251336\ttotal: 23.2s\tremaining: 330ms\n",
      "493:\tlearn: 0.5251271\ttotal: 23.3s\tremaining: 283ms\n",
      "494:\tlearn: 0.5251195\ttotal: 23.3s\tremaining: 236ms\n",
      "495:\tlearn: 0.5251117\ttotal: 23.4s\tremaining: 189ms\n",
      "496:\tlearn: 0.5251039\ttotal: 23.4s\tremaining: 141ms\n",
      "497:\tlearn: 0.5250994\ttotal: 23.5s\tremaining: 94.3ms\n",
      "498:\tlearn: 0.5250928\ttotal: 23.5s\tremaining: 47.2ms\n",
      "499:\tlearn: 0.5250842\ttotal: 23.6s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0175\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x46\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0123\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x92\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x26\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x94\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0065\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0063\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x53\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x52\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0055\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x50\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x67\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x93\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0031\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x47\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0029\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x73\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x48\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x72\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x71\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x54\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x57\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.64%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 75 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"PermutationImportance(cv='prefit',\\n                      estimator=VotingClassifier(estimators=[('xgb',\\n                                                              XGBClassifier(base_score=0.5,\\n                                                                            booster='gbtree',\\n                                                                            colsample_bylevel=1,\\n                                                                            colsample_bynode=1,\\n                                                                            colsample_bytree=1.0,\\n                                                                            gamma=0.5,\\n                                                                            learning_rate=0.1,\\n                                                                            max_delta_step=0,\\n                                                                            max_depth=4,\\n                                                                            min_child_weight=1,\\n                                                                            missing=None,\\n                                                                            n_estimators=800,\\n                                                                            n_jobs=1,\\n                                                                            nthread=None,\\n                                                                            objective='binary:logistic',\\n                                                                            random_s...\\n                                                                             n_jobs=-1,\\n                                                                             num_leaves=46,\\n                                                                             objective=None,\\n                                                                             random_state=None,\\n                                                                             reg_alpha=10,\\n                                                                             reg_lambda=0.1,\\n                                                                             silent=True,\\n                                                                             subsample=0.9250788935312149,\\n                                                                             subsample_for_bin=200000,\\n                                                                             subsample_freq=0)),\\n                                                             ('cat',\\n                                                              <catboost.core.CatBoostClassifier object at 0x7fc833d02eb8>)],\\n                                                 flatten_transform=True,\\n                                                 n_jobs=None, voting='soft',\\n                                                 weights=None),\\n                      n_iter=5, random_state=None, refit=True, scoring=None)\", description=\"\\nFeature importances, computed as a decrease in score when feature\\nvalues are permuted (i.e. become noise). This is also known as \\npermutation importance.\\n\\nIf feature importances are computed on the same data as used for training, \\nthey don't reflect importance of features for generalization. Use a held-out\\ndataset if you want generalization feature importances.\\n\", error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='x46', weight=0.017466000000000027, std=0.0002887474867615668, value=None), FeatureWeight(feature='x92', weight=0.01229866666666668, std=0.00035047016040361777, value=None), FeatureWeight(feature='x26', weight=0.009097333333333379, std=0.0002478027889718538, value=None), FeatureWeight(feature='x94', weight=0.007966666666666677, std=5.707694611468037e-05, value=None), FeatureWeight(feature='x5', weight=0.007958000000000043, std=0.0001625436693459389, value=None), FeatureWeight(feature='x22', weight=0.0064580000000000306, std=0.00012886858077560312, value=None), FeatureWeight(feature='x53', weight=0.006309333333333366, std=0.00013511147660767622, value=None), FeatureWeight(feature='x52', weight=0.006162000000000045, std=0.000124661318958392, value=None), FeatureWeight(feature='x1', weight=0.00564733333333336, std=0.00028580024103871515, value=None), FeatureWeight(feature='x50', weight=0.005530000000000012, std=0.00017684896255153635, value=None), FeatureWeight(feature='x67', weight=0.004524666666666688, std=0.00010851727972998103, value=None), FeatureWeight(feature='x93', weight=0.0038046666666667005, std=0.0003061052832677873, value=None), FeatureWeight(feature='x7', weight=0.003170666666666677, std=0.0001360947382442705, value=None), FeatureWeight(feature='x47', weight=0.0031440000000000578, std=0.0001391625747901476, value=None), FeatureWeight(feature='x73', weight=0.0029080000000000217, std=0.00012041779122886396, value=None), FeatureWeight(feature='x48', weight=0.0026086666666667035, std=0.00017361003555219984, value=None), FeatureWeight(feature='x72', weight=0.0021606666666666775, std=6.621178142896888e-05, value=None), FeatureWeight(feature='x71', weight=0.002022666666666706, std=0.00011572764963002315, value=None), FeatureWeight(feature='x54', weight=0.002018666666666724, std=7.338180216436994e-05, value=None), FeatureWeight(feature='x57', weight=0.0019846666666667235, std=4.9602867300612984e-05, value=None)], remaining=75), decision_tree=None, highlight_spaces=None, transition_features=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5.sklearn.explain_weights import explain_permutation_importance\n",
    "from eli5.sklearn import PermutationImportance\n",
    "ensemble.fit(enc_train, train.target)\n",
    "perms = PermutationImportance(ensemble).fit(enc_train, train.target,refit=False)\n",
    "explain_permutation_importance(perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( perms.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(ensemble, enc_train.astype('int64'), train.target.astype('int64'), cv = 10, scoring='roc_auc', n_jobs = 10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble.predict(enc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('input/sample_submission.csv')\n",
    "sub['target'] = pred\n",
    "sub.to_csv('onehot_cluster.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
